{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, alpha=0.1):\n",
    "    # initialize the list of weights matrices, then store the\n",
    "    # network architecture and learning rate\n",
    "        self.W = []\n",
    "        self.layers = layers\n",
    "        self.alpha = alpha\n",
    "    \n",
    "        #looping from the index of the first layer but stop before last 2 layers\n",
    "        for i in np.arange(0, len(layers) - 2):\n",
    "            # initialize a weight matrix connecting the number of nodes in each \n",
    "            # layer together, add an extra node for the bias\n",
    "            w = np.random.randn(layers[i]+1, layers[i+1]+1)\n",
    "            self.W.append(w / np.sqrt(layers[i]))\n",
    "            #print(\"w.shape:{}\".format(w.shape))\n",
    "            #print(\"W.shape:{}\".format(np.array(self.W)))\n",
    "\n",
    "        # the last two layers are a special case where the input \n",
    "        # connections need a bias term but the output does not\n",
    "        w = np.random.randn(layers[-2] + 1, layers[-1])\n",
    "        self.W.append(w / np.sqrt(layers[-2]))\n",
    "        #print(\"W.shape:{}\".format(np.array(self.W)))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # construct and return a string that represents the network architecture\n",
    "        return \"NeuralNetwork: {}\".format(\"_\".join(str(l) for l in self.layers))\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_deriv(self, x):\n",
    "        # compute the derivative of the sigmoid function ASSUMING that 'x'\n",
    "        # has already been passed through the sigmoid function\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def fit(self, X, y, epochs=1000, displayUpdate=100):\n",
    "        # add bias\n",
    "        X = np.c_[X, np.ones((X.shape[0]))]\n",
    "        #loop over the desired number of epochs\n",
    "        for epoch in np.arange(0, epochs):\n",
    "            # loop over each individual data point and train\n",
    "            for (x, target) in zip(X,y):\n",
    "                self.fit_partial(x, target)\n",
    "            \n",
    "            #check to see if we should display a training update\n",
    "            if epoch == 0 or (epoch + 1) % displayUpdate == 0:\n",
    "                loss = self.calculate_loss(X,y)\n",
    "                print(\"[INFO] epoch={}, loss={:.7f}\".format(epoch + 1, loss))\n",
    "                \n",
    "    def fit_partial(self, x, y):\n",
    "        # construct out list of output activations for each layer as data point\n",
    "        # flows through the network; the first activation is a special case -- its\n",
    "        # just the input feature vector itself\n",
    "        A = [np.atleast_2d(x)]\n",
    "        #print(\"A:{}\".format(A))\n",
    "        \n",
    "        #Feedforward\n",
    "        #loop over layers in the network\n",
    "        for layer in np.arange(0,len(self.W)):\n",
    "            #print(\"layer:{}\".format(layer))\n",
    "            #print(\"A:{}\".format(A[layer].shape))\n",
    "            #print(\"W:{}\".format(self.W[layer].shape))\n",
    "            # feedforward the activation at the current layer by\n",
    "            # Activation * weight, this is called 'net input' \n",
    "            # A is computed from last layer\n",
    "            net = A[layer].dot(self.W[layer])\n",
    "            \n",
    "            out = self.sigmoid(net)\n",
    "            \n",
    "            #once we have the net output, add it to our list of activations\n",
    "            A.append(out)\n",
    "        \n",
    "        # Backpropagation\n",
    "        # the first phase of bp is compute the error between \n",
    "        # prediction and target\n",
    "        \n",
    "        error = A[-1] - y\n",
    "        \n",
    "        # from here, we need to apply the chain rule and build our\n",
    "        # list of deltas ‘D‘; the first entry in the deltas is\n",
    "        # simply the error of the output layer times the derivative\n",
    "        # of our activation function for the output value\n",
    "        \n",
    "        D = [error * self.sigmoid_deriv(A[-1])]\n",
    "        \n",
    "        #once given the D for the final layer, we can work backforward by loop\n",
    "        for layer in np.arange(len(A) - 2, 0 , -1):\n",
    "            # the delta for the current layer is equal to the delta of the\n",
    "            # *previous layer* dotted by *weight matrix* of the current layer,\n",
    "            # followed by multiplying the delta by the derivative of the activation\n",
    "            delta = D[-1].dot(self.W[layer].T)\n",
    "            delta = delta * self.sigmoid_deriv(A[layer])\n",
    "            D.append(delta)\n",
    "            \n",
    "        #since we looped over all the layers in reverse order we need to reverse\n",
    "        # the deltas\n",
    "        D = D[::-1]\n",
    "\n",
    "        # WEIGHT UPDATE PHASE\n",
    "        # loop over the layers\n",
    "        for layer in np.arange(0, len(self.W)):\n",
    "            self.W[layer] += -self.alpha * A[layer].T.dot(D[layer])\n",
    "    \n",
    "    def predict(self, X, addBias = True):\n",
    "        # initialize the output prediction as the input features -- this value\n",
    "        # will be (forward) propagated through the network to obtain the final\n",
    "        # prediction\n",
    "        \n",
    "        p = np.atleast_2d(X)\n",
    "        \n",
    "        # check to see if the bias should be added\n",
    "        \n",
    "        if addBias:\n",
    "            p = np.c_[p, np.ones((p.shape[0]))]\n",
    "        \n",
    "        # loop over our layers in the network\n",
    "        for layer in np.arange(0, len(self.W)):\n",
    "            p = self.sigmoid(np.dot(p, self.W[layer]))\n",
    "            # just dot from first layer to final layer\n",
    "            \n",
    "        return p\n",
    "    \n",
    "    def calculate_loss(self, X, targets):\n",
    "        targets = np.atleast_2d(targets)\n",
    "        predictions = self.predict(X, addBias=False)\n",
    "        loss = 0.5 * np.sum((predictions - targets) ** 2)\n",
    "        \n",
    "        return loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading MNIST (sample) dataset...\n",
      "[[  0.   0.   5. ...,   0.   0.   0.]\n",
      " [  0.   0.   0. ...,  10.   0.   0.]\n",
      " [  0.   0.   0. ...,  16.   9.   0.]\n",
      " ..., \n",
      " [  0.   0.   1. ...,   6.   0.   0.]\n",
      " [  0.   0.   2. ...,  12.   0.   0.]\n",
      " [  0.   0.  10. ...,  12.   1.   0.]]\n",
      "[INFO] sample: 1797, dim:64\n",
      "[3 8 9 ..., 2 8 7]\n",
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 0 1 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 1 0]\n",
      " [0 0 0 ..., 1 0 0]]\n",
      "[INFO] training network...\n",
      "[INFO] NeuralNetwork: 64_32_16_10\n",
      "[INFO] epoch=1, loss=605.7775273\n",
      "[INFO] epoch=100, loss=6.2868144\n",
      "[INFO] epoch=200, loss=3.2276279\n",
      "[INFO] epoch=300, loss=2.0825180\n",
      "[INFO] epoch=400, loss=1.8711338\n",
      "[INFO] epoch=500, loss=1.7708537\n",
      "[INFO] epoch=600, loss=1.7121665\n",
      "[INFO] epoch=700, loss=1.6737334\n",
      "[INFO] epoch=800, loss=1.6466836\n",
      "[INFO] epoch=900, loss=1.6266576\n",
      "[INFO] epoch=1000, loss=1.6112634\n",
      "[INFO] evluating netword...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        48\n",
      "          1       0.92      0.96      0.94        47\n",
      "          2       1.00      0.98      0.99        45\n",
      "          3       0.97      1.00      0.99        38\n",
      "          4       0.98      1.00      0.99        44\n",
      "          5       0.96      0.98      0.97        47\n",
      "          6       1.00      1.00      1.00        47\n",
      "          7       1.00      0.96      0.98        49\n",
      "          8       0.95      0.91      0.93        46\n",
      "          9       0.92      0.92      0.92        39\n",
      "\n",
      "avg / total       0.97      0.97      0.97       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MNIST\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "\n",
    "# load the MNIST and apply mix/max scaling to scale the pixel intensity valeus\n",
    "# to the range[0,1] (each image is represented by an 8*8 = 64-dim feature vector)\n",
    "\n",
    "print(\"[INFO] loading MNIST (sample) dataset...\")\n",
    "digits = datasets.load_digits()\n",
    "data = digits.data.astype(\"float\")\n",
    "print(data)\n",
    "data = (data - data.min()) / (data.max() - data.min())\n",
    "print(\"[INFO] sample: {}, dim:{}\".format(data.shape[0],data.shape[1]))\n",
    "\n",
    "(train_X, test_X, train_y, test_y) = train_test_split(data,\n",
    "                                digits.target, test_size=0.25)\n",
    "\n",
    "print(train_y)\n",
    "# one-hot encoding\n",
    "# convert the labels from intergers to vectors\n",
    "train_y = LabelBinarizer().fit_transform(train_y)\n",
    "test_y = LabelBinarizer().fit_transform(test_y)\n",
    "print(train_y)\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "nn = NeuralNetwork([train_X.shape[1],32,16,10])\n",
    "print(\"[INFO] {}\".format(nn))\n",
    "nn.fit(train_X,train_y,epochs=1000)\n",
    "\n",
    "# evaluate the network\n",
    "print(\"[INFO] evluating netword...\")\n",
    "predictions = nn.predict(test_X)\n",
    "predictions = predictions.argmax(axis = 1)\n",
    "print(classification_report(test_y.argmax(axis=1),predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading MNIST (full) dataset...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'digits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f9683b4bf57b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m (train_X, test_X, train_y, test_y) = train_test_split(data,\n\u001b[1;32m---> 24\u001b[1;33m                                 data.digits.target, test_size=0.25)\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mlb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'digits'"
     ]
    }
   ],
   "source": [
    "# multi-layer networks with keras\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "# construct the argument parse and parse the argument in commond line\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-o\",\"--output\",\n",
    "                required = True, help=\"path to the ouput loos/accuracy plot\")\n",
    "args = vars(ap.parse_args)\n",
    "\n",
    "print(\"[INFO] loading MNIST (full) dataset...\")\n",
    "dataset = datasets.fetch_mldata(\"MNIST Original\")\n",
    "\n",
    "data = dataset.data.astype(\"float\")/255.0\n",
    "(train_X, test_X, train_y, test_y) = train_test_split(data,\n",
    "                                data.digits.target, test_size=0.25)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "train_y = lb.fit_transform(train_y)\n",
    "test_y = lb.fit_transform(test_y)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256,input_shape=(784,),activation=\"sigmoid\"))\n",
    "model.add(Dense(128,activation=\"sigmoid\"))\n",
    "model.add(Dense(10,activation=\"softmax\"))\n",
    "\n",
    "# train the model with SGD\n",
    "print(\"[INFO] training network...\")\n",
    "sgd = SGD(0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=sgd,\n",
    "              metrics=[\"accuracy\"])\n",
    "H = model.fit(train_X, train_y, validation_data=(test_X,test_y),\n",
    "              epochs = 100, batch_size=128)\n",
    "\n",
    "# evaluate\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(test_X, batch_size=128)\n",
    "print(classification_report(test_y.argmax(axis=1),predictions.argmax(axis=1),\n",
    "      target_names=[str(x) for x in lb.classes_]))\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 100), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(args[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading CIFAR-10 data...\n",
      "[INFO] training network...\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 1.8291 - acc: 0.3479 - val_loss: 1.7387 - val_acc: 0.3550\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 35s 708us/step - loss: 1.6483 - acc: 0.4165 - val_loss: 1.6246 - val_acc: 0.4191\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 36s 730us/step - loss: 1.5681 - acc: 0.4449 - val_loss: 1.6693 - val_acc: 0.4006\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 36s 729us/step - loss: 1.5102 - acc: 0.4660 - val_loss: 1.5394 - val_acc: 0.4549\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 37s 736us/step - loss: 1.4613 - acc: 0.4849 - val_loss: 1.5042 - val_acc: 0.4581\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 38s 755us/step - loss: 1.4210 - acc: 0.5002 - val_loss: 1.4801 - val_acc: 0.4623\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 37s 738us/step - loss: 1.3861 - acc: 0.5133 - val_loss: 1.4732 - val_acc: 0.4790\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 37s 738us/step - loss: 1.3532 - acc: 0.5238 - val_loss: 1.4391 - val_acc: 0.4939\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 37s 739us/step - loss: 1.3240 - acc: 0.5347 - val_loss: 1.3942 - val_acc: 0.5007\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 39s 772us/step - loss: 1.2976 - acc: 0.5434 - val_loss: 1.4057 - val_acc: 0.5140\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 35s 700us/step - loss: 1.2680 - acc: 0.5528 - val_loss: 1.4700 - val_acc: 0.4805\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 34s 689us/step - loss: 1.2434 - acc: 0.5626 - val_loss: 1.4013 - val_acc: 0.5035\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 34s 685us/step - loss: 1.2196 - acc: 0.5728 - val_loss: 1.5696 - val_acc: 0.4521\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 1.1951 - acc: 0.5782 - val_loss: 1.3974 - val_acc: 0.5120\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 34s 682us/step - loss: 1.1720 - acc: 0.5899 - val_loss: 1.4966 - val_acc: 0.4841\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 34s 690us/step - loss: 1.1495 - acc: 0.5966 - val_loss: 1.3604 - val_acc: 0.5184\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 34s 688us/step - loss: 1.1270 - acc: 0.6052 - val_loss: 1.4263 - val_acc: 0.4960\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 34s 686us/step - loss: 1.1049 - acc: 0.6137 - val_loss: 1.3462 - val_acc: 0.5265\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 35s 691us/step - loss: 1.0813 - acc: 0.6218 - val_loss: 1.4066 - val_acc: 0.5118\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 34s 688us/step - loss: 1.0598 - acc: 0.6267 - val_loss: 1.3673 - val_acc: 0.5226\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 35s 693us/step - loss: 1.0385 - acc: 0.6349 - val_loss: 1.3819 - val_acc: 0.5129\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 34s 689us/step - loss: 1.0179 - acc: 0.6440 - val_loss: 1.3251 - val_acc: 0.5339\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 34s 688us/step - loss: 0.9945 - acc: 0.6530 - val_loss: 1.3952 - val_acc: 0.5116\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 34s 688us/step - loss: 0.9759 - acc: 0.6593 - val_loss: 1.3299 - val_acc: 0.5346\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 34s 688us/step - loss: 0.9558 - acc: 0.6667 - val_loss: 1.4359 - val_acc: 0.5113\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 34s 687us/step - loss: 0.9320 - acc: 0.6743 - val_loss: 1.3918 - val_acc: 0.5232\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 34s 685us/step - loss: 0.9130 - acc: 0.6807 - val_loss: 1.4647 - val_acc: 0.5071\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 34s 684us/step - loss: 0.8917 - acc: 0.6890 - val_loss: 1.4027 - val_acc: 0.5266\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 0.8702 - acc: 0.6970 - val_loss: 1.3772 - val_acc: 0.5261\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 0.8482 - acc: 0.7056 - val_loss: 1.4574 - val_acc: 0.5124\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 34s 686us/step - loss: 0.8252 - acc: 0.7122 - val_loss: 1.3663 - val_acc: 0.5365\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 0.8091 - acc: 0.7182 - val_loss: 1.5276 - val_acc: 0.4925\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 0.7852 - acc: 0.7269 - val_loss: 1.4288 - val_acc: 0.5304\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 34s 687us/step - loss: 0.7672 - acc: 0.7333 - val_loss: 1.4995 - val_acc: 0.5163\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 34s 685us/step - loss: 0.7442 - acc: 0.7444 - val_loss: 1.6368 - val_acc: 0.4889\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 0.7286 - acc: 0.7478 - val_loss: 1.4557 - val_acc: 0.5232\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 34s 682us/step - loss: 0.7032 - acc: 0.7588 - val_loss: 1.4322 - val_acc: 0.5349\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 34s 684us/step - loss: 0.6850 - acc: 0.7665 - val_loss: 1.4913 - val_acc: 0.5258\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 0.6648 - acc: 0.7721 - val_loss: 1.3936 - val_acc: 0.5471\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 34s 684us/step - loss: 0.6463 - acc: 0.7778 - val_loss: 1.4178 - val_acc: 0.5390\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 34s 685us/step - loss: 0.6251 - acc: 0.7872 - val_loss: 1.3984 - val_acc: 0.5522\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 34s 685us/step - loss: 0.6042 - acc: 0.7952 - val_loss: 1.4967 - val_acc: 0.5395\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 0.5862 - acc: 0.7997 - val_loss: 1.4683 - val_acc: 0.5433\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 0.5667 - acc: 0.8068 - val_loss: 1.5321 - val_acc: 0.5236\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 0.5457 - acc: 0.8167 - val_loss: 1.4673 - val_acc: 0.5517\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 34s 684us/step - loss: 0.5298 - acc: 0.8207 - val_loss: 1.5267 - val_acc: 0.5372\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 34s 684us/step - loss: 0.5087 - acc: 0.8304 - val_loss: 1.5601 - val_acc: 0.5362\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 34s 684us/step - loss: 0.4943 - acc: 0.8343 - val_loss: 1.5809 - val_acc: 0.5309\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 34s 684us/step - loss: 0.4704 - acc: 0.8447 - val_loss: 1.7181 - val_acc: 0.5215\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 34s 682us/step - loss: 0.4595 - acc: 0.8463 - val_loss: 1.4906 - val_acc: 0.5625\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 34s 682us/step - loss: 0.4407 - acc: 0.8533 - val_loss: 1.5690 - val_acc: 0.5477\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 0.4246 - acc: 0.8603 - val_loss: 1.5352 - val_acc: 0.5544\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 34s 682us/step - loss: 0.4079 - acc: 0.8655 - val_loss: 1.6795 - val_acc: 0.5353\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 34s 681us/step - loss: 0.3899 - acc: 0.8737 - val_loss: 1.5946 - val_acc: 0.5561\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 34s 685us/step - loss: 0.3744 - acc: 0.8792 - val_loss: 1.6094 - val_acc: 0.5517\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 34s 685us/step - loss: 0.3602 - acc: 0.8828 - val_loss: 1.6846 - val_acc: 0.5456\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 34s 684us/step - loss: 0.3446 - acc: 0.8885 - val_loss: 1.6433 - val_acc: 0.5577\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 34s 684us/step - loss: 0.3325 - acc: 0.8930 - val_loss: 1.8776 - val_acc: 0.5083\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 34s 684us/step - loss: 0.3162 - acc: 0.8989 - val_loss: 1.9476 - val_acc: 0.5108\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 34s 682us/step - loss: 0.3065 - acc: 0.9026 - val_loss: 1.7738 - val_acc: 0.5485\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 34s 682us/step - loss: 0.2895 - acc: 0.9108 - val_loss: 2.1752 - val_acc: 0.4830\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 0.2751 - acc: 0.9162 - val_loss: 1.7828 - val_acc: 0.5486\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 0.2610 - acc: 0.9183 - val_loss: 1.8319 - val_acc: 0.5438\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 34s 685us/step - loss: 0.2500 - acc: 0.9240 - val_loss: 2.0362 - val_acc: 0.5133\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 34s 684us/step - loss: 0.2429 - acc: 0.9254 - val_loss: 1.9685 - val_acc: 0.5195\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 0.2267 - acc: 0.9328 - val_loss: 1.8803 - val_acc: 0.5449\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 34s 685us/step - loss: 0.2178 - acc: 0.9348 - val_loss: 1.8680 - val_acc: 0.5479\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 34s 683us/step - loss: 0.2030 - acc: 0.9399 - val_loss: 1.8256 - val_acc: 0.5555\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 34s 684us/step - loss: 0.1913 - acc: 0.9441 - val_loss: 1.8975 - val_acc: 0.5524\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 10012s 200ms/step - loss: 0.1872 - acc: 0.9455 - val_loss: 1.8706 - val_acc: 0.5552\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.1754 - acc: 0.9502 - val_loss: 1.9057 - val_acc: 0.5590\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 36s 710us/step - loss: 0.1637 - acc: 0.9549 - val_loss: 1.9308 - val_acc: 0.5497\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 34s 689us/step - loss: 0.1575 - acc: 0.9561 - val_loss: 1.9541 - val_acc: 0.5501\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 35s 702us/step - loss: 0.1485 - acc: 0.9598 - val_loss: 1.9477 - val_acc: 0.5565\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 35s 703us/step - loss: 0.1377 - acc: 0.9649 - val_loss: 1.9206 - val_acc: 0.5575\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 34s 682us/step - loss: 0.1311 - acc: 0.9662 - val_loss: 1.9670 - val_acc: 0.5500\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 34s 677us/step - loss: 0.1246 - acc: 0.9683 - val_loss: 2.0941 - val_acc: 0.5464\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 35s 696us/step - loss: 0.1150 - acc: 0.9720 - val_loss: 2.1258 - val_acc: 0.5428\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 35s 702us/step - loss: 0.1095 - acc: 0.9729 - val_loss: 2.0120 - val_acc: 0.5606\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 28790s 576ms/step - loss: 0.0989 - acc: 0.9774 - val_loss: 2.0137 - val_acc: 0.5626\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 34s 689us/step - loss: 0.0982 - acc: 0.9774 - val_loss: 2.1270 - val_acc: 0.5543\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 35s 693us/step - loss: 0.0869 - acc: 0.9812 - val_loss: 2.2017 - val_acc: 0.5391\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 34s 689us/step - loss: 0.0862 - acc: 0.9810 - val_loss: 2.0860 - val_acc: 0.5582\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 36s 711us/step - loss: 0.0785 - acc: 0.9835 - val_loss: 2.0856 - val_acc: 0.5697\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 36s 713us/step - loss: 0.0753 - acc: 0.9840 - val_loss: 2.1080 - val_acc: 0.5631\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 37s 737us/step - loss: 0.0666 - acc: 0.9869 - val_loss: 2.1682 - val_acc: 0.5580\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 41s 817us/step - loss: 0.0616 - acc: 0.9892 - val_loss: 2.1190 - val_acc: 0.5628\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 41s 826us/step - loss: 0.0570 - acc: 0.9900 - val_loss: 2.1271 - val_acc: 0.5657\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 41s 818us/step - loss: 0.0551 - acc: 0.9903 - val_loss: 2.3366 - val_acc: 0.5445\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 41s 820us/step - loss: 0.0504 - acc: 0.9923 - val_loss: 2.1921 - val_acc: 0.5642\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 41s 824us/step - loss: 0.0481 - acc: 0.9923 - val_loss: 2.2254 - val_acc: 0.5614\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 42s 848us/step - loss: 0.0448 - acc: 0.9937 - val_loss: 2.1950 - val_acc: 0.5644\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 41s 825us/step - loss: 0.0413 - acc: 0.9939 - val_loss: 2.4558 - val_acc: 0.5458\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 41s 816us/step - loss: 0.0418 - acc: 0.9933 - val_loss: 2.2789 - val_acc: 0.5521\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 41s 816us/step - loss: 0.0391 - acc: 0.9937 - val_loss: 2.2362 - val_acc: 0.5634\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 41s 821us/step - loss: 0.0341 - acc: 0.9954 - val_loss: 2.2395 - val_acc: 0.5667\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 41s 815us/step - loss: 0.0328 - acc: 0.9957 - val_loss: 2.2559 - val_acc: 0.5641\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 41s 821us/step - loss: 0.0309 - acc: 0.9961 - val_loss: 2.2932 - val_acc: 0.5686\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 42s 838us/step - loss: 0.0284 - acc: 0.9969 - val_loss: 2.2730 - val_acc: 0.5589\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 41s 828us/step - loss: 0.0263 - acc: 0.9971 - val_loss: 2.2769 - val_acc: 0.5609\n",
      "[INFO] evaluating network...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   airplane       0.64      0.65      0.64      1000\n",
      " automobile       0.72      0.64      0.68      1000\n",
      "       bird       0.46      0.46      0.46      1000\n",
      "        cat       0.34      0.47      0.40      1000\n",
      "       deer       0.48      0.51      0.49      1000\n",
      "        dog       0.51      0.40      0.45      1000\n",
      "       frog       0.63      0.58      0.60      1000\n",
      "      horse       0.62      0.61      0.62      1000\n",
      "       ship       0.69      0.69      0.69      1000\n",
      "      truck       0.62      0.60      0.61      1000\n",
      "\n",
      "avg / total       0.57      0.56      0.56     10000\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-cf23175f9881>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loss/Accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"output\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'output'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dc5977a630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "# construct the argument parse and parse the argument in commond line\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-o\",\"--output\",\n",
    "                required = True, help=\"path to the ouput loos/accuracy plot\")\n",
    "args = vars(ap.parse_args)\n",
    "\n",
    "print(\"[INFO] loading CIFAR-10 data...\")\n",
    "(train_X,train_y),(test_X,test_y) = cifar10.load_data()\n",
    "train_X = train_X.astype(\"float\") / 255.0\n",
    "test_X = test_X.astype(\"float\") / 255.0\n",
    "\n",
    "train_X = train_X.reshape((train_X.shape[0], 3072))#32*32*3 per image;5000 total\n",
    "test_X = test_X.reshape((test_X.shape[0], 3072))\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "train_y = lb.fit_transform(train_y)\n",
    "test_y = lb.fit_transform(test_y)\n",
    "\n",
    "# initialize the label names for the CIFAR-10 dataset\n",
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "              \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,input_shape=(3072,),activation=\"relu\"))\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dense(10,activation=\"softmax\"))\n",
    "\n",
    "# train the model with SGD\n",
    "print(\"[INFO] training network...\")\n",
    "sgd = SGD(0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=sgd,\n",
    "              metrics=[\"accuracy\"])\n",
    "H = model.fit(train_X, train_y, validation_data=(test_X,test_y),\n",
    "              epochs = 100, batch_size=32)\n",
    "\n",
    "# evaluate\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(test_X, batch_size=32)\n",
    "print(classification_report(test_y.argmax(axis=1),predictions.argmax(axis=1),\n",
    "      target_names=labelNames))\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 100), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, 100), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(args[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
