{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "class HDF5DatasetGenerator:\n",
    "    def __init__(self, dbPath, batchSize, preprocessors=None,\n",
    "        aug=None, binarize=True, classes=2):\n",
    "        # store the batch size, preprocessors, and data augmentor,\n",
    "        # whether or not the labels should be binarized, along with\n",
    "        # the total number of classes\n",
    "        self.batchSize = batchSize\n",
    "        self.preprocessors = preprocessors\n",
    "        self.aug = aug\n",
    "        self.binarize = binarize\n",
    "        self.classes = classes\n",
    "\n",
    "        # open the HDF5 database for reading and determine the total\n",
    "        # number of entries in the database\n",
    "        self.db = h5py.File(dbPath)\n",
    "        self.numImages = self.db[\"labels\"].shape[0]\n",
    "     \n",
    "    # 此函数提供给 keras 的fit.generator的\n",
    "    def generator(self, passes=np.inf):\n",
    "    # initialize the epoch count\n",
    "        epochs = 0\n",
    "        # keep looping infinitely -- the model will stop once we have\n",
    "        # reach the desired number of epochs\n",
    "        while epochs < passes:\n",
    "            # loop over the HDF5 dataset\n",
    "            for i in np.arange(0, self.numImages, self.batchSize):\n",
    "            # extract the images and labels from the HDF dataset\n",
    "                images = self.db[\"images\"][i: i + self.batchSize]\n",
    "                labels = self.db[\"labels\"][i: i + self.batchSize]\n",
    "                # check to see if the labels should be binarized\n",
    "                # [0,0,0,0,1]五类中的第五类\n",
    "                if self.binarize:\n",
    "                    labels = np_utils.to_categorical(labels,\n",
    "                        self.classes)\n",
    "                # check to see if our preprocessors are not None\n",
    "                if self.preprocessors is not None:\n",
    "                    # initialize the list of processed images\n",
    "                    procImages = []\n",
    "\n",
    "                    # loop over the images\n",
    "                    for image in images:\n",
    "                        # loop over the preprocessors and apply each\n",
    "                        # to the image\n",
    "                        for p in self.preprocessors:\n",
    "                            image = p.preprocess(image)\n",
    "\n",
    "                        # update the list of processed images\n",
    "                        procImages.append(image)\n",
    "\n",
    "                    # update the images array to be the processed\n",
    "                    # images\n",
    "                    images = np.array(procImages)\n",
    "                # if the data augmenator exists, apply it\n",
    "                if self.aug is not None:\n",
    "                    (images, labels) = next(self.aug.flow(images,\n",
    "                                 labels, batch_size=self.batchSize))\n",
    "                # yield a tuple of images and labels\n",
    "                yield (images, labels)\n",
    "            # increment the total number of epochs\n",
    "            epochs += 1\n",
    "    def close(self):\n",
    "        self.db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
