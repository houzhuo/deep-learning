{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HOU\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from CV.nn.conv.LeNet import LeNet\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import backend as K\n",
    "from CV.preprocessing.ImageToArrayPreprocessor import ImageToArrayPreprocessor\n",
    "from CV.preprocessing.SimplePreprocessor import SimplePreprocessor\n",
    "from CV.datasets.SimpleDatasetLoader import SimpleDatasetLoader\n",
    "from CV.nn.conv.ShallowNet import ShallowNet\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from CV.nn.conv.alexnet import AlexNet\n",
    "import argparse \n",
    "from CV.nn.conv.MiniVGGNet import MiniVGGNet\n",
    "'''\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
    "help=\"path to the input data\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "print(\"[info] loading images...\")'''\n",
    "#imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
    "#imagePaths = list(paths.list_images(\"C:/Users/HOU/Documents/practical_bundle/data3/\"))\n",
    "imagePaths = list(paths.list_images(\"C:/Users/HOU/Documents/practical_bundle/data3_1/\"))\n",
    "\n",
    "size = 64\n",
    "\n",
    "sp = SimplePreprocessor(size,size)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "\n",
    "sdl = SimpleDatasetLoader(preprocessors=[sp, iap])\n",
    "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
    "\n",
    "data = data-255.0\n",
    "data = data.astype(\"float\") / 50\n",
    "#if K.image_data_format() == \"channels_first\":\n",
    "#    data = data.reshape(data.shape[0],1,28,28)\n",
    "#else:\n",
    "#    data = data.reshape(data.shape[0], 28, 28, 1)\n",
    "    \n",
    "\n",
    "(train_X, test_X, train_y, test_y) = train_test_split(data,\n",
    "                               labels, test_size=0.25,\n",
    "                                                     random_state=7)\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "lb = LabelBinarizer()\n",
    "#train_y = lb.fit_transform(train_y)\n",
    "#test_y = lb.fit_transform(test_y)\n",
    "lb.fit(train_y)\n",
    "train_y=lb.transform(train_y)\n",
    "test_y = lb.transform(test_y)\n",
    "train_y = to_categorical(train_y, num_classes=2)\n",
    "test_y = to_categorical(test_y, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189, 64, 64, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Normalize the data: subtract the mean image\n",
    "# data.shape[0]\n",
    "# mean = np.mean(data,axis=0)\n",
    "# for i in range(data.shape[0]):\n",
    "#     data[i] = data[i] - mean\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Train on 116 samples, validate on 116 samples\n",
      "Epoch 1/10\n",
      "116/116 [==============================] - 8s 69ms/step - loss: 2.1780 - acc: 0.4224 - val_loss: 5.8915 - val_acc: 0.5172\n",
      "Epoch 2/10\n",
      "116/116 [==============================] - 6s 54ms/step - loss: 0.9155 - acc: 0.6897 - val_loss: 5.5984 - val_acc: 0.5086\n",
      "Epoch 3/10\n",
      "116/116 [==============================] - 6s 54ms/step - loss: 0.6337 - acc: 0.7500 - val_loss: 4.7634 - val_acc: 0.5259\n",
      "Epoch 4/10\n",
      "116/116 [==============================] - 6s 55ms/step - loss: 0.4604 - acc: 0.8362 - val_loss: 4.2851 - val_acc: 0.5086\n",
      "Epoch 5/10\n",
      "116/116 [==============================] - 6s 55ms/step - loss: 0.3129 - acc: 0.8879 - val_loss: 3.8164 - val_acc: 0.4655\n",
      "Epoch 6/10\n",
      "116/116 [==============================] - 6s 54ms/step - loss: 0.1993 - acc: 0.9224 - val_loss: 3.0680 - val_acc: 0.5259\n",
      "Epoch 7/10\n",
      "116/116 [==============================] - 6s 55ms/step - loss: 0.0801 - acc: 0.9741 - val_loss: 2.9472 - val_acc: 0.5862\n",
      "Epoch 8/10\n",
      " 16/116 [===>..........................] - ETA: 4s - loss: 0.0246 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-572045301e05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[INFO] training network...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m H = model.fit(train_X, train_y,validation_data=(test_X, test_y),\n\u001b[1;32m---> 27\u001b[1;33m     batch_size=BS, epochs=EPOCHS, verbose=1)\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# evaluate the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1002\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications import Xception # TensorFlow ONLY\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import VGG19\n",
    "#lb = LabelBinarizer()\n",
    "#train_y = lb.fit_transform(train_y)\n",
    "#test_y = lb.fit_transform(test_y)\n",
    "\n",
    "EPOCHS = 10\n",
    "INIT_LR = 1e-3\n",
    "BS =32\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=0.005, decay=0.005/EPOCHS, momentum=0.9,nesterov=True)\n",
    "#opt = Adam(lr=0.01, decay=0.05 / 25)\n",
    "#opt = SGD(lr=0.005)\n",
    "#opt = SGD(lr=0.05, decay=0.05/20, momentum=0.9,nesterov=True)\n",
    "model = MiniVGGNet.build(width=size, height=size, depth=3, classes=2)\n",
    "#model = AlexNet.build(width=128, height=128, depth=3, classes=2)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,#binary_crossentropy#categorical_crossentropy\n",
    "metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit(train_X, train_y,validation_data=(test_X, test_y),\n",
    "    batch_size=BS, epochs=EPOCHS, verbose=1)\n",
    "\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(test_X, batch_size=BS)\n",
    "print(classification_report(test_y.argmax(axis=1),predictions.argmax(axis=1),\n",
    "      target_names=[str(x) for x in lb.classes_]))\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               33554944  \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 33,624,354\n",
      "Trainable params: 33,622,946\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_9_input:0' shape=(?, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation_13': <keras.layers.core.Activation at 0x1be8f619b00>,\n",
       " 'batch_normalization_11': <keras.layers.normalization.BatchNormalization at 0x1be8f619cc0>,\n",
       " 'conv2d_10': <keras.layers.convolutional.Conv2D at 0x1be8f619ef0>,\n",
       " 'activation_14': <keras.layers.core.Activation at 0x1be8f617d68>,\n",
       " 'batch_normalization_12': <keras.layers.normalization.BatchNormalization at 0x1bfcc097f28>,\n",
       " 'max_pooling2d_3': <keras.layers.pooling.MaxPooling2D at 0x1bfcbebcf60>,\n",
       " 'dropout_7': <keras.layers.core.Dropout at 0x1be8f386160>,\n",
       " 'conv2d_11': <keras.layers.convolutional.Conv2D at 0x1be8f796da0>,\n",
       " 'activation_15': <keras.layers.core.Activation at 0x1be8f7d38d0>,\n",
       " 'batch_normalization_13': <keras.layers.normalization.BatchNormalization at 0x1be8f776d68>,\n",
       " 'conv2d_12': <keras.layers.convolutional.Conv2D at 0x1be8f7767f0>,\n",
       " 'activation_16': <keras.layers.core.Activation at 0x1bf1b2334e0>,\n",
       " 'batch_normalization_14': <keras.layers.normalization.BatchNormalization at 0x1bf1b2b5978>,\n",
       " 'dropout_8': <keras.layers.core.Dropout at 0x1bf1b345da0>,\n",
       " 'flatten_3': <keras.layers.core.Flatten at 0x1bf1b356d30>,\n",
       " 'dense_5': <keras.layers.core.Dense at 0x1bf1b3a99b0>,\n",
       " 'activation_17': <keras.layers.core.Activation at 0x1bf1b483208>,\n",
       " 'batch_normalization_15': <keras.layers.normalization.BatchNormalization at 0x1bf1b483780>,\n",
       " 'dropout_9': <keras.layers.core.Dropout at 0x1bf1b483320>,\n",
       " 'dense_6': <keras.layers.core.Dense at 0x1bf1b483b38>,\n",
       " 'activation_18': <keras.layers.core.Activation at 0x1bf1b4f20f0>}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict([(layer.name, layer) for layer in model.layers[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               33554944  \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 33,624,354\n",
      "Trainable params: 33,622,946\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Processing filter 0\n",
      "Current loss value: 11218.641\n",
      "Current loss value: 11407.283\n",
      "Current loss value: 11595.904\n",
      "Current loss value: 11784.528\n",
      "Current loss value: 11973.1\n",
      "Current loss value: 12161.577\n",
      "Current loss value: 12350.057\n",
      "Current loss value: 12538.535\n",
      "Current loss value: 12727.109\n",
      "Current loss value: 12915.712\n",
      "Current loss value: 13104.455\n",
      "Current loss value: 13293.33\n",
      "Current loss value: 13482.342\n",
      "Current loss value: 13671.4\n",
      "Current loss value: 13860.553\n",
      "Current loss value: 14049.799\n",
      "Current loss value: 14238.99\n",
      "Current loss value: 14428.326\n",
      "Current loss value: 14617.651\n",
      "Current loss value: 14807.143\n",
      "Filter 0 processed in 6s\n",
      "Processing filter 1\n",
      "Current loss value: -7183.1865\n",
      "Filter 1 processed in 5s\n",
      "Processing filter 2\n",
      "Current loss value: -4029.749\n",
      "Filter 2 processed in 5s\n",
      "Processing filter 3\n",
      "Current loss value: 4258.0996\n",
      "Current loss value: 4333.6367\n",
      "Current loss value: 4409.205\n",
      "Current loss value: 4484.7944\n",
      "Current loss value: 4560.4043\n",
      "Current loss value: 4636.01\n",
      "Current loss value: 4711.62\n",
      "Current loss value: 4787.2803\n",
      "Current loss value: 4862.9727\n",
      "Current loss value: 4938.671\n",
      "Current loss value: 5014.416\n",
      "Current loss value: 5090.1943\n",
      "Current loss value: 5165.9805\n",
      "Current loss value: 5241.8096\n",
      "Current loss value: 5317.6533\n",
      "Current loss value: 5393.5215\n",
      "Current loss value: 5469.418\n",
      "Current loss value: 5545.3477\n",
      "Current loss value: 5621.329\n",
      "Current loss value: 5697.383\n",
      "Filter 3 processed in 6s\n",
      "Processing filter 4\n",
      "Current loss value: -3145.0576\n",
      "Filter 4 processed in 5s\n",
      "Processing filter 5\n",
      "Current loss value: -5656.9297\n",
      "Filter 5 processed in 5s\n",
      "Processing filter 6\n",
      "Current loss value: -362.61066\n",
      "Filter 6 processed in 5s\n",
      "Processing filter 7\n",
      "Current loss value: -357.34927\n",
      "Filter 7 processed in 5s\n",
      "Processing filter 8\n",
      "Current loss value: 539.9361\n",
      "Current loss value: 556.3165\n",
      "Current loss value: 572.61957\n",
      "Current loss value: 588.8944\n",
      "Current loss value: 605.06805\n",
      "Current loss value: 621.17957\n",
      "Current loss value: 637.26416\n",
      "Current loss value: 653.28436\n",
      "Current loss value: 669.21674\n",
      "Current loss value: 685.1684\n",
      "Current loss value: 701.0582\n",
      "Current loss value: 716.96185\n",
      "Current loss value: 732.84204\n",
      "Current loss value: 748.72675\n",
      "Current loss value: 764.62726\n",
      "Current loss value: 780.51385\n",
      "Current loss value: 796.3564\n",
      "Current loss value: 812.22766\n",
      "Current loss value: 828.1559\n",
      "Current loss value: 844.06085\n",
      "Filter 8 processed in 6s\n",
      "Processing filter 9\n",
      "Current loss value: 614.4668\n",
      "Current loss value: 631.7925\n",
      "Current loss value: 648.386\n",
      "Current loss value: 664.44293\n",
      "Current loss value: 680.10284\n",
      "Current loss value: 695.3943\n",
      "Current loss value: 710.4298\n",
      "Current loss value: 725.31177\n",
      "Current loss value: 740.0476\n",
      "Current loss value: 754.5852\n",
      "Current loss value: 768.9864\n",
      "Current loss value: 783.3534\n",
      "Current loss value: 797.6299\n",
      "Current loss value: 811.85767\n",
      "Current loss value: 825.8967\n",
      "Current loss value: 839.8019\n",
      "Current loss value: 853.58826\n",
      "Current loss value: 867.404\n",
      "Current loss value: 880.9939\n",
      "Current loss value: 894.46594\n",
      "Filter 9 processed in 6s\n",
      "Processing filter 10\n",
      "Current loss value: 221.16916\n",
      "Current loss value: 241.66017\n",
      "Current loss value: 261.0185\n",
      "Current loss value: 279.5274\n",
      "Current loss value: 297.3024\n",
      "Current loss value: 314.38403\n",
      "Current loss value: 331.0344\n",
      "Current loss value: 347.19287\n",
      "Current loss value: 362.81857\n",
      "Current loss value: 378.19678\n",
      "Current loss value: 393.52258\n",
      "Current loss value: 408.5103\n",
      "Current loss value: 423.4574\n",
      "Current loss value: 438.31305\n",
      "Current loss value: 453.11133\n",
      "Current loss value: 467.95926\n",
      "Current loss value: 482.6054\n",
      "Current loss value: 497.18658\n",
      "Current loss value: 511.92264\n",
      "Current loss value: 526.6207\n",
      "Filter 10 processed in 6s\n",
      "Processing filter 11\n",
      "Current loss value: 4333.634\n",
      "Current loss value: 4404.6436\n",
      "Current loss value: 4475.7363\n",
      "Current loss value: 4546.915\n",
      "Current loss value: 4618.182\n",
      "Current loss value: 4689.544\n",
      "Current loss value: 4760.9688\n",
      "Current loss value: 4832.462\n",
      "Current loss value: 4904.0176\n",
      "Current loss value: 4975.6387\n",
      "Current loss value: 5047.3335\n",
      "Current loss value: 5119.0684\n",
      "Current loss value: 5190.8823\n",
      "Current loss value: 5262.783\n",
      "Current loss value: 5334.7803\n",
      "Current loss value: 5406.85\n",
      "Current loss value: 5479.002\n",
      "Current loss value: 5551.2373\n",
      "Current loss value: 5623.552\n",
      "Current loss value: 5695.9355\n",
      "Filter 11 processed in 6s\n",
      "Processing filter 12\n",
      "Current loss value: 5127.086\n",
      "Current loss value: 5213.0913\n",
      "Current loss value: 5299.0957\n",
      "Current loss value: 5385.116\n",
      "Current loss value: 5471.1562\n",
      "Current loss value: 5557.123\n",
      "Current loss value: 5643.1455\n",
      "Current loss value: 5729.119\n",
      "Current loss value: 5815.142\n",
      "Current loss value: 5901.2417\n",
      "Current loss value: 5987.4053\n",
      "Current loss value: 6073.6274\n",
      "Current loss value: 6159.9033\n",
      "Current loss value: 6246.2197\n",
      "Current loss value: 6332.546\n",
      "Current loss value: 6418.9116\n",
      "Current loss value: 6505.3066\n",
      "Current loss value: 6591.751\n",
      "Current loss value: 6678.217\n",
      "Current loss value: 6764.727\n",
      "Filter 12 processed in 6s\n",
      "Processing filter 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: -4675.2915\n",
      "Filter 13 processed in 6s\n",
      "Processing filter 14\n",
      "Current loss value: -3542.5234\n",
      "Filter 14 processed in 5s\n",
      "Processing filter 15\n",
      "Current loss value: -1028.4653\n",
      "Filter 15 processed in 6s\n",
      "Processing filter 16\n",
      "Current loss value: 5775.259\n",
      "Current loss value: 5874.16\n",
      "Current loss value: 5973.072\n",
      "Current loss value: 6072.009\n",
      "Current loss value: 6170.9873\n",
      "Current loss value: 6269.9756\n",
      "Current loss value: 6368.9844\n",
      "Current loss value: 6468.04\n",
      "Current loss value: 6567.133\n",
      "Current loss value: 6666.2817\n",
      "Current loss value: 6765.4775\n",
      "Current loss value: 6864.6855\n",
      "Current loss value: 6963.9585\n",
      "Current loss value: 7063.3047\n",
      "Current loss value: 7162.71\n",
      "Current loss value: 7262.166\n",
      "Current loss value: 7361.627\n",
      "Current loss value: 7461.184\n",
      "Current loss value: 7560.8037\n",
      "Current loss value: 7660.4697\n",
      "Filter 16 processed in 6s\n",
      "Processing filter 17\n",
      "Current loss value: -1433.4608\n",
      "Filter 17 processed in 6s\n",
      "Processing filter 18\n",
      "Current loss value: -3846.3403\n",
      "Filter 18 processed in 6s\n",
      "Processing filter 19\n",
      "Current loss value: -1624.7966\n",
      "Filter 19 processed in 5s\n",
      "Processing filter 20\n",
      "Current loss value: -5750.459\n",
      "Filter 20 processed in 6s\n",
      "Processing filter 21\n",
      "Current loss value: -1044.8175\n",
      "Filter 21 processed in 6s\n",
      "Processing filter 22\n",
      "Current loss value: 7412.294\n",
      "Current loss value: 7540.336\n",
      "Current loss value: 7668.465\n",
      "Current loss value: 7796.583\n",
      "Current loss value: 7924.736\n",
      "Current loss value: 8052.962\n",
      "Current loss value: 8181.246\n",
      "Current loss value: 8309.638\n",
      "Current loss value: 8438.107\n",
      "Current loss value: 8566.641\n",
      "Current loss value: 8695.307\n",
      "Current loss value: 8823.969\n",
      "Current loss value: 8952.666\n",
      "Current loss value: 9081.436\n",
      "Current loss value: 9210.272\n",
      "Current loss value: 9339.157\n",
      "Current loss value: 9468.159\n",
      "Current loss value: 9597.323\n",
      "Current loss value: 9726.547\n",
      "Current loss value: 9855.889\n",
      "Filter 22 processed in 6s\n",
      "Processing filter 23\n",
      "Current loss value: -8967.44\n",
      "Filter 23 processed in 6s\n",
      "Processing filter 24\n",
      "Current loss value: 4094.2346\n",
      "Current loss value: 4167.6523\n",
      "Current loss value: 4240.9023\n",
      "Current loss value: 4314.0576\n",
      "Current loss value: 4386.9385\n",
      "Current loss value: 4459.6553\n",
      "Current loss value: 4532.339\n",
      "Current loss value: 4604.9756\n",
      "Current loss value: 4677.5293\n",
      "Current loss value: 4750.0234\n",
      "Current loss value: 4822.5225\n",
      "Current loss value: 4894.9707\n",
      "Current loss value: 4967.395\n",
      "Current loss value: 5039.8354\n",
      "Current loss value: 5112.317\n",
      "Current loss value: 5184.79\n",
      "Current loss value: 5257.2495\n",
      "Current loss value: 5329.6636\n",
      "Current loss value: 5402.125\n",
      "Current loss value: 5474.6006\n",
      "Filter 24 processed in 6s\n",
      "Processing filter 25\n",
      "Current loss value: -311.3479\n",
      "Filter 25 processed in 6s\n",
      "Processing filter 26\n",
      "Current loss value: 4820.0894\n",
      "Current loss value: 4900.2827\n",
      "Current loss value: 4980.5283\n",
      "Current loss value: 5060.8496\n",
      "Current loss value: 5141.2246\n",
      "Current loss value: 5221.661\n",
      "Current loss value: 5302.1494\n",
      "Current loss value: 5382.677\n",
      "Current loss value: 5463.246\n",
      "Current loss value: 5543.855\n",
      "Current loss value: 5624.4966\n",
      "Current loss value: 5705.1846\n",
      "Current loss value: 5785.915\n",
      "Current loss value: 5866.696\n",
      "Current loss value: 5947.5117\n",
      "Current loss value: 6028.3896\n",
      "Current loss value: 6109.3076\n",
      "Current loss value: 6190.285\n",
      "Current loss value: 6271.3125\n",
      "Current loss value: 6352.3916\n",
      "Filter 26 processed in 6s\n",
      "Processing filter 27\n",
      "Current loss value: -4183.8906\n",
      "Filter 27 processed in 6s\n",
      "Processing filter 28\n",
      "Current loss value: -5129.5596\n",
      "Filter 28 processed in 6s\n",
      "Processing filter 29\n",
      "Current loss value: -283.39392\n",
      "Filter 29 processed in 6s\n",
      "Processing filter 30\n",
      "Current loss value: -2003.7599\n",
      "Filter 30 processed in 6s\n",
      "Processing filter 31\n",
      "Current loss value: -4380.498\n",
      "Filter 31 processed in 6s\n",
      "Processing filter 32\n",
      "Current loss value: 2745.2192\n",
      "Current loss value: 2791.7349\n",
      "Current loss value: 2838.1602\n",
      "Current loss value: 2884.4912\n",
      "Current loss value: 2930.7627\n",
      "Current loss value: 2976.9456\n",
      "Current loss value: 3023.0996\n",
      "Current loss value: 3069.1763\n",
      "Current loss value: 3115.1875\n",
      "Current loss value: 3161.191\n",
      "Current loss value: 3207.1875\n",
      "Current loss value: 3253.1367\n",
      "Current loss value: 3299.0493\n",
      "Current loss value: 3344.9072\n",
      "Current loss value: 3390.7656\n",
      "Current loss value: 3436.5918\n",
      "Current loss value: 3482.3901\n",
      "Current loss value: 3528.2036\n",
      "Current loss value: 3574.0032\n",
      "Current loss value: 3619.7874\n",
      "Filter 32 processed in 6s\n",
      "Processing filter 33\n",
      "Current loss value: 54.183277\n",
      "Current loss value: 66.88511\n",
      "Current loss value: 78.60645\n",
      "Current loss value: 89.65166\n",
      "Current loss value: 100.0703\n",
      "Current loss value: 110.014656\n",
      "Current loss value: 119.528046\n",
      "Current loss value: 128.87027\n",
      "Current loss value: 137.89487\n",
      "Current loss value: 146.67052\n",
      "Current loss value: 155.10068\n",
      "Current loss value: 163.37668\n",
      "Current loss value: 171.71432\n",
      "Current loss value: 180.0368\n",
      "Current loss value: 188.51419\n",
      "Current loss value: 196.61089\n",
      "Current loss value: 204.81453\n",
      "Current loss value: 212.96713\n",
      "Current loss value: 221.27602\n",
      "Current loss value: 229.1955\n",
      "Filter 33 processed in 6s\n",
      "Processing filter 34\n",
      "Current loss value: -6923.451\n",
      "Filter 34 processed in 6s\n",
      "Processing filter 35\n",
      "Current loss value: 2883.8901\n",
      "Current loss value: 2939.9358\n",
      "Current loss value: 2995.9526\n",
      "Current loss value: 3051.9072\n",
      "Current loss value: 3107.8296\n",
      "Current loss value: 3163.7073\n",
      "Current loss value: 3219.5635\n",
      "Current loss value: 3275.4167\n",
      "Current loss value: 3331.2258\n",
      "Current loss value: 3387.0059\n",
      "Current loss value: 3442.7295\n",
      "Current loss value: 3498.4133\n",
      "Current loss value: 3554.0625\n",
      "Current loss value: 3609.712\n",
      "Current loss value: 3665.3457\n",
      "Current loss value: 3720.9614\n",
      "Current loss value: 3776.585\n",
      "Current loss value: 3832.2097\n",
      "Current loss value: 3887.8135\n",
      "Current loss value: 3943.4226\n",
      "Filter 35 processed in 6s\n",
      "Processing filter 36\n",
      "Current loss value: -5903.6987\n",
      "Filter 36 processed in 6s\n",
      "Processing filter 37\n",
      "Current loss value: -4797.8955\n",
      "Filter 37 processed in 6s\n",
      "Processing filter 38\n",
      "Current loss value: -1335.078\n",
      "Filter 38 processed in 6s\n",
      "Processing filter 39\n",
      "Current loss value: -1134.7068\n",
      "Filter 39 processed in 6s\n",
      "Processing filter 40\n",
      "Current loss value: 1716.0938\n",
      "Current loss value: 1755.4673\n",
      "Current loss value: 1794.667\n",
      "Current loss value: 1833.7488\n",
      "Current loss value: 1872.7183\n",
      "Current loss value: 1911.6891\n",
      "Current loss value: 1950.6685\n",
      "Current loss value: 1989.5725\n",
      "Current loss value: 2028.345\n",
      "Current loss value: 2067.0896\n",
      "Current loss value: 2105.8503\n",
      "Current loss value: 2144.5525\n",
      "Current loss value: 2183.273\n",
      "Current loss value: 2221.9717\n",
      "Current loss value: 2260.68\n",
      "Current loss value: 2299.401\n",
      "Current loss value: 2338.1572\n",
      "Current loss value: 2376.942\n",
      "Current loss value: 2415.7515\n",
      "Current loss value: 2454.6074\n",
      "Filter 40 processed in 6s\n",
      "Processing filter 41\n",
      "Current loss value: 1359.4156\n",
      "Current loss value: 1393.7041\n",
      "Current loss value: 1427.077\n",
      "Current loss value: 1459.6024\n",
      "Current loss value: 1491.3745\n",
      "Current loss value: 1522.4958\n",
      "Current loss value: 1553.098\n",
      "Current loss value: 1583.1805\n",
      "Current loss value: 1612.847\n",
      "Current loss value: 1641.9915\n",
      "Current loss value: 1670.7649\n",
      "Current loss value: 1699.4875\n",
      "Current loss value: 1727.8665\n",
      "Current loss value: 1755.845\n",
      "Current loss value: 1783.8992\n",
      "Current loss value: 1811.4672\n",
      "Current loss value: 1839.1489\n",
      "Current loss value: 1866.6787\n",
      "Current loss value: 1894.064\n",
      "Current loss value: 1921.1981\n",
      "Filter 41 processed in 7s\n",
      "Processing filter 42\n",
      "Current loss value: -4500.1367\n",
      "Filter 42 processed in 6s\n",
      "Processing filter 43\n",
      "Current loss value: -3559.4204\n",
      "Filter 43 processed in 6s\n",
      "Processing filter 44\n",
      "Current loss value: -58.98313\n",
      "Filter 44 processed in 6s\n",
      "Processing filter 45\n",
      "Current loss value: -4706.4736\n",
      "Filter 45 processed in 6s\n",
      "Processing filter 46\n",
      "Current loss value: 556.3346\n",
      "Current loss value: 570.89465\n",
      "Current loss value: 585.1769\n",
      "Current loss value: 599.2813\n",
      "Current loss value: 613.21814\n",
      "Current loss value: 626.96936\n",
      "Current loss value: 640.58356\n",
      "Current loss value: 654.05774\n",
      "Current loss value: 667.4387\n",
      "Current loss value: 680.7333\n",
      "Current loss value: 693.8883\n",
      "Current loss value: 706.9628\n",
      "Current loss value: 719.9034\n",
      "Current loss value: 732.8409\n",
      "Current loss value: 745.6928\n",
      "Current loss value: 758.47925\n",
      "Current loss value: 771.23486\n",
      "Current loss value: 783.90656\n",
      "Current loss value: 796.6001\n",
      "Current loss value: 809.2622\n",
      "Filter 46 processed in 7s\n",
      "Processing filter 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 838.08984\n",
      "Current loss value: 869.3434\n",
      "Current loss value: 900.12305\n",
      "Current loss value: 930.6308\n",
      "Current loss value: 960.87585\n",
      "Current loss value: 990.8953\n",
      "Current loss value: 1020.55597\n",
      "Current loss value: 1050.0554\n",
      "Current loss value: 1079.3867\n",
      "Current loss value: 1108.5444\n",
      "Current loss value: 1137.5132\n",
      "Current loss value: 1166.1263\n",
      "Current loss value: 1194.4976\n",
      "Current loss value: 1222.5474\n",
      "Current loss value: 1250.3654\n",
      "Current loss value: 1278.034\n",
      "Current loss value: 1305.3038\n",
      "Current loss value: 1332.4664\n",
      "Current loss value: 1359.3301\n",
      "Current loss value: 1386.054\n",
      "Filter 47 processed in 7s\n",
      "Processing filter 48\n",
      "Current loss value: -3120.605\n",
      "Filter 48 processed in 6s\n",
      "Processing filter 49\n",
      "Current loss value: -6840.5244\n",
      "Filter 49 processed in 6s\n",
      "Processing filter 50\n",
      "Current loss value: -5997.802\n",
      "Filter 50 processed in 6s\n",
      "Processing filter 51\n",
      "Current loss value: -5268.014\n",
      "Filter 51 processed in 6s\n",
      "Processing filter 52\n",
      "Current loss value: -3854.1611\n",
      "Filter 52 processed in 6s\n",
      "Processing filter 53\n",
      "Current loss value: 2305.019\n",
      "Current loss value: 2346.4487\n",
      "Current loss value: 2388.1885\n",
      "Current loss value: 2430.294\n",
      "Current loss value: 2472.74\n",
      "Current loss value: 2515.4773\n",
      "Current loss value: 2558.506\n",
      "Current loss value: 2601.7805\n",
      "Current loss value: 2645.3188\n",
      "Current loss value: 2689.0793\n",
      "Current loss value: 2733.0366\n",
      "Current loss value: 2777.2656\n",
      "Current loss value: 2821.6956\n",
      "Current loss value: 2866.3108\n",
      "Current loss value: 2911.1145\n",
      "Current loss value: 2956.1313\n",
      "Current loss value: 3001.2925\n",
      "Current loss value: 3046.6316\n",
      "Current loss value: 3092.1377\n",
      "Current loss value: 3137.7837\n",
      "Filter 53 processed in 7s\n",
      "Processing filter 54\n",
      "Current loss value: -1950.0781\n",
      "Filter 54 processed in 6s\n",
      "Processing filter 55\n",
      "Current loss value: 729.74146\n",
      "Current loss value: 748.4824\n",
      "Current loss value: 766.9881\n",
      "Current loss value: 785.31104\n",
      "Current loss value: 803.36896\n",
      "Current loss value: 821.2168\n",
      "Current loss value: 838.95654\n",
      "Current loss value: 856.5238\n",
      "Current loss value: 874.06055\n",
      "Current loss value: 891.5393\n",
      "Current loss value: 909.0051\n",
      "Current loss value: 926.39374\n",
      "Current loss value: 943.7484\n",
      "Current loss value: 961.067\n",
      "Current loss value: 978.34644\n",
      "Current loss value: 995.58734\n",
      "Current loss value: 1012.75104\n",
      "Current loss value: 1029.9768\n",
      "Current loss value: 1047.1855\n",
      "Current loss value: 1064.4125\n",
      "Filter 55 processed in 7s\n",
      "Processing filter 56\n",
      "Current loss value: -237.17694\n",
      "Filter 56 processed in 6s\n",
      "Processing filter 57\n",
      "Current loss value: -1073.1246\n",
      "Filter 57 processed in 6s\n",
      "Processing filter 58\n",
      "Current loss value: 6102.0166\n",
      "Current loss value: 6200.1104\n",
      "Current loss value: 6298.2666\n",
      "Current loss value: 6396.497\n",
      "Current loss value: 6494.833\n",
      "Current loss value: 6593.2695\n",
      "Current loss value: 6691.781\n",
      "Current loss value: 6790.3677\n",
      "Current loss value: 6889.001\n",
      "Current loss value: 6987.6914\n",
      "Current loss value: 7086.4688\n",
      "Current loss value: 7185.3286\n",
      "Current loss value: 7284.267\n",
      "Current loss value: 7383.2656\n",
      "Current loss value: 7482.318\n",
      "Current loss value: 7581.426\n",
      "Current loss value: 7680.617\n",
      "Current loss value: 7779.8613\n",
      "Current loss value: 7879.165\n",
      "Current loss value: 7978.524\n",
      "Filter 58 processed in 7s\n",
      "Processing filter 59\n",
      "Current loss value: 7.995247\n",
      "Current loss value: 30.850815\n",
      "Current loss value: 52.679092\n",
      "Current loss value: 73.610344\n",
      "Current loss value: 93.86001\n",
      "Current loss value: 113.680824\n",
      "Current loss value: 133.07474\n",
      "Current loss value: 152.15277\n",
      "Current loss value: 170.73083\n",
      "Current loss value: 188.74332\n",
      "Current loss value: 206.0279\n",
      "Current loss value: 222.89877\n",
      "Current loss value: 239.5077\n",
      "Current loss value: 255.94409\n",
      "Current loss value: 272.05994\n",
      "Current loss value: 288.15448\n",
      "Current loss value: 303.99872\n",
      "Current loss value: 319.5501\n",
      "Current loss value: 335.00098\n",
      "Current loss value: 350.15112\n",
      "Filter 59 processed in 7s\n",
      "Processing filter 60\n",
      "Current loss value: -3968.4568\n",
      "Filter 60 processed in 6s\n",
      "Processing filter 61\n",
      "Current loss value: -11293.522\n",
      "Filter 61 processed in 6s\n",
      "Processing filter 62\n",
      "Current loss value: -1672.7706\n",
      "Filter 62 processed in 6s\n",
      "Processing filter 63\n",
      "Current loss value: -902.4741\n",
      "Filter 63 processed in 6s\n"
     ]
    }
   ],
   "source": [
    "'''Visualization of the filters of VGG16, via gradient ascent in input space.\n",
    "This script can run on CPU in a few minutes.\n",
    "Results example: http://i.imgur.com/4nj4KjN.jpg\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from scipy.misc import imsave\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.applications import vgg16\n",
    "from keras import backend as K\n",
    "\n",
    "# dimensions of the generated pictures for each filter.\n",
    "img_width = 64\n",
    "img_height = 64\n",
    "\n",
    "# the name of the layer we want to visualize\n",
    "# (see model definition at keras/applications/vgg16.py)\n",
    "layer_name = 'conv2d_12'\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "# build the VGG16 network with ImageNet weights\n",
    "print('Model loaded.')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# this is the placeholder for the input images\n",
    "input_img = model.input\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())\n",
    "\n",
    "\n",
    "kept_filters = []\n",
    "for filter_index in range(64):\n",
    "    # we only scan through the first 200 filters,\n",
    "    # but there are actually 512 of them\n",
    "    print('Processing filter %d' % filter_index)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # we build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads = normalize(grads)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "    # step size for gradient ascent\n",
    "    step = 1.\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_img_data = np.random.random((1, 3, img_width, img_height))\n",
    "    else:\n",
    "        input_img_data = np.random.random((1, img_width, img_height, 3))\n",
    "    input_img_data = (input_img_data - 0.5) * 60 + 64\n",
    "    \n",
    "\n",
    "    # we run gradient ascent for 20 steps\n",
    "    for i in range(20):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "\n",
    "        print('Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            break\n",
    "\n",
    "    # decode the resulting input image\n",
    "    if loss_value > 0:\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        kept_filters.append((img, loss_value))\n",
    "    end_time = time.time()\n",
    "    print('Filter %d processed in %ds' % (filter_index, end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HOU\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\ipykernel_launcher.py:25: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# we will stich the best 64 filters on a 8 x 8 grid.\n",
    "n = 4\n",
    "\n",
    "# the filters that have the highest loss are assumed to be better-looking.\n",
    "# we will only keep the top 64 filters.\n",
    "kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "kept_filters = kept_filters[:n * n]\n",
    "\n",
    "# build a black picture with enough space for\n",
    "# our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "margin =1\n",
    "width = n * img_width + (n - 1) * margin\n",
    "height = n * img_height + (n - 1) * margin\n",
    "stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "# fill the picture with our saved filters\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        img, loss = kept_filters[i * n + j]\n",
    "        stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n",
    "                         (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n",
    "\n",
    "# save the result to disk\n",
    "imsave('64stitched_filters3_%dx%d.png' % (n, n), stitched_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CV.nn.conv.LeNet import LeNet\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import backend as K\n",
    "from CV.preprocessing.ImageToArrayPreprocessor import ImageToArrayPreprocessor\n",
    "from CV.preprocessing.SimplePreprocessor import SimplePreprocessor\n",
    "from CV.datasets.SimpleDatasetLoader import SimpleDatasetLoader\n",
    "from CV.nn.conv.ShallowNet import ShallowNet\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "import argparse \n",
    "from CV.nn.conv.MiniVGGNet import MiniVGGNet\n",
    "imagePaths = list(paths.list_images(\"C:/Users/HOU/Documents/practical_bundle/TrainSet/05s_filter/\"))\n",
    "\n",
    "sp = SimplePreprocessor(size,size)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "\n",
    "sdl = SimpleDatasetLoader(preprocessors=[sp, iap])\n",
    "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
    "\n",
    "data = data-255.0\n",
    "data = data.astype(\"float\") / 50\n",
    "#if K.image_data_format() == \"channels_first\":\n",
    "#    data = data.reshape(data.shape[0],1,28,28)\n",
    "#else:\n",
    "#    data = data.reshape(data.shape[0], 28, 28, 1)\n",
    "    \n",
    "\n",
    "(train_X, test_X, train_y, test_y) = train_test_split(data,\n",
    "                               labels, test_size=.5,\n",
    "                                                     random_state=21)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 64, 64, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "                                                                precision    recall  f1-score   support\n",
      "\n",
      "C:/Users/HOU/Documents/practical_bundle/TrainSet/05s_filter/00       0.48      0.25      0.33        55\n",
      "C:/Users/HOU/Documents/practical_bundle/TrainSet/05s_filter/11       0.53      0.75      0.62        61\n",
      "\n",
      "                                                   avg / total       0.51      0.52      0.48       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "lb = LabelBinarizer()\n",
    "#train_y = lb.fit_transform(train_y)\n",
    "#test_y = lb.fit_transform(test_y)\n",
    "lb.fit(train_y)\n",
    "train_y=lb.transform(train_y)\n",
    "test_y = lb.transform(test_y)\n",
    "train_y = to_categorical(train_y, num_classes=2)\n",
    "test_y = to_categorical(test_y, num_classes=2)\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications import Xception # TensorFlow ONLY\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import VGG19\n",
    "#lb = LabelBinarizer()\n",
    "#train_y = lb.fit_transform(train_y)\n",
    "#test_y = lb.fit_transform(test_y)\n",
    "\n",
    "EPOCHS = 7\n",
    "INIT_LR = 1e-3\n",
    "BS = 128\n",
    "# initialize the optimizer and model\n",
    "#print(\"[INFO] compiling model...\")\n",
    "#opt = SGD(lr=0.01, decay=0.01/40, momentum=0.9,nesterov=True)\n",
    "#opt = Adam(lr=0.05, decay=0.05 / 25)\n",
    "#opt = SGD(lr=0.05)\n",
    "#opt = SGD(lr=0.05, decay=0.05/20, momentum=0.9,nesterov=True)\n",
    "#model = MiniVGGNet.build(width=28, height=28, depth=3, classes=2)\n",
    "#model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "#metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "#print(\"[INFO] training network...\")\n",
    "#H = model.fit(train_X, train_y,# validation_data=(test_X, test_y),\n",
    "#    batch_size=BS, epochs=EPOCHS, verbose=1)\n",
    "\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(test_X, batch_size=BS)\n",
    "print(classification_report(test_y.argmax(axis=1),predictions.argmax(axis=1),\n",
    "      target_names=[str(x) for x in lb.classes_]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
