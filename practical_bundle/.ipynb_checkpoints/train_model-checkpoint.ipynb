{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "usage: ipykernel_launcher.py [-h] -o OUTPUT -m MODELS [-n NUM_MODELS]\n",
      "ipykernel_launcher.py: error: the following arguments are required: -o/--output, -m/--models\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HOU\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from CV.nn.conv.MiniVGGNet import MiniVGGNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-o\", \"--output\", required=True,\n",
    "    help=\"path to output directory\")\n",
    "ap.add_argument(\"-m\", \"--models\", required=True,\n",
    "    help=\"path to output models directory\")\n",
    "ap.add_argument(\"-n\", \"--num-models\", type=int, default=5,\n",
    "    help=\"# of models to train\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# load the training and testing data, then scale it into the\n",
    "# range [0, 1]\n",
    "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
    "trainX = trainX.astype(\"float\") / 255.0\n",
    "testX = testX.astype(\"float\") / 255.0\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "# initialize the label names for the CIFAR-10 dataset\n",
    "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=10, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, horizontal_flip=True,\n",
    "                         fill_mode=\"nearest\")\n",
    "\n",
    "# loop over the number of models to train\n",
    "for i in np.arange(0, args[\"num_models\"]):\n",
    "    # initialize the optimizer and model\n",
    "    print(\"[INFO] training model {}/{}\".format(i + 1,\n",
    "        args[\"num_models\"]))\n",
    "    opt = SGD(lr=0.01, decay=0.01 / 40, momentum=0.9,\n",
    "        nesterov=True)\n",
    "    model = MiniVGGNet.build(width=32, height=32, depth=3,\n",
    "        classes=10)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "        metrics=[\"accuracy\"])\n",
    "    # train the network\n",
    "    # train the network\n",
    "    H = model.fit_generator(aug.flow(trainX, trainY, batch_size=64),\n",
    "        validation_data=(testX, testY), epochs=40,\n",
    "        steps_per_epoch=len(trainX) // 64, verbose=1)\n",
    "\n",
    "    # save the model to disk\n",
    "    p = [args[\"models\"], \"model_{}.model\".format(i)]\n",
    "    model.save(os.path.sep.join(p))\n",
    "    \n",
    "    # evaluate the network\n",
    "    predictions = model.predict(testX, batch_size=64)\n",
    "    report = classification_report(testY.argmax(axis=1),\n",
    "        predictions.argmax(axis=1), target_names=labelNames)\n",
    "\n",
    "    # save the classification report to file\n",
    "    p = [args[\"output\"], \"model_{}.txt\".format(i)]\n",
    "    f = open(os.path.sep.join(p), \"w\")\n",
    "    f.write(report)\n",
    "    f.close()\n",
    "    \n",
    "    # plot the training loss and accuracy\n",
    "    p = [args[\"output\"], \"model_{}.png\".format(i)]\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, 40), H.history[\"loss\"],\n",
    "        label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, 40), H.history[\"val_loss\"],\n",
    "        label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, 40), H.history[\"acc\"],\n",
    "        label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, 40), H.history[\"val_acc\"],\n",
    "        label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy for model {}\".format(i))\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.sep.join(p))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
