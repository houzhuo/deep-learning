{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HOU\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\sklearn\\preprocessing\\data.py:181: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0 0.5 [0.26]\n",
      "3 1.5 2.0 [1.64]\n",
      "4 2.0 2.5 [2.27]\n",
      "7 3.5 4.0 [3.53]\n",
      "8 4.0 4.5 [4.04]\n",
      "11 5.5 6.0 [5.96]\n",
      "12 6.0 6.5 [6.44]\n",
      "13 6.5 7.0 [6.755]\n",
      "16 8.0 8.5 [8.36]\n",
      "24 12.0 12.5 [12.185]\n",
      "31 15.5 16.0 [15.62]\n",
      "36 18.0 18.5 [18.29]\n",
      "38 19.0 19.5 [19.145]\n",
      "39 19.5 20.0 [19.895]\n",
      "40 20.0 20.5 [20.06]\n",
      "41 20.5 21.0 [20.855]\n",
      "42 21.0 21.5 [21.44]\n",
      "43 21.5 22.0 [21.86]\n",
      "45 22.5 23.0 [22.82]\n",
      "48 24.0 24.5 [24.425]\n",
      "51 25.5 26.0 [25.7]\n",
      "52 26.0 26.5 [26.33]\n",
      "54 27.0 27.5 [27.02]\n",
      "55 27.5 28.0 [27.86]\n",
      "56 28.0 28.5 [28.49]\n",
      "57 28.5 29.0 [28.91]\n",
      "61 30.5 31.0 [30.515]\n",
      "64 32.0 32.5 [32.27]\n",
      "72 36.0 36.5 [36.095]\n",
      "78 39.0 39.5 [39.05]\n",
      "79 39.5 40.0 [39.53]\n",
      "80 40.0 40.5 [40.445]\n",
      "81 40.5 41.0 [40.865]\n",
      "82 41.0 41.5 [41.435]\n",
      "83 41.5 42.0 [41.855]\n",
      "84 42.0 42.5 [42.035]\n",
      "85 42.5 43.0 [42.725]\n",
      "86 43.0 43.5 [43.355]\n",
      "87 43.5 44.0 [43.805]\n",
      "88 44.0 44.5 [44.06]\n",
      "90 45.0 45.5 [45.08]\n",
      "91 45.5 46.0 [45.53]\n",
      "92 46.0 46.5 [46.22]\n",
      "95 47.5 48.0 [47.885]\n",
      "96 48.0 48.5 [48.365]\n",
      "98 49.0 49.5 [49.055]\n",
      "99 49.5 50.0 [49.85]\n",
      "105 52.5 53.0 [52.7]\n",
      "107 53.5 54.0 [53.66]\n",
      "109 54.5 55.0 [54.62]\n",
      "113 56.5 57.0 [56.54]\n",
      "115 57.5 58.0 [57.83]\n",
      "118 59.0 59.5 [59.465]\n",
      "120 60.0 60.5 [60.44]\n",
      "122 61.0 61.5 [61.415]\n",
      "123 61.5 62.0 [61.88]\n",
      "125 62.5 63.0 [62.705]\n",
      "126 63.0 63.5 [63.365]\n",
      "127 63.5 64.0 [63.635]\n",
      "128 64.0 64.5 [64.49]\n",
      "131 65.5 66.0 [65.675]\n",
      "132 66.0 66.5 [66.14]\n",
      "133 66.5 67.0 [66.53]\n",
      "134 67.0 67.5 [67.355]\n",
      "135 67.5 68.0 [67.625]\n",
      "136 68.0 68.5 [68.12]\n",
      "137 68.5 69.0 [68.555]\n",
      "138 69.0 69.5 [69.17]\n",
      "139 69.5 70.0 [69.575]\n",
      "140 70.0 70.5 [70.235]\n",
      "141 70.5 71.0 [70.865]\n",
      "142 71.0 71.5 [71.165]\n",
      "143 71.5 72.0 [71.975]\n",
      "144 72.0 72.5 [72.08]\n",
      "145 72.5 73.0 [72.605]\n",
      "146 73.0 73.5 [73.19]\n",
      "147 73.5 74.0 [73.52]\n",
      "148 74.0 74.5 [74.09]\n",
      "149 74.5 75.0 [74.615]\n",
      "150 75.0 75.5 [75.245]\n",
      "151 75.5 76.0 [75.62]\n",
      "152 76.0 76.5 [76.115]\n",
      "153 76.5 77.0 [76.865]\n",
      "154 77.0 77.5 [77.075]\n",
      "155 77.5 78.0 [77.855]\n",
      "156 78.0 78.5 [78.455]\n",
      "157 78.5 79.0 [78.635]\n",
      "158 79.0 79.5 [79.01]\n",
      "159 79.5 80.0 [79.76]\n",
      "160 80.0 80.5 [80.06]\n",
      "162 81.0 81.5 [81.44]\n",
      "163 81.5 82.0 [81.92]\n",
      "164 82.0 82.5 [82.43]\n",
      "166 83.0 83.5 [83.105]\n",
      "167 83.5 84.0 [83.735]\n",
      "168 84.0 84.5 [84.47]\n",
      "169 84.5 85.0 [84.725]\n",
      "170 85.0 85.5 [85.4]\n",
      "171 85.5 86.0 [85.655]\n",
      "172 86.0 86.5 [86.375]\n",
      "173 86.5 87.0 [86.69]\n",
      "174 87.0 87.5 [87.035]\n",
      "175 87.5 88.0 [87.785]\n",
      "176 88.0 88.5 [88.415]\n",
      "177 88.5 89.0 [88.67]\n",
      "178 89.0 89.5 [89.24]\n",
      "179 89.5 90.0 [89.525]\n",
      "181 90.5 91.0 [90.86]\n",
      "182 91.0 91.5 [91.01]\n",
      "183 91.5 92.0 [91.64]\n",
      "184 92.0 92.5 [92.165]\n",
      "186 93.0 93.5 [93.095]\n",
      "187 93.5 94.0 [93.77]\n",
      "188 94.0 94.5 [94.085]\n",
      "189 94.5 95.0 [94.565]\n",
      "190 95.0 95.5 [95.255]\n",
      "191 95.5 96.0 [95.915]\n",
      "193 96.5 97.0 [96.59]\n",
      "194 97.0 97.5 [97.205]\n",
      "195 97.5 98.0 [97.7]\n",
      "196 98.0 98.5 [98.06]\n",
      "197 98.5 99.0 [98.66]\n",
      "198 99.0 99.5 [99.35]\n",
      "199 99.5 100.0 [99.515]\n",
      "200 100.0 100.5 [100.07]\n",
      "201 100.5 101.0 [100.7]\n",
      "202 101.0 101.5 [101.24]\n",
      "203 101.5 102.0 [101.885]\n",
      "204 102.0 102.5 [102.2]\n",
      "205 102.5 103.0 [102.62]\n",
      "211 105.5 106.0 [105.95]\n",
      "212 106.0 106.5 [106.1]\n",
      "214 107.0 107.5 [107.225]\n",
      "215 107.5 108.0 [107.705]\n",
      "217 108.5 109.0 [108.695]\n",
      "218 109.0 109.5 [109.175]\n",
      "220 110.0 110.5 [110.165]\n",
      "227 113.5 114.0 [113.99]\n",
      "231 115.5 116.0 [115.865]\n",
      "232 116.0 116.5 [116.18]\n",
      "234 117.0 117.5 [117.17]\n",
      "235 117.5 118.0 [117.575]\n",
      "236 118.0 118.5 [118.04]\n",
      "237 118.5 119.0 [118.73]\n",
      "238 119.0 119.5 [119.045]\n",
      "239 119.5 120.0 [119.6]\n",
      "240 120.0 120.5 [120.395]\n",
      "241 120.5 121.0 [120.8]\n",
      "242 121.0 121.5 [121.115]\n",
      "243 121.5 122.0 [121.67]\n",
      "244 122.0 122.5 [122.15]\n",
      "245 122.5 123.0 [122.54]\n",
      "246 123.0 123.5 [123.035]\n",
      "247 123.5 124.0 [123.665]\n",
      "248 124.0 124.5 [124.16]\n",
      "250 125.0 125.5 [125.06]\n",
      "252 126.0 126.5 [126.11]\n",
      "253 126.5 127.0 [126.77]\n",
      "254 127.0 127.5 [127.025]\n",
      "255 127.5 128.0 [127.505]\n",
      "256 128.0 128.5 [128.345]\n",
      "257 128.5 129.0 [128.735]\n",
      "258 129.0 129.5 [129.29]\n",
      "259 129.5 130.0 [129.62]\n",
      "260 130.0 130.5 [130.16]\n",
      "261 130.5 131.0 [130.745]\n",
      "262 131.0 131.5 [131.195]\n",
      "263 131.5 132.0 [131.645]\n",
      "264 132.0 132.5 [132.215]\n",
      "265 132.5 133.0 [132.875]\n",
      "266 133.0 133.5 [133.13]\n",
      "267 133.5 134.0 [133.58]\n",
      "268 134.0 134.5 [134.105]\n",
      "269 134.5 135.0 [134.585]\n",
      "273 136.5 137.0 [136.94]\n",
      "274 137.0 137.5 [137.255]\n",
      "275 137.5 138.0 [137.63]\n",
      "276 138.0 138.5 [138.005]\n",
      "277 138.5 139.0 [138.785]\n",
      "279 139.5 140.0 [139.61]\n",
      "280 140.0 140.5 [140.345]\n",
      "281 140.5 141.0 [140.69]\n",
      "282 141.0 141.5 [141.005]\n",
      "283 141.5 142.0 [141.965]\n",
      "284 142.0 142.5 [142.445]\n",
      "286 143.0 143.5 [143.105]\n",
      "287 143.5 144.0 [143.57]\n",
      "288 144.0 144.5 [144.2]\n",
      "289 144.5 145.0 [144.56]\n",
      "290 145.0 145.5 [145.04]\n",
      "291 145.5 146.0 [145.52]\n",
      "292 146.0 146.5 [146.255]\n",
      "293 146.5 147.0 [146.735]\n",
      "294 147.0 147.5 [147.125]\n",
      "295 147.5 148.0 [147.62]\n",
      "296 148.0 148.5 [148.085]\n",
      "297 148.5 149.0 [148.505]\n",
      "298 149.0 149.5 [149.045]\n",
      "299 149.5 150.0 [149.66]\n",
      "300 150.0 150.5 [150.11]\n",
      "301 150.5 151.0 [150.65]\n",
      "302 151.0 151.5 [151.055]\n",
      "303 151.5 152.0 [151.97]\n",
      "305 152.5 153.0 [152.63]\n",
      "306 153.0 153.5 [153.08]\n",
      "307 153.5 154.0 [153.665]\n",
      "308 154.0 154.5 [154.055]\n",
      "309 154.5 155.0 [154.64]\n",
      "310 155.0 155.5 [155.15]\n",
      "311 155.5 156.0 [155.66]\n",
      "314 157.0 157.5 [157.235]\n",
      "315 157.5 158.0 [157.565]\n",
      "316 158.0 158.5 [158.105]\n",
      "317 158.5 159.0 [158.525]\n",
      "318 159.0 159.5 [159.155]\n",
      "319 159.5 160.0 [159.635]\n",
      "320 160.0 160.5 [160.115]\n",
      "321 160.5 161.0 [160.775]\n",
      "322 161.0 161.5 [161.09]\n",
      "324 162.0 162.5 [162.005]\n",
      "325 162.5 163.0 [162.725]\n",
      "326 163.0 163.5 [163.04]\n",
      "327 163.5 164.0 [163.52]\n",
      "329 164.5 165.0 [164.63]\n",
      "330 165.0 165.5 [165.11]\n",
      "331 165.5 166.0 [165.59]\n",
      "332 166.0 166.5 [166.1]\n",
      "333 166.5 167.0 [166.76]\n",
      "334 167.0 167.5 [167.075]\n",
      "338 169.0 169.5 [169.205]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for 'block5_pool/MaxPool' (op: 'MaxPool') with input shapes: [?,1,1,512].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1566\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1567\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1568\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'block5_pool/MaxPool' (op: 'MaxPool') with input shapes: [?,1,1,512].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a4892420fe9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m baseModel = VGG16(weights=\"imagenet\", include_top=False,\n\u001b[1;32m--> 102\u001b[1;33m                  input_tensor=Input(shape=(24,24,3)))\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;31m#baseModel = VGG16(weights=\"imagenet\", include_top=False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\applications\\vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'block5_conv2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'block5_conv3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'block5_pool'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 619\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    156\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                                         data_format=self.data_format)\n\u001b[0m\u001b[0;32m    159\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36m_pooling_function\u001b[1;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[0;32m    219\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[0;32m    220\u001b[0m                           \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m                           pool_mode='max')\n\u001b[0m\u001b[0;32m    222\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[1;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[0;32m   3661\u001b[0m         x = tf.nn.max_pool(x, pool_size, strides,\n\u001b[0;32m   3662\u001b[0m                            \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3663\u001b[1;33m                            data_format=tf_data_format)\n\u001b[0m\u001b[0;32m   3664\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'avg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3665\u001b[0m         x = tf.nn.avg_pool(x, pool_size, strides,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(value, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m   2140\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2142\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   2143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m   5043\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m   5044\u001b[0m         \u001b[1;34m\"MaxPool\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5045\u001b[1;33m         data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m   5046\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5047\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3392\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3394\u001b[0m       \u001b[1;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1734\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1735\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1568\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'block5_pool/MaxPool' (op: 'MaxPool') with input shapes: [?,1,1,512]."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from CV.preprocessing.ImageToArrayPreprocessor import ImageToArrayPreprocessor\n",
    "from CV.preprocessing.aspectawarepreprocessor import AspectAwarePreprocessor\n",
    "from CV.datasets.SimpleDatasetLoader import SimpleDatasetLoader\n",
    "from CV.nn.conv.fcheadnet import FCHeadNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "full = pd.read_csv('C:/Users/HOU/Documents/practical_bundle/origin/sugisakaya48de1-4.csv')\n",
    "label= pd.read_csv('C:/Users/HOU/Documents/practical_bundle/origin/keyf0713.csv')\n",
    "\n",
    "full = preprocessing.scale(full)\n",
    "full[:3]\n",
    "full = preprocessing.normalize(full, norm='l2')\n",
    "\n",
    "'''aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "                        height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                        horizontal_flip=True, fill_mode=\"nearest\")'''\n",
    "\n",
    "# # grab the list of images that we’ll be describing, then extract\n",
    "# # the class label names from the image paths\n",
    "# print(\"[INFO] loading images...\")\n",
    "# imagePaths = list(paths.list_images(\"data3\"))\n",
    "# classNames = [pt.split(os.path.sep)[-2] for pt in imagePaths]\n",
    "# classNames = [str(x) for x in np.unique(classNames)]\n",
    "\n",
    "# # initialize the image preprocessors\n",
    "# aap = AspectAwarePreprocessor(128,128)\n",
    "# iap = ImageToArrayPreprocessor()\n",
    "\n",
    "# # load the dataset from disk then scale the raw pixel intensities to\n",
    "# # the range [0, 1]\n",
    "\n",
    "# sdl = SimpleDatasetLoader(preprocessors=[aap, iap])\n",
    "# (data, labels) = sdl.load(imagePaths, verbose = 500)\n",
    "# data = data.astype(\"float\")/255.0\n",
    "\n",
    "# (trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "#     test_size=0.1, random_state=42)\n",
    "\n",
    "# #convert the labels from integers to vectors\n",
    "# #trainY = LabelBinarizer().fit_transform(trainY)\n",
    "# #testY = LabelBinarizer().fit_transform(testY)\n",
    "\n",
    "list=[]\n",
    "n=0\n",
    "for i in range(int(full.shape[0]/24)):\n",
    "    for j in range(label.shape[0]):\n",
    "        if (i)*0.5 <label.values[j] and ((i+1)*0.5)>label.values[j]:\n",
    "            n=n+1\n",
    "            #print(i,i*0.5,(i+1)*0.5,label.values[j])\n",
    "            list.append(i)\n",
    "            break;\n",
    "    \n",
    "            \n",
    "data=[]\n",
    "labels=[]\n",
    "n=0\n",
    "for i in range(int(full.shape[0]/24)):\n",
    "    if i in list:\n",
    "        data.append(full[i*24:(i+1)*24])\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        data.append(full[i*24:(i+1)*24])\n",
    "        labels.append(0) \n",
    "\n",
    "data = np.array(data)\n",
    "\n",
    "data = data.reshape(data.shape[0], 24, 24, 1)\n",
    "\n",
    "(train_X, test_X, trainY, testY) = train_test_split(data,\n",
    "                               labels, test_size=.2,random_state=27)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "lb = LabelBinarizer()\n",
    "#train_y = lb.fit_transform(train_y)\n",
    "#test_y = lb.fit_transform(test_y)\n",
    "lb.fit(trainY)\n",
    "trainY=lb.transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "trainY = to_categorical(trainY, num_classes=2)\n",
    "testY = to_categorical(testY, num_classes=2)\n",
    "\n",
    "# load the VGG16 network, ensuring the head FC layer sets are left\n",
    "# off\n",
    "\n",
    "baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
    "                 input_tensor=Input(shape=(24,24,3)))\n",
    "#baseModel = VGG16(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# initialize the new head of the network, a set of FC layers\n",
    "# followed by a softmax classifier\n",
    "headModel = FCHeadNet.build(baseModel, len(classNames),256)\n",
    "\n",
    "# place the head FC model on top of the base model -- this will\n",
    "# become the actual model we will train\n",
    "model = Model(inputs=baseModel.input, output = headModel)\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they\n",
    "# will *not* be updated during the training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# compile our model (this needs to be done after our setting our\n",
    "# layers to being non-trainable\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = RMSprop(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=opt,\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network for a few epochs (all other\n",
    "# layers are frozen) -- this will allow the new FC layers to\n",
    "# start to become initialized with actual \"learned\" values\n",
    "# versus pure random\n",
    "print(\"[INFO] training head...\")\n",
    "'''model.fit_generator(aug.flow(trainX, trainY, batch_size=32),\n",
    "    validation_data=(testX, testY), epochs=25,\n",
    "    steps_per_epoch=len(trainX) // 32, verbose=1)'''\n",
    "model.fit(trainX, trainY, batch_size=32,\n",
    "    validation_data=(testX, testY), epochs=10,\n",
    "     verbose=1)\n",
    "# evaluate the network after initialization\n",
    "print(\"[INFO] evaluating after initialization...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1),target_names=classNames))\n",
    "\n",
    "\n",
    "# now that the head FC layers have been trained/initialized, lets\n",
    "# unfreeze the final set of CONV layers and make them trainable\n",
    "for layer in baseModel.layers[15:]:\n",
    "    layer.trainable = True\n",
    "# 用小lr的sgd重新finetune\n",
    "print(\"[INFO] re-compile model...\")\n",
    "opt = SGD(lr = 0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer = opt,\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"[INFO] fine-tuning model...\")\n",
    "model.fit(trainX, trainY, batch_size=32,\n",
    "    validation_data=(testX, testY), epochs=25,\n",
    "     verbose=1)\n",
    "\n",
    "# evaluate the network after fine-tune\n",
    "print(\"[INFO] evaluating after initialization...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1),target_names=classNames))\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing model...\")\n",
    "model.save(\"flowers17.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
