{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from CV.preprocessing.ImageToArrayPreprocessor import ImageToArrayPreprocessor\n",
    "from CV.preprocessing.aspectawarepreprocessor import AspectAwarePreprocessor\n",
    "from CV.datasets.SimpleDatasetLoader import SimpleDatasetLoader\n",
    "from CV.nn.conv.fcheadnet import FCHeadNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "#我再\n",
    "'''aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "                        height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                        horizontal_flip=True, fill_mode=\"nearest\")'''\n",
    "\n",
    "# grab the list of images that we’ll be describing, then extract\n",
    "# the class label names from the image paths\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(\"data3\"))\n",
    "classNames = [pt.split(os.path.sep)[-2] for pt in imagePaths]\n",
    "classNames = [str(x) for x in np.unique(classNames)]\n",
    "\n",
    "# initialize the image preprocessors\n",
    "aap = AspectAwarePreprocessor(128,128)\n",
    "iap = ImageToArrayPreprocessor()\n",
    "\n",
    "# load the dataset from disk then scale the raw pixel intensities to\n",
    "# the range [0, 1]\n",
    "\n",
    "sdl = SimpleDatasetLoader(preprocessors=[aap, iap])\n",
    "(data, labels) = sdl.load(imagePaths, verbose = 500)\n",
    "data = data.astype(\"float\")/255.0\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "    test_size=0.1, random_state=42)\n",
    "\n",
    "#convert the labels from integers to vectors\n",
    "#trainY = LabelBinarizer().fit_transform(trainY)\n",
    "#testY = LabelBinarizer().fit_transform(testY)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "lb = LabelBinarizer()\n",
    "#train_y = lb.fit_transform(train_y)\n",
    "#test_y = lb.fit_transform(test_y)\n",
    "lb.fit(trainY)\n",
    "trainY=lb.transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "trainY = to_categorical(trainY, num_classes=2)\n",
    "testY = to_categorical(testY, num_classes=2)\n",
    "\n",
    "# load the VGG16 network, ensuring the head FC layer sets are left\n",
    "# off\n",
    "\n",
    "#baseModel = VGG16(weights=\"imagenet\", include_top=False,\n",
    "#                 input_tensor=Input(shape=(128,128,3)))\n",
    "baseModel = ResNet50(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# initialize the new head of the network, a set of FC layers\n",
    "# followed by a softmax classifier\n",
    "headModel = FCHeadNet.build(baseModel, len(classNames),256)\n",
    "\n",
    "# place the head FC model on top of the base model -- this will\n",
    "# become the actual model we will train\n",
    "model = Model(inputs=baseModel.input, output = headModel)\n",
    "\n",
    "# loop over all layers in the base model and freeze them so they\n",
    "# will *not* be updated during the training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# compile our model (this needs to be done after our setting our\n",
    "# layers to being non-trainable\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = RMSprop(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=opt,\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "# train the head of the network for a few epochs (all other\n",
    "# layers are frozen) -- this will allow the new FC layers to\n",
    "# start to become initialized with actual \"learned\" values\n",
    "# versus pure random\n",
    "print(\"[INFO] training head...\")\n",
    "'''model.fit_generator(aug.flow(trainX, trainY, batch_size=32),\n",
    "    validation_data=(testX, testY), epochs=25,\n",
    "    steps_per_epoch=len(trainX) // 32, verbose=1)'''\n",
    "model.fit(trainX, trainY, batch_size=32,\n",
    "    validation_data=(testX, testY), epochs=25,\n",
    "     verbose=1)\n",
    "# evaluate the network after initialization\n",
    "print(\"[INFO] evaluating after initialization...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1),target_names=classNames))\n",
    "\n",
    "\n",
    "# now that the head FC layers have been trained/initialized, lets\n",
    "# unfreeze the final set of CONV layers and make them trainable\n",
    "for layer in baseModel.layers[15:]:\n",
    "    layer.trainable = True\n",
    "# 用小lr的sgd重新finetune\n",
    "print(\"[INFO] re-compile model...\")\n",
    "opt = SGD(lr = 0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer = opt,\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"[INFO] fine-tuning model...\")\n",
    "model.fit(trainX, trainY, batch_size=32,\n",
    "    validation_data=(testX, testY), epochs=25,\n",
    "     verbose=1)\n",
    "\n",
    "# evaluate the network after fine-tune\n",
    "print(\"[INFO] evaluating after initialization...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1),target_names=classNames))\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing model...\")\n",
    "model.save(\"flowers17.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] re-compile model...\n",
      "[INFO] fine-tuning model...\n",
      "Train on 4374 samples, validate on 1458 samples\n",
      "Epoch 1/10\n",
      "4374/4374 [==============================] - 438s 100ms/step - loss: 0.0565 - acc: 0.9781 - val_loss: 0.6080 - val_acc: 0.8615\n",
      "Epoch 2/10\n",
      "4374/4374 [==============================] - 445s 102ms/step - loss: 0.0519 - acc: 0.9815 - val_loss: 0.6006 - val_acc: 0.8587\n",
      "Epoch 3/10\n",
      "4374/4374 [==============================] - 437s 100ms/step - loss: 0.0507 - acc: 0.9824 - val_loss: 0.6611 - val_acc: 0.8601\n",
      "Epoch 4/10\n",
      "4374/4374 [==============================] - 441s 101ms/step - loss: 0.1567 - acc: 0.9417 - val_loss: 0.6387 - val_acc: 0.8505\n",
      "Epoch 5/10\n",
      "4374/4374 [==============================] - 445s 102ms/step - loss: 0.0478 - acc: 0.9835 - val_loss: 0.5398 - val_acc: 0.8635\n",
      "Epoch 6/10\n",
      "4374/4374 [==============================] - 445s 102ms/step - loss: 0.0572 - acc: 0.9806 - val_loss: 0.6420 - val_acc: 0.8628\n",
      "Epoch 7/10\n",
      "4374/4374 [==============================] - 437s 100ms/step - loss: 0.0381 - acc: 0.9879 - val_loss: 0.6893 - val_acc: 0.8608\n",
      "Epoch 8/10\n",
      "4374/4374 [==============================] - 443s 101ms/step - loss: 0.1388 - acc: 0.9566 - val_loss: 0.6318 - val_acc: 0.5885\n",
      "Epoch 9/10\n",
      "4374/4374 [==============================] - 448s 102ms/step - loss: 0.3683 - acc: 0.8308 - val_loss: 0.5234 - val_acc: 0.8464\n",
      "Epoch 10/10\n",
      "4374/4374 [==============================] - 447s 102ms/step - loss: 0.1078 - acc: 0.9611 - val_loss: 0.4681 - val_acc: 0.8642\n",
      "[INFO] evaluating after initialization...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.81      0.85       711\n",
      "          1       0.84      0.91      0.87       747\n",
      "\n",
      "avg / total       0.87      0.86      0.86      1458\n",
      "\n",
      "[INFO] serializing model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (25,) and (10,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-81acd77ab59f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ggplot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3356\u001b[0m                       mplDeprecation)\n\u001b[0;32m   3357\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3358\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3359\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1527\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m             \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'plot'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[1;32m--> 242\u001b[1;33m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[0;32m    243\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (25,) and (10,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCHS =15\n",
    "# now that the head FC layers have been trained/initialized, lets\n",
    "# unfreeze the final set of CONV layers and make them trainable\n",
    "for layer in baseModel.layers[15:]:\n",
    "    layer.trainable = True\n",
    "# 用小lr的sgd重新finetune\n",
    "print(\"[INFO] re-compile model...\")\n",
    "opt = SGD(lr = 0.001)\n",
    "#opt = SGD(lr=0.01, decay=0.05/20, momentum=0.9,nesterov=True)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer = opt,\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"[INFO] fine-tuning model...\")\n",
    "H = model.fit(trainX, trainY, batch_size=32,\n",
    "    validation_data=(testX, testY), epochs=EPOCHS,\n",
    "     verbose=1)\n",
    "\n",
    "# evaluate the network after fine-tune\n",
    "print(\"[INFO] evaluating after initialization...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "                           predictions.argmax(axis=1),target_names=classNames))\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing model...\")\n",
    "model.save(\"flowers17.model\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1958cfc4278e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ggplot\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "##### import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 25), model.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 25), model.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 25),model.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, 25), model.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 16,812,610\n",
      "Trainable params: 9,177,346\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'block1_conv1': <keras.layers.convolutional.Conv2D at 0x23f200fe780>,\n",
       " 'block1_conv2': <keras.layers.convolutional.Conv2D at 0x23f201862b0>,\n",
       " 'block1_pool': <keras.layers.pooling.MaxPooling2D at 0x23f20186e10>,\n",
       " 'block2_conv1': <keras.layers.convolutional.Conv2D at 0x23f200fef60>,\n",
       " 'block2_conv2': <keras.layers.convolutional.Conv2D at 0x23f2019a710>,\n",
       " 'block2_pool': <keras.layers.pooling.MaxPooling2D at 0x23f45aa9320>,\n",
       " 'block3_conv1': <keras.layers.convolutional.Conv2D at 0x23f45ac29b0>,\n",
       " 'block3_conv2': <keras.layers.convolutional.Conv2D at 0x23ff0f77630>,\n",
       " 'block3_conv3': <keras.layers.convolutional.Conv2D at 0x23ff0f688d0>,\n",
       " 'block3_pool': <keras.layers.pooling.MaxPooling2D at 0x23ff0fa0f28>,\n",
       " 'block4_conv1': <keras.layers.convolutional.Conv2D at 0x23ff0fb18d0>,\n",
       " 'block4_conv2': <keras.layers.convolutional.Conv2D at 0x23ff0fe0828>,\n",
       " 'block4_conv3': <keras.layers.convolutional.Conv2D at 0x23ff0fcaf98>,\n",
       " 'block4_pool': <keras.layers.pooling.MaxPooling2D at 0x23ff0ff3f98>,\n",
       " 'block5_conv1': <keras.layers.convolutional.Conv2D at 0x23ff10196a0>,\n",
       " 'block5_conv2': <keras.layers.convolutional.Conv2D at 0x23ff102e940>,\n",
       " 'block5_conv3': <keras.layers.convolutional.Conv2D at 0x23ff1047e80>,\n",
       " 'block5_pool': <keras.layers.pooling.MaxPooling2D at 0x23ff105b390>,\n",
       " 'flatten': <keras.layers.core.Flatten at 0x23f14084a90>,\n",
       " 'dense_1': <keras.layers.core.Dense at 0x23ff49c3e10>,\n",
       " 'dropout_1': <keras.layers.core.Dropout at 0x23ff49e8fd0>,\n",
       " 'dense_2': <keras.layers.core.Dense at 0x23ff49e8b70>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict([(layer.name, layer) for layer in model.layers[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 16,812,610\n",
      "Trainable params: 9,177,346\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n",
      "Processing filter 0\n",
      "Current loss value: 0.0\n",
      "Filter 0 processed in 0s\n",
      "Processing filter 1\n",
      "Current loss value: 0.0\n",
      "Filter 1 processed in 0s\n",
      "Processing filter 2\n",
      "Current loss value: 0.0\n",
      "Filter 2 processed in 0s\n",
      "Processing filter 3\n",
      "Current loss value: 0.0\n",
      "Filter 3 processed in 0s\n",
      "Processing filter 4\n",
      "Current loss value: 0.0\n",
      "Filter 4 processed in 0s\n",
      "Processing filter 5\n",
      "Current loss value: 0.0\n",
      "Filter 5 processed in 0s\n",
      "Processing filter 6\n",
      "Current loss value: 0.0\n",
      "Filter 6 processed in 0s\n",
      "Processing filter 7\n",
      "Current loss value: 0.0\n",
      "Filter 7 processed in 0s\n",
      "Processing filter 8\n",
      "Current loss value: 0.0\n",
      "Filter 8 processed in 0s\n",
      "Processing filter 9\n",
      "Current loss value: 0.0\n",
      "Filter 9 processed in 0s\n",
      "Processing filter 10\n",
      "Current loss value: 0.0\n",
      "Filter 10 processed in 0s\n",
      "Processing filter 11\n",
      "Current loss value: 0.0\n",
      "Filter 11 processed in 0s\n",
      "Processing filter 12\n",
      "Current loss value: 0.14871383\n",
      "Current loss value: 0.753561\n",
      "Current loss value: 1.1349463\n",
      "Current loss value: 2.9767413\n",
      "Current loss value: 13.461571\n",
      "Current loss value: 27.60854\n",
      "Current loss value: 39.147423\n",
      "Current loss value: 55.323307\n",
      "Current loss value: 66.52329\n",
      "Current loss value: 79.08582\n",
      "Current loss value: 91.71428\n",
      "Current loss value: 106.35484\n",
      "Current loss value: 122.92099\n",
      "Current loss value: 126.49789\n",
      "Current loss value: 152.58315\n",
      "Current loss value: 154.34613\n",
      "Current loss value: 183.53458\n",
      "Current loss value: 197.50415\n",
      "Current loss value: 212.83328\n",
      "Current loss value: 237.43994\n",
      "Filter 12 processed in 4s\n",
      "Processing filter 13\n",
      "Current loss value: 0.0\n",
      "Filter 13 processed in 0s\n",
      "Processing filter 14\n",
      "Current loss value: 0.0\n",
      "Filter 14 processed in 0s\n",
      "Processing filter 15\n",
      "Current loss value: 0.0\n",
      "Filter 15 processed in 0s\n",
      "Processing filter 16\n",
      "Current loss value: 0.0\n",
      "Filter 16 processed in 0s\n",
      "Processing filter 17\n",
      "Current loss value: 0.0\n",
      "Filter 17 processed in 0s\n",
      "Processing filter 18\n",
      "Current loss value: 0.0\n",
      "Filter 18 processed in 0s\n",
      "Processing filter 19\n",
      "Current loss value: 0.0012217988\n",
      "Current loss value: 2.6709018\n",
      "Current loss value: 13.0623\n",
      "Current loss value: 28.69797\n",
      "Current loss value: 44.966923\n",
      "Current loss value: 70.23178\n",
      "Current loss value: 97.367096\n",
      "Current loss value: 114.28429\n",
      "Current loss value: 139.92982\n",
      "Current loss value: 165.7188\n",
      "Current loss value: 177.93347\n",
      "Current loss value: 196.21909\n",
      "Current loss value: 215.69789\n",
      "Current loss value: 232.86691\n",
      "Current loss value: 250.34708\n",
      "Current loss value: 266.56094\n",
      "Current loss value: 287.1633\n",
      "Current loss value: 294.24933\n",
      "Current loss value: 319.19745\n",
      "Current loss value: 326.86664\n",
      "Filter 19 processed in 4s\n",
      "Processing filter 20\n",
      "Current loss value: 0.0\n",
      "Filter 20 processed in 0s\n",
      "Processing filter 21\n",
      "Current loss value: 0.0\n",
      "Filter 21 processed in 0s\n",
      "Processing filter 22\n",
      "Current loss value: 0.0\n",
      "Filter 22 processed in 0s\n",
      "Processing filter 23\n",
      "Current loss value: 0.0\n",
      "Filter 23 processed in 0s\n",
      "Processing filter 24\n",
      "Current loss value: 0.0\n",
      "Filter 24 processed in 0s\n",
      "Processing filter 25\n",
      "Current loss value: 0.0\n",
      "Filter 25 processed in 0s\n",
      "Processing filter 26\n",
      "Current loss value: 0.0\n",
      "Filter 26 processed in 0s\n",
      "Processing filter 27\n",
      "Current loss value: 0.0\n",
      "Filter 27 processed in 0s\n",
      "Processing filter 28\n",
      "Current loss value: 0.0\n",
      "Filter 28 processed in 0s\n",
      "Processing filter 29\n",
      "Current loss value: 0.0\n",
      "Filter 29 processed in 0s\n",
      "Processing filter 30\n",
      "Current loss value: 0.0\n",
      "Filter 30 processed in 0s\n",
      "Processing filter 31\n",
      "Current loss value: 0.0\n",
      "Filter 31 processed in 0s\n",
      "Processing filter 32\n",
      "Current loss value: 0.0\n",
      "Filter 32 processed in 0s\n",
      "Processing filter 33\n",
      "Current loss value: 0.0\n",
      "Filter 33 processed in 0s\n",
      "Processing filter 34\n",
      "Current loss value: 0.0\n",
      "Filter 34 processed in 0s\n",
      "Processing filter 35\n",
      "Current loss value: 0.0\n",
      "Filter 35 processed in 0s\n",
      "Processing filter 36\n",
      "Current loss value: 0.32478115\n",
      "Current loss value: 6.1403\n",
      "Current loss value: 18.177711\n",
      "Current loss value: 52.679436\n",
      "Current loss value: 64.928024\n",
      "Current loss value: 86.37816\n",
      "Current loss value: 100.63307\n",
      "Current loss value: 127.96822\n",
      "Current loss value: 146.00967\n",
      "Current loss value: 161.11555\n",
      "Current loss value: 193.65366\n",
      "Current loss value: 212.43103\n",
      "Current loss value: 226.58539\n",
      "Current loss value: 237.8853\n",
      "Current loss value: 268.94507\n",
      "Current loss value: 281.0209\n",
      "Current loss value: 300.99435\n",
      "Current loss value: 316.2761\n",
      "Current loss value: 333.53455\n",
      "Current loss value: 346.17886\n",
      "Filter 36 processed in 4s\n",
      "Processing filter 37\n",
      "Current loss value: 0.021983849\n",
      "Current loss value: 0.0\n",
      "Filter 37 processed in 1s\n",
      "Processing filter 38\n",
      "Current loss value: 0.0\n",
      "Filter 38 processed in 0s\n",
      "Processing filter 39\n",
      "Current loss value: 0.0\n",
      "Filter 39 processed in 0s\n",
      "Processing filter 40\n",
      "Current loss value: 0.0\n",
      "Filter 40 processed in 0s\n",
      "Processing filter 41\n",
      "Current loss value: 0.0\n",
      "Filter 41 processed in 0s\n",
      "Processing filter 42\n",
      "Current loss value: 3.4070225\n",
      "Current loss value: 19.311577\n",
      "Current loss value: 34.285606\n",
      "Current loss value: 49.093853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 64.536865\n",
      "Current loss value: 75.07038\n",
      "Current loss value: 90.27225\n",
      "Current loss value: 102.85107\n",
      "Current loss value: 115.09915\n",
      "Current loss value: 126.05972\n",
      "Current loss value: 138.03796\n",
      "Current loss value: 146.00037\n",
      "Current loss value: 166.05855\n",
      "Current loss value: 174.75084\n",
      "Current loss value: 183.13806\n",
      "Current loss value: 198.24211\n",
      "Current loss value: 207.18103\n",
      "Current loss value: 220.72537\n",
      "Current loss value: 232.703\n",
      "Current loss value: 245.98196\n",
      "Filter 42 processed in 4s\n",
      "Processing filter 43\n",
      "Current loss value: 0.0\n",
      "Filter 43 processed in 0s\n",
      "Processing filter 44\n",
      "Current loss value: 0.0\n",
      "Filter 44 processed in 0s\n",
      "Processing filter 45\n",
      "Current loss value: 0.43614185\n",
      "Current loss value: 0.9358306\n",
      "Current loss value: 8.856112\n",
      "Current loss value: 12.673282\n",
      "Current loss value: 24.299694\n",
      "Current loss value: 38.37829\n",
      "Current loss value: 48.7965\n",
      "Current loss value: 67.15813\n",
      "Current loss value: 95.87837\n",
      "Current loss value: 121.2885\n",
      "Current loss value: 154.53302\n",
      "Current loss value: 194.97058\n",
      "Current loss value: 236.74454\n",
      "Current loss value: 274.51547\n",
      "Current loss value: 313.91928\n",
      "Current loss value: 351.42252\n",
      "Current loss value: 393.70062\n",
      "Current loss value: 429.90503\n",
      "Current loss value: 462.1125\n",
      "Current loss value: 495.35907\n",
      "Filter 45 processed in 4s\n",
      "Processing filter 46\n",
      "Current loss value: 0.366763\n",
      "Current loss value: 0.2761215\n",
      "Current loss value: 1.9163761\n",
      "Current loss value: 9.732048\n",
      "Current loss value: 17.93491\n",
      "Current loss value: 32.575203\n",
      "Current loss value: 50.826084\n",
      "Current loss value: 73.08989\n",
      "Current loss value: 98.332184\n",
      "Current loss value: 119.711975\n",
      "Current loss value: 140.21144\n",
      "Current loss value: 154.0728\n",
      "Current loss value: 170.40479\n",
      "Current loss value: 187.18907\n",
      "Current loss value: 210.54257\n",
      "Current loss value: 222.12204\n",
      "Current loss value: 238.89941\n",
      "Current loss value: 253.3045\n",
      "Current loss value: 270.04767\n",
      "Current loss value: 285.3441\n",
      "Filter 46 processed in 4s\n",
      "Processing filter 47\n",
      "Current loss value: 0.0\n",
      "Filter 47 processed in 0s\n",
      "Processing filter 48\n",
      "Current loss value: 0.0\n",
      "Filter 48 processed in 0s\n",
      "Processing filter 49\n",
      "Current loss value: 0.0\n",
      "Filter 49 processed in 0s\n",
      "Processing filter 50\n",
      "Current loss value: 0.13769948\n",
      "Current loss value: 2.5336823\n",
      "Current loss value: 8.60689\n",
      "Current loss value: 8.853034\n",
      "Current loss value: 22.11356\n",
      "Current loss value: 37.39126\n",
      "Current loss value: 53.494244\n",
      "Current loss value: 75.94783\n",
      "Current loss value: 104.117966\n",
      "Current loss value: 125.12105\n",
      "Current loss value: 149.1081\n",
      "Current loss value: 181.2533\n",
      "Current loss value: 201.60709\n",
      "Current loss value: 227.69312\n",
      "Current loss value: 251.05763\n",
      "Current loss value: 278.32288\n",
      "Current loss value: 303.8418\n",
      "Current loss value: 317.1066\n",
      "Current loss value: 349.13266\n",
      "Current loss value: 367.09628\n",
      "Filter 50 processed in 4s\n",
      "Processing filter 51\n",
      "Current loss value: 0.34479654\n",
      "Current loss value: 6.3095236\n",
      "Current loss value: 17.210508\n",
      "Current loss value: 29.761265\n",
      "Current loss value: 43.23223\n",
      "Current loss value: 58.13385\n",
      "Current loss value: 77.66817\n",
      "Current loss value: 90.04937\n",
      "Current loss value: 108.11533\n",
      "Current loss value: 121.49737\n",
      "Current loss value: 141.23097\n",
      "Current loss value: 156.37656\n",
      "Current loss value: 166.63626\n",
      "Current loss value: 184.15613\n",
      "Current loss value: 201.1904\n",
      "Current loss value: 220.3584\n",
      "Current loss value: 232.4158\n",
      "Current loss value: 250.27554\n",
      "Current loss value: 263.80847\n",
      "Current loss value: 277.69965\n",
      "Filter 51 processed in 4s\n",
      "Processing filter 52\n",
      "Current loss value: 0.0\n",
      "Filter 52 processed in 0s\n",
      "Processing filter 53\n",
      "Current loss value: 0.0\n",
      "Filter 53 processed in 0s\n",
      "Processing filter 54\n",
      "Current loss value: 0.0\n",
      "Filter 54 processed in 0s\n",
      "Processing filter 55\n",
      "Current loss value: 0.85195696\n",
      "Current loss value: 10.68429\n",
      "Current loss value: 22.545233\n",
      "Current loss value: 31.794127\n",
      "Current loss value: 48.08535\n",
      "Current loss value: 63.659294\n",
      "Current loss value: 76.16378\n",
      "Current loss value: 94.814964\n",
      "Current loss value: 109.59064\n",
      "Current loss value: 127.32145\n",
      "Current loss value: 143.29634\n",
      "Current loss value: 157.55653\n",
      "Current loss value: 172.9094\n",
      "Current loss value: 187.30133\n",
      "Current loss value: 199.50827\n",
      "Current loss value: 219.01273\n",
      "Current loss value: 233.1634\n",
      "Current loss value: 249.85683\n",
      "Current loss value: 267.1303\n",
      "Current loss value: 280.3889\n",
      "Filter 55 processed in 4s\n",
      "Processing filter 56\n",
      "Current loss value: 0.52262056\n",
      "Current loss value: 0.0\n",
      "Filter 56 processed in 1s\n",
      "Processing filter 57\n",
      "Current loss value: 0.0\n",
      "Filter 57 processed in 0s\n",
      "Processing filter 58\n",
      "Current loss value: 0.0\n",
      "Filter 58 processed in 0s\n",
      "Processing filter 59\n",
      "Current loss value: 0.0\n",
      "Filter 59 processed in 0s\n",
      "Processing filter 60\n",
      "Current loss value: 0.0\n",
      "Filter 60 processed in 0s\n",
      "Processing filter 61\n",
      "Current loss value: 0.0\n",
      "Filter 61 processed in 0s\n",
      "Processing filter 62\n",
      "Current loss value: 0.0\n",
      "Filter 62 processed in 0s\n",
      "Processing filter 63\n",
      "Current loss value: 0.0\n",
      "Filter 63 processed in 0s\n",
      "Processing filter 64\n",
      "Current loss value: 0.0\n",
      "Filter 64 processed in 0s\n",
      "Processing filter 65\n",
      "Current loss value: 0.0\n",
      "Filter 65 processed in 0s\n",
      "Processing filter 66\n",
      "Current loss value: 0.0\n",
      "Filter 66 processed in 0s\n",
      "Processing filter 67\n",
      "Current loss value: 0.0\n",
      "Filter 67 processed in 0s\n",
      "Processing filter 68\n",
      "Current loss value: 0.0\n",
      "Filter 68 processed in 0s\n",
      "Processing filter 69\n",
      "Current loss value: 0.0\n",
      "Filter 69 processed in 0s\n",
      "Processing filter 70\n",
      "Current loss value: 0.0\n",
      "Filter 70 processed in 0s\n",
      "Processing filter 71\n",
      "Current loss value: 0.0\n",
      "Filter 71 processed in 0s\n",
      "Processing filter 72\n",
      "Current loss value: 0.009660833\n",
      "Current loss value: 2.2693734\n",
      "Current loss value: 7.771945\n",
      "Current loss value: 19.658813\n",
      "Current loss value: 29.94178\n",
      "Current loss value: 42.61707\n",
      "Current loss value: 63.51951\n",
      "Current loss value: 83.81775\n",
      "Current loss value: 106.45039\n",
      "Current loss value: 130.46204\n",
      "Current loss value: 161.31131\n",
      "Current loss value: 182.61844\n",
      "Current loss value: 210.83765\n",
      "Current loss value: 238.43721\n",
      "Current loss value: 263.74762\n",
      "Current loss value: 288.1018\n",
      "Current loss value: 328.86914\n",
      "Current loss value: 355.48978\n",
      "Current loss value: 387.01776\n",
      "Current loss value: 422.03323\n",
      "Filter 72 processed in 4s\n",
      "Processing filter 73\n",
      "Current loss value: 0.0\n",
      "Filter 73 processed in 1s\n",
      "Processing filter 74\n",
      "Current loss value: 0.0\n",
      "Filter 74 processed in 1s\n",
      "Processing filter 75\n",
      "Current loss value: 0.0\n",
      "Filter 75 processed in 1s\n",
      "Processing filter 76\n",
      "Current loss value: 0.19174556\n",
      "Current loss value: 5.007964\n",
      "Current loss value: 23.581938\n",
      "Current loss value: 36.359768\n",
      "Current loss value: 55.553642\n",
      "Current loss value: 79.46669\n",
      "Current loss value: 82.66497\n",
      "Current loss value: 110.95323\n",
      "Current loss value: 109.792\n",
      "Current loss value: 157.7862\n",
      "Current loss value: 158.37576\n",
      "Current loss value: 186.44211\n",
      "Current loss value: 199.42255\n",
      "Current loss value: 217.6531\n",
      "Current loss value: 237.73991\n",
      "Current loss value: 255.18669\n",
      "Current loss value: 272.78522\n",
      "Current loss value: 285.10162\n",
      "Current loss value: 305.736\n",
      "Current loss value: 308.42664\n",
      "Filter 76 processed in 4s\n",
      "Processing filter 77\n",
      "Current loss value: 0.0\n",
      "Filter 77 processed in 1s\n",
      "Processing filter 78\n",
      "Current loss value: 0.0\n",
      "Filter 78 processed in 1s\n",
      "Processing filter 79\n",
      "Current loss value: 0.0\n",
      "Filter 79 processed in 1s\n",
      "Processing filter 80\n",
      "Current loss value: 0.0\n",
      "Filter 80 processed in 1s\n",
      "Processing filter 81\n",
      "Current loss value: 0.0\n",
      "Filter 81 processed in 1s\n",
      "Processing filter 82\n",
      "Current loss value: 0.034074116\n",
      "Current loss value: 0.923355\n",
      "Current loss value: 3.5324252\n",
      "Current loss value: 9.954889\n",
      "Current loss value: 21.959902\n",
      "Current loss value: 33.84573\n",
      "Current loss value: 40.878716\n",
      "Current loss value: 55.678055\n",
      "Current loss value: 62.2706\n",
      "Current loss value: 76.330124\n",
      "Current loss value: 82.7863\n",
      "Current loss value: 98.317566\n",
      "Current loss value: 106.39957\n",
      "Current loss value: 120.70474\n",
      "Current loss value: 134.72069\n",
      "Current loss value: 152.76038\n",
      "Current loss value: 162.79651\n",
      "Current loss value: 175.13676\n",
      "Current loss value: 186.03687\n",
      "Current loss value: 200.8595\n",
      "Filter 82 processed in 4s\n",
      "Processing filter 83\n",
      "Current loss value: 0.0\n",
      "Filter 83 processed in 1s\n",
      "Processing filter 84\n",
      "Current loss value: 0.0\n",
      "Filter 84 processed in 1s\n",
      "Processing filter 85\n",
      "Current loss value: 0.0\n",
      "Filter 85 processed in 1s\n",
      "Processing filter 86\n",
      "Current loss value: 0.0\n",
      "Filter 86 processed in 1s\n",
      "Processing filter 87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 0.0\n",
      "Filter 87 processed in 1s\n",
      "Processing filter 88\n",
      "Current loss value: 0.0\n",
      "Filter 88 processed in 1s\n",
      "Processing filter 89\n",
      "Current loss value: 0.0\n",
      "Filter 89 processed in 1s\n",
      "Processing filter 90\n",
      "Current loss value: 0.0\n",
      "Filter 90 processed in 1s\n",
      "Processing filter 91\n",
      "Current loss value: 0.0\n",
      "Filter 91 processed in 1s\n",
      "Processing filter 92\n",
      "Current loss value: 0.0\n",
      "Filter 92 processed in 1s\n",
      "Processing filter 93\n",
      "Current loss value: 0.0\n",
      "Filter 93 processed in 1s\n",
      "Processing filter 94\n",
      "Current loss value: 0.0\n",
      "Filter 94 processed in 1s\n",
      "Processing filter 95\n",
      "Current loss value: 0.0\n",
      "Filter 95 processed in 1s\n",
      "Processing filter 96\n",
      "Current loss value: 0.0\n",
      "Filter 96 processed in 1s\n",
      "Processing filter 97\n",
      "Current loss value: 0.0\n",
      "Filter 97 processed in 1s\n",
      "Processing filter 98\n",
      "Current loss value: 0.0\n",
      "Filter 98 processed in 1s\n",
      "Processing filter 99\n",
      "Current loss value: 0.00046803989\n",
      "Current loss value: 1.6038191\n",
      "Current loss value: 7.564179\n",
      "Current loss value: 27.099327\n",
      "Current loss value: 50.288315\n",
      "Current loss value: 79.49083\n",
      "Current loss value: 107.511406\n",
      "Current loss value: 108.640045\n",
      "Current loss value: 147.55817\n",
      "Current loss value: 156.0547\n",
      "Current loss value: 180.06339\n",
      "Current loss value: 188.3637\n",
      "Current loss value: 211.48041\n",
      "Current loss value: 217.1221\n",
      "Current loss value: 238.79752\n",
      "Current loss value: 245.08908\n",
      "Current loss value: 274.213\n",
      "Current loss value: 280.92572\n",
      "Current loss value: 296.2035\n",
      "Current loss value: 305.10733\n",
      "Filter 99 processed in 4s\n",
      "Processing filter 100\n",
      "Current loss value: 0.0\n",
      "Filter 100 processed in 1s\n",
      "Processing filter 101\n",
      "Current loss value: 0.0\n",
      "Filter 101 processed in 1s\n",
      "Processing filter 102\n",
      "Current loss value: 0.0\n",
      "Filter 102 processed in 1s\n",
      "Processing filter 103\n",
      "Current loss value: 0.0\n",
      "Filter 103 processed in 1s\n",
      "Processing filter 104\n",
      "Current loss value: 0.0\n",
      "Filter 104 processed in 1s\n",
      "Processing filter 105\n",
      "Current loss value: 0.0\n",
      "Filter 105 processed in 1s\n",
      "Processing filter 106\n",
      "Current loss value: 0.0\n",
      "Filter 106 processed in 1s\n",
      "Processing filter 107\n",
      "Current loss value: 0.0\n",
      "Filter 107 processed in 1s\n",
      "Processing filter 108\n",
      "Current loss value: 0.0\n",
      "Filter 108 processed in 1s\n",
      "Processing filter 109\n",
      "Current loss value: 0.21572837\n",
      "Current loss value: 5.9154396\n",
      "Current loss value: 20.904186\n",
      "Current loss value: 56.76941\n",
      "Current loss value: 94.83559\n",
      "Current loss value: 136.7308\n",
      "Current loss value: 172.073\n",
      "Current loss value: 212.85619\n",
      "Current loss value: 248.42294\n",
      "Current loss value: 274.3994\n",
      "Current loss value: 304.11316\n",
      "Current loss value: 331.0868\n",
      "Current loss value: 360.9684\n",
      "Current loss value: 385.01935\n",
      "Current loss value: 418.4199\n",
      "Current loss value: 439.42084\n",
      "Current loss value: 467.8993\n",
      "Current loss value: 490.50726\n",
      "Current loss value: 511.47913\n",
      "Current loss value: 540.3469\n",
      "Filter 109 processed in 4s\n",
      "Processing filter 110\n",
      "Current loss value: 0.0\n",
      "Filter 110 processed in 1s\n",
      "Processing filter 111\n",
      "Current loss value: 0.0\n",
      "Filter 111 processed in 1s\n",
      "Processing filter 112\n",
      "Current loss value: 0.0\n",
      "Filter 112 processed in 1s\n",
      "Processing filter 113\n",
      "Current loss value: 0.0\n",
      "Filter 113 processed in 1s\n",
      "Processing filter 114\n",
      "Current loss value: 0.0\n",
      "Filter 114 processed in 1s\n",
      "Processing filter 115\n",
      "Current loss value: 0.0\n",
      "Filter 115 processed in 1s\n",
      "Processing filter 116\n",
      "Current loss value: 0.0\n",
      "Filter 116 processed in 1s\n",
      "Processing filter 117\n",
      "Current loss value: 0.0\n",
      "Filter 117 processed in 1s\n",
      "Processing filter 118\n",
      "Current loss value: 0.0\n",
      "Filter 118 processed in 1s\n",
      "Processing filter 119\n",
      "Current loss value: 11.595397\n",
      "Current loss value: 15.431076\n",
      "Current loss value: 30.381393\n",
      "Current loss value: 41.718906\n",
      "Current loss value: 53.652122\n",
      "Current loss value: 66.1646\n",
      "Current loss value: 76.58921\n",
      "Current loss value: 87.4019\n",
      "Current loss value: 97.44668\n",
      "Current loss value: 108.23331\n",
      "Current loss value: 120.09608\n",
      "Current loss value: 129.26321\n",
      "Current loss value: 134.90005\n",
      "Current loss value: 147.47278\n",
      "Current loss value: 154.91042\n",
      "Current loss value: 166.02052\n",
      "Current loss value: 173.45393\n",
      "Current loss value: 184.69876\n",
      "Current loss value: 190.88156\n",
      "Current loss value: 197.15633\n",
      "Filter 119 processed in 4s\n",
      "Processing filter 120\n",
      "Current loss value: 0.0\n",
      "Filter 120 processed in 1s\n",
      "Processing filter 121\n",
      "Current loss value: 0.0\n",
      "Filter 121 processed in 1s\n",
      "Processing filter 122\n",
      "Current loss value: 0.0\n",
      "Filter 122 processed in 1s\n",
      "Processing filter 123\n",
      "Current loss value: 0.033525933\n",
      "Current loss value: 0.26414394\n",
      "Current loss value: 2.499083\n",
      "Current loss value: 6.757893\n",
      "Current loss value: 9.364723\n",
      "Current loss value: 19.24636\n",
      "Current loss value: 25.417377\n",
      "Current loss value: 34.908257\n",
      "Current loss value: 39.113304\n",
      "Current loss value: 54.083675\n",
      "Current loss value: 56.300106\n",
      "Current loss value: 75.071304\n",
      "Current loss value: 82.63109\n",
      "Current loss value: 95.02271\n",
      "Current loss value: 100.04342\n",
      "Current loss value: 112.42857\n",
      "Current loss value: 116.381195\n",
      "Current loss value: 126.16055\n",
      "Current loss value: 133.81577\n",
      "Current loss value: 145.37695\n",
      "Filter 123 processed in 4s\n",
      "Processing filter 124\n",
      "Current loss value: 0.19592725\n",
      "Current loss value: 1.9896487\n",
      "Current loss value: 18.360107\n",
      "Current loss value: 42.093884\n",
      "Current loss value: 67.401405\n",
      "Current loss value: 99.050964\n",
      "Current loss value: 140.74088\n",
      "Current loss value: 184.1346\n",
      "Current loss value: 235.61276\n",
      "Current loss value: 280.82312\n",
      "Current loss value: 314.9433\n",
      "Current loss value: 354.2878\n",
      "Current loss value: 385.51498\n",
      "Current loss value: 423.9181\n",
      "Current loss value: 456.1898\n",
      "Current loss value: 490.04053\n",
      "Current loss value: 521.2272\n",
      "Current loss value: 553.8743\n",
      "Current loss value: 579.7689\n",
      "Current loss value: 610.59875\n",
      "Filter 124 processed in 4s\n",
      "Processing filter 125\n",
      "Current loss value: 0.0\n",
      "Filter 125 processed in 1s\n",
      "Processing filter 126\n",
      "Current loss value: 0.0\n",
      "Filter 126 processed in 1s\n",
      "Processing filter 127\n",
      "Current loss value: 0.0\n",
      "Filter 127 processed in 1s\n",
      "Processing filter 128\n",
      "Current loss value: 0.0\n",
      "Filter 128 processed in 1s\n",
      "Processing filter 129\n",
      "Current loss value: 0.0\n",
      "Filter 129 processed in 1s\n",
      "Processing filter 130\n",
      "Current loss value: 0.0\n",
      "Filter 130 processed in 1s\n",
      "Processing filter 131\n",
      "Current loss value: 0.0\n",
      "Filter 131 processed in 1s\n",
      "Processing filter 132\n",
      "Current loss value: 0.0\n",
      "Filter 132 processed in 1s\n",
      "Processing filter 133\n",
      "Current loss value: 0.0\n",
      "Filter 133 processed in 1s\n",
      "Processing filter 134\n",
      "Current loss value: 0.0\n",
      "Filter 134 processed in 1s\n",
      "Processing filter 135\n",
      "Current loss value: 0.0\n",
      "Filter 135 processed in 1s\n",
      "Processing filter 136\n",
      "Current loss value: 0.0\n",
      "Filter 136 processed in 1s\n",
      "Processing filter 137\n",
      "Current loss value: 0.0\n",
      "Filter 137 processed in 1s\n",
      "Processing filter 138\n",
      "Current loss value: 0.0\n",
      "Filter 138 processed in 1s\n",
      "Processing filter 139\n",
      "Current loss value: 0.0\n",
      "Filter 139 processed in 1s\n",
      "Processing filter 140\n",
      "Current loss value: 0.0\n",
      "Filter 140 processed in 1s\n",
      "Processing filter 141\n",
      "Current loss value: 0.0\n",
      "Filter 141 processed in 1s\n",
      "Processing filter 142\n",
      "Current loss value: 0.0\n",
      "Filter 142 processed in 1s\n",
      "Processing filter 143\n",
      "Current loss value: 1.437543\n",
      "Current loss value: 7.345192\n",
      "Current loss value: 7.1723466\n",
      "Current loss value: 24.803398\n",
      "Current loss value: 37.888084\n",
      "Current loss value: 50.678978\n",
      "Current loss value: 74.04747\n",
      "Current loss value: 82.7612\n",
      "Current loss value: 104.25095\n",
      "Current loss value: 114.61929\n",
      "Current loss value: 134.24069\n",
      "Current loss value: 140.21965\n",
      "Current loss value: 160.00699\n",
      "Current loss value: 170.12276\n",
      "Current loss value: 193.03302\n",
      "Current loss value: 196.90512\n",
      "Current loss value: 218.642\n",
      "Current loss value: 217.73343\n",
      "Current loss value: 234.31348\n",
      "Current loss value: 240.98972\n",
      "Filter 143 processed in 4s\n",
      "Processing filter 144\n",
      "Current loss value: 0.0\n",
      "Filter 144 processed in 1s\n",
      "Processing filter 145\n",
      "Current loss value: 0.0\n",
      "Filter 145 processed in 1s\n",
      "Processing filter 146\n",
      "Current loss value: 0.0\n",
      "Filter 146 processed in 1s\n",
      "Processing filter 147\n",
      "Current loss value: 0.0\n",
      "Filter 147 processed in 1s\n",
      "Processing filter 148\n",
      "Current loss value: 0.0\n",
      "Filter 148 processed in 1s\n",
      "Processing filter 149\n",
      "Current loss value: 0.4279647\n",
      "Current loss value: 16.616358\n",
      "Current loss value: 50.52507\n",
      "Current loss value: 89.97291\n",
      "Current loss value: 117.10751\n",
      "Current loss value: 155.2846\n",
      "Current loss value: 184.3696\n",
      "Current loss value: 229.70982\n",
      "Current loss value: 270.1684\n",
      "Current loss value: 317.64847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss value: 358.68787\n",
      "Current loss value: 400.8246\n",
      "Current loss value: 439.79663\n",
      "Current loss value: 484.33502\n",
      "Current loss value: 503.20776\n",
      "Current loss value: 542.05194\n",
      "Current loss value: 565.77966\n",
      "Current loss value: 602.8788\n",
      "Current loss value: 627.7487\n",
      "Current loss value: 663.0447\n",
      "Filter 149 processed in 4s\n",
      "Processing filter 150\n",
      "Current loss value: 0.0\n",
      "Filter 150 processed in 1s\n",
      "Processing filter 151\n",
      "Current loss value: 0.0\n",
      "Filter 151 processed in 1s\n",
      "Processing filter 152\n",
      "Current loss value: 0.0\n",
      "Filter 152 processed in 1s\n",
      "Processing filter 153\n",
      "Current loss value: 0.0\n",
      "Filter 153 processed in 1s\n",
      "Processing filter 154\n",
      "Current loss value: 0.0\n",
      "Filter 154 processed in 1s\n",
      "Processing filter 155\n",
      "Current loss value: 0.0\n",
      "Filter 155 processed in 1s\n",
      "Processing filter 156\n",
      "Current loss value: 0.0\n",
      "Filter 156 processed in 1s\n",
      "Processing filter 157\n",
      "Current loss value: 0.06563922\n",
      "Current loss value: 0.41332257\n",
      "Current loss value: 5.8655915\n",
      "Current loss value: 17.76541\n",
      "Current loss value: 43.171562\n",
      "Current loss value: 70.81775\n",
      "Current loss value: 92.00182\n",
      "Current loss value: 117.33058\n",
      "Current loss value: 146.91042\n",
      "Current loss value: 169.31882\n",
      "Current loss value: 197.12703\n",
      "Current loss value: 226.26062\n",
      "Current loss value: 251.04097\n",
      "Current loss value: 282.63806\n",
      "Current loss value: 301.2691\n",
      "Current loss value: 328.09814\n",
      "Current loss value: 347.01627\n",
      "Current loss value: 381.75928\n",
      "Current loss value: 397.64868\n",
      "Current loss value: 429.42682\n",
      "Filter 157 processed in 4s\n",
      "Processing filter 158\n",
      "Current loss value: 0.0\n",
      "Filter 158 processed in 1s\n",
      "Processing filter 159\n",
      "Current loss value: 0.0\n",
      "Filter 159 processed in 1s\n",
      "Processing filter 160\n",
      "Current loss value: 0.0\n",
      "Filter 160 processed in 1s\n",
      "Processing filter 161\n",
      "Current loss value: 0.0\n",
      "Filter 161 processed in 1s\n",
      "Processing filter 162\n",
      "Current loss value: 0.0\n",
      "Filter 162 processed in 1s\n",
      "Processing filter 163\n",
      "Current loss value: 0.0\n",
      "Filter 163 processed in 1s\n",
      "Processing filter 164\n",
      "Current loss value: 0.0\n",
      "Filter 164 processed in 1s\n",
      "Processing filter 165\n",
      "Current loss value: 0.0\n",
      "Filter 165 processed in 1s\n",
      "Processing filter 166\n",
      "Current loss value: 0.009258617\n",
      "Current loss value: 2.528521\n",
      "Current loss value: 18.88135\n",
      "Current loss value: 47.482452\n",
      "Current loss value: 83.49021\n",
      "Current loss value: 119.32736\n",
      "Current loss value: 153.25871\n",
      "Current loss value: 184.22493\n",
      "Current loss value: 209.16069\n",
      "Current loss value: 234.77657\n",
      "Current loss value: 259.47656\n",
      "Current loss value: 291.93768\n",
      "Current loss value: 319.30753\n",
      "Current loss value: 350.9565\n",
      "Current loss value: 372.0866\n",
      "Current loss value: 397.54535\n",
      "Current loss value: 421.3104\n",
      "Current loss value: 448.69476\n",
      "Current loss value: 468.76694\n",
      "Current loss value: 510.47034\n",
      "Filter 166 processed in 4s\n",
      "Processing filter 167\n",
      "Current loss value: 0.0\n",
      "Filter 167 processed in 1s\n",
      "Processing filter 168\n",
      "Current loss value: 0.04208681\n",
      "Current loss value: 0.72044694\n",
      "Current loss value: 6.3760223\n",
      "Current loss value: 13.798968\n",
      "Current loss value: 27.422653\n",
      "Current loss value: 42.596603\n",
      "Current loss value: 64.23209\n",
      "Current loss value: 75.385605\n",
      "Current loss value: 104.81598\n",
      "Current loss value: 114.29547\n",
      "Current loss value: 138.98782\n",
      "Current loss value: 138.20505\n",
      "Current loss value: 170.39838\n",
      "Current loss value: 163.00659\n",
      "Current loss value: 200.0374\n",
      "Current loss value: 202.53166\n",
      "Current loss value: 230.83572\n",
      "Current loss value: 246.73087\n",
      "Current loss value: 265.11267\n",
      "Current loss value: 273.04318\n",
      "Filter 168 processed in 4s\n",
      "Processing filter 169\n",
      "Current loss value: 0.0\n",
      "Filter 169 processed in 1s\n",
      "Processing filter 170\n",
      "Current loss value: 0.0\n",
      "Filter 170 processed in 1s\n",
      "Processing filter 171\n",
      "Current loss value: 0.0\n",
      "Filter 171 processed in 1s\n",
      "Processing filter 172\n",
      "Current loss value: 0.39008915\n",
      "Current loss value: 9.474781\n",
      "Current loss value: 31.825413\n",
      "Current loss value: 57.32344\n",
      "Current loss value: 81.79031\n",
      "Current loss value: 102.09052\n",
      "Current loss value: 120.83541\n",
      "Current loss value: 136.98886\n",
      "Current loss value: 158.2861\n",
      "Current loss value: 183.46252\n",
      "Current loss value: 204.89613\n",
      "Current loss value: 230.25954\n",
      "Current loss value: 252.86803\n",
      "Current loss value: 269.321\n",
      "Current loss value: 293.8756\n",
      "Current loss value: 311.8974\n",
      "Current loss value: 332.0693\n",
      "Current loss value: 353.62024\n",
      "Current loss value: 370.78207\n",
      "Current loss value: 393.99225\n",
      "Filter 172 processed in 4s\n",
      "Processing filter 173\n",
      "Current loss value: 0.0\n",
      "Filter 173 processed in 1s\n",
      "Processing filter 174\n",
      "Current loss value: 0.0\n",
      "Filter 174 processed in 1s\n",
      "Processing filter 175\n",
      "Current loss value: 0.0\n",
      "Filter 175 processed in 1s\n",
      "Processing filter 176\n",
      "Current loss value: 0.0\n",
      "Filter 176 processed in 1s\n",
      "Processing filter 177\n",
      "Current loss value: 0.0\n",
      "Filter 177 processed in 1s\n",
      "Processing filter 178\n",
      "Current loss value: 0.0\n",
      "Filter 178 processed in 1s\n",
      "Processing filter 179\n",
      "Current loss value: 0.34316352\n",
      "Current loss value: 1.9572028\n",
      "Current loss value: 9.57716\n",
      "Current loss value: 27.023296\n",
      "Current loss value: 46.264145\n",
      "Current loss value: 72.059204\n",
      "Current loss value: 93.26882\n",
      "Current loss value: 114.43335\n",
      "Current loss value: 128.71799\n",
      "Current loss value: 147.14908\n",
      "Current loss value: 164.28354\n",
      "Current loss value: 181.9525\n",
      "Current loss value: 194.92035\n",
      "Current loss value: 210.49101\n",
      "Current loss value: 224.54308\n",
      "Current loss value: 236.2142\n",
      "Current loss value: 252.5485\n",
      "Current loss value: 263.4151\n",
      "Current loss value: 279.75186\n",
      "Current loss value: 292.70477\n",
      "Filter 179 processed in 4s\n",
      "Processing filter 180\n",
      "Current loss value: 0.0\n",
      "Filter 180 processed in 1s\n",
      "Processing filter 181\n",
      "Current loss value: 0.0\n",
      "Filter 181 processed in 1s\n",
      "Processing filter 182\n",
      "Current loss value: 0.0\n",
      "Filter 182 processed in 1s\n",
      "Processing filter 183\n",
      "Current loss value: 0.0\n",
      "Filter 183 processed in 1s\n",
      "Processing filter 184\n",
      "Current loss value: 0.0\n",
      "Filter 184 processed in 1s\n",
      "Processing filter 185\n",
      "Current loss value: 0.011320358\n",
      "Current loss value: 2.7182016\n",
      "Current loss value: 11.761258\n",
      "Current loss value: 21.863945\n",
      "Current loss value: 30.128979\n",
      "Current loss value: 50.371216\n",
      "Current loss value: 59.841217\n",
      "Current loss value: 79.768684\n",
      "Current loss value: 93.742\n",
      "Current loss value: 117.45903\n",
      "Current loss value: 137.5079\n",
      "Current loss value: 162.6586\n",
      "Current loss value: 184.65964\n",
      "Current loss value: 205.45137\n",
      "Current loss value: 228.51523\n",
      "Current loss value: 245.85623\n",
      "Current loss value: 269.42398\n",
      "Current loss value: 294.25507\n",
      "Current loss value: 320.54434\n",
      "Current loss value: 345.649\n",
      "Filter 185 processed in 4s\n",
      "Processing filter 186\n",
      "Current loss value: 0.0\n",
      "Filter 186 processed in 1s\n",
      "Processing filter 187\n",
      "Current loss value: 0.0\n",
      "Filter 187 processed in 1s\n",
      "Processing filter 188\n",
      "Current loss value: 0.0\n",
      "Filter 188 processed in 1s\n",
      "Processing filter 189\n",
      "Current loss value: 0.0\n",
      "Filter 189 processed in 1s\n",
      "Processing filter 190\n",
      "Current loss value: 0.0\n",
      "Filter 190 processed in 1s\n",
      "Processing filter 191\n",
      "Current loss value: 0.0\n",
      "Filter 191 processed in 1s\n",
      "Processing filter 192\n",
      "Current loss value: 0.0\n",
      "Filter 192 processed in 1s\n",
      "Processing filter 193\n",
      "Current loss value: 0.0\n",
      "Filter 193 processed in 1s\n",
      "Processing filter 194\n",
      "Current loss value: 0.0\n",
      "Filter 194 processed in 1s\n",
      "Processing filter 195\n",
      "Current loss value: 0.0\n",
      "Filter 195 processed in 1s\n",
      "Processing filter 196\n",
      "Current loss value: 0.0\n",
      "Filter 196 processed in 1s\n",
      "Processing filter 197\n",
      "Current loss value: 0.0\n",
      "Filter 197 processed in 1s\n",
      "Processing filter 198\n",
      "Current loss value: 0.0\n",
      "Filter 198 processed in 1s\n",
      "Processing filter 199\n",
      "Current loss value: 0.037229918\n",
      "Current loss value: 1.0357988\n",
      "Current loss value: 6.29949\n",
      "Current loss value: 14.557771\n",
      "Current loss value: 31.781002\n",
      "Current loss value: 49.489365\n",
      "Current loss value: 56.370358\n",
      "Current loss value: 75.62902\n",
      "Current loss value: 91.48719\n",
      "Current loss value: 112.39222\n",
      "Current loss value: 133.08737\n",
      "Current loss value: 154.0953\n",
      "Current loss value: 170.87723\n",
      "Current loss value: 195.28131\n",
      "Current loss value: 213.7588\n",
      "Current loss value: 230.94513\n",
      "Current loss value: 252.30713\n",
      "Current loss value: 273.21286\n",
      "Current loss value: 288.0122\n",
      "Current loss value: 306.52563\n",
      "Filter 199 processed in 4s\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-768342b07c67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkept_filters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n\u001b[0;32m    130\u001b[0m                          (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "'''Visualization of the filters of VGG16, via gradient ascent in input space.\n",
    "This script can run on CPU in a few minutes.\n",
    "Results example: http://i.imgur.com/4nj4KjN.jpg\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from scipy.misc import imsave\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.applications import vgg16\n",
    "from keras import backend as K\n",
    "\n",
    "# dimensions of the generated pictures for each filter.\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "\n",
    "# the name of the layer we want to visualize\n",
    "# (see model definition at keras/applications/vgg16.py)\n",
    "layer_name = 'block5_conv3'\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "# build the VGG16 network with ImageNet weights\n",
    "print('Model loaded.')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# this is the placeholder for the input images\n",
    "input_img = model.input\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())\n",
    "\n",
    "\n",
    "kept_filters = []\n",
    "for filter_index in range(200):\n",
    "    # we only scan through the first 200 filters,\n",
    "    # but there are actually 512 of them\n",
    "    print('Processing filter %d' % filter_index)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # we build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads = normalize(grads)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "    # step size for gradient ascent\n",
    "    step = 1.\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_img_data = np.random.random((1, 3, img_width, img_height))\n",
    "    else:\n",
    "        input_img_data = np.random.random((1, img_width, img_height, 3))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "    \n",
    "\n",
    "    # we run gradient ascent for 20 steps\n",
    "    for i in range(20):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "\n",
    "        print('Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            break\n",
    "\n",
    "    # decode the resulting input image\n",
    "    if loss_value > 0:\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        kept_filters.append((img, loss_value))\n",
    "    end_time = time.time()\n",
    "    print('Filter %d processed in %ds' % (filter_index, end_time - start_time))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HOU\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\ipykernel_launcher.py:24: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    }
   ],
   "source": [
    "# we will stich the best 64 filters on a 8 x 8 grid.\n",
    "n = 4\n",
    "\n",
    "# the filters that have the highest loss are assumed to be better-looking.\n",
    "# we will only keep the top 64 filters.\n",
    "kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "kept_filters = kept_filters[:n * n]\n",
    "\n",
    "# build a black picture with enough space for\n",
    "# our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "margin =5\n",
    "width = n * img_width + (n - 1) * margin\n",
    "height = n * img_height + (n - 1) * margin\n",
    "stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "# fill the picture with our saved filters\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        img, loss = kept_filters[i * n + j]\n",
    "        stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n",
    "                         (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n",
    "\n",
    "# save the result to disk\n",
    "imsave('128stitched_filters_%dx%d.png' % (n, n), stitched_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
