{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True [[[137 133 129]\n",
      "  [139 135 131]\n",
      "  [135 131 127]\n",
      "  ...\n",
      "  [102  99  93]\n",
      "  [104 101  95]\n",
      "  [102  99  93]]\n",
      "\n",
      " [[139 135 131]\n",
      "  [140 136 132]\n",
      "  [136 132 128]\n",
      "  ...\n",
      "  [105 102  96]\n",
      "  [102  99  93]\n",
      "  [104 101  95]]\n",
      "\n",
      " [[136 132 128]\n",
      "  [136 132 128]\n",
      "  [136 132 128]\n",
      "  ...\n",
      "  [101  98  92]\n",
      "  [101  98  92]\n",
      "  [102  99  93]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 92  95  93]\n",
      "  [ 92  95  93]\n",
      "  [ 95  98  96]\n",
      "  ...\n",
      "  [104 106 108]\n",
      "  [105 107 109]\n",
      "  [102 104 106]]\n",
      "\n",
      " [[ 93  96  94]\n",
      "  [ 93  96  94]\n",
      "  [ 93  96  94]\n",
      "  ...\n",
      "  [104 106 108]\n",
      "  [104 106 108]\n",
      "  [102 104 106]]\n",
      "\n",
      " [[ 91  94  92]\n",
      "  [ 92  95  93]\n",
      "  [ 92  95  93]\n",
      "  ...\n",
      "  [102 104 106]\n",
      "  [102 104 106]\n",
      "  [104 106 108]]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'grabbed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d0956f0bdb63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcamera\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgrabbed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grabbed' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    " \n",
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import time\n",
    "import math\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"C:/Users/lll/Documents/hz/shape_predictor_68_face_landmarks.dat\")\n",
    "POINTS_NUM_LANDMARK = 68\n",
    "\n",
    "# 获取最大的人脸\n",
    "def _largest_face(dets):\n",
    "    if len(dets) == 1:\n",
    "        return 0\n",
    "\n",
    "    face_areas = [ (det.right()-det.left())*(det.bottom()-det.top()) for det in dets]\n",
    "\n",
    "    largest_area = face_areas[0]\n",
    "    largest_index = 0\n",
    "    for index in range(1, len(dets)):\n",
    "        if face_areas[index] > largest_area :\n",
    "            largest_index = index\n",
    "            largest_area = face_areas[index]\n",
    "\n",
    "    print(\"largest_face index is {} in {} faces\".format(largest_index, len(dets)))\n",
    "\n",
    "    return largest_index\n",
    "\n",
    "# 从dlib的检测结果抽取姿态估计需要的点坐标\n",
    "def get_image_points_from_landmark_shape(landmark_shape):\n",
    "    if landmark_shape.num_parts != POINTS_NUM_LANDMARK:\n",
    "        print(\"ERROR:landmark_shape.num_parts-{}\".format(landmark_shape.num_parts))\n",
    "        return -1, None\n",
    "    \n",
    "    #2D image points. If you change the image, you need to change vector\n",
    "    image_points = np.array([\n",
    "                                (landmark_shape.part(30).x, landmark_shape.part(30).y),     # Nose tip\n",
    "                                (landmark_shape.part(8).x, landmark_shape.part(8).y),     # Chin\n",
    "                                (landmark_shape.part(36).x, landmark_shape.part(36).y),     # Left eye left corner\n",
    "                                (landmark_shape.part(45).x, landmark_shape.part(45).y),     # Right eye right corne\n",
    "                                (landmark_shape.part(48).x, landmark_shape.part(48).y),     # Left Mouth corner\n",
    "                                (landmark_shape.part(54).x, landmark_shape.part(54).y)      # Right mouth corner\n",
    "                            ], dtype=\"double\")\n",
    "\n",
    "    return 0, image_points\n",
    "    \n",
    "# 用dlib检测关键点，返回姿态估计需要的几个点坐标\n",
    "def get_image_points(img):\n",
    "                            \n",
    "    #gray = cv2.cvtColor( img, cv2.COLOR_BGR2GRAY )  # 图片调整为灰色\n",
    "    dets = detector( img, 0 )\n",
    "\n",
    "    if 0 == len( dets ):\n",
    "        print( \"ERROR: found no face\" )\n",
    "        return -1, None\n",
    "    largest_index = _largest_face(dets)\n",
    "    face_rectangle = dets[largest_index]\n",
    "\n",
    "    landmark_shape = predictor(img, face_rectangle)\n",
    "\n",
    "    return get_image_points_from_landmark_shape(landmark_shape)\n",
    "\n",
    "\n",
    "# 获取旋转向量和平移向量                        \n",
    "def get_pose_estimation(img_size, image_points ):\n",
    "    # 3D model points.\n",
    "    model_points = np.array([\n",
    "                                (0.0, 0.0, 0.0),             # Nose tip\n",
    "                                (0.0, -330.0, -65.0),        # Chin\n",
    "                                (-225.0, 170.0, -135.0),     # Left eye left corner\n",
    "                                (225.0, 170.0, -135.0),      # Right eye right corne\n",
    "                                (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "                                (150.0, -150.0, -125.0)      # Right mouth corner\n",
    "                             \n",
    "                            ])\n",
    "     \n",
    "    # Camera internals\n",
    "     \n",
    "    focal_length = img_size[1]\n",
    "    center = (img_size[1]/2, img_size[0]/2)\n",
    "    camera_matrix = np.array(\n",
    "                             [[focal_length, 0, center[0]],\n",
    "                             [0, focal_length, center[1]],\n",
    "                             [0, 0, 1]], dtype = \"double\"\n",
    "                             )\n",
    "     \n",
    "    print(\"Camera Matrix :{}\".format(camera_matrix))\n",
    "     \n",
    "    dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    "    (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE )\n",
    " \n",
    "    print(\"Rotation Vector:\\n {}\".format(rotation_vector))\n",
    "    print(\"Translation Vector:\\n {}\".format(translation_vector))\n",
    "    return success, rotation_vector, translation_vector, camera_matrix, dist_coeffs\n",
    "\n",
    "# 从旋转向量转换为欧拉角\n",
    "def get_euler_angle(rotation_vector):\n",
    "    # calculate rotation angles\n",
    "    theta = cv2.norm(rotation_vector, cv2.NORM_L2)\n",
    "    \n",
    "    # transformed to quaterniond\n",
    "    w = math.cos(theta / 2)\n",
    "    x = math.sin(theta / 2)*rotation_vector[0][0] / theta\n",
    "    y = math.sin(theta / 2)*rotation_vector[1][0] / theta\n",
    "    z = math.sin(theta / 2)*rotation_vector[2][0] / theta\n",
    "    \n",
    "    ysqr = y * y\n",
    "    # pitch (x-axis rotation)\n",
    "    t0 = 2.0 * (w * x + y * z)\n",
    "    t1 = 1.0 - 2.0 * (x * x + ysqr)\n",
    "    print('t0:{}, t1:{}'.format(t0, t1))\n",
    "    pitch = math.atan2(t0, t1)\n",
    "    \n",
    "    # yaw (y-axis rotation)\n",
    "    t2 = 2.0 * (w * y - z * x)\n",
    "    if t2 > 1.0:\n",
    "        t2 = 1.0\n",
    "    if t2 < -1.0:\n",
    "        t2 = -1.0\n",
    "    yaw = math.asin(t2)\n",
    "    \n",
    "    # roll (z-axis rotation)\n",
    "    t3 = 2.0 * (w * z + x * y)\n",
    "    t4 = 1.0 - 2.0 * (ysqr + z * z)\n",
    "    roll = math.atan2(t3, t4)\n",
    "    \n",
    "    print('pitch:{}, yaw:{}, roll:{}'.format(pitch, yaw, roll))\n",
    "    \n",
    "\t# 单位转换：将弧度转换为度\n",
    "    Y = int((pitch/math.pi)*180)\n",
    "    X = int((yaw/math.pi)*180)\n",
    "    Z = int((roll/math.pi)*180)\n",
    "    \n",
    "    return 0, Y, X, Z\n",
    "\n",
    "def get_pose_estimation_in_euler_angle(landmark_shape, im_szie):\n",
    "    try:\n",
    "        ret, image_points = get_image_points_from_landmark_shape(landmark_shape)\n",
    "        if ret != 0:\n",
    "            print('get_image_points failed')\n",
    "            return -1, None, None, None\n",
    "    \n",
    "        ret, rotation_vector, translation_vector, camera_matrix, dist_coeffs = get_pose_estimation(im_szie, image_points)\n",
    "        if ret != True:\n",
    "            print('get_pose_estimation failed')\n",
    "            return -1, None, None, None\n",
    "    \n",
    "        ret, pitch, yaw, roll = get_euler_angle(rotation_vector)\n",
    "        if ret != 0:\n",
    "            print('get_euler_angle failed')\n",
    "            return -1, None, None, None\n",
    "\n",
    "        euler_angle_str = 'Y:{}, X:{}, Z:{}'.format(pitch, yaw, roll)\n",
    "        print(euler_angle_str)\n",
    "        return 0, pitch, yaw, roll\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('get_pose_estimation_in_euler_angle exception:{}'.format(e))\n",
    "        return -1, None, None, None\n",
    "        \n",
    "\n",
    "camera =cv2.VideoCapture(\"C:/Users/lll/Documents/hz/conda/images/video.mp4\")\n",
    "while True:\n",
    "    \n",
    "    ret, im = camera.read()\n",
    "    print(ret,im)\n",
    "    if not grabbed:\n",
    "        break\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Read Image\n",
    "    \n",
    "    if ret != True:\n",
    "        print('read frame failed')\n",
    "        continue\n",
    "    size = im.shape\n",
    "\n",
    "    if size[0] > 700:\n",
    "        h = size[0] / 2\n",
    "        w = size[1] / 2\n",
    "        im = cv2.resize( im, (int( w ), int( h )), interpolation=cv2.INTER_CUBIC )\n",
    "        size = im.shape\n",
    "\n",
    "    ret, image_points = get_image_points(im)\n",
    "    if ret != 0:\n",
    "        print('get_image_points failed')\n",
    "        continue\n",
    "\n",
    "    ret, rotation_vector, translation_vector, camera_matrix, dist_coeffs = get_pose_estimation(size, image_points)\n",
    "    if ret != True:\n",
    "        print('get_pose_estimation failed')\n",
    "        continue\n",
    "    used_time = time.time() - start_time\n",
    "    print(\"used_time:{} sec\".format(round(used_time, 3)))\n",
    "\n",
    "    ret, pitch, yaw, roll = get_euler_angle(rotation_vector)\n",
    "    euler_angle_str = 'Y:{}, X:{}, Z:{}'.format(pitch, yaw, roll)\n",
    "    print(euler_angle_str)\n",
    "\n",
    "    # Project a 3D point (0, 0, 1000.0) onto the image plane.\n",
    "    # We use this to draw a line sticking out of the nose\n",
    "\n",
    "    (nose_end_point2D, jacobian) = cv2.projectPoints(np.array([(0.0, 0.0, 1000.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "\n",
    "    for p in image_points:\n",
    "        cv2.circle(im, (int(p[0]), int(p[1])), 3, (0,0,255), -1)\n",
    "\n",
    "\n",
    "    p1 = ( int(image_points[0][0]), int(image_points[0][1]))\n",
    "    p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
    "\n",
    "    cv2.line(im, p1, p2, (255,0,0), 2)\n",
    "\n",
    "    # Display image\n",
    "    #cv2.putText( im, str(rotation_vector), (0, 100), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 1 )\n",
    "    cv2.putText( im, euler_angle_str, (0, 120), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 1 )\n",
    "    cv2.imshow(\"Output\", im)\n",
    "    cv2.waitKey(1)\n",
    "   \n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
