{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3L6a4yTZ0E4i",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "4d4f2b87-7716-416e-d30c-6deae680dba5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524878251131,
          "user_tz": -540,
          "elapsed": 37117,
          "user": {
            "displayName": "侯卓",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110472473765101011281"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmp5mgvs30a/pubring.gpg' created\n",
            "gpg: /tmp/tmp5mgvs30a/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9gSk30Yq0-YO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive  -o nonempty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WQSDf1rS1Kcy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HdmdNHKa1NYu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "ed42be35-fd92-4784-f99e-3d3395bbba77",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524878497230,
          "user_tz": -540,
          "elapsed": 145387,
          "user": {
            "displayName": "侯卓",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110472473765101011281"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''Trains a simple convnet on the MNIST dataset.\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "(there is still a lot of margin for parameter tuning).\n",
        "16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 13s 222us/step - loss: 0.2685 - acc: 0.9182 - val_loss: 0.0654 - val_acc: 0.9808\n",
            "Epoch 2/12\n",
            "24704/60000 [===========>..................] - ETA: 6s - loss: 0.0923 - acc: 0.9723"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0865 - acc: 0.9741 - val_loss: 0.0403 - val_acc: 0.9877\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 11s 183us/step - loss: 0.0649 - acc: 0.9806 - val_loss: 0.0352 - val_acc: 0.9877\n",
            "Epoch 4/12\n",
            "52480/60000 [=========================>....] - ETA: 1s - loss: 0.0548 - acc: 0.9838"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0542 - acc: 0.9840 - val_loss: 0.0297 - val_acc: 0.9906\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0449 - acc: 0.9865 - val_loss: 0.0328 - val_acc: 0.9890\n",
            "Epoch 6/12\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9875"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0402 - acc: 0.9875 - val_loss: 0.0291 - val_acc: 0.9910\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0379 - acc: 0.9887 - val_loss: 0.0290 - val_acc: 0.9902\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 0.0345 - acc: 0.9899 - val_loss: 0.0278 - val_acc: 0.9919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 0.0309 - acc: 0.9901 - val_loss: 0.0264 - val_acc: 0.9923\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0286 - acc: 0.9914 - val_loss: 0.0267 - val_acc: 0.9917\n",
            "Epoch 11/12\n",
            "42880/60000 [====================>.........] - ETA: 3s - loss: 0.0253 - acc: 0.9920"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0263 - acc: 0.9918 - val_loss: 0.0270 - val_acc: 0.9920\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 11s 183us/step - loss: 0.0259 - acc: 0.9922 - val_loss: 0.0264 - val_acc: 0.9924\n",
            "Test loss: 0.026386173812904052\n",
            "Test accuracy: 0.9924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WsKZONnU19Tp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "ff8f736f-1e2e-4d54-8fcc-cd58b2a75ea1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524878545605,
          "user_tz": -540,
          "elapsed": 9906,
          "user": {
            "displayName": "侯卓",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110472473765101011281"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "# See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "  random_image_cpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n",
        "  net_cpu = tf.reduce_sum(net_cpu)\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
        "  net_gpu = tf.reduce_sum(net_gpu)\n",
        "\n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "# Test execution once to detect errors early.\n",
        "try:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "except tf.errors.InvalidArgumentError:\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise\n",
        "\n",
        "def cpu():\n",
        "  sess.run(net_cpu)\n",
        "  \n",
        "def gpu():\n",
        "  sess.run(net_gpu)\n",
        "  \n",
        "# Runs the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "8.948938666000004\n",
            "GPU (s):\n",
            "0.2615954700000884\n",
            "GPU speedup over CPU: 34x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s0D94r2JED9k",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 172171
        },
        "outputId": "fa906e22-f31e-41fe-d15b-5793db1912aa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524895062600,
          "user_tz": -540,
          "elapsed": 6218017,
          "user": {
            "displayName": "侯卓",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110472473765101011281"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "DCGAN on MNIST using Keras\n",
        "Dependencies: tensorflow 1.0 and keras 2.0\n",
        "Usage: python dcgan_mnist.py\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Reshape\n",
        "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
        "from keras.layers import LeakyReLU, Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class ElapsedTimer(object):\n",
        "    def __init__(self):\n",
        "        self.start_time = time.time()\n",
        "    def elapsed(self,sec):\n",
        "        if sec < 60:\n",
        "            return str(sec) + \" sec\"\n",
        "        elif sec < (60 * 60):\n",
        "            return str(sec / 60) + \" min\"\n",
        "        else:\n",
        "            return str(sec / (60 * 60)) + \" hr\"\n",
        "    def elapsed_time(self):\n",
        "        print(\"Elapsed: %s \" % self.elapsed(time.time() - self.start_time) )\n",
        "\n",
        "        \n",
        "class DCGAN(object):\n",
        "    def __init__(self, img_rows=28, img_cols=28, channel=1):\n",
        "\n",
        "        self.img_rows = img_rows\n",
        "        self.img_cols = img_cols\n",
        "        self.channel = channel\n",
        "        self.D = None   # discriminator\n",
        "        self.G = None   # generator\n",
        "        self.AM = None  # adversarial model\n",
        "        self.DM = None  # discriminator model\n",
        "\n",
        "    # (W−F+2P)/S+1 \n",
        "    def discriminator(self): #输入图片，生成概率\n",
        "        if self.D:\n",
        "            return self.D\n",
        "        self.D = Sequential()\n",
        "        depth = 64  #w设置filter为64,生成64个unit\n",
        "        dropout = 0.4#防止学习偷懒\n",
        "        # In: 28 x 28 x 1, depth = 1\n",
        "        # Out: 14 x 14 x 1, depth=64\n",
        "        #conv2d(filters输出的维度,kernel_size,strides,padding policy)\n",
        "        input_shape = (self.img_rows, self.img_cols, self.channel)\n",
        "        self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape,\\\n",
        "            padding='same'))\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\n",
        "        self.D.add(Dropout(dropout))\n",
        "\n",
        "        self.D.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\n",
        "        self.D.add(Dropout(dropout))\n",
        "\n",
        "        self.D.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\n",
        "        self.D.add(Dropout(dropout))\n",
        "\n",
        "        self.D.add(Conv2D(depth*8, 5, strides=1, padding='same'))\n",
        "        self.D.add(LeakyReLU(alpha=0.2))\n",
        "        self.D.add(Dropout(dropout))\n",
        "\n",
        "        # Out: 1-dim probability\n",
        "        self.D.add(Flatten())\n",
        "        self.D.add(Dense(1))\n",
        "        self.D.add(Activation('sigmoid'))\n",
        "        self.D.summary()\n",
        "        return self.D\n",
        "\n",
        "    def generator(self):#100维随机向量生成一个dim x dim x depth的图片\n",
        "        if self.G:\n",
        "            return self.G\n",
        "        self.G = Sequential()\n",
        "        dropout = 0.4\n",
        "        depth = 64+64+64+64\n",
        "        dim = 7\n",
        "        # In: 100\n",
        "        # Out: dim x dim x depth\n",
        "        self.G.add(Dense(dim*dim*depth, input_dim=100))#全联接，100 x 1变成dim x dim x depth\n",
        "        self.G.add(BatchNormalization(momentum=0.9)) #防止网络太深梯度vanish\n",
        "        self.G.add(Activation('relu'))\n",
        "        self.G.add(Reshape((dim, dim, depth)))#???\n",
        "        self.G.add(Dropout(dropout))\n",
        "\n",
        "        # In: dim x dim x depth\n",
        "        # Out: 2*dim x 2*dim x depth/2\n",
        "        self.G.add(UpSampling2D())#反卷积\n",
        "        self.G.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
        "        self.G.add(BatchNormalization(momentum=0.9))\n",
        "        self.G.add(Activation('relu'))\n",
        "\n",
        "        self.G.add(UpSampling2D())\n",
        "        self.G.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n",
        "        self.G.add(BatchNormalization(momentum=0.9))\n",
        "        self.G.add(Activation('relu'))\n",
        "\n",
        "        self.G.add(Conv2DTranspose(int(depth/8), 5, padding='same'))\n",
        "        self.G.add(BatchNormalization(momentum=0.9))\n",
        "        self.G.add(Activation('relu'))\n",
        "\n",
        "        # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\n",
        "        self.G.add(Conv2DTranspose(1, 5, padding='same'))\n",
        "        self.G.add(Activation('sigmoid'))\n",
        "        self.G.summary()\n",
        "        return self.G\n",
        "\n",
        "    def discriminator_model(self):#分类器\n",
        "        if self.DM:\n",
        "            return self.DM\n",
        "        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
        "        self.DM = Sequential()\n",
        "        self.DM.add(self.discriminator())\n",
        "        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
        "            metrics=['accuracy'])\n",
        "        return self.DM\n",
        "\n",
        "    def adversarial_model(self):#拼起来\n",
        "        if self.AM:\n",
        "            return self.AM\n",
        "        optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
        "        self.AM = Sequential()\n",
        "        self.AM.add(self.generator())\n",
        "        self.AM.add(self.discriminator())\n",
        "        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
        "            metrics=['accuracy'])\n",
        "        return self.AM\n",
        "      \n",
        "class MNIST_DCGAN(object):#先训练一个Discriminator，再迭代交替训练generator和discriminator\n",
        "    def __init__(self):\n",
        "        self.img_rows = 28\n",
        "        self.img_cols = 28\n",
        "        self.channel = 1\n",
        "\n",
        "        self.x_train = input_data.read_data_sets(\"mnist\",\\\n",
        "        \tone_hot=True).train.images\n",
        "        self.x_train = self.x_train.reshape(-1, self.img_rows,\\\n",
        "        \tself.img_cols, 1).astype(np.float32)\n",
        "\n",
        "        self.DCGAN = DCGAN()\n",
        "        self.discriminator =  self.DCGAN.discriminator_model()\n",
        "        self.adversarial = self.DCGAN.adversarial_model()\n",
        "        self.generator = self.DCGAN.generator()\n",
        "\n",
        "    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n",
        "        noise_input = None\n",
        "        if save_interval>0:\n",
        "            noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
        "        for i in range(train_steps):\n",
        "            images_train = self.x_train[np.random.randint(0,\n",
        "                self.x_train.shape[0], size=batch_size), :, :, :]\n",
        "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
        "            images_fake = self.generator.predict(noise)\n",
        "            x = np.concatenate((images_train, images_fake))\n",
        "            y = np.ones([2*batch_size, 1])\n",
        "            y[batch_size:, :] = 0#前一半真实batch行设为0？\n",
        "            d_loss = self.discriminator.train_on_batch(x, y)\n",
        "\n",
        "            y = np.ones([batch_size, 1])\n",
        "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
        "            a_loss = self.adversarial.train_on_batch(noise, y)\n",
        "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
        "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
        "            print(log_mesg)\n",
        "            if save_interval>0:\n",
        "                if (i+1)%save_interval==0:\n",
        "                    self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n",
        "                        noise=noise_input, step=(i+1))\n",
        "\n",
        "    def plot_images(self, save2file=False, fake=True, samples=16, noise=None, step=0):\n",
        "        filename = 'mnist.png'\n",
        "        if fake:\n",
        "            if noise is None:\n",
        "                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n",
        "            else:\n",
        "                filename = \"mnist_%d.png\" % step\n",
        "            images = self.generator.predict(noise)\n",
        "        else:\n",
        "            i = np.random.randint(0, self.x_train.shape[0], samples)\n",
        "            images = self.x_train[i, :, :, :]\n",
        "\n",
        "        plt.figure(figsize=(10,10))\n",
        "        for i in range(images.shape[0]):\n",
        "            plt.subplot(4, 4, i+1)\n",
        "            image = images[i, :, :, :]\n",
        "            image = np.reshape(image, [self.img_rows, self.img_cols])\n",
        "            plt.imshow(image, cmap='gray')\n",
        "            plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        if save2file:\n",
        "            plt.savefig(filename)\n",
        "            plt.close('all')\n",
        "        else:\n",
        "            plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    mnist_dcgan = MNIST_DCGAN()\n",
        "    timer = ElapsedTimer()\n",
        "    mnist_dcgan.train(train_steps=10000, batch_size=256, save_interval=500)\n",
        "    timer.elapsed_time()\n",
        "    mnist_dcgan.plot_images(fake=True)\n",
        "    mnist_dcgan.plot_images(fake=False, save2file=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting mnist/train-images-idx3-ubyte.gz\n",
            "Extracting mnist/train-labels-idx1-ubyte.gz\n",
            "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
            "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 14, 14, 64)        1664      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 7, 7, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 4, 4, 256)         819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 4, 4, 512)         3277312   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 8193      \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 4,311,553\n",
            "Trainable params: 4,311,553\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 12544)             1266944   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 12544)             50176     \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2 (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_9 (Conv2DTr (None, 14, 14, 128)       819328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2 (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_10 (Conv2DT (None, 28, 28, 64)        204864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_11 (Conv2DT (None, 28, 28, 32)        51232     \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_12 (Conv2DT (None, 28, 28, 1)         801       \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 2,394,241\n",
            "Trainable params: 2,368,705\n",
            "Non-trainable params: 25,536\n",
            "_________________________________________________________________\n",
            "0: [D loss: 0.692856, acc: 0.511719]  [A loss: 1.072748, acc: 0.000000]\n",
            "1: [D loss: 0.673486, acc: 0.500000]  [A loss: 1.054612, acc: 0.000000]\n",
            "2: [D loss: 0.640605, acc: 0.980469]  [A loss: 0.794071, acc: 0.007812]\n",
            "3: [D loss: 0.839845, acc: 0.500000]  [A loss: 1.158814, acc: 0.000000]\n",
            "4: [D loss: 0.543351, acc: 0.951172]  [A loss: 1.087376, acc: 0.000000]\n",
            "5: [D loss: 0.507202, acc: 0.998047]  [A loss: 1.141041, acc: 0.000000]\n",
            "6: [D loss: 0.523325, acc: 0.652344]  [A loss: 1.480584, acc: 0.000000]\n",
            "7: [D loss: 0.537133, acc: 0.857422]  [A loss: 1.124415, acc: 0.000000]\n",
            "8: [D loss: 0.498155, acc: 0.601562]  [A loss: 1.666867, acc: 0.000000]\n",
            "9: [D loss: 0.483620, acc: 0.980469]  [A loss: 1.017235, acc: 0.000000]\n",
            "10: [D loss: 0.581158, acc: 0.500000]  [A loss: 1.791021, acc: 0.000000]\n",
            "11: [D loss: 0.497779, acc: 0.904297]  [A loss: 1.123987, acc: 0.000000]\n",
            "12: [D loss: 0.397030, acc: 0.945312]  [A loss: 1.179273, acc: 0.000000]\n",
            "13: [D loss: 0.369869, acc: 0.880859]  [A loss: 1.506209, acc: 0.000000]\n",
            "14: [D loss: 0.330161, acc: 0.994141]  [A loss: 1.423113, acc: 0.000000]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15: [D loss: 0.319668, acc: 0.941406]  [A loss: 1.802847, acc: 0.000000]\n",
            "16: [D loss: 0.288876, acc: 0.998047]  [A loss: 1.350905, acc: 0.000000]\n",
            "17: [D loss: 0.340714, acc: 0.804688]  [A loss: 2.259546, acc: 0.000000]\n",
            "18: [D loss: 0.332406, acc: 0.949219]  [A loss: 1.246825, acc: 0.003906]\n",
            "19: [D loss: 0.335510, acc: 0.806641]  [A loss: 1.884596, acc: 0.000000]\n",
            "20: [D loss: 0.199351, acc: 0.992188]  [A loss: 1.403253, acc: 0.000000]\n",
            "21: [D loss: 0.233905, acc: 0.962891]  [A loss: 1.892402, acc: 0.000000]\n",
            "22: [D loss: 0.164812, acc: 1.000000]  [A loss: 1.646998, acc: 0.000000]\n",
            "23: [D loss: 0.199522, acc: 0.976562]  [A loss: 2.092599, acc: 0.000000]\n",
            "24: [D loss: 0.154552, acc: 0.996094]  [A loss: 1.737538, acc: 0.000000]\n",
            "25: [D loss: 0.168084, acc: 0.986328]  [A loss: 2.189342, acc: 0.000000]\n",
            "26: [D loss: 0.154180, acc: 0.990234]  [A loss: 1.627434, acc: 0.000000]\n",
            "27: [D loss: 0.217948, acc: 0.925781]  [A loss: 2.671492, acc: 0.000000]\n",
            "28: [D loss: 0.217270, acc: 0.941406]  [A loss: 1.017228, acc: 0.136719]\n",
            "29: [D loss: 0.692445, acc: 0.548828]  [A loss: 2.773153, acc: 0.000000]\n",
            "30: [D loss: 0.342133, acc: 0.863281]  [A loss: 1.320926, acc: 0.003906]\n",
            "31: [D loss: 0.198424, acc: 0.976562]  [A loss: 1.393688, acc: 0.007812]\n",
            "32: [D loss: 0.236472, acc: 0.921875]  [A loss: 1.629523, acc: 0.000000]\n",
            "33: [D loss: 0.191785, acc: 0.953125]  [A loss: 1.771072, acc: 0.000000]\n",
            "34: [D loss: 0.204998, acc: 0.955078]  [A loss: 1.865794, acc: 0.000000]\n",
            "35: [D loss: 0.189723, acc: 0.957031]  [A loss: 1.796639, acc: 0.003906]\n",
            "36: [D loss: 0.230748, acc: 0.919922]  [A loss: 2.217324, acc: 0.000000]\n",
            "37: [D loss: 0.156239, acc: 0.992188]  [A loss: 1.872178, acc: 0.000000]\n",
            "38: [D loss: 0.210945, acc: 0.939453]  [A loss: 2.244298, acc: 0.000000]\n",
            "39: [D loss: 0.178417, acc: 0.976562]  [A loss: 2.121663, acc: 0.000000]\n",
            "40: [D loss: 0.163451, acc: 0.970703]  [A loss: 1.729010, acc: 0.003906]\n",
            "41: [D loss: 0.244037, acc: 0.900391]  [A loss: 2.687553, acc: 0.000000]\n",
            "42: [D loss: 0.207016, acc: 0.935547]  [A loss: 0.851890, acc: 0.351562]\n",
            "43: [D loss: 0.812887, acc: 0.542969]  [A loss: 3.153915, acc: 0.000000]\n",
            "44: [D loss: 0.447740, acc: 0.808594]  [A loss: 1.030914, acc: 0.128906]\n",
            "45: [D loss: 0.426518, acc: 0.722656]  [A loss: 1.647873, acc: 0.000000]\n",
            "46: [D loss: 0.183476, acc: 0.970703]  [A loss: 1.467885, acc: 0.019531]\n",
            "47: [D loss: 0.260834, acc: 0.890625]  [A loss: 1.656174, acc: 0.011719]\n",
            "48: [D loss: 0.241604, acc: 0.914062]  [A loss: 1.735964, acc: 0.015625]\n",
            "49: [D loss: 0.248431, acc: 0.908203]  [A loss: 1.804439, acc: 0.003906]\n",
            "50: [D loss: 0.254018, acc: 0.898438]  [A loss: 1.838850, acc: 0.000000]\n",
            "51: [D loss: 0.248608, acc: 0.916016]  [A loss: 1.786744, acc: 0.003906]\n",
            "52: [D loss: 0.272584, acc: 0.892578]  [A loss: 1.959181, acc: 0.000000]\n",
            "53: [D loss: 0.222489, acc: 0.937500]  [A loss: 1.683521, acc: 0.003906]\n",
            "54: [D loss: 0.314133, acc: 0.855469]  [A loss: 2.327052, acc: 0.003906]\n",
            "55: [D loss: 0.258715, acc: 0.939453]  [A loss: 1.043243, acc: 0.230469]\n",
            "56: [D loss: 0.653868, acc: 0.607422]  [A loss: 3.282652, acc: 0.000000]\n",
            "57: [D loss: 0.678568, acc: 0.716797]  [A loss: 0.517156, acc: 0.781250]\n",
            "58: [D loss: 0.864294, acc: 0.523438]  [A loss: 1.537132, acc: 0.003906]\n",
            "59: [D loss: 0.291434, acc: 0.945312]  [A loss: 1.189451, acc: 0.046875]\n",
            "60: [D loss: 0.395557, acc: 0.765625]  [A loss: 1.586446, acc: 0.003906]\n",
            "61: [D loss: 0.317065, acc: 0.880859]  [A loss: 1.299462, acc: 0.023438]\n",
            "62: [D loss: 0.413746, acc: 0.751953]  [A loss: 1.842155, acc: 0.000000]\n",
            "63: [D loss: 0.356692, acc: 0.876953]  [A loss: 1.148207, acc: 0.121094]\n",
            "64: [D loss: 0.514567, acc: 0.669922]  [A loss: 2.089235, acc: 0.000000]\n",
            "65: [D loss: 0.358083, acc: 0.906250]  [A loss: 1.038307, acc: 0.148438]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "66: [D loss: 0.589867, acc: 0.587891]  [A loss: 2.338211, acc: 0.000000]\n",
            "67: [D loss: 0.440154, acc: 0.847656]  [A loss: 0.648773, acc: 0.597656]\n",
            "68: [D loss: 0.861579, acc: 0.507812]  [A loss: 1.978750, acc: 0.000000]\n",
            "69: [D loss: 0.396950, acc: 0.910156]  [A loss: 0.971420, acc: 0.148438]\n",
            "70: [D loss: 0.595570, acc: 0.558594]  [A loss: 1.811597, acc: 0.000000]\n",
            "71: [D loss: 0.395147, acc: 0.894531]  [A loss: 1.044552, acc: 0.113281]\n",
            "72: [D loss: 0.598381, acc: 0.580078]  [A loss: 1.987984, acc: 0.000000]\n",
            "73: [D loss: 0.404750, acc: 0.902344]  [A loss: 1.028412, acc: 0.093750]\n",
            "74: [D loss: 0.621832, acc: 0.550781]  [A loss: 2.024428, acc: 0.000000]\n",
            "75: [D loss: 0.424328, acc: 0.884766]  [A loss: 0.999227, acc: 0.121094]\n",
            "76: [D loss: 0.651972, acc: 0.537109]  [A loss: 2.140009, acc: 0.000000]\n",
            "77: [D loss: 0.436085, acc: 0.888672]  [A loss: 0.763902, acc: 0.425781]\n",
            "78: [D loss: 0.714478, acc: 0.517578]  [A loss: 1.961708, acc: 0.000000]\n",
            "79: [D loss: 0.400756, acc: 0.906250]  [A loss: 1.082768, acc: 0.074219]\n",
            "80: [D loss: 0.570820, acc: 0.568359]  [A loss: 1.953593, acc: 0.000000]\n",
            "81: [D loss: 0.417352, acc: 0.898438]  [A loss: 1.020012, acc: 0.105469]\n",
            "82: [D loss: 0.589018, acc: 0.529297]  [A loss: 2.138066, acc: 0.000000]\n",
            "83: [D loss: 0.400874, acc: 0.931641]  [A loss: 0.938870, acc: 0.183594]\n",
            "84: [D loss: 0.645643, acc: 0.519531]  [A loss: 2.172116, acc: 0.000000]\n",
            "85: [D loss: 0.423386, acc: 0.908203]  [A loss: 0.829547, acc: 0.300781]\n",
            "86: [D loss: 0.670957, acc: 0.501953]  [A loss: 2.066000, acc: 0.000000]\n",
            "87: [D loss: 0.393692, acc: 0.947266]  [A loss: 0.996839, acc: 0.093750]\n",
            "88: [D loss: 0.579178, acc: 0.541016]  [A loss: 2.086339, acc: 0.000000]\n",
            "89: [D loss: 0.371027, acc: 0.957031]  [A loss: 1.094266, acc: 0.042969]\n",
            "90: [D loss: 0.578453, acc: 0.537109]  [A loss: 2.302662, acc: 0.000000]\n",
            "91: [D loss: 0.382761, acc: 0.931641]  [A loss: 0.920541, acc: 0.152344]\n",
            "92: [D loss: 0.630271, acc: 0.511719]  [A loss: 2.281773, acc: 0.000000]\n",
            "93: [D loss: 0.368746, acc: 0.939453]  [A loss: 0.961856, acc: 0.105469]\n",
            "94: [D loss: 0.598141, acc: 0.527344]  [A loss: 2.204409, acc: 0.000000]\n",
            "95: [D loss: 0.372940, acc: 0.943359]  [A loss: 1.022506, acc: 0.035156]\n",
            "96: [D loss: 0.588249, acc: 0.517578]  [A loss: 2.315329, acc: 0.000000]\n",
            "97: [D loss: 0.351697, acc: 0.941406]  [A loss: 1.041993, acc: 0.058594]\n",
            "98: [D loss: 0.571170, acc: 0.529297]  [A loss: 2.354231, acc: 0.000000]\n",
            "99: [D loss: 0.336458, acc: 0.955078]  [A loss: 1.006649, acc: 0.082031]\n",
            "100: [D loss: 0.565036, acc: 0.529297]  [A loss: 2.382058, acc: 0.000000]\n",
            "101: [D loss: 0.322603, acc: 0.957031]  [A loss: 1.007635, acc: 0.046875]\n",
            "102: [D loss: 0.569285, acc: 0.533203]  [A loss: 2.478496, acc: 0.000000]\n",
            "103: [D loss: 0.311834, acc: 0.947266]  [A loss: 1.101569, acc: 0.058594]\n",
            "104: [D loss: 0.539120, acc: 0.544922]  [A loss: 2.418742, acc: 0.000000]\n",
            "105: [D loss: 0.304254, acc: 0.960938]  [A loss: 1.097420, acc: 0.050781]\n",
            "106: [D loss: 0.538041, acc: 0.550781]  [A loss: 2.463258, acc: 0.000000]\n",
            "107: [D loss: 0.313067, acc: 0.945312]  [A loss: 1.128549, acc: 0.023438]\n",
            "108: [D loss: 0.537364, acc: 0.554688]  [A loss: 2.531683, acc: 0.000000]\n",
            "109: [D loss: 0.297037, acc: 0.957031]  [A loss: 1.179623, acc: 0.031250]\n",
            "110: [D loss: 0.532523, acc: 0.550781]  [A loss: 2.490536, acc: 0.000000]\n",
            "111: [D loss: 0.311596, acc: 0.939453]  [A loss: 1.093304, acc: 0.058594]\n",
            "112: [D loss: 0.564921, acc: 0.548828]  [A loss: 2.509550, acc: 0.000000]\n",
            "113: [D loss: 0.322058, acc: 0.941406]  [A loss: 1.145810, acc: 0.066406]\n",
            "114: [D loss: 0.597363, acc: 0.552734]  [A loss: 2.581032, acc: 0.000000]\n",
            "115: [D loss: 0.335546, acc: 0.935547]  [A loss: 1.070462, acc: 0.109375]\n",
            "116: [D loss: 0.670863, acc: 0.529297]  [A loss: 2.590766, acc: 0.000000]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "117: [D loss: 0.370499, acc: 0.906250]  [A loss: 1.019869, acc: 0.152344]\n",
            "118: [D loss: 0.742535, acc: 0.507812]  [A loss: 2.414506, acc: 0.000000]\n",
            "119: [D loss: 0.421800, acc: 0.865234]  [A loss: 1.068563, acc: 0.113281]\n",
            "120: [D loss: 0.674160, acc: 0.541016]  [A loss: 2.332684, acc: 0.000000]\n",
            "121: [D loss: 0.441222, acc: 0.859375]  [A loss: 1.141715, acc: 0.074219]\n",
            "122: [D loss: 0.695715, acc: 0.539062]  [A loss: 2.462987, acc: 0.000000]\n",
            "123: [D loss: 0.480150, acc: 0.837891]  [A loss: 0.966187, acc: 0.242188]\n",
            "124: [D loss: 0.782340, acc: 0.515625]  [A loss: 2.430812, acc: 0.000000]\n",
            "125: [D loss: 0.520073, acc: 0.773438]  [A loss: 0.868351, acc: 0.320312]\n",
            "126: [D loss: 0.808760, acc: 0.509766]  [A loss: 2.258348, acc: 0.000000]\n",
            "127: [D loss: 0.551996, acc: 0.753906]  [A loss: 0.959704, acc: 0.187500]\n",
            "128: [D loss: 0.779193, acc: 0.519531]  [A loss: 2.044429, acc: 0.000000]\n",
            "129: [D loss: 0.555252, acc: 0.748047]  [A loss: 0.977027, acc: 0.191406]\n",
            "130: [D loss: 0.748194, acc: 0.515625]  [A loss: 2.073030, acc: 0.000000]\n",
            "131: [D loss: 0.560226, acc: 0.746094]  [A loss: 0.892555, acc: 0.246094]\n",
            "132: [D loss: 0.768951, acc: 0.505859]  [A loss: 2.111403, acc: 0.000000]\n",
            "133: [D loss: 0.564738, acc: 0.757812]  [A loss: 0.891641, acc: 0.250000]\n",
            "134: [D loss: 0.767020, acc: 0.517578]  [A loss: 2.077833, acc: 0.000000]\n",
            "135: [D loss: 0.562172, acc: 0.750000]  [A loss: 0.850944, acc: 0.292969]\n",
            "136: [D loss: 0.763044, acc: 0.503906]  [A loss: 1.926078, acc: 0.000000]\n",
            "137: [D loss: 0.588008, acc: 0.724609]  [A loss: 0.797585, acc: 0.347656]\n",
            "138: [D loss: 0.787493, acc: 0.500000]  [A loss: 1.907200, acc: 0.000000]\n",
            "139: [D loss: 0.596477, acc: 0.710938]  [A loss: 0.843621, acc: 0.312500]\n",
            "140: [D loss: 0.748060, acc: 0.500000]  [A loss: 1.936545, acc: 0.000000]\n",
            "141: [D loss: 0.603808, acc: 0.693359]  [A loss: 0.827639, acc: 0.320312]\n",
            "142: [D loss: 0.757870, acc: 0.513672]  [A loss: 1.877569, acc: 0.000000]\n",
            "143: [D loss: 0.625828, acc: 0.640625]  [A loss: 0.895643, acc: 0.230469]\n",
            "144: [D loss: 0.743879, acc: 0.500000]  [A loss: 1.875153, acc: 0.000000]\n",
            "145: [D loss: 0.603292, acc: 0.699219]  [A loss: 0.833793, acc: 0.273438]\n",
            "146: [D loss: 0.761044, acc: 0.501953]  [A loss: 1.924055, acc: 0.000000]\n",
            "147: [D loss: 0.610248, acc: 0.707031]  [A loss: 0.728046, acc: 0.492188]\n",
            "148: [D loss: 0.760996, acc: 0.507812]  [A loss: 1.823432, acc: 0.000000]\n",
            "149: [D loss: 0.595494, acc: 0.730469]  [A loss: 0.810847, acc: 0.335938]\n",
            "150: [D loss: 0.747650, acc: 0.507812]  [A loss: 1.858240, acc: 0.000000]\n",
            "151: [D loss: 0.611915, acc: 0.718750]  [A loss: 0.703171, acc: 0.500000]\n",
            "152: [D loss: 0.770034, acc: 0.494141]  [A loss: 1.838849, acc: 0.000000]\n",
            "153: [D loss: 0.624693, acc: 0.718750]  [A loss: 0.676691, acc: 0.550781]\n",
            "154: [D loss: 0.789351, acc: 0.494141]  [A loss: 1.822166, acc: 0.000000]\n",
            "155: [D loss: 0.621955, acc: 0.714844]  [A loss: 0.693792, acc: 0.511719]\n",
            "156: [D loss: 0.756428, acc: 0.501953]  [A loss: 1.622771, acc: 0.000000]\n",
            "157: [D loss: 0.604299, acc: 0.724609]  [A loss: 0.797658, acc: 0.324219]\n",
            "158: [D loss: 0.702677, acc: 0.496094]  [A loss: 1.625194, acc: 0.000000]\n",
            "159: [D loss: 0.599034, acc: 0.707031]  [A loss: 0.800914, acc: 0.320312]\n",
            "160: [D loss: 0.681365, acc: 0.515625]  [A loss: 1.712327, acc: 0.000000]\n",
            "161: [D loss: 0.593753, acc: 0.750000]  [A loss: 0.739650, acc: 0.402344]\n",
            "162: [D loss: 0.728649, acc: 0.501953]  [A loss: 1.688590, acc: 0.000000]\n",
            "163: [D loss: 0.605641, acc: 0.720703]  [A loss: 0.710944, acc: 0.488281]\n",
            "164: [D loss: 0.713881, acc: 0.503906]  [A loss: 1.655116, acc: 0.000000]\n",
            "165: [D loss: 0.592315, acc: 0.742188]  [A loss: 0.778727, acc: 0.371094]\n",
            "166: [D loss: 0.702608, acc: 0.500000]  [A loss: 1.792911, acc: 0.000000]\n",
            "167: [D loss: 0.579633, acc: 0.763672]  [A loss: 0.670912, acc: 0.582031]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "168: [D loss: 0.713598, acc: 0.498047]  [A loss: 1.718617, acc: 0.000000]\n",
            "169: [D loss: 0.566732, acc: 0.761719]  [A loss: 0.691408, acc: 0.539062]\n",
            "170: [D loss: 0.697647, acc: 0.507812]  [A loss: 1.711565, acc: 0.000000]\n",
            "171: [D loss: 0.571672, acc: 0.783203]  [A loss: 0.757935, acc: 0.382812]\n",
            "172: [D loss: 0.654988, acc: 0.515625]  [A loss: 1.713101, acc: 0.000000]\n",
            "173: [D loss: 0.552797, acc: 0.814453]  [A loss: 0.731712, acc: 0.429688]\n",
            "174: [D loss: 0.715004, acc: 0.509766]  [A loss: 1.801864, acc: 0.000000]\n",
            "175: [D loss: 0.571927, acc: 0.750000]  [A loss: 0.680482, acc: 0.558594]\n",
            "176: [D loss: 0.699435, acc: 0.507812]  [A loss: 1.631965, acc: 0.000000]\n",
            "177: [D loss: 0.577103, acc: 0.767578]  [A loss: 0.810085, acc: 0.277344]\n",
            "178: [D loss: 0.673931, acc: 0.503906]  [A loss: 1.635245, acc: 0.000000]\n",
            "179: [D loss: 0.577492, acc: 0.742188]  [A loss: 0.781128, acc: 0.363281]\n",
            "180: [D loss: 0.692355, acc: 0.513672]  [A loss: 1.728073, acc: 0.000000]\n",
            "181: [D loss: 0.579432, acc: 0.751953]  [A loss: 0.695237, acc: 0.519531]\n",
            "182: [D loss: 0.702655, acc: 0.507812]  [A loss: 1.661844, acc: 0.000000]\n",
            "183: [D loss: 0.577352, acc: 0.763672]  [A loss: 0.776361, acc: 0.375000]\n",
            "184: [D loss: 0.667788, acc: 0.515625]  [A loss: 1.658612, acc: 0.000000]\n",
            "185: [D loss: 0.566287, acc: 0.792969]  [A loss: 0.761849, acc: 0.378906]\n",
            "186: [D loss: 0.681655, acc: 0.513672]  [A loss: 1.707771, acc: 0.000000]\n",
            "187: [D loss: 0.580816, acc: 0.724609]  [A loss: 0.712932, acc: 0.449219]\n",
            "188: [D loss: 0.679438, acc: 0.511719]  [A loss: 1.561388, acc: 0.000000]\n",
            "189: [D loss: 0.569230, acc: 0.777344]  [A loss: 0.781923, acc: 0.371094]\n",
            "190: [D loss: 0.661940, acc: 0.535156]  [A loss: 1.613236, acc: 0.000000]\n",
            "191: [D loss: 0.567240, acc: 0.773438]  [A loss: 0.707745, acc: 0.472656]\n",
            "192: [D loss: 0.698401, acc: 0.505859]  [A loss: 1.634646, acc: 0.000000]\n",
            "193: [D loss: 0.579308, acc: 0.748047]  [A loss: 0.713431, acc: 0.480469]\n",
            "194: [D loss: 0.677834, acc: 0.515625]  [A loss: 1.603667, acc: 0.000000]\n",
            "195: [D loss: 0.564728, acc: 0.783203]  [A loss: 0.760402, acc: 0.359375]\n",
            "196: [D loss: 0.666821, acc: 0.527344]  [A loss: 1.531486, acc: 0.000000]\n",
            "197: [D loss: 0.570982, acc: 0.794922]  [A loss: 0.744394, acc: 0.390625]\n",
            "198: [D loss: 0.668729, acc: 0.513672]  [A loss: 1.545481, acc: 0.000000]\n",
            "199: [D loss: 0.549438, acc: 0.816406]  [A loss: 0.763740, acc: 0.410156]\n",
            "200: [D loss: 0.689806, acc: 0.511719]  [A loss: 1.611717, acc: 0.000000]\n",
            "201: [D loss: 0.578868, acc: 0.732422]  [A loss: 0.692196, acc: 0.515625]\n",
            "202: [D loss: 0.701208, acc: 0.517578]  [A loss: 1.546531, acc: 0.000000]\n",
            "203: [D loss: 0.564669, acc: 0.800781]  [A loss: 0.759646, acc: 0.394531]\n",
            "204: [D loss: 0.692628, acc: 0.517578]  [A loss: 1.612712, acc: 0.000000]\n",
            "205: [D loss: 0.572673, acc: 0.751953]  [A loss: 0.749883, acc: 0.421875]\n",
            "206: [D loss: 0.670921, acc: 0.533203]  [A loss: 1.537732, acc: 0.000000]\n",
            "207: [D loss: 0.556696, acc: 0.802734]  [A loss: 0.846614, acc: 0.277344]\n",
            "208: [D loss: 0.656118, acc: 0.544922]  [A loss: 1.683481, acc: 0.000000]\n",
            "209: [D loss: 0.571048, acc: 0.759766]  [A loss: 0.714133, acc: 0.445312]\n",
            "210: [D loss: 0.698466, acc: 0.521484]  [A loss: 1.699682, acc: 0.000000]\n",
            "211: [D loss: 0.575612, acc: 0.761719]  [A loss: 0.734274, acc: 0.480469]\n",
            "212: [D loss: 0.722069, acc: 0.511719]  [A loss: 1.594429, acc: 0.000000]\n",
            "213: [D loss: 0.579256, acc: 0.744141]  [A loss: 0.743285, acc: 0.433594]\n",
            "214: [D loss: 0.686416, acc: 0.542969]  [A loss: 1.559043, acc: 0.000000]\n",
            "215: [D loss: 0.586985, acc: 0.712891]  [A loss: 0.719440, acc: 0.496094]\n",
            "216: [D loss: 0.697315, acc: 0.523438]  [A loss: 1.508287, acc: 0.000000]\n",
            "217: [D loss: 0.589525, acc: 0.738281]  [A loss: 0.790365, acc: 0.343750]\n",
            "218: [D loss: 0.689808, acc: 0.533203]  [A loss: 1.536728, acc: 0.003906]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "219: [D loss: 0.592756, acc: 0.718750]  [A loss: 0.796575, acc: 0.312500]\n",
            "220: [D loss: 0.718313, acc: 0.525391]  [A loss: 1.655712, acc: 0.000000]\n",
            "221: [D loss: 0.603639, acc: 0.671875]  [A loss: 0.705590, acc: 0.503906]\n",
            "222: [D loss: 0.722026, acc: 0.511719]  [A loss: 1.342692, acc: 0.000000]\n",
            "223: [D loss: 0.593909, acc: 0.738281]  [A loss: 0.857902, acc: 0.218750]\n",
            "224: [D loss: 0.659126, acc: 0.558594]  [A loss: 1.384537, acc: 0.011719]\n",
            "225: [D loss: 0.596730, acc: 0.703125]  [A loss: 0.894783, acc: 0.195312]\n",
            "226: [D loss: 0.649987, acc: 0.574219]  [A loss: 1.458986, acc: 0.007812]\n",
            "227: [D loss: 0.591509, acc: 0.732422]  [A loss: 0.822295, acc: 0.281250]\n",
            "228: [D loss: 0.696333, acc: 0.537109]  [A loss: 1.678880, acc: 0.000000]\n",
            "229: [D loss: 0.603396, acc: 0.691406]  [A loss: 0.657948, acc: 0.609375]\n",
            "230: [D loss: 0.733657, acc: 0.513672]  [A loss: 1.511365, acc: 0.000000]\n",
            "231: [D loss: 0.616358, acc: 0.697266]  [A loss: 0.772528, acc: 0.375000]\n",
            "232: [D loss: 0.699501, acc: 0.535156]  [A loss: 1.430957, acc: 0.003906]\n",
            "233: [D loss: 0.607235, acc: 0.705078]  [A loss: 0.821405, acc: 0.257812]\n",
            "234: [D loss: 0.679497, acc: 0.537109]  [A loss: 1.388671, acc: 0.000000]\n",
            "235: [D loss: 0.622285, acc: 0.652344]  [A loss: 0.784487, acc: 0.316406]\n",
            "236: [D loss: 0.678511, acc: 0.525391]  [A loss: 1.448597, acc: 0.000000]\n",
            "237: [D loss: 0.598539, acc: 0.712891]  [A loss: 0.838795, acc: 0.277344]\n",
            "238: [D loss: 0.676394, acc: 0.546875]  [A loss: 1.488439, acc: 0.000000]\n",
            "239: [D loss: 0.604465, acc: 0.722656]  [A loss: 0.844480, acc: 0.207031]\n",
            "240: [D loss: 0.688462, acc: 0.529297]  [A loss: 1.566067, acc: 0.000000]\n",
            "241: [D loss: 0.618528, acc: 0.671875]  [A loss: 0.767751, acc: 0.410156]\n",
            "242: [D loss: 0.696948, acc: 0.521484]  [A loss: 1.627544, acc: 0.000000]\n",
            "243: [D loss: 0.610770, acc: 0.693359]  [A loss: 0.735746, acc: 0.433594]\n",
            "244: [D loss: 0.701739, acc: 0.509766]  [A loss: 1.486679, acc: 0.000000]\n",
            "245: [D loss: 0.627503, acc: 0.669922]  [A loss: 0.730284, acc: 0.449219]\n",
            "246: [D loss: 0.708039, acc: 0.517578]  [A loss: 1.437159, acc: 0.000000]\n",
            "247: [D loss: 0.604743, acc: 0.708984]  [A loss: 0.784488, acc: 0.316406]\n",
            "248: [D loss: 0.671258, acc: 0.533203]  [A loss: 1.412405, acc: 0.000000]\n",
            "249: [D loss: 0.621257, acc: 0.679688]  [A loss: 0.778923, acc: 0.355469]\n",
            "250: [D loss: 0.708880, acc: 0.507812]  [A loss: 1.477149, acc: 0.000000]\n",
            "251: [D loss: 0.608417, acc: 0.710938]  [A loss: 0.729165, acc: 0.460938]\n",
            "252: [D loss: 0.705394, acc: 0.515625]  [A loss: 1.379524, acc: 0.000000]\n",
            "253: [D loss: 0.631715, acc: 0.673828]  [A loss: 0.769413, acc: 0.359375]\n",
            "254: [D loss: 0.684646, acc: 0.511719]  [A loss: 1.280549, acc: 0.011719]\n",
            "255: [D loss: 0.610640, acc: 0.687500]  [A loss: 0.873540, acc: 0.210938]\n",
            "256: [D loss: 0.665367, acc: 0.566406]  [A loss: 1.310571, acc: 0.000000]\n",
            "257: [D loss: 0.618483, acc: 0.707031]  [A loss: 0.842727, acc: 0.269531]\n",
            "258: [D loss: 0.678078, acc: 0.542969]  [A loss: 1.492764, acc: 0.000000]\n",
            "259: [D loss: 0.634008, acc: 0.658203]  [A loss: 0.714135, acc: 0.488281]\n",
            "260: [D loss: 0.741784, acc: 0.501953]  [A loss: 1.624760, acc: 0.000000]\n",
            "261: [D loss: 0.638034, acc: 0.654297]  [A loss: 0.659083, acc: 0.574219]\n",
            "262: [D loss: 0.731540, acc: 0.503906]  [A loss: 1.372546, acc: 0.000000]\n",
            "263: [D loss: 0.631379, acc: 0.677734]  [A loss: 0.774793, acc: 0.320312]\n",
            "264: [D loss: 0.684769, acc: 0.513672]  [A loss: 1.236729, acc: 0.003906]\n",
            "265: [D loss: 0.620689, acc: 0.699219]  [A loss: 0.794202, acc: 0.332031]\n",
            "266: [D loss: 0.694901, acc: 0.539062]  [A loss: 1.300892, acc: 0.000000]\n",
            "267: [D loss: 0.621679, acc: 0.699219]  [A loss: 0.816084, acc: 0.296875]\n",
            "268: [D loss: 0.673462, acc: 0.533203]  [A loss: 1.335176, acc: 0.007812]\n",
            "269: [D loss: 0.618151, acc: 0.705078]  [A loss: 0.857502, acc: 0.226562]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "270: [D loss: 0.687876, acc: 0.552734]  [A loss: 1.418479, acc: 0.000000]\n",
            "271: [D loss: 0.620429, acc: 0.683594]  [A loss: 0.726537, acc: 0.464844]\n",
            "272: [D loss: 0.710254, acc: 0.519531]  [A loss: 1.410003, acc: 0.000000]\n",
            "273: [D loss: 0.617689, acc: 0.691406]  [A loss: 0.752030, acc: 0.417969]\n",
            "274: [D loss: 0.702269, acc: 0.525391]  [A loss: 1.463456, acc: 0.000000]\n",
            "275: [D loss: 0.631719, acc: 0.681641]  [A loss: 0.730630, acc: 0.417969]\n",
            "276: [D loss: 0.703471, acc: 0.517578]  [A loss: 1.308083, acc: 0.000000]\n",
            "277: [D loss: 0.629848, acc: 0.675781]  [A loss: 0.783758, acc: 0.363281]\n",
            "278: [D loss: 0.689581, acc: 0.515625]  [A loss: 1.276373, acc: 0.003906]\n",
            "279: [D loss: 0.626499, acc: 0.697266]  [A loss: 0.806956, acc: 0.281250]\n",
            "280: [D loss: 0.678536, acc: 0.542969]  [A loss: 1.296020, acc: 0.000000]\n",
            "281: [D loss: 0.619472, acc: 0.703125]  [A loss: 0.749177, acc: 0.398438]\n",
            "282: [D loss: 0.695082, acc: 0.527344]  [A loss: 1.400889, acc: 0.000000]\n",
            "283: [D loss: 0.645547, acc: 0.630859]  [A loss: 0.659661, acc: 0.574219]\n",
            "284: [D loss: 0.725664, acc: 0.507812]  [A loss: 1.331260, acc: 0.003906]\n",
            "285: [D loss: 0.646305, acc: 0.652344]  [A loss: 0.712666, acc: 0.457031]\n",
            "286: [D loss: 0.715155, acc: 0.519531]  [A loss: 1.222148, acc: 0.003906]\n",
            "287: [D loss: 0.648117, acc: 0.642578]  [A loss: 0.801775, acc: 0.285156]\n",
            "288: [D loss: 0.671647, acc: 0.542969]  [A loss: 1.157555, acc: 0.003906]\n",
            "289: [D loss: 0.631404, acc: 0.666016]  [A loss: 0.849936, acc: 0.234375]\n",
            "290: [D loss: 0.675539, acc: 0.542969]  [A loss: 1.262479, acc: 0.007812]\n",
            "291: [D loss: 0.635626, acc: 0.667969]  [A loss: 0.738981, acc: 0.406250]\n",
            "292: [D loss: 0.697460, acc: 0.533203]  [A loss: 1.414839, acc: 0.003906]\n",
            "293: [D loss: 0.634535, acc: 0.644531]  [A loss: 0.660493, acc: 0.640625]\n",
            "294: [D loss: 0.711944, acc: 0.511719]  [A loss: 1.316148, acc: 0.000000]\n",
            "295: [D loss: 0.655239, acc: 0.632812]  [A loss: 0.728771, acc: 0.406250]\n",
            "296: [D loss: 0.691404, acc: 0.525391]  [A loss: 1.226271, acc: 0.003906]\n",
            "297: [D loss: 0.637187, acc: 0.664062]  [A loss: 0.784322, acc: 0.316406]\n",
            "298: [D loss: 0.695201, acc: 0.529297]  [A loss: 1.212009, acc: 0.011719]\n",
            "299: [D loss: 0.663433, acc: 0.591797]  [A loss: 0.795589, acc: 0.277344]\n",
            "300: [D loss: 0.668657, acc: 0.533203]  [A loss: 1.222260, acc: 0.007812]\n",
            "301: [D loss: 0.657806, acc: 0.593750]  [A loss: 0.787270, acc: 0.292969]\n",
            "302: [D loss: 0.680528, acc: 0.541016]  [A loss: 1.269165, acc: 0.007812]\n",
            "303: [D loss: 0.652899, acc: 0.609375]  [A loss: 0.755632, acc: 0.386719]\n",
            "304: [D loss: 0.695410, acc: 0.527344]  [A loss: 1.329881, acc: 0.000000]\n",
            "305: [D loss: 0.648791, acc: 0.628906]  [A loss: 0.669174, acc: 0.589844]\n",
            "306: [D loss: 0.703716, acc: 0.515625]  [A loss: 1.303968, acc: 0.000000]\n",
            "307: [D loss: 0.646628, acc: 0.644531]  [A loss: 0.710938, acc: 0.511719]\n",
            "308: [D loss: 0.703349, acc: 0.527344]  [A loss: 1.167767, acc: 0.000000]\n",
            "309: [D loss: 0.640626, acc: 0.660156]  [A loss: 0.779809, acc: 0.324219]\n",
            "310: [D loss: 0.682860, acc: 0.539062]  [A loss: 1.188031, acc: 0.000000]\n",
            "311: [D loss: 0.640293, acc: 0.648438]  [A loss: 0.742634, acc: 0.386719]\n",
            "312: [D loss: 0.693569, acc: 0.533203]  [A loss: 1.230708, acc: 0.003906]\n",
            "313: [D loss: 0.652443, acc: 0.621094]  [A loss: 0.748116, acc: 0.351562]\n",
            "314: [D loss: 0.689389, acc: 0.519531]  [A loss: 1.181453, acc: 0.003906]\n",
            "315: [D loss: 0.644361, acc: 0.644531]  [A loss: 0.731535, acc: 0.414062]\n",
            "316: [D loss: 0.695522, acc: 0.521484]  [A loss: 1.244310, acc: 0.007812]\n",
            "317: [D loss: 0.655552, acc: 0.605469]  [A loss: 0.711538, acc: 0.484375]\n",
            "318: [D loss: 0.714032, acc: 0.511719]  [A loss: 1.143564, acc: 0.015625]\n",
            "319: [D loss: 0.656262, acc: 0.615234]  [A loss: 0.727896, acc: 0.457031]\n",
            "320: [D loss: 0.695938, acc: 0.531250]  [A loss: 1.213455, acc: 0.003906]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "321: [D loss: 0.635206, acc: 0.701172]  [A loss: 0.725257, acc: 0.417969]\n",
            "322: [D loss: 0.704817, acc: 0.529297]  [A loss: 1.213561, acc: 0.007812]\n",
            "323: [D loss: 0.649561, acc: 0.634766]  [A loss: 0.724289, acc: 0.484375]\n",
            "324: [D loss: 0.681493, acc: 0.535156]  [A loss: 1.161484, acc: 0.000000]\n",
            "325: [D loss: 0.666857, acc: 0.615234]  [A loss: 0.791151, acc: 0.312500]\n",
            "326: [D loss: 0.676691, acc: 0.564453]  [A loss: 1.133643, acc: 0.007812]\n",
            "327: [D loss: 0.643287, acc: 0.652344]  [A loss: 0.811410, acc: 0.230469]\n",
            "328: [D loss: 0.697960, acc: 0.542969]  [A loss: 1.154411, acc: 0.007812]\n",
            "329: [D loss: 0.649801, acc: 0.642578]  [A loss: 0.756277, acc: 0.359375]\n",
            "330: [D loss: 0.698989, acc: 0.529297]  [A loss: 1.222113, acc: 0.000000]\n",
            "331: [D loss: 0.651569, acc: 0.630859]  [A loss: 0.700047, acc: 0.445312]\n",
            "332: [D loss: 0.704256, acc: 0.529297]  [A loss: 1.200887, acc: 0.007812]\n",
            "333: [D loss: 0.657269, acc: 0.609375]  [A loss: 0.750774, acc: 0.367188]\n",
            "334: [D loss: 0.696622, acc: 0.511719]  [A loss: 1.061458, acc: 0.015625]\n",
            "335: [D loss: 0.651347, acc: 0.625000]  [A loss: 0.789235, acc: 0.277344]\n",
            "336: [D loss: 0.677457, acc: 0.556641]  [A loss: 1.136618, acc: 0.019531]\n",
            "337: [D loss: 0.655319, acc: 0.625000]  [A loss: 0.773264, acc: 0.332031]\n",
            "338: [D loss: 0.691759, acc: 0.535156]  [A loss: 1.235821, acc: 0.003906]\n",
            "339: [D loss: 0.650846, acc: 0.613281]  [A loss: 0.688937, acc: 0.531250]\n",
            "340: [D loss: 0.699813, acc: 0.533203]  [A loss: 1.188457, acc: 0.011719]\n",
            "341: [D loss: 0.667950, acc: 0.607422]  [A loss: 0.696603, acc: 0.507812]\n",
            "342: [D loss: 0.701667, acc: 0.523438]  [A loss: 1.182705, acc: 0.003906]\n",
            "343: [D loss: 0.656893, acc: 0.632812]  [A loss: 0.753705, acc: 0.351562]\n",
            "344: [D loss: 0.683688, acc: 0.541016]  [A loss: 1.108674, acc: 0.007812]\n",
            "345: [D loss: 0.657128, acc: 0.603516]  [A loss: 0.786998, acc: 0.285156]\n",
            "346: [D loss: 0.685433, acc: 0.529297]  [A loss: 1.094388, acc: 0.019531]\n",
            "347: [D loss: 0.653620, acc: 0.607422]  [A loss: 0.807593, acc: 0.222656]\n",
            "348: [D loss: 0.676915, acc: 0.554688]  [A loss: 1.109095, acc: 0.015625]\n",
            "349: [D loss: 0.656199, acc: 0.603516]  [A loss: 0.790671, acc: 0.324219]\n",
            "350: [D loss: 0.678769, acc: 0.525391]  [A loss: 1.062597, acc: 0.007812]\n",
            "351: [D loss: 0.659285, acc: 0.634766]  [A loss: 0.795433, acc: 0.296875]\n",
            "352: [D loss: 0.691485, acc: 0.535156]  [A loss: 1.219772, acc: 0.003906]\n",
            "353: [D loss: 0.643921, acc: 0.638672]  [A loss: 0.646301, acc: 0.628906]\n",
            "354: [D loss: 0.724551, acc: 0.513672]  [A loss: 1.274954, acc: 0.003906]\n",
            "355: [D loss: 0.662951, acc: 0.583984]  [A loss: 0.658123, acc: 0.613281]\n",
            "356: [D loss: 0.713772, acc: 0.517578]  [A loss: 1.120456, acc: 0.011719]\n",
            "357: [D loss: 0.671897, acc: 0.587891]  [A loss: 0.777623, acc: 0.308594]\n",
            "358: [D loss: 0.676664, acc: 0.562500]  [A loss: 0.988595, acc: 0.054688]\n",
            "359: [D loss: 0.671381, acc: 0.589844]  [A loss: 0.853544, acc: 0.164062]\n",
            "360: [D loss: 0.670975, acc: 0.595703]  [A loss: 0.959150, acc: 0.070312]\n",
            "361: [D loss: 0.666477, acc: 0.609375]  [A loss: 0.921425, acc: 0.109375]\n",
            "362: [D loss: 0.669931, acc: 0.572266]  [A loss: 0.924662, acc: 0.101562]\n",
            "363: [D loss: 0.645155, acc: 0.644531]  [A loss: 0.916168, acc: 0.132812]\n",
            "364: [D loss: 0.656270, acc: 0.621094]  [A loss: 0.991481, acc: 0.058594]\n",
            "365: [D loss: 0.660326, acc: 0.605469]  [A loss: 0.915171, acc: 0.121094]\n",
            "366: [D loss: 0.669062, acc: 0.599609]  [A loss: 1.057431, acc: 0.042969]\n",
            "367: [D loss: 0.677295, acc: 0.589844]  [A loss: 0.795520, acc: 0.273438]\n",
            "368: [D loss: 0.680648, acc: 0.542969]  [A loss: 1.202551, acc: 0.007812]\n",
            "369: [D loss: 0.663927, acc: 0.589844]  [A loss: 0.645861, acc: 0.652344]\n",
            "370: [D loss: 0.714929, acc: 0.515625]  [A loss: 1.314348, acc: 0.000000]\n",
            "371: [D loss: 0.675241, acc: 0.570312]  [A loss: 0.642527, acc: 0.683594]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "372: [D loss: 0.726675, acc: 0.511719]  [A loss: 1.094834, acc: 0.035156]\n",
            "373: [D loss: 0.654939, acc: 0.636719]  [A loss: 0.748826, acc: 0.429688]\n",
            "374: [D loss: 0.680772, acc: 0.554688]  [A loss: 1.029623, acc: 0.054688]\n",
            "375: [D loss: 0.662982, acc: 0.609375]  [A loss: 0.824413, acc: 0.246094]\n",
            "376: [D loss: 0.676582, acc: 0.568359]  [A loss: 0.990320, acc: 0.089844]\n",
            "377: [D loss: 0.658509, acc: 0.617188]  [A loss: 0.801061, acc: 0.316406]\n",
            "378: [D loss: 0.680070, acc: 0.562500]  [A loss: 1.060387, acc: 0.039062]\n",
            "379: [D loss: 0.640577, acc: 0.681641]  [A loss: 0.781570, acc: 0.347656]\n",
            "380: [D loss: 0.695129, acc: 0.539062]  [A loss: 1.111055, acc: 0.019531]\n",
            "381: [D loss: 0.667467, acc: 0.603516]  [A loss: 0.723605, acc: 0.457031]\n",
            "382: [D loss: 0.691256, acc: 0.523438]  [A loss: 1.096377, acc: 0.027344]\n",
            "383: [D loss: 0.658408, acc: 0.611328]  [A loss: 0.748122, acc: 0.351562]\n",
            "384: [D loss: 0.697608, acc: 0.521484]  [A loss: 1.076952, acc: 0.019531]\n",
            "385: [D loss: 0.683854, acc: 0.558594]  [A loss: 0.816732, acc: 0.210938]\n",
            "386: [D loss: 0.670457, acc: 0.580078]  [A loss: 0.961193, acc: 0.042969]\n",
            "387: [D loss: 0.661085, acc: 0.593750]  [A loss: 0.855022, acc: 0.156250]\n",
            "388: [D loss: 0.673966, acc: 0.568359]  [A loss: 0.991522, acc: 0.035156]\n",
            "389: [D loss: 0.658546, acc: 0.601562]  [A loss: 0.845038, acc: 0.156250]\n",
            "390: [D loss: 0.673932, acc: 0.566406]  [A loss: 1.090985, acc: 0.023438]\n",
            "391: [D loss: 0.644169, acc: 0.669922]  [A loss: 0.788172, acc: 0.289062]\n",
            "392: [D loss: 0.698862, acc: 0.521484]  [A loss: 1.181942, acc: 0.003906]\n",
            "393: [D loss: 0.672388, acc: 0.574219]  [A loss: 0.675835, acc: 0.570312]\n",
            "394: [D loss: 0.749774, acc: 0.501953]  [A loss: 1.207099, acc: 0.007812]\n",
            "395: [D loss: 0.664273, acc: 0.587891]  [A loss: 0.678051, acc: 0.593750]\n",
            "396: [D loss: 0.706236, acc: 0.513672]  [A loss: 1.087730, acc: 0.007812]\n",
            "397: [D loss: 0.666006, acc: 0.578125]  [A loss: 0.728783, acc: 0.406250]\n",
            "398: [D loss: 0.697603, acc: 0.509766]  [A loss: 1.033636, acc: 0.023438]\n",
            "399: [D loss: 0.671078, acc: 0.593750]  [A loss: 0.763911, acc: 0.324219]\n",
            "400: [D loss: 0.688658, acc: 0.525391]  [A loss: 1.019921, acc: 0.039062]\n",
            "401: [D loss: 0.658330, acc: 0.642578]  [A loss: 0.846911, acc: 0.195312]\n",
            "402: [D loss: 0.658370, acc: 0.648438]  [A loss: 0.933819, acc: 0.089844]\n",
            "403: [D loss: 0.670006, acc: 0.568359]  [A loss: 0.854145, acc: 0.140625]\n",
            "404: [D loss: 0.680233, acc: 0.570312]  [A loss: 0.950934, acc: 0.074219]\n",
            "405: [D loss: 0.672280, acc: 0.593750]  [A loss: 0.928698, acc: 0.093750]\n",
            "406: [D loss: 0.656778, acc: 0.613281]  [A loss: 0.942069, acc: 0.078125]\n",
            "407: [D loss: 0.653366, acc: 0.625000]  [A loss: 0.881707, acc: 0.144531]\n",
            "408: [D loss: 0.678899, acc: 0.576172]  [A loss: 1.003970, acc: 0.066406]\n",
            "409: [D loss: 0.670698, acc: 0.572266]  [A loss: 0.873024, acc: 0.136719]\n",
            "410: [D loss: 0.673200, acc: 0.585938]  [A loss: 1.031796, acc: 0.031250]\n",
            "411: [D loss: 0.670110, acc: 0.570312]  [A loss: 0.785231, acc: 0.316406]\n",
            "412: [D loss: 0.701209, acc: 0.529297]  [A loss: 1.210423, acc: 0.007812]\n",
            "413: [D loss: 0.673215, acc: 0.599609]  [A loss: 0.620361, acc: 0.726562]\n",
            "414: [D loss: 0.717761, acc: 0.515625]  [A loss: 1.254765, acc: 0.000000]\n",
            "415: [D loss: 0.668929, acc: 0.576172]  [A loss: 0.610096, acc: 0.738281]\n",
            "416: [D loss: 0.731531, acc: 0.515625]  [A loss: 1.075378, acc: 0.019531]\n",
            "417: [D loss: 0.670354, acc: 0.576172]  [A loss: 0.751236, acc: 0.386719]\n",
            "418: [D loss: 0.695586, acc: 0.531250]  [A loss: 0.962964, acc: 0.062500]\n",
            "419: [D loss: 0.667202, acc: 0.615234]  [A loss: 0.786606, acc: 0.300781]\n",
            "420: [D loss: 0.675526, acc: 0.572266]  [A loss: 0.907240, acc: 0.101562]\n",
            "421: [D loss: 0.666898, acc: 0.585938]  [A loss: 0.833214, acc: 0.203125]\n",
            "422: [D loss: 0.676472, acc: 0.558594]  [A loss: 0.944221, acc: 0.054688]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "423: [D loss: 0.659236, acc: 0.603516]  [A loss: 0.846625, acc: 0.167969]\n",
            "424: [D loss: 0.678934, acc: 0.556641]  [A loss: 0.890444, acc: 0.105469]\n",
            "425: [D loss: 0.682050, acc: 0.564453]  [A loss: 0.922800, acc: 0.125000]\n",
            "426: [D loss: 0.684464, acc: 0.537109]  [A loss: 0.868598, acc: 0.152344]\n",
            "427: [D loss: 0.667741, acc: 0.593750]  [A loss: 0.919127, acc: 0.097656]\n",
            "428: [D loss: 0.680019, acc: 0.574219]  [A loss: 0.950541, acc: 0.042969]\n",
            "429: [D loss: 0.674132, acc: 0.578125]  [A loss: 0.858224, acc: 0.160156]\n",
            "430: [D loss: 0.674063, acc: 0.576172]  [A loss: 1.030118, acc: 0.039062]\n",
            "431: [D loss: 0.680031, acc: 0.578125]  [A loss: 0.773515, acc: 0.312500]\n",
            "432: [D loss: 0.685575, acc: 0.548828]  [A loss: 1.073227, acc: 0.011719]\n",
            "433: [D loss: 0.671315, acc: 0.576172]  [A loss: 0.731915, acc: 0.425781]\n",
            "434: [D loss: 0.699217, acc: 0.525391]  [A loss: 1.129151, acc: 0.007812]\n",
            "435: [D loss: 0.671581, acc: 0.587891]  [A loss: 0.727090, acc: 0.425781]\n",
            "436: [D loss: 0.695895, acc: 0.513672]  [A loss: 1.109300, acc: 0.019531]\n",
            "437: [D loss: 0.664406, acc: 0.601562]  [A loss: 0.725634, acc: 0.421875]\n",
            "438: [D loss: 0.699210, acc: 0.507812]  [A loss: 1.091017, acc: 0.007812]\n",
            "439: [D loss: 0.672261, acc: 0.597656]  [A loss: 0.735052, acc: 0.402344]\n",
            "440: [D loss: 0.701311, acc: 0.541016]  [A loss: 1.055044, acc: 0.011719]\n",
            "441: [D loss: 0.670125, acc: 0.591797]  [A loss: 0.721713, acc: 0.468750]\n",
            "442: [D loss: 0.685770, acc: 0.541016]  [A loss: 0.980434, acc: 0.031250]\n",
            "443: [D loss: 0.664931, acc: 0.621094]  [A loss: 0.780813, acc: 0.292969]\n",
            "444: [D loss: 0.673726, acc: 0.554688]  [A loss: 1.000059, acc: 0.054688]\n",
            "445: [D loss: 0.679776, acc: 0.556641]  [A loss: 0.800534, acc: 0.242188]\n",
            "446: [D loss: 0.678148, acc: 0.546875]  [A loss: 0.965684, acc: 0.042969]\n",
            "447: [D loss: 0.663726, acc: 0.599609]  [A loss: 0.854987, acc: 0.156250]\n",
            "448: [D loss: 0.679507, acc: 0.576172]  [A loss: 0.940396, acc: 0.109375]\n",
            "449: [D loss: 0.673801, acc: 0.591797]  [A loss: 0.872468, acc: 0.148438]\n",
            "450: [D loss: 0.675458, acc: 0.585938]  [A loss: 0.964553, acc: 0.042969]\n",
            "451: [D loss: 0.658781, acc: 0.617188]  [A loss: 0.868968, acc: 0.175781]\n",
            "452: [D loss: 0.668754, acc: 0.582031]  [A loss: 1.047882, acc: 0.031250]\n",
            "453: [D loss: 0.673757, acc: 0.605469]  [A loss: 0.732623, acc: 0.433594]\n",
            "454: [D loss: 0.740958, acc: 0.505859]  [A loss: 1.200146, acc: 0.003906]\n",
            "455: [D loss: 0.669798, acc: 0.582031]  [A loss: 0.643988, acc: 0.652344]\n",
            "456: [D loss: 0.704695, acc: 0.513672]  [A loss: 1.074437, acc: 0.042969]\n",
            "457: [D loss: 0.668305, acc: 0.587891]  [A loss: 0.733427, acc: 0.417969]\n",
            "458: [D loss: 0.691237, acc: 0.554688]  [A loss: 0.965339, acc: 0.046875]\n",
            "459: [D loss: 0.671301, acc: 0.582031]  [A loss: 0.762887, acc: 0.339844]\n",
            "460: [D loss: 0.670728, acc: 0.583984]  [A loss: 0.950258, acc: 0.050781]\n",
            "461: [D loss: 0.661680, acc: 0.599609]  [A loss: 0.819592, acc: 0.214844]\n",
            "462: [D loss: 0.688310, acc: 0.564453]  [A loss: 0.948746, acc: 0.089844]\n",
            "463: [D loss: 0.677035, acc: 0.574219]  [A loss: 0.748034, acc: 0.417969]\n",
            "464: [D loss: 0.689012, acc: 0.541016]  [A loss: 0.999692, acc: 0.027344]\n",
            "465: [D loss: 0.661775, acc: 0.597656]  [A loss: 0.774387, acc: 0.328125]\n",
            "466: [D loss: 0.702166, acc: 0.535156]  [A loss: 1.031009, acc: 0.027344]\n",
            "467: [D loss: 0.657703, acc: 0.611328]  [A loss: 0.751722, acc: 0.355469]\n",
            "468: [D loss: 0.690563, acc: 0.546875]  [A loss: 0.986025, acc: 0.039062]\n",
            "469: [D loss: 0.669521, acc: 0.591797]  [A loss: 0.777439, acc: 0.316406]\n",
            "470: [D loss: 0.683945, acc: 0.548828]  [A loss: 0.994145, acc: 0.039062]\n",
            "471: [D loss: 0.659593, acc: 0.613281]  [A loss: 0.777637, acc: 0.312500]\n",
            "472: [D loss: 0.676101, acc: 0.582031]  [A loss: 1.000615, acc: 0.035156]\n",
            "473: [D loss: 0.674123, acc: 0.574219]  [A loss: 0.842204, acc: 0.167969]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "474: [D loss: 0.691673, acc: 0.541016]  [A loss: 0.983420, acc: 0.062500]\n",
            "475: [D loss: 0.667997, acc: 0.625000]  [A loss: 0.781372, acc: 0.308594]\n",
            "476: [D loss: 0.673550, acc: 0.560547]  [A loss: 1.025315, acc: 0.015625]\n",
            "477: [D loss: 0.660321, acc: 0.615234]  [A loss: 0.762851, acc: 0.324219]\n",
            "478: [D loss: 0.687599, acc: 0.550781]  [A loss: 1.044879, acc: 0.023438]\n",
            "479: [D loss: 0.659751, acc: 0.599609]  [A loss: 0.771848, acc: 0.328125]\n",
            "480: [D loss: 0.698323, acc: 0.531250]  [A loss: 1.034345, acc: 0.027344]\n",
            "481: [D loss: 0.662640, acc: 0.626953]  [A loss: 0.833262, acc: 0.218750]\n",
            "482: [D loss: 0.672501, acc: 0.566406]  [A loss: 0.972127, acc: 0.050781]\n",
            "483: [D loss: 0.678980, acc: 0.568359]  [A loss: 0.778181, acc: 0.292969]\n",
            "484: [D loss: 0.671953, acc: 0.550781]  [A loss: 1.000491, acc: 0.027344]\n",
            "485: [D loss: 0.668091, acc: 0.595703]  [A loss: 0.762405, acc: 0.335938]\n",
            "486: [D loss: 0.686687, acc: 0.539062]  [A loss: 1.000451, acc: 0.031250]\n",
            "487: [D loss: 0.653653, acc: 0.644531]  [A loss: 0.750195, acc: 0.378906]\n",
            "488: [D loss: 0.687756, acc: 0.550781]  [A loss: 1.057022, acc: 0.023438]\n",
            "489: [D loss: 0.664876, acc: 0.583984]  [A loss: 0.771058, acc: 0.312500]\n",
            "490: [D loss: 0.670782, acc: 0.564453]  [A loss: 0.956322, acc: 0.054688]\n",
            "491: [D loss: 0.670172, acc: 0.597656]  [A loss: 0.809853, acc: 0.230469]\n",
            "492: [D loss: 0.691710, acc: 0.521484]  [A loss: 0.918012, acc: 0.089844]\n",
            "493: [D loss: 0.657336, acc: 0.625000]  [A loss: 0.813859, acc: 0.238281]\n",
            "494: [D loss: 0.657163, acc: 0.591797]  [A loss: 0.941113, acc: 0.085938]\n",
            "495: [D loss: 0.662513, acc: 0.591797]  [A loss: 0.866631, acc: 0.179688]\n",
            "496: [D loss: 0.666455, acc: 0.576172]  [A loss: 0.968921, acc: 0.085938]\n",
            "497: [D loss: 0.664454, acc: 0.593750]  [A loss: 0.892975, acc: 0.128906]\n",
            "498: [D loss: 0.678469, acc: 0.574219]  [A loss: 0.923252, acc: 0.105469]\n",
            "499: [D loss: 0.681263, acc: 0.568359]  [A loss: 1.023710, acc: 0.019531]\n",
            "500: [D loss: 0.660264, acc: 0.615234]  [A loss: 0.770048, acc: 0.375000]\n",
            "501: [D loss: 0.693718, acc: 0.542969]  [A loss: 1.055988, acc: 0.023438]\n",
            "502: [D loss: 0.672370, acc: 0.585938]  [A loss: 0.735228, acc: 0.406250]\n",
            "503: [D loss: 0.699340, acc: 0.566406]  [A loss: 1.100408, acc: 0.027344]\n",
            "504: [D loss: 0.668102, acc: 0.587891]  [A loss: 0.761102, acc: 0.351562]\n",
            "505: [D loss: 0.719514, acc: 0.519531]  [A loss: 1.116342, acc: 0.019531]\n",
            "506: [D loss: 0.670881, acc: 0.583984]  [A loss: 0.709505, acc: 0.476562]\n",
            "507: [D loss: 0.696833, acc: 0.535156]  [A loss: 1.010900, acc: 0.058594]\n",
            "508: [D loss: 0.671537, acc: 0.585938]  [A loss: 0.765431, acc: 0.324219]\n",
            "509: [D loss: 0.681902, acc: 0.542969]  [A loss: 0.914266, acc: 0.136719]\n",
            "510: [D loss: 0.670102, acc: 0.591797]  [A loss: 0.849436, acc: 0.171875]\n",
            "511: [D loss: 0.680667, acc: 0.552734]  [A loss: 0.895244, acc: 0.121094]\n",
            "512: [D loss: 0.662893, acc: 0.593750]  [A loss: 0.862944, acc: 0.199219]\n",
            "513: [D loss: 0.667636, acc: 0.583984]  [A loss: 0.877995, acc: 0.152344]\n",
            "514: [D loss: 0.655005, acc: 0.578125]  [A loss: 0.912973, acc: 0.125000]\n",
            "515: [D loss: 0.660642, acc: 0.609375]  [A loss: 0.920751, acc: 0.101562]\n",
            "516: [D loss: 0.662205, acc: 0.595703]  [A loss: 0.948826, acc: 0.109375]\n",
            "517: [D loss: 0.656843, acc: 0.623047]  [A loss: 0.908166, acc: 0.148438]\n",
            "518: [D loss: 0.662660, acc: 0.580078]  [A loss: 1.000807, acc: 0.050781]\n",
            "519: [D loss: 0.662963, acc: 0.605469]  [A loss: 0.831831, acc: 0.195312]\n",
            "520: [D loss: 0.677457, acc: 0.560547]  [A loss: 1.040935, acc: 0.058594]\n",
            "521: [D loss: 0.662575, acc: 0.605469]  [A loss: 0.737521, acc: 0.414062]\n",
            "522: [D loss: 0.672233, acc: 0.570312]  [A loss: 1.101089, acc: 0.035156]\n",
            "523: [D loss: 0.656602, acc: 0.623047]  [A loss: 0.722146, acc: 0.437500]\n",
            "524: [D loss: 0.708930, acc: 0.531250]  [A loss: 1.128720, acc: 0.011719]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "525: [D loss: 0.662395, acc: 0.597656]  [A loss: 0.710719, acc: 0.453125]\n",
            "526: [D loss: 0.702890, acc: 0.546875]  [A loss: 1.023178, acc: 0.042969]\n",
            "527: [D loss: 0.655403, acc: 0.609375]  [A loss: 0.773527, acc: 0.324219]\n",
            "528: [D loss: 0.676815, acc: 0.542969]  [A loss: 0.987040, acc: 0.046875]\n",
            "529: [D loss: 0.663923, acc: 0.609375]  [A loss: 0.797387, acc: 0.312500]\n",
            "530: [D loss: 0.686549, acc: 0.542969]  [A loss: 0.964045, acc: 0.093750]\n",
            "531: [D loss: 0.664730, acc: 0.632812]  [A loss: 0.833254, acc: 0.179688]\n",
            "532: [D loss: 0.667040, acc: 0.593750]  [A loss: 0.940200, acc: 0.109375]\n",
            "533: [D loss: 0.651691, acc: 0.634766]  [A loss: 0.899241, acc: 0.140625]\n",
            "534: [D loss: 0.656462, acc: 0.583984]  [A loss: 0.921741, acc: 0.125000]\n",
            "535: [D loss: 0.655294, acc: 0.615234]  [A loss: 0.894197, acc: 0.144531]\n",
            "536: [D loss: 0.667020, acc: 0.603516]  [A loss: 0.917067, acc: 0.156250]\n",
            "537: [D loss: 0.638832, acc: 0.644531]  [A loss: 0.875722, acc: 0.183594]\n",
            "538: [D loss: 0.670715, acc: 0.576172]  [A loss: 1.073816, acc: 0.054688]\n",
            "539: [D loss: 0.649274, acc: 0.625000]  [A loss: 0.750688, acc: 0.398438]\n",
            "540: [D loss: 0.682007, acc: 0.558594]  [A loss: 1.115268, acc: 0.015625]\n",
            "541: [D loss: 0.656419, acc: 0.607422]  [A loss: 0.716937, acc: 0.460938]\n",
            "542: [D loss: 0.720472, acc: 0.523438]  [A loss: 1.074488, acc: 0.027344]\n",
            "543: [D loss: 0.669955, acc: 0.566406]  [A loss: 0.771753, acc: 0.335938]\n",
            "544: [D loss: 0.713898, acc: 0.523438]  [A loss: 1.006306, acc: 0.066406]\n",
            "545: [D loss: 0.670275, acc: 0.611328]  [A loss: 0.791723, acc: 0.308594]\n",
            "546: [D loss: 0.687813, acc: 0.554688]  [A loss: 0.951474, acc: 0.089844]\n",
            "547: [D loss: 0.657308, acc: 0.623047]  [A loss: 0.837088, acc: 0.234375]\n",
            "548: [D loss: 0.687387, acc: 0.542969]  [A loss: 0.984215, acc: 0.054688]\n",
            "549: [D loss: 0.660943, acc: 0.613281]  [A loss: 0.811877, acc: 0.296875]\n",
            "550: [D loss: 0.684503, acc: 0.542969]  [A loss: 1.014808, acc: 0.070312]\n",
            "551: [D loss: 0.664518, acc: 0.613281]  [A loss: 0.785721, acc: 0.292969]\n",
            "552: [D loss: 0.683131, acc: 0.580078]  [A loss: 0.929010, acc: 0.117188]\n",
            "553: [D loss: 0.662434, acc: 0.607422]  [A loss: 0.878295, acc: 0.148438]\n",
            "554: [D loss: 0.666096, acc: 0.595703]  [A loss: 0.912510, acc: 0.136719]\n",
            "555: [D loss: 0.683090, acc: 0.582031]  [A loss: 0.975152, acc: 0.093750]\n",
            "556: [D loss: 0.660909, acc: 0.632812]  [A loss: 0.889244, acc: 0.179688]\n",
            "557: [D loss: 0.676690, acc: 0.566406]  [A loss: 0.965140, acc: 0.082031]\n",
            "558: [D loss: 0.663137, acc: 0.617188]  [A loss: 0.851789, acc: 0.199219]\n",
            "559: [D loss: 0.654458, acc: 0.615234]  [A loss: 1.026416, acc: 0.046875]\n",
            "560: [D loss: 0.658703, acc: 0.621094]  [A loss: 0.877448, acc: 0.152344]\n",
            "561: [D loss: 0.673524, acc: 0.587891]  [A loss: 1.072393, acc: 0.023438]\n",
            "562: [D loss: 0.647103, acc: 0.666016]  [A loss: 0.773790, acc: 0.359375]\n",
            "563: [D loss: 0.691148, acc: 0.558594]  [A loss: 1.082414, acc: 0.027344]\n",
            "564: [D loss: 0.674799, acc: 0.595703]  [A loss: 0.730094, acc: 0.457031]\n",
            "565: [D loss: 0.728384, acc: 0.535156]  [A loss: 1.112628, acc: 0.003906]\n",
            "566: [D loss: 0.659015, acc: 0.597656]  [A loss: 0.785990, acc: 0.312500]\n",
            "567: [D loss: 0.666254, acc: 0.570312]  [A loss: 0.937129, acc: 0.089844]\n",
            "568: [D loss: 0.664495, acc: 0.599609]  [A loss: 0.903333, acc: 0.160156]\n",
            "569: [D loss: 0.667331, acc: 0.582031]  [A loss: 0.926510, acc: 0.097656]\n",
            "570: [D loss: 0.690776, acc: 0.529297]  [A loss: 0.992322, acc: 0.078125]\n",
            "571: [D loss: 0.654251, acc: 0.626953]  [A loss: 0.842775, acc: 0.210938]\n",
            "572: [D loss: 0.689581, acc: 0.554688]  [A loss: 0.969410, acc: 0.054688]\n",
            "573: [D loss: 0.672815, acc: 0.593750]  [A loss: 0.890897, acc: 0.117188]\n",
            "574: [D loss: 0.671882, acc: 0.582031]  [A loss: 0.912555, acc: 0.128906]\n",
            "575: [D loss: 0.683768, acc: 0.546875]  [A loss: 0.975530, acc: 0.078125]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "576: [D loss: 0.661263, acc: 0.597656]  [A loss: 0.834256, acc: 0.203125]\n",
            "577: [D loss: 0.677552, acc: 0.570312]  [A loss: 1.030740, acc: 0.035156]\n",
            "578: [D loss: 0.668649, acc: 0.576172]  [A loss: 0.889882, acc: 0.187500]\n",
            "579: [D loss: 0.662375, acc: 0.582031]  [A loss: 1.038026, acc: 0.039062]\n",
            "580: [D loss: 0.669203, acc: 0.582031]  [A loss: 0.821018, acc: 0.226562]\n",
            "581: [D loss: 0.662841, acc: 0.582031]  [A loss: 1.067785, acc: 0.054688]\n",
            "582: [D loss: 0.667425, acc: 0.595703]  [A loss: 0.790180, acc: 0.351562]\n",
            "583: [D loss: 0.686316, acc: 0.562500]  [A loss: 1.097849, acc: 0.015625]\n",
            "584: [D loss: 0.668915, acc: 0.580078]  [A loss: 0.690453, acc: 0.531250]\n",
            "585: [D loss: 0.686560, acc: 0.535156]  [A loss: 1.125375, acc: 0.019531]\n",
            "586: [D loss: 0.657767, acc: 0.593750]  [A loss: 0.775547, acc: 0.343750]\n",
            "587: [D loss: 0.724232, acc: 0.513672]  [A loss: 1.141914, acc: 0.015625]\n",
            "588: [D loss: 0.673629, acc: 0.593750]  [A loss: 0.713532, acc: 0.453125]\n",
            "589: [D loss: 0.687830, acc: 0.560547]  [A loss: 0.978890, acc: 0.074219]\n",
            "590: [D loss: 0.665421, acc: 0.593750]  [A loss: 0.826351, acc: 0.230469]\n",
            "591: [D loss: 0.659416, acc: 0.597656]  [A loss: 0.901707, acc: 0.195312]\n",
            "592: [D loss: 0.685987, acc: 0.517578]  [A loss: 0.893024, acc: 0.175781]\n",
            "593: [D loss: 0.677171, acc: 0.589844]  [A loss: 0.913725, acc: 0.105469]\n",
            "594: [D loss: 0.666342, acc: 0.595703]  [A loss: 0.890411, acc: 0.160156]\n",
            "595: [D loss: 0.671350, acc: 0.585938]  [A loss: 0.927071, acc: 0.117188]\n",
            "596: [D loss: 0.670520, acc: 0.597656]  [A loss: 0.949630, acc: 0.101562]\n",
            "597: [D loss: 0.664720, acc: 0.578125]  [A loss: 0.883200, acc: 0.164062]\n",
            "598: [D loss: 0.672404, acc: 0.570312]  [A loss: 0.953341, acc: 0.140625]\n",
            "599: [D loss: 0.680923, acc: 0.562500]  [A loss: 0.937948, acc: 0.125000]\n",
            "600: [D loss: 0.653673, acc: 0.593750]  [A loss: 0.935341, acc: 0.113281]\n",
            "601: [D loss: 0.679382, acc: 0.562500]  [A loss: 1.007885, acc: 0.058594]\n",
            "602: [D loss: 0.666749, acc: 0.576172]  [A loss: 0.854769, acc: 0.191406]\n",
            "603: [D loss: 0.665696, acc: 0.589844]  [A loss: 0.936880, acc: 0.113281]\n",
            "604: [D loss: 0.660920, acc: 0.583984]  [A loss: 0.932499, acc: 0.148438]\n",
            "605: [D loss: 0.658686, acc: 0.589844]  [A loss: 0.870922, acc: 0.179688]\n",
            "606: [D loss: 0.681640, acc: 0.541016]  [A loss: 1.027410, acc: 0.078125]\n",
            "607: [D loss: 0.658444, acc: 0.597656]  [A loss: 0.865056, acc: 0.214844]\n",
            "608: [D loss: 0.674701, acc: 0.580078]  [A loss: 1.088503, acc: 0.050781]\n",
            "609: [D loss: 0.679851, acc: 0.576172]  [A loss: 0.759896, acc: 0.382812]\n",
            "610: [D loss: 0.696304, acc: 0.544922]  [A loss: 1.130365, acc: 0.023438]\n",
            "611: [D loss: 0.680609, acc: 0.562500]  [A loss: 0.727016, acc: 0.453125]\n",
            "612: [D loss: 0.700009, acc: 0.529297]  [A loss: 1.150595, acc: 0.027344]\n",
            "613: [D loss: 0.664318, acc: 0.611328]  [A loss: 0.847979, acc: 0.230469]\n",
            "614: [D loss: 0.662451, acc: 0.582031]  [A loss: 0.939675, acc: 0.125000]\n",
            "615: [D loss: 0.659868, acc: 0.595703]  [A loss: 0.874991, acc: 0.156250]\n",
            "616: [D loss: 0.671902, acc: 0.597656]  [A loss: 0.892504, acc: 0.148438]\n",
            "617: [D loss: 0.658845, acc: 0.585938]  [A loss: 0.988516, acc: 0.089844]\n",
            "618: [D loss: 0.662125, acc: 0.619141]  [A loss: 0.893381, acc: 0.136719]\n",
            "619: [D loss: 0.660456, acc: 0.583984]  [A loss: 1.003966, acc: 0.058594]\n",
            "620: [D loss: 0.669982, acc: 0.609375]  [A loss: 0.890146, acc: 0.156250]\n",
            "621: [D loss: 0.680341, acc: 0.574219]  [A loss: 0.881813, acc: 0.171875]\n",
            "622: [D loss: 0.690772, acc: 0.554688]  [A loss: 1.040918, acc: 0.050781]\n",
            "623: [D loss: 0.665328, acc: 0.615234]  [A loss: 0.898325, acc: 0.167969]\n",
            "624: [D loss: 0.670525, acc: 0.572266]  [A loss: 1.041608, acc: 0.066406]\n",
            "625: [D loss: 0.667072, acc: 0.595703]  [A loss: 0.820843, acc: 0.242188]\n",
            "626: [D loss: 0.710405, acc: 0.519531]  [A loss: 1.083627, acc: 0.019531]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "627: [D loss: 0.686327, acc: 0.544922]  [A loss: 0.752072, acc: 0.363281]\n",
            "628: [D loss: 0.707554, acc: 0.546875]  [A loss: 1.126597, acc: 0.035156]\n",
            "629: [D loss: 0.653278, acc: 0.636719]  [A loss: 0.780981, acc: 0.324219]\n",
            "630: [D loss: 0.713749, acc: 0.507812]  [A loss: 1.031419, acc: 0.035156]\n",
            "631: [D loss: 0.663940, acc: 0.599609]  [A loss: 0.759353, acc: 0.386719]\n",
            "632: [D loss: 0.693927, acc: 0.544922]  [A loss: 1.001719, acc: 0.066406]\n",
            "633: [D loss: 0.659359, acc: 0.591797]  [A loss: 0.817104, acc: 0.277344]\n",
            "634: [D loss: 0.681498, acc: 0.574219]  [A loss: 0.938468, acc: 0.128906]\n",
            "635: [D loss: 0.669769, acc: 0.607422]  [A loss: 0.851432, acc: 0.191406]\n",
            "636: [D loss: 0.665557, acc: 0.591797]  [A loss: 0.975605, acc: 0.062500]\n",
            "637: [D loss: 0.673537, acc: 0.585938]  [A loss: 0.861316, acc: 0.183594]\n",
            "638: [D loss: 0.660297, acc: 0.589844]  [A loss: 0.938223, acc: 0.136719]\n",
            "639: [D loss: 0.663663, acc: 0.609375]  [A loss: 0.910686, acc: 0.156250]\n",
            "640: [D loss: 0.663762, acc: 0.593750]  [A loss: 0.900433, acc: 0.175781]\n",
            "641: [D loss: 0.664772, acc: 0.595703]  [A loss: 0.908360, acc: 0.144531]\n",
            "642: [D loss: 0.671987, acc: 0.593750]  [A loss: 0.955510, acc: 0.113281]\n",
            "643: [D loss: 0.677138, acc: 0.548828]  [A loss: 0.900196, acc: 0.167969]\n",
            "644: [D loss: 0.671675, acc: 0.585938]  [A loss: 1.000240, acc: 0.066406]\n",
            "645: [D loss: 0.664538, acc: 0.589844]  [A loss: 0.886174, acc: 0.167969]\n",
            "646: [D loss: 0.707215, acc: 0.527344]  [A loss: 1.064774, acc: 0.023438]\n",
            "647: [D loss: 0.670373, acc: 0.595703]  [A loss: 0.833825, acc: 0.230469]\n",
            "648: [D loss: 0.674166, acc: 0.572266]  [A loss: 1.035523, acc: 0.074219]\n",
            "649: [D loss: 0.664555, acc: 0.599609]  [A loss: 0.854237, acc: 0.214844]\n",
            "650: [D loss: 0.671691, acc: 0.593750]  [A loss: 1.127313, acc: 0.015625]\n",
            "651: [D loss: 0.667859, acc: 0.593750]  [A loss: 0.810070, acc: 0.308594]\n",
            "652: [D loss: 0.673074, acc: 0.583984]  [A loss: 1.021248, acc: 0.058594]\n",
            "653: [D loss: 0.658699, acc: 0.609375]  [A loss: 0.930764, acc: 0.132812]\n",
            "654: [D loss: 0.681479, acc: 0.544922]  [A loss: 0.920973, acc: 0.171875]\n",
            "655: [D loss: 0.689491, acc: 0.564453]  [A loss: 0.962339, acc: 0.156250]\n",
            "656: [D loss: 0.670646, acc: 0.560547]  [A loss: 0.969186, acc: 0.117188]\n",
            "657: [D loss: 0.672573, acc: 0.576172]  [A loss: 0.932691, acc: 0.144531]\n",
            "658: [D loss: 0.683085, acc: 0.570312]  [A loss: 0.925849, acc: 0.136719]\n",
            "659: [D loss: 0.661185, acc: 0.601562]  [A loss: 1.020408, acc: 0.062500]\n",
            "660: [D loss: 0.664616, acc: 0.585938]  [A loss: 0.844013, acc: 0.207031]\n",
            "661: [D loss: 0.686679, acc: 0.542969]  [A loss: 1.131194, acc: 0.035156]\n",
            "662: [D loss: 0.657652, acc: 0.623047]  [A loss: 0.782336, acc: 0.359375]\n",
            "663: [D loss: 0.691425, acc: 0.531250]  [A loss: 1.135661, acc: 0.046875]\n",
            "664: [D loss: 0.669006, acc: 0.568359]  [A loss: 0.736509, acc: 0.445312]\n",
            "665: [D loss: 0.727568, acc: 0.539062]  [A loss: 1.123338, acc: 0.023438]\n",
            "666: [D loss: 0.669032, acc: 0.599609]  [A loss: 0.693045, acc: 0.546875]\n",
            "667: [D loss: 0.733084, acc: 0.511719]  [A loss: 1.157937, acc: 0.031250]\n",
            "668: [D loss: 0.671266, acc: 0.562500]  [A loss: 0.763386, acc: 0.371094]\n",
            "669: [D loss: 0.704625, acc: 0.539062]  [A loss: 0.976288, acc: 0.066406]\n",
            "670: [D loss: 0.664592, acc: 0.595703]  [A loss: 0.776922, acc: 0.351562]\n",
            "671: [D loss: 0.698409, acc: 0.531250]  [A loss: 0.991051, acc: 0.058594]\n",
            "672: [D loss: 0.684506, acc: 0.552734]  [A loss: 0.864669, acc: 0.183594]\n",
            "673: [D loss: 0.665882, acc: 0.587891]  [A loss: 0.881962, acc: 0.132812]\n",
            "674: [D loss: 0.669337, acc: 0.597656]  [A loss: 0.917344, acc: 0.140625]\n",
            "675: [D loss: 0.667197, acc: 0.583984]  [A loss: 0.883151, acc: 0.175781]\n",
            "676: [D loss: 0.677916, acc: 0.605469]  [A loss: 0.923942, acc: 0.132812]\n",
            "677: [D loss: 0.667372, acc: 0.583984]  [A loss: 0.920125, acc: 0.144531]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "678: [D loss: 0.674607, acc: 0.580078]  [A loss: 0.932365, acc: 0.121094]\n",
            "679: [D loss: 0.691937, acc: 0.544922]  [A loss: 0.985891, acc: 0.093750]\n",
            "680: [D loss: 0.661292, acc: 0.601562]  [A loss: 0.858969, acc: 0.218750]\n",
            "681: [D loss: 0.689669, acc: 0.546875]  [A loss: 0.995011, acc: 0.078125]\n",
            "682: [D loss: 0.676437, acc: 0.562500]  [A loss: 0.871481, acc: 0.179688]\n",
            "683: [D loss: 0.676265, acc: 0.585938]  [A loss: 0.937426, acc: 0.144531]\n",
            "684: [D loss: 0.712064, acc: 0.525391]  [A loss: 1.018587, acc: 0.054688]\n",
            "685: [D loss: 0.679005, acc: 0.552734]  [A loss: 0.845782, acc: 0.230469]\n",
            "686: [D loss: 0.681282, acc: 0.570312]  [A loss: 1.078789, acc: 0.050781]\n",
            "687: [D loss: 0.661482, acc: 0.589844]  [A loss: 0.839749, acc: 0.250000]\n",
            "688: [D loss: 0.684215, acc: 0.562500]  [A loss: 1.043928, acc: 0.054688]\n",
            "689: [D loss: 0.671445, acc: 0.601562]  [A loss: 0.785754, acc: 0.363281]\n",
            "690: [D loss: 0.696903, acc: 0.515625]  [A loss: 1.040773, acc: 0.031250]\n",
            "691: [D loss: 0.658247, acc: 0.589844]  [A loss: 0.829211, acc: 0.292969]\n",
            "692: [D loss: 0.699626, acc: 0.554688]  [A loss: 1.042871, acc: 0.058594]\n",
            "693: [D loss: 0.672310, acc: 0.580078]  [A loss: 0.732743, acc: 0.488281]\n",
            "694: [D loss: 0.698971, acc: 0.531250]  [A loss: 1.122098, acc: 0.050781]\n",
            "695: [D loss: 0.664075, acc: 0.613281]  [A loss: 0.786645, acc: 0.343750]\n",
            "696: [D loss: 0.691363, acc: 0.576172]  [A loss: 1.050341, acc: 0.070312]\n",
            "697: [D loss: 0.667157, acc: 0.615234]  [A loss: 0.770376, acc: 0.378906]\n",
            "698: [D loss: 0.690233, acc: 0.552734]  [A loss: 0.956459, acc: 0.105469]\n",
            "699: [D loss: 0.664673, acc: 0.591797]  [A loss: 0.820294, acc: 0.269531]\n",
            "700: [D loss: 0.685658, acc: 0.548828]  [A loss: 1.007383, acc: 0.074219]\n",
            "701: [D loss: 0.674646, acc: 0.574219]  [A loss: 0.788814, acc: 0.273438]\n",
            "702: [D loss: 0.684033, acc: 0.568359]  [A loss: 1.034347, acc: 0.066406]\n",
            "703: [D loss: 0.679942, acc: 0.570312]  [A loss: 0.873577, acc: 0.164062]\n",
            "704: [D loss: 0.666105, acc: 0.574219]  [A loss: 0.976543, acc: 0.089844]\n",
            "705: [D loss: 0.663841, acc: 0.605469]  [A loss: 0.863102, acc: 0.218750]\n",
            "706: [D loss: 0.673041, acc: 0.568359]  [A loss: 0.989033, acc: 0.093750]\n",
            "707: [D loss: 0.670524, acc: 0.574219]  [A loss: 0.859019, acc: 0.179688]\n",
            "708: [D loss: 0.674653, acc: 0.574219]  [A loss: 0.971070, acc: 0.082031]\n",
            "709: [D loss: 0.667621, acc: 0.613281]  [A loss: 0.834912, acc: 0.257812]\n",
            "710: [D loss: 0.670199, acc: 0.572266]  [A loss: 1.007714, acc: 0.078125]\n",
            "711: [D loss: 0.670857, acc: 0.605469]  [A loss: 0.893371, acc: 0.187500]\n",
            "712: [D loss: 0.672602, acc: 0.599609]  [A loss: 0.970160, acc: 0.082031]\n",
            "713: [D loss: 0.660114, acc: 0.587891]  [A loss: 0.869869, acc: 0.191406]\n",
            "714: [D loss: 0.761936, acc: 0.511719]  [A loss: 1.145569, acc: 0.015625]\n",
            "715: [D loss: 0.696176, acc: 0.541016]  [A loss: 0.671970, acc: 0.574219]\n",
            "716: [D loss: 0.734689, acc: 0.507812]  [A loss: 1.148442, acc: 0.019531]\n",
            "717: [D loss: 0.669759, acc: 0.578125]  [A loss: 0.764640, acc: 0.367188]\n",
            "718: [D loss: 0.689241, acc: 0.556641]  [A loss: 0.928029, acc: 0.128906]\n",
            "719: [D loss: 0.699458, acc: 0.544922]  [A loss: 0.850854, acc: 0.226562]\n",
            "720: [D loss: 0.682318, acc: 0.539062]  [A loss: 0.900149, acc: 0.144531]\n",
            "721: [D loss: 0.680328, acc: 0.560547]  [A loss: 0.871761, acc: 0.175781]\n",
            "722: [D loss: 0.674386, acc: 0.576172]  [A loss: 0.937975, acc: 0.093750]\n",
            "723: [D loss: 0.687584, acc: 0.537109]  [A loss: 0.857208, acc: 0.214844]\n",
            "724: [D loss: 0.671020, acc: 0.572266]  [A loss: 0.975513, acc: 0.082031]\n",
            "725: [D loss: 0.661024, acc: 0.605469]  [A loss: 0.864427, acc: 0.191406]\n",
            "726: [D loss: 0.664258, acc: 0.601562]  [A loss: 0.915067, acc: 0.117188]\n",
            "727: [D loss: 0.664188, acc: 0.554688]  [A loss: 0.905024, acc: 0.144531]\n",
            "728: [D loss: 0.674740, acc: 0.570312]  [A loss: 0.958646, acc: 0.093750]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "729: [D loss: 0.673334, acc: 0.546875]  [A loss: 0.901875, acc: 0.156250]\n",
            "730: [D loss: 0.682983, acc: 0.552734]  [A loss: 0.955800, acc: 0.117188]\n",
            "731: [D loss: 0.670083, acc: 0.585938]  [A loss: 0.860292, acc: 0.230469]\n",
            "732: [D loss: 0.676984, acc: 0.562500]  [A loss: 1.018734, acc: 0.074219]\n",
            "733: [D loss: 0.673896, acc: 0.583984]  [A loss: 0.856888, acc: 0.203125]\n",
            "734: [D loss: 0.719441, acc: 0.519531]  [A loss: 1.123506, acc: 0.031250]\n",
            "735: [D loss: 0.695343, acc: 0.562500]  [A loss: 0.745377, acc: 0.441406]\n",
            "736: [D loss: 0.685702, acc: 0.564453]  [A loss: 1.062424, acc: 0.046875]\n",
            "737: [D loss: 0.652555, acc: 0.601562]  [A loss: 0.851572, acc: 0.234375]\n",
            "738: [D loss: 0.707719, acc: 0.523438]  [A loss: 1.036905, acc: 0.054688]\n",
            "739: [D loss: 0.666055, acc: 0.574219]  [A loss: 0.776807, acc: 0.406250]\n",
            "740: [D loss: 0.696688, acc: 0.548828]  [A loss: 1.017917, acc: 0.078125]\n",
            "741: [D loss: 0.649877, acc: 0.609375]  [A loss: 0.799025, acc: 0.316406]\n",
            "742: [D loss: 0.683844, acc: 0.542969]  [A loss: 1.079779, acc: 0.066406]\n",
            "743: [D loss: 0.681087, acc: 0.550781]  [A loss: 0.723758, acc: 0.476562]\n",
            "744: [D loss: 0.714612, acc: 0.523438]  [A loss: 1.123658, acc: 0.031250]\n",
            "745: [D loss: 0.677020, acc: 0.560547]  [A loss: 0.758576, acc: 0.398438]\n",
            "746: [D loss: 0.695267, acc: 0.533203]  [A loss: 1.021616, acc: 0.066406]\n",
            "747: [D loss: 0.664508, acc: 0.605469]  [A loss: 0.806242, acc: 0.269531]\n",
            "748: [D loss: 0.690601, acc: 0.539062]  [A loss: 0.988391, acc: 0.113281]\n",
            "749: [D loss: 0.663502, acc: 0.583984]  [A loss: 0.820816, acc: 0.273438]\n",
            "750: [D loss: 0.674490, acc: 0.554688]  [A loss: 1.014728, acc: 0.089844]\n",
            "751: [D loss: 0.661723, acc: 0.621094]  [A loss: 0.823730, acc: 0.277344]\n",
            "752: [D loss: 0.699219, acc: 0.537109]  [A loss: 1.013298, acc: 0.089844]\n",
            "753: [D loss: 0.658901, acc: 0.613281]  [A loss: 0.768983, acc: 0.328125]\n",
            "754: [D loss: 0.685951, acc: 0.556641]  [A loss: 1.023279, acc: 0.062500]\n",
            "755: [D loss: 0.654556, acc: 0.626953]  [A loss: 0.708368, acc: 0.507812]\n",
            "756: [D loss: 0.716763, acc: 0.541016]  [A loss: 1.118902, acc: 0.023438]\n",
            "757: [D loss: 0.668723, acc: 0.599609]  [A loss: 0.724886, acc: 0.445312]\n",
            "758: [D loss: 0.705327, acc: 0.531250]  [A loss: 1.052337, acc: 0.070312]\n",
            "759: [D loss: 0.659600, acc: 0.609375]  [A loss: 0.774114, acc: 0.320312]\n",
            "760: [D loss: 0.684293, acc: 0.552734]  [A loss: 1.005766, acc: 0.054688]\n",
            "761: [D loss: 0.660678, acc: 0.609375]  [A loss: 0.788821, acc: 0.339844]\n",
            "762: [D loss: 0.723566, acc: 0.515625]  [A loss: 0.950710, acc: 0.105469]\n",
            "763: [D loss: 0.684414, acc: 0.527344]  [A loss: 0.839528, acc: 0.210938]\n",
            "764: [D loss: 0.666183, acc: 0.576172]  [A loss: 0.936469, acc: 0.105469]\n",
            "765: [D loss: 0.679757, acc: 0.568359]  [A loss: 0.901626, acc: 0.148438]\n",
            "766: [D loss: 0.679509, acc: 0.564453]  [A loss: 0.921774, acc: 0.140625]\n",
            "767: [D loss: 0.667051, acc: 0.607422]  [A loss: 0.833078, acc: 0.238281]\n",
            "768: [D loss: 0.658709, acc: 0.619141]  [A loss: 1.010146, acc: 0.089844]\n",
            "769: [D loss: 0.665973, acc: 0.607422]  [A loss: 0.796545, acc: 0.324219]\n",
            "770: [D loss: 0.672880, acc: 0.582031]  [A loss: 1.013037, acc: 0.074219]\n",
            "771: [D loss: 0.652697, acc: 0.613281]  [A loss: 0.810885, acc: 0.281250]\n",
            "772: [D loss: 0.693309, acc: 0.564453]  [A loss: 0.976597, acc: 0.101562]\n",
            "773: [D loss: 0.681817, acc: 0.568359]  [A loss: 0.823800, acc: 0.281250]\n",
            "774: [D loss: 0.684558, acc: 0.542969]  [A loss: 1.038489, acc: 0.078125]\n",
            "775: [D loss: 0.661108, acc: 0.601562]  [A loss: 0.798272, acc: 0.316406]\n",
            "776: [D loss: 0.711373, acc: 0.525391]  [A loss: 1.070526, acc: 0.058594]\n",
            "777: [D loss: 0.669900, acc: 0.589844]  [A loss: 0.767307, acc: 0.382812]\n",
            "778: [D loss: 0.685309, acc: 0.576172]  [A loss: 1.014883, acc: 0.089844]\n",
            "779: [D loss: 0.673707, acc: 0.566406]  [A loss: 0.805348, acc: 0.292969]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "780: [D loss: 0.699343, acc: 0.550781]  [A loss: 1.016205, acc: 0.082031]\n",
            "781: [D loss: 0.664743, acc: 0.623047]  [A loss: 0.774358, acc: 0.371094]\n",
            "782: [D loss: 0.705733, acc: 0.527344]  [A loss: 0.943783, acc: 0.117188]\n",
            "783: [D loss: 0.678724, acc: 0.568359]  [A loss: 0.851050, acc: 0.253906]\n",
            "784: [D loss: 0.669311, acc: 0.576172]  [A loss: 1.009518, acc: 0.074219]\n",
            "785: [D loss: 0.668997, acc: 0.587891]  [A loss: 0.804741, acc: 0.332031]\n",
            "786: [D loss: 0.684667, acc: 0.560547]  [A loss: 0.996752, acc: 0.101562]\n",
            "787: [D loss: 0.675214, acc: 0.583984]  [A loss: 0.825646, acc: 0.281250]\n",
            "788: [D loss: 0.696415, acc: 0.544922]  [A loss: 0.983328, acc: 0.125000]\n",
            "789: [D loss: 0.673710, acc: 0.593750]  [A loss: 0.852282, acc: 0.222656]\n",
            "790: [D loss: 0.669676, acc: 0.574219]  [A loss: 1.003341, acc: 0.101562]\n",
            "791: [D loss: 0.678435, acc: 0.560547]  [A loss: 0.834144, acc: 0.226562]\n",
            "792: [D loss: 0.661701, acc: 0.570312]  [A loss: 1.009057, acc: 0.089844]\n",
            "793: [D loss: 0.666593, acc: 0.605469]  [A loss: 0.889360, acc: 0.183594]\n",
            "794: [D loss: 0.679347, acc: 0.580078]  [A loss: 0.869245, acc: 0.242188]\n",
            "795: [D loss: 0.689011, acc: 0.544922]  [A loss: 0.931171, acc: 0.128906]\n",
            "796: [D loss: 0.666778, acc: 0.585938]  [A loss: 0.916899, acc: 0.148438]\n",
            "797: [D loss: 0.670839, acc: 0.580078]  [A loss: 0.920506, acc: 0.125000]\n",
            "798: [D loss: 0.663421, acc: 0.583984]  [A loss: 0.985887, acc: 0.117188]\n",
            "799: [D loss: 0.676491, acc: 0.558594]  [A loss: 1.024561, acc: 0.070312]\n",
            "800: [D loss: 0.661715, acc: 0.587891]  [A loss: 0.794480, acc: 0.308594]\n",
            "801: [D loss: 0.698990, acc: 0.531250]  [A loss: 1.097094, acc: 0.070312]\n",
            "802: [D loss: 0.667832, acc: 0.576172]  [A loss: 0.729093, acc: 0.441406]\n",
            "803: [D loss: 0.716045, acc: 0.533203]  [A loss: 1.140867, acc: 0.042969]\n",
            "804: [D loss: 0.671341, acc: 0.593750]  [A loss: 0.642401, acc: 0.656250]\n",
            "805: [D loss: 0.713355, acc: 0.533203]  [A loss: 1.093241, acc: 0.062500]\n",
            "806: [D loss: 0.672903, acc: 0.582031]  [A loss: 0.787162, acc: 0.289062]\n",
            "807: [D loss: 0.707993, acc: 0.537109]  [A loss: 1.026025, acc: 0.058594]\n",
            "808: [D loss: 0.666870, acc: 0.595703]  [A loss: 0.742310, acc: 0.464844]\n",
            "809: [D loss: 0.695494, acc: 0.525391]  [A loss: 0.992648, acc: 0.078125]\n",
            "810: [D loss: 0.664398, acc: 0.587891]  [A loss: 0.793739, acc: 0.316406]\n",
            "811: [D loss: 0.690741, acc: 0.546875]  [A loss: 0.954534, acc: 0.109375]\n",
            "812: [D loss: 0.669276, acc: 0.597656]  [A loss: 0.784174, acc: 0.351562]\n",
            "813: [D loss: 0.673164, acc: 0.560547]  [A loss: 0.966985, acc: 0.113281]\n",
            "814: [D loss: 0.667990, acc: 0.587891]  [A loss: 0.806985, acc: 0.300781]\n",
            "815: [D loss: 0.676665, acc: 0.580078]  [A loss: 0.916324, acc: 0.140625]\n",
            "816: [D loss: 0.664803, acc: 0.615234]  [A loss: 0.911956, acc: 0.171875]\n",
            "817: [D loss: 0.671417, acc: 0.582031]  [A loss: 0.908887, acc: 0.191406]\n",
            "818: [D loss: 0.673155, acc: 0.595703]  [A loss: 0.919830, acc: 0.156250]\n",
            "819: [D loss: 0.688877, acc: 0.572266]  [A loss: 0.979824, acc: 0.144531]\n",
            "820: [D loss: 0.675058, acc: 0.560547]  [A loss: 0.915998, acc: 0.187500]\n",
            "821: [D loss: 0.666201, acc: 0.591797]  [A loss: 0.965794, acc: 0.101562]\n",
            "822: [D loss: 0.667885, acc: 0.556641]  [A loss: 0.872065, acc: 0.226562]\n",
            "823: [D loss: 0.685121, acc: 0.587891]  [A loss: 1.066908, acc: 0.062500]\n",
            "824: [D loss: 0.685961, acc: 0.556641]  [A loss: 0.797138, acc: 0.347656]\n",
            "825: [D loss: 0.687931, acc: 0.541016]  [A loss: 1.114877, acc: 0.062500]\n",
            "826: [D loss: 0.685167, acc: 0.548828]  [A loss: 0.705468, acc: 0.523438]\n",
            "827: [D loss: 0.717130, acc: 0.531250]  [A loss: 1.080784, acc: 0.089844]\n",
            "828: [D loss: 0.666623, acc: 0.595703]  [A loss: 0.751274, acc: 0.414062]\n",
            "829: [D loss: 0.710518, acc: 0.509766]  [A loss: 1.069448, acc: 0.074219]\n",
            "830: [D loss: 0.682380, acc: 0.566406]  [A loss: 0.805387, acc: 0.296875]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "831: [D loss: 0.693301, acc: 0.562500]  [A loss: 0.914919, acc: 0.144531]\n",
            "832: [D loss: 0.658331, acc: 0.609375]  [A loss: 0.871752, acc: 0.199219]\n",
            "833: [D loss: 0.686122, acc: 0.560547]  [A loss: 0.933959, acc: 0.121094]\n",
            "834: [D loss: 0.685616, acc: 0.552734]  [A loss: 0.881745, acc: 0.207031]\n",
            "835: [D loss: 0.663891, acc: 0.587891]  [A loss: 0.909186, acc: 0.160156]\n",
            "836: [D loss: 0.665244, acc: 0.599609]  [A loss: 0.888491, acc: 0.199219]\n",
            "837: [D loss: 0.676149, acc: 0.578125]  [A loss: 0.940676, acc: 0.160156]\n",
            "838: [D loss: 0.677425, acc: 0.572266]  [A loss: 0.889545, acc: 0.203125]\n",
            "839: [D loss: 0.675708, acc: 0.611328]  [A loss: 0.962886, acc: 0.136719]\n",
            "840: [D loss: 0.670995, acc: 0.591797]  [A loss: 0.881353, acc: 0.183594]\n",
            "841: [D loss: 0.674614, acc: 0.583984]  [A loss: 1.027299, acc: 0.097656]\n",
            "842: [D loss: 0.683564, acc: 0.572266]  [A loss: 0.858360, acc: 0.253906]\n",
            "843: [D loss: 0.678207, acc: 0.578125]  [A loss: 1.028620, acc: 0.078125]\n",
            "844: [D loss: 0.672780, acc: 0.570312]  [A loss: 0.827893, acc: 0.269531]\n",
            "845: [D loss: 0.692481, acc: 0.558594]  [A loss: 1.075943, acc: 0.054688]\n",
            "846: [D loss: 0.680716, acc: 0.554688]  [A loss: 0.855891, acc: 0.242188]\n",
            "847: [D loss: 0.678159, acc: 0.564453]  [A loss: 1.034065, acc: 0.050781]\n",
            "848: [D loss: 0.656478, acc: 0.603516]  [A loss: 0.860680, acc: 0.238281]\n",
            "849: [D loss: 0.690905, acc: 0.525391]  [A loss: 1.042630, acc: 0.062500]\n",
            "850: [D loss: 0.657989, acc: 0.591797]  [A loss: 0.881668, acc: 0.191406]\n",
            "851: [D loss: 0.661433, acc: 0.630859]  [A loss: 0.986551, acc: 0.125000]\n",
            "852: [D loss: 0.674629, acc: 0.576172]  [A loss: 0.892797, acc: 0.207031]\n",
            "853: [D loss: 0.675911, acc: 0.582031]  [A loss: 0.994744, acc: 0.097656]\n",
            "854: [D loss: 0.671314, acc: 0.583984]  [A loss: 0.831431, acc: 0.289062]\n",
            "855: [D loss: 0.693113, acc: 0.544922]  [A loss: 1.088781, acc: 0.062500]\n",
            "856: [D loss: 0.679682, acc: 0.564453]  [A loss: 0.706613, acc: 0.480469]\n",
            "857: [D loss: 0.750699, acc: 0.496094]  [A loss: 1.194857, acc: 0.019531]\n",
            "858: [D loss: 0.661951, acc: 0.587891]  [A loss: 0.671881, acc: 0.593750]\n",
            "859: [D loss: 0.712127, acc: 0.552734]  [A loss: 1.102425, acc: 0.054688]\n",
            "860: [D loss: 0.675843, acc: 0.574219]  [A loss: 0.764461, acc: 0.390625]\n",
            "861: [D loss: 0.707354, acc: 0.542969]  [A loss: 0.929265, acc: 0.156250]\n",
            "862: [D loss: 0.666486, acc: 0.582031]  [A loss: 0.865285, acc: 0.195312]\n",
            "863: [D loss: 0.662785, acc: 0.609375]  [A loss: 0.885953, acc: 0.195312]\n",
            "864: [D loss: 0.687139, acc: 0.537109]  [A loss: 0.883509, acc: 0.171875]\n",
            "865: [D loss: 0.672403, acc: 0.582031]  [A loss: 0.880632, acc: 0.140625]\n",
            "866: [D loss: 0.673367, acc: 0.583984]  [A loss: 0.969947, acc: 0.140625]\n",
            "867: [D loss: 0.685790, acc: 0.558594]  [A loss: 0.912066, acc: 0.175781]\n",
            "868: [D loss: 0.669242, acc: 0.605469]  [A loss: 0.919407, acc: 0.156250]\n",
            "869: [D loss: 0.686373, acc: 0.546875]  [A loss: 0.948894, acc: 0.140625]\n",
            "870: [D loss: 0.661217, acc: 0.595703]  [A loss: 0.824722, acc: 0.316406]\n",
            "871: [D loss: 0.674359, acc: 0.580078]  [A loss: 1.044603, acc: 0.085938]\n",
            "872: [D loss: 0.663430, acc: 0.591797]  [A loss: 0.830149, acc: 0.292969]\n",
            "873: [D loss: 0.709892, acc: 0.544922]  [A loss: 1.120336, acc: 0.062500]\n",
            "874: [D loss: 0.690622, acc: 0.544922]  [A loss: 0.743763, acc: 0.429688]\n",
            "875: [D loss: 0.693126, acc: 0.531250]  [A loss: 1.105253, acc: 0.050781]\n",
            "876: [D loss: 0.682521, acc: 0.589844]  [A loss: 0.760853, acc: 0.382812]\n",
            "877: [D loss: 0.719085, acc: 0.519531]  [A loss: 1.103944, acc: 0.050781]\n",
            "878: [D loss: 0.668096, acc: 0.580078]  [A loss: 0.712851, acc: 0.507812]\n",
            "879: [D loss: 0.721198, acc: 0.513672]  [A loss: 1.111451, acc: 0.027344]\n",
            "880: [D loss: 0.676608, acc: 0.568359]  [A loss: 0.750354, acc: 0.421875]\n",
            "881: [D loss: 0.715857, acc: 0.515625]  [A loss: 1.010365, acc: 0.058594]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "882: [D loss: 0.667318, acc: 0.576172]  [A loss: 0.768766, acc: 0.351562]\n",
            "883: [D loss: 0.682687, acc: 0.548828]  [A loss: 1.003989, acc: 0.085938]\n",
            "884: [D loss: 0.655056, acc: 0.613281]  [A loss: 0.819651, acc: 0.277344]\n",
            "885: [D loss: 0.674834, acc: 0.585938]  [A loss: 0.958082, acc: 0.144531]\n",
            "886: [D loss: 0.666002, acc: 0.587891]  [A loss: 0.919634, acc: 0.140625]\n",
            "887: [D loss: 0.667324, acc: 0.591797]  [A loss: 0.942448, acc: 0.101562]\n",
            "888: [D loss: 0.669935, acc: 0.597656]  [A loss: 0.925957, acc: 0.187500]\n",
            "889: [D loss: 0.670022, acc: 0.591797]  [A loss: 0.902255, acc: 0.187500]\n",
            "890: [D loss: 0.674017, acc: 0.572266]  [A loss: 0.952786, acc: 0.160156]\n",
            "891: [D loss: 0.671654, acc: 0.566406]  [A loss: 0.867348, acc: 0.253906]\n",
            "892: [D loss: 0.681862, acc: 0.560547]  [A loss: 1.004324, acc: 0.085938]\n",
            "893: [D loss: 0.677868, acc: 0.560547]  [A loss: 0.871393, acc: 0.183594]\n",
            "894: [D loss: 0.674459, acc: 0.583984]  [A loss: 1.049242, acc: 0.093750]\n",
            "895: [D loss: 0.664564, acc: 0.580078]  [A loss: 0.806029, acc: 0.324219]\n",
            "896: [D loss: 0.710662, acc: 0.541016]  [A loss: 1.126700, acc: 0.058594]\n",
            "897: [D loss: 0.673075, acc: 0.597656]  [A loss: 0.770956, acc: 0.363281]\n",
            "898: [D loss: 0.709367, acc: 0.527344]  [A loss: 1.136776, acc: 0.042969]\n",
            "899: [D loss: 0.657622, acc: 0.626953]  [A loss: 0.794235, acc: 0.343750]\n",
            "900: [D loss: 0.699595, acc: 0.542969]  [A loss: 1.084466, acc: 0.058594]\n",
            "901: [D loss: 0.671444, acc: 0.599609]  [A loss: 0.818496, acc: 0.300781]\n",
            "902: [D loss: 0.683473, acc: 0.564453]  [A loss: 0.999920, acc: 0.113281]\n",
            "903: [D loss: 0.664101, acc: 0.617188]  [A loss: 0.788265, acc: 0.332031]\n",
            "904: [D loss: 0.688136, acc: 0.562500]  [A loss: 1.027931, acc: 0.082031]\n",
            "905: [D loss: 0.684615, acc: 0.560547]  [A loss: 0.809415, acc: 0.320312]\n",
            "906: [D loss: 0.700449, acc: 0.550781]  [A loss: 1.070045, acc: 0.089844]\n",
            "907: [D loss: 0.677396, acc: 0.564453]  [A loss: 0.729680, acc: 0.433594]\n",
            "908: [D loss: 0.698310, acc: 0.558594]  [A loss: 1.070572, acc: 0.066406]\n",
            "909: [D loss: 0.680748, acc: 0.541016]  [A loss: 0.743644, acc: 0.417969]\n",
            "910: [D loss: 0.695502, acc: 0.546875]  [A loss: 1.031315, acc: 0.066406]\n",
            "911: [D loss: 0.678228, acc: 0.572266]  [A loss: 0.816517, acc: 0.312500]\n",
            "912: [D loss: 0.685858, acc: 0.585938]  [A loss: 1.021555, acc: 0.070312]\n",
            "913: [D loss: 0.673790, acc: 0.564453]  [A loss: 0.818771, acc: 0.289062]\n",
            "914: [D loss: 0.690776, acc: 0.548828]  [A loss: 0.997927, acc: 0.082031]\n",
            "915: [D loss: 0.665137, acc: 0.578125]  [A loss: 0.803841, acc: 0.285156]\n",
            "916: [D loss: 0.672149, acc: 0.564453]  [A loss: 1.013032, acc: 0.089844]\n",
            "917: [D loss: 0.675274, acc: 0.576172]  [A loss: 0.851297, acc: 0.250000]\n",
            "918: [D loss: 0.690732, acc: 0.560547]  [A loss: 0.936254, acc: 0.160156]\n",
            "919: [D loss: 0.692907, acc: 0.529297]  [A loss: 0.893151, acc: 0.203125]\n",
            "920: [D loss: 0.673450, acc: 0.570312]  [A loss: 0.958057, acc: 0.136719]\n",
            "921: [D loss: 0.695521, acc: 0.550781]  [A loss: 0.949491, acc: 0.160156]\n",
            "922: [D loss: 0.663775, acc: 0.593750]  [A loss: 0.911535, acc: 0.171875]\n",
            "923: [D loss: 0.664422, acc: 0.615234]  [A loss: 0.933595, acc: 0.160156]\n",
            "924: [D loss: 0.669014, acc: 0.599609]  [A loss: 0.893335, acc: 0.179688]\n",
            "925: [D loss: 0.670756, acc: 0.552734]  [A loss: 1.037792, acc: 0.066406]\n",
            "926: [D loss: 0.670267, acc: 0.578125]  [A loss: 0.810031, acc: 0.351562]\n",
            "927: [D loss: 0.714795, acc: 0.498047]  [A loss: 1.145744, acc: 0.039062]\n",
            "928: [D loss: 0.678781, acc: 0.585938]  [A loss: 0.667806, acc: 0.593750]\n",
            "929: [D loss: 0.724028, acc: 0.558594]  [A loss: 1.128389, acc: 0.070312]\n",
            "930: [D loss: 0.675415, acc: 0.562500]  [A loss: 0.809932, acc: 0.304688]\n",
            "931: [D loss: 0.683926, acc: 0.550781]  [A loss: 1.018578, acc: 0.082031]\n",
            "932: [D loss: 0.662887, acc: 0.599609]  [A loss: 0.763163, acc: 0.406250]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "933: [D loss: 0.693225, acc: 0.568359]  [A loss: 0.984513, acc: 0.148438]\n",
            "934: [D loss: 0.666291, acc: 0.599609]  [A loss: 0.872031, acc: 0.257812]\n",
            "935: [D loss: 0.677942, acc: 0.568359]  [A loss: 0.965364, acc: 0.140625]\n",
            "936: [D loss: 0.670324, acc: 0.605469]  [A loss: 0.818957, acc: 0.320312]\n",
            "937: [D loss: 0.679163, acc: 0.556641]  [A loss: 0.957635, acc: 0.113281]\n",
            "938: [D loss: 0.674801, acc: 0.578125]  [A loss: 0.835796, acc: 0.253906]\n",
            "939: [D loss: 0.673420, acc: 0.593750]  [A loss: 0.940701, acc: 0.160156]\n",
            "940: [D loss: 0.679678, acc: 0.539062]  [A loss: 0.833481, acc: 0.289062]\n",
            "941: [D loss: 0.677417, acc: 0.574219]  [A loss: 1.046371, acc: 0.058594]\n",
            "942: [D loss: 0.683948, acc: 0.558594]  [A loss: 0.833687, acc: 0.296875]\n",
            "943: [D loss: 0.686028, acc: 0.558594]  [A loss: 1.021842, acc: 0.082031]\n",
            "944: [D loss: 0.689225, acc: 0.574219]  [A loss: 0.814846, acc: 0.328125]\n",
            "945: [D loss: 0.688515, acc: 0.527344]  [A loss: 1.045853, acc: 0.066406]\n",
            "946: [D loss: 0.672628, acc: 0.580078]  [A loss: 0.746019, acc: 0.410156]\n",
            "947: [D loss: 0.672217, acc: 0.578125]  [A loss: 1.055121, acc: 0.097656]\n",
            "948: [D loss: 0.669244, acc: 0.566406]  [A loss: 0.792869, acc: 0.347656]\n",
            "949: [D loss: 0.691551, acc: 0.566406]  [A loss: 1.060286, acc: 0.050781]\n",
            "950: [D loss: 0.663586, acc: 0.593750]  [A loss: 0.751001, acc: 0.417969]\n",
            "951: [D loss: 0.672261, acc: 0.574219]  [A loss: 1.041690, acc: 0.070312]\n",
            "952: [D loss: 0.672157, acc: 0.562500]  [A loss: 0.806459, acc: 0.257812]\n",
            "953: [D loss: 0.686138, acc: 0.566406]  [A loss: 0.992811, acc: 0.101562]\n",
            "954: [D loss: 0.653630, acc: 0.615234]  [A loss: 0.812443, acc: 0.328125]\n",
            "955: [D loss: 0.668680, acc: 0.570312]  [A loss: 0.981328, acc: 0.105469]\n",
            "956: [D loss: 0.676049, acc: 0.570312]  [A loss: 0.828192, acc: 0.289062]\n",
            "957: [D loss: 0.680300, acc: 0.576172]  [A loss: 1.006011, acc: 0.097656]\n",
            "958: [D loss: 0.661072, acc: 0.595703]  [A loss: 0.783305, acc: 0.367188]\n",
            "959: [D loss: 0.697623, acc: 0.554688]  [A loss: 1.009728, acc: 0.109375]\n",
            "960: [D loss: 0.669970, acc: 0.591797]  [A loss: 0.862320, acc: 0.246094]\n",
            "961: [D loss: 0.708616, acc: 0.531250]  [A loss: 1.009776, acc: 0.097656]\n",
            "962: [D loss: 0.686688, acc: 0.527344]  [A loss: 0.884236, acc: 0.199219]\n",
            "963: [D loss: 0.702711, acc: 0.517578]  [A loss: 0.956880, acc: 0.117188]\n",
            "964: [D loss: 0.675328, acc: 0.576172]  [A loss: 0.875899, acc: 0.199219]\n",
            "965: [D loss: 0.677776, acc: 0.580078]  [A loss: 0.967710, acc: 0.121094]\n",
            "966: [D loss: 0.682761, acc: 0.554688]  [A loss: 0.851987, acc: 0.238281]\n",
            "967: [D loss: 0.689182, acc: 0.513672]  [A loss: 0.949995, acc: 0.132812]\n",
            "968: [D loss: 0.691837, acc: 0.537109]  [A loss: 0.837954, acc: 0.250000]\n",
            "969: [D loss: 0.705911, acc: 0.513672]  [A loss: 1.050390, acc: 0.070312]\n",
            "970: [D loss: 0.676717, acc: 0.562500]  [A loss: 0.785110, acc: 0.359375]\n",
            "971: [D loss: 0.698888, acc: 0.566406]  [A loss: 1.091968, acc: 0.039062]\n",
            "972: [D loss: 0.665724, acc: 0.580078]  [A loss: 0.730174, acc: 0.464844]\n",
            "973: [D loss: 0.699655, acc: 0.572266]  [A loss: 1.068962, acc: 0.074219]\n",
            "974: [D loss: 0.664025, acc: 0.599609]  [A loss: 0.712138, acc: 0.484375]\n",
            "975: [D loss: 0.691489, acc: 0.548828]  [A loss: 1.026754, acc: 0.074219]\n",
            "976: [D loss: 0.679853, acc: 0.552734]  [A loss: 0.761364, acc: 0.410156]\n",
            "977: [D loss: 0.688394, acc: 0.554688]  [A loss: 0.944302, acc: 0.132812]\n",
            "978: [D loss: 0.674756, acc: 0.582031]  [A loss: 0.820489, acc: 0.281250]\n",
            "979: [D loss: 0.694866, acc: 0.537109]  [A loss: 0.972040, acc: 0.128906]\n",
            "980: [D loss: 0.681578, acc: 0.560547]  [A loss: 0.836107, acc: 0.300781]\n",
            "981: [D loss: 0.689115, acc: 0.558594]  [A loss: 0.978406, acc: 0.109375]\n",
            "982: [D loss: 0.690014, acc: 0.558594]  [A loss: 0.821761, acc: 0.281250]\n",
            "983: [D loss: 0.667075, acc: 0.591797]  [A loss: 0.928399, acc: 0.140625]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "984: [D loss: 0.667942, acc: 0.609375]  [A loss: 0.907919, acc: 0.167969]\n",
            "985: [D loss: 0.671867, acc: 0.593750]  [A loss: 0.865120, acc: 0.207031]\n",
            "986: [D loss: 0.670486, acc: 0.572266]  [A loss: 0.951010, acc: 0.125000]\n",
            "987: [D loss: 0.692315, acc: 0.533203]  [A loss: 0.931452, acc: 0.160156]\n",
            "988: [D loss: 0.667958, acc: 0.587891]  [A loss: 0.841473, acc: 0.250000]\n",
            "989: [D loss: 0.663906, acc: 0.564453]  [A loss: 0.953843, acc: 0.136719]\n",
            "990: [D loss: 0.671260, acc: 0.568359]  [A loss: 0.865599, acc: 0.238281]\n",
            "991: [D loss: 0.700442, acc: 0.550781]  [A loss: 1.112777, acc: 0.042969]\n",
            "992: [D loss: 0.693239, acc: 0.548828]  [A loss: 0.749579, acc: 0.414062]\n",
            "993: [D loss: 0.702793, acc: 0.542969]  [A loss: 1.113392, acc: 0.046875]\n",
            "994: [D loss: 0.697997, acc: 0.521484]  [A loss: 0.840221, acc: 0.281250]\n",
            "995: [D loss: 0.703821, acc: 0.519531]  [A loss: 1.007043, acc: 0.125000]\n",
            "996: [D loss: 0.665579, acc: 0.593750]  [A loss: 0.792990, acc: 0.378906]\n",
            "997: [D loss: 0.695739, acc: 0.587891]  [A loss: 1.012578, acc: 0.089844]\n",
            "998: [D loss: 0.676088, acc: 0.548828]  [A loss: 0.868158, acc: 0.218750]\n",
            "999: [D loss: 0.695761, acc: 0.548828]  [A loss: 0.919928, acc: 0.160156]\n",
            "1000: [D loss: 0.685961, acc: 0.527344]  [A loss: 0.841464, acc: 0.250000]\n",
            "1001: [D loss: 0.678431, acc: 0.589844]  [A loss: 0.942425, acc: 0.152344]\n",
            "1002: [D loss: 0.667300, acc: 0.580078]  [A loss: 0.924314, acc: 0.167969]\n",
            "1003: [D loss: 0.677227, acc: 0.576172]  [A loss: 0.900973, acc: 0.207031]\n",
            "1004: [D loss: 0.681454, acc: 0.564453]  [A loss: 0.863538, acc: 0.253906]\n",
            "1005: [D loss: 0.674840, acc: 0.572266]  [A loss: 1.007880, acc: 0.101562]\n",
            "1006: [D loss: 0.676100, acc: 0.574219]  [A loss: 0.807176, acc: 0.343750]\n",
            "1007: [D loss: 0.682215, acc: 0.582031]  [A loss: 1.058396, acc: 0.074219]\n",
            "1008: [D loss: 0.679344, acc: 0.591797]  [A loss: 0.711598, acc: 0.515625]\n",
            "1009: [D loss: 0.696284, acc: 0.542969]  [A loss: 1.093217, acc: 0.035156]\n",
            "1010: [D loss: 0.671778, acc: 0.587891]  [A loss: 0.780229, acc: 0.378906]\n",
            "1011: [D loss: 0.705772, acc: 0.527344]  [A loss: 1.079891, acc: 0.031250]\n",
            "1012: [D loss: 0.674326, acc: 0.574219]  [A loss: 0.756928, acc: 0.406250]\n",
            "1013: [D loss: 0.697303, acc: 0.546875]  [A loss: 0.992740, acc: 0.109375]\n",
            "1014: [D loss: 0.671906, acc: 0.595703]  [A loss: 0.799876, acc: 0.335938]\n",
            "1015: [D loss: 0.689458, acc: 0.550781]  [A loss: 0.992090, acc: 0.144531]\n",
            "1016: [D loss: 0.667214, acc: 0.578125]  [A loss: 0.807875, acc: 0.289062]\n",
            "1017: [D loss: 0.693039, acc: 0.558594]  [A loss: 0.989525, acc: 0.093750]\n",
            "1018: [D loss: 0.679001, acc: 0.574219]  [A loss: 0.823339, acc: 0.277344]\n",
            "1019: [D loss: 0.677095, acc: 0.566406]  [A loss: 0.913626, acc: 0.179688]\n",
            "1020: [D loss: 0.656774, acc: 0.601562]  [A loss: 0.851327, acc: 0.234375]\n",
            "1021: [D loss: 0.674666, acc: 0.576172]  [A loss: 0.977935, acc: 0.140625]\n",
            "1022: [D loss: 0.656215, acc: 0.625000]  [A loss: 0.804907, acc: 0.312500]\n",
            "1023: [D loss: 0.692641, acc: 0.558594]  [A loss: 1.043127, acc: 0.054688]\n",
            "1024: [D loss: 0.669990, acc: 0.572266]  [A loss: 0.774806, acc: 0.382812]\n",
            "1025: [D loss: 0.697981, acc: 0.550781]  [A loss: 1.137636, acc: 0.039062]\n",
            "1026: [D loss: 0.680890, acc: 0.570312]  [A loss: 0.745746, acc: 0.414062]\n",
            "1027: [D loss: 0.675257, acc: 0.560547]  [A loss: 1.046129, acc: 0.054688]\n",
            "1028: [D loss: 0.665067, acc: 0.607422]  [A loss: 0.832649, acc: 0.265625]\n",
            "1029: [D loss: 0.667432, acc: 0.597656]  [A loss: 0.966220, acc: 0.117188]\n",
            "1030: [D loss: 0.666315, acc: 0.613281]  [A loss: 0.900253, acc: 0.199219]\n",
            "1031: [D loss: 0.690171, acc: 0.572266]  [A loss: 0.936966, acc: 0.171875]\n",
            "1032: [D loss: 0.683434, acc: 0.552734]  [A loss: 0.867096, acc: 0.238281]\n",
            "1033: [D loss: 0.689608, acc: 0.582031]  [A loss: 0.982945, acc: 0.101562]\n",
            "1034: [D loss: 0.671522, acc: 0.591797]  [A loss: 0.893344, acc: 0.218750]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1035: [D loss: 0.673509, acc: 0.578125]  [A loss: 0.995150, acc: 0.101562]\n",
            "1036: [D loss: 0.666426, acc: 0.578125]  [A loss: 0.845121, acc: 0.273438]\n",
            "1037: [D loss: 0.697947, acc: 0.556641]  [A loss: 1.120972, acc: 0.035156]\n",
            "1038: [D loss: 0.678494, acc: 0.560547]  [A loss: 0.765645, acc: 0.371094]\n",
            "1039: [D loss: 0.691513, acc: 0.566406]  [A loss: 1.090336, acc: 0.039062]\n",
            "1040: [D loss: 0.677347, acc: 0.582031]  [A loss: 0.753380, acc: 0.394531]\n",
            "1041: [D loss: 0.707487, acc: 0.544922]  [A loss: 1.089977, acc: 0.066406]\n",
            "1042: [D loss: 0.654215, acc: 0.621094]  [A loss: 0.741535, acc: 0.433594]\n",
            "1043: [D loss: 0.698978, acc: 0.550781]  [A loss: 1.024324, acc: 0.085938]\n",
            "1044: [D loss: 0.691940, acc: 0.552734]  [A loss: 0.765374, acc: 0.386719]\n",
            "1045: [D loss: 0.705416, acc: 0.517578]  [A loss: 0.981413, acc: 0.128906]\n",
            "1046: [D loss: 0.683881, acc: 0.572266]  [A loss: 0.874850, acc: 0.203125]\n",
            "1047: [D loss: 0.683708, acc: 0.566406]  [A loss: 0.965665, acc: 0.105469]\n",
            "1048: [D loss: 0.683013, acc: 0.523438]  [A loss: 0.817217, acc: 0.292969]\n",
            "1049: [D loss: 0.674752, acc: 0.583984]  [A loss: 0.940166, acc: 0.144531]\n",
            "1050: [D loss: 0.687349, acc: 0.562500]  [A loss: 0.823558, acc: 0.273438]\n",
            "1051: [D loss: 0.680671, acc: 0.556641]  [A loss: 0.975886, acc: 0.097656]\n",
            "1052: [D loss: 0.691044, acc: 0.541016]  [A loss: 0.764929, acc: 0.406250]\n",
            "1053: [D loss: 0.683959, acc: 0.583984]  [A loss: 1.006853, acc: 0.082031]\n",
            "1054: [D loss: 0.667184, acc: 0.580078]  [A loss: 0.826526, acc: 0.289062]\n",
            "1055: [D loss: 0.693484, acc: 0.578125]  [A loss: 1.017920, acc: 0.066406]\n",
            "1056: [D loss: 0.683318, acc: 0.544922]  [A loss: 0.794726, acc: 0.312500]\n",
            "1057: [D loss: 0.689750, acc: 0.556641]  [A loss: 1.013953, acc: 0.089844]\n",
            "1058: [D loss: 0.655731, acc: 0.628906]  [A loss: 0.774464, acc: 0.371094]\n",
            "1059: [D loss: 0.694408, acc: 0.556641]  [A loss: 1.045851, acc: 0.101562]\n",
            "1060: [D loss: 0.671429, acc: 0.578125]  [A loss: 0.688850, acc: 0.511719]\n",
            "1061: [D loss: 0.715456, acc: 0.515625]  [A loss: 1.036767, acc: 0.078125]\n",
            "1062: [D loss: 0.680475, acc: 0.582031]  [A loss: 0.806706, acc: 0.308594]\n",
            "1063: [D loss: 0.686391, acc: 0.566406]  [A loss: 1.008083, acc: 0.089844]\n",
            "1064: [D loss: 0.661200, acc: 0.591797]  [A loss: 0.862158, acc: 0.218750]\n",
            "1065: [D loss: 0.687617, acc: 0.554688]  [A loss: 0.993834, acc: 0.085938]\n",
            "1066: [D loss: 0.681712, acc: 0.568359]  [A loss: 0.824786, acc: 0.265625]\n",
            "1067: [D loss: 0.667250, acc: 0.591797]  [A loss: 0.994130, acc: 0.097656]\n",
            "1068: [D loss: 0.664611, acc: 0.613281]  [A loss: 0.813893, acc: 0.300781]\n",
            "1069: [D loss: 0.680873, acc: 0.558594]  [A loss: 0.989671, acc: 0.078125]\n",
            "1070: [D loss: 0.694592, acc: 0.548828]  [A loss: 0.765226, acc: 0.367188]\n",
            "1071: [D loss: 0.702050, acc: 0.548828]  [A loss: 1.069635, acc: 0.082031]\n",
            "1072: [D loss: 0.689179, acc: 0.556641]  [A loss: 0.801742, acc: 0.320312]\n",
            "1073: [D loss: 0.689344, acc: 0.556641]  [A loss: 0.950948, acc: 0.132812]\n",
            "1074: [D loss: 0.686094, acc: 0.560547]  [A loss: 0.842246, acc: 0.265625]\n",
            "1075: [D loss: 0.675814, acc: 0.564453]  [A loss: 0.965368, acc: 0.085938]\n",
            "1076: [D loss: 0.662990, acc: 0.613281]  [A loss: 0.868286, acc: 0.246094]\n",
            "1077: [D loss: 0.682177, acc: 0.589844]  [A loss: 0.998857, acc: 0.125000]\n",
            "1078: [D loss: 0.678094, acc: 0.583984]  [A loss: 0.876236, acc: 0.210938]\n",
            "1079: [D loss: 0.685097, acc: 0.574219]  [A loss: 1.028533, acc: 0.062500]\n",
            "1080: [D loss: 0.666390, acc: 0.585938]  [A loss: 0.838469, acc: 0.277344]\n",
            "1081: [D loss: 0.683622, acc: 0.560547]  [A loss: 1.019101, acc: 0.070312]\n",
            "1082: [D loss: 0.678991, acc: 0.583984]  [A loss: 0.793578, acc: 0.312500]\n",
            "1083: [D loss: 0.678825, acc: 0.554688]  [A loss: 1.042271, acc: 0.066406]\n",
            "1084: [D loss: 0.679738, acc: 0.566406]  [A loss: 0.826550, acc: 0.292969]\n",
            "1085: [D loss: 0.674452, acc: 0.578125]  [A loss: 1.044385, acc: 0.082031]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1086: [D loss: 0.666566, acc: 0.611328]  [A loss: 0.845487, acc: 0.273438]\n",
            "1087: [D loss: 0.694693, acc: 0.539062]  [A loss: 0.996736, acc: 0.121094]\n",
            "1088: [D loss: 0.689620, acc: 0.578125]  [A loss: 0.904589, acc: 0.175781]\n",
            "1089: [D loss: 0.674942, acc: 0.589844]  [A loss: 0.998541, acc: 0.101562]\n",
            "1090: [D loss: 0.684822, acc: 0.562500]  [A loss: 0.806087, acc: 0.328125]\n",
            "1091: [D loss: 0.705509, acc: 0.544922]  [A loss: 1.146245, acc: 0.046875]\n",
            "1092: [D loss: 0.676789, acc: 0.593750]  [A loss: 0.706782, acc: 0.500000]\n",
            "1093: [D loss: 0.703000, acc: 0.546875]  [A loss: 1.099039, acc: 0.035156]\n",
            "1094: [D loss: 0.674193, acc: 0.574219]  [A loss: 0.791685, acc: 0.328125]\n",
            "1095: [D loss: 0.692750, acc: 0.548828]  [A loss: 1.081256, acc: 0.078125]\n",
            "1096: [D loss: 0.691513, acc: 0.546875]  [A loss: 0.805605, acc: 0.308594]\n",
            "1097: [D loss: 0.691912, acc: 0.544922]  [A loss: 1.075248, acc: 0.078125]\n",
            "1098: [D loss: 0.668850, acc: 0.582031]  [A loss: 0.738946, acc: 0.457031]\n",
            "1099: [D loss: 0.700657, acc: 0.541016]  [A loss: 1.042813, acc: 0.074219]\n",
            "1100: [D loss: 0.663005, acc: 0.601562]  [A loss: 0.798627, acc: 0.320312]\n",
            "1101: [D loss: 0.686960, acc: 0.572266]  [A loss: 0.966477, acc: 0.164062]\n",
            "1102: [D loss: 0.676179, acc: 0.578125]  [A loss: 0.828675, acc: 0.308594]\n",
            "1103: [D loss: 0.688226, acc: 0.562500]  [A loss: 1.013288, acc: 0.078125]\n",
            "1104: [D loss: 0.660699, acc: 0.613281]  [A loss: 0.788197, acc: 0.343750]\n",
            "1105: [D loss: 0.685160, acc: 0.578125]  [A loss: 1.050204, acc: 0.078125]\n",
            "1106: [D loss: 0.659085, acc: 0.609375]  [A loss: 0.824714, acc: 0.316406]\n",
            "1107: [D loss: 0.712063, acc: 0.533203]  [A loss: 1.079650, acc: 0.039062]\n",
            "1108: [D loss: 0.671498, acc: 0.558594]  [A loss: 0.761694, acc: 0.417969]\n",
            "1109: [D loss: 0.683844, acc: 0.562500]  [A loss: 1.048047, acc: 0.105469]\n",
            "1110: [D loss: 0.672638, acc: 0.566406]  [A loss: 0.758632, acc: 0.355469]\n",
            "1111: [D loss: 0.696005, acc: 0.554688]  [A loss: 1.022940, acc: 0.082031]\n",
            "1112: [D loss: 0.697553, acc: 0.546875]  [A loss: 0.787894, acc: 0.355469]\n",
            "1113: [D loss: 0.712233, acc: 0.517578]  [A loss: 1.006644, acc: 0.101562]\n",
            "1114: [D loss: 0.673914, acc: 0.593750]  [A loss: 0.770978, acc: 0.343750]\n",
            "1115: [D loss: 0.690708, acc: 0.562500]  [A loss: 0.990560, acc: 0.089844]\n",
            "1116: [D loss: 0.675265, acc: 0.589844]  [A loss: 0.847444, acc: 0.273438]\n",
            "1117: [D loss: 0.685902, acc: 0.552734]  [A loss: 0.995663, acc: 0.066406]\n",
            "1118: [D loss: 0.663427, acc: 0.595703]  [A loss: 0.838666, acc: 0.285156]\n",
            "1119: [D loss: 0.672636, acc: 0.572266]  [A loss: 0.938698, acc: 0.148438]\n",
            "1120: [D loss: 0.664974, acc: 0.585938]  [A loss: 0.921054, acc: 0.183594]\n",
            "1121: [D loss: 0.678585, acc: 0.585938]  [A loss: 0.976169, acc: 0.136719]\n",
            "1122: [D loss: 0.678484, acc: 0.560547]  [A loss: 0.898959, acc: 0.203125]\n",
            "1123: [D loss: 0.679461, acc: 0.546875]  [A loss: 0.980487, acc: 0.132812]\n",
            "1124: [D loss: 0.684995, acc: 0.542969]  [A loss: 0.885516, acc: 0.199219]\n",
            "1125: [D loss: 0.688551, acc: 0.566406]  [A loss: 1.074800, acc: 0.109375]\n",
            "1126: [D loss: 0.688368, acc: 0.556641]  [A loss: 0.913953, acc: 0.207031]\n",
            "1127: [D loss: 0.670935, acc: 0.607422]  [A loss: 0.901702, acc: 0.250000]\n",
            "1128: [D loss: 0.698005, acc: 0.541016]  [A loss: 1.032989, acc: 0.101562]\n",
            "1129: [D loss: 0.660601, acc: 0.595703]  [A loss: 0.845236, acc: 0.300781]\n",
            "1130: [D loss: 0.695572, acc: 0.556641]  [A loss: 1.054970, acc: 0.074219]\n",
            "1131: [D loss: 0.678853, acc: 0.582031]  [A loss: 0.735533, acc: 0.441406]\n",
            "1132: [D loss: 0.706667, acc: 0.541016]  [A loss: 1.229706, acc: 0.035156]\n",
            "1133: [D loss: 0.678795, acc: 0.535156]  [A loss: 0.678014, acc: 0.554688]\n",
            "1134: [D loss: 0.723874, acc: 0.529297]  [A loss: 1.113729, acc: 0.050781]\n",
            "1135: [D loss: 0.701404, acc: 0.519531]  [A loss: 0.731282, acc: 0.468750]\n",
            "1136: [D loss: 0.712862, acc: 0.539062]  [A loss: 0.973134, acc: 0.113281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1137: [D loss: 0.669526, acc: 0.578125]  [A loss: 0.862622, acc: 0.238281]\n",
            "1138: [D loss: 0.692918, acc: 0.552734]  [A loss: 0.922175, acc: 0.152344]\n",
            "1139: [D loss: 0.691900, acc: 0.578125]  [A loss: 0.923956, acc: 0.195312]\n",
            "1140: [D loss: 0.662497, acc: 0.617188]  [A loss: 0.914249, acc: 0.167969]\n",
            "1141: [D loss: 0.678605, acc: 0.587891]  [A loss: 0.897421, acc: 0.203125]\n",
            "1142: [D loss: 0.700655, acc: 0.544922]  [A loss: 0.920389, acc: 0.171875]\n",
            "1143: [D loss: 0.667620, acc: 0.580078]  [A loss: 0.910490, acc: 0.187500]\n",
            "1144: [D loss: 0.684729, acc: 0.580078]  [A loss: 0.884452, acc: 0.203125]\n",
            "1145: [D loss: 0.697309, acc: 0.537109]  [A loss: 0.998660, acc: 0.128906]\n",
            "1146: [D loss: 0.679461, acc: 0.550781]  [A loss: 0.744039, acc: 0.429688]\n",
            "1147: [D loss: 0.700379, acc: 0.541016]  [A loss: 1.132205, acc: 0.046875]\n",
            "1148: [D loss: 0.700211, acc: 0.546875]  [A loss: 0.694852, acc: 0.519531]\n",
            "1149: [D loss: 0.710811, acc: 0.541016]  [A loss: 1.066832, acc: 0.058594]\n",
            "1150: [D loss: 0.657808, acc: 0.595703]  [A loss: 0.711455, acc: 0.523438]\n",
            "1151: [D loss: 0.717301, acc: 0.529297]  [A loss: 1.059940, acc: 0.058594]\n",
            "1152: [D loss: 0.669774, acc: 0.578125]  [A loss: 0.803780, acc: 0.296875]\n",
            "1153: [D loss: 0.685792, acc: 0.558594]  [A loss: 0.966377, acc: 0.179688]\n",
            "1154: [D loss: 0.676650, acc: 0.558594]  [A loss: 0.809899, acc: 0.292969]\n",
            "1155: [D loss: 0.667866, acc: 0.585938]  [A loss: 0.969800, acc: 0.144531]\n",
            "1156: [D loss: 0.680039, acc: 0.535156]  [A loss: 0.873119, acc: 0.214844]\n",
            "1157: [D loss: 0.677745, acc: 0.560547]  [A loss: 1.008994, acc: 0.093750]\n",
            "1158: [D loss: 0.667601, acc: 0.587891]  [A loss: 0.837824, acc: 0.273438]\n",
            "1159: [D loss: 0.678969, acc: 0.572266]  [A loss: 1.009110, acc: 0.117188]\n",
            "1160: [D loss: 0.689871, acc: 0.580078]  [A loss: 0.861944, acc: 0.246094]\n",
            "1161: [D loss: 0.704583, acc: 0.531250]  [A loss: 1.045204, acc: 0.101562]\n",
            "1162: [D loss: 0.671885, acc: 0.595703]  [A loss: 0.870196, acc: 0.250000]\n",
            "1163: [D loss: 0.689433, acc: 0.566406]  [A loss: 0.977078, acc: 0.128906]\n",
            "1164: [D loss: 0.670511, acc: 0.544922]  [A loss: 0.955526, acc: 0.136719]\n",
            "1165: [D loss: 0.678186, acc: 0.568359]  [A loss: 0.855051, acc: 0.230469]\n",
            "1166: [D loss: 0.675229, acc: 0.582031]  [A loss: 0.969122, acc: 0.117188]\n",
            "1167: [D loss: 0.687666, acc: 0.546875]  [A loss: 0.872377, acc: 0.195312]\n",
            "1168: [D loss: 0.683992, acc: 0.583984]  [A loss: 1.040246, acc: 0.078125]\n",
            "1169: [D loss: 0.676068, acc: 0.591797]  [A loss: 0.712472, acc: 0.484375]\n",
            "1170: [D loss: 0.735236, acc: 0.539062]  [A loss: 1.270281, acc: 0.011719]\n",
            "1171: [D loss: 0.693405, acc: 0.546875]  [A loss: 0.701167, acc: 0.542969]\n",
            "1172: [D loss: 0.714695, acc: 0.535156]  [A loss: 1.056829, acc: 0.074219]\n",
            "1173: [D loss: 0.687135, acc: 0.546875]  [A loss: 0.768211, acc: 0.386719]\n",
            "1174: [D loss: 0.689095, acc: 0.582031]  [A loss: 1.015997, acc: 0.105469]\n",
            "1175: [D loss: 0.669728, acc: 0.564453]  [A loss: 0.800566, acc: 0.351562]\n",
            "1176: [D loss: 0.667788, acc: 0.580078]  [A loss: 1.058330, acc: 0.066406]\n",
            "1177: [D loss: 0.688507, acc: 0.570312]  [A loss: 0.750473, acc: 0.406250]\n",
            "1178: [D loss: 0.697509, acc: 0.552734]  [A loss: 1.088392, acc: 0.058594]\n",
            "1179: [D loss: 0.683472, acc: 0.560547]  [A loss: 0.739222, acc: 0.433594]\n",
            "1180: [D loss: 0.683526, acc: 0.568359]  [A loss: 1.043696, acc: 0.105469]\n",
            "1181: [D loss: 0.683772, acc: 0.554688]  [A loss: 0.805364, acc: 0.324219]\n",
            "1182: [D loss: 0.690630, acc: 0.554688]  [A loss: 0.918819, acc: 0.183594]\n",
            "1183: [D loss: 0.659526, acc: 0.613281]  [A loss: 0.901126, acc: 0.210938]\n",
            "1184: [D loss: 0.681795, acc: 0.570312]  [A loss: 0.970261, acc: 0.117188]\n",
            "1185: [D loss: 0.680453, acc: 0.566406]  [A loss: 0.926609, acc: 0.160156]\n",
            "1186: [D loss: 0.670752, acc: 0.578125]  [A loss: 0.954611, acc: 0.152344]\n",
            "1187: [D loss: 0.666133, acc: 0.580078]  [A loss: 0.906601, acc: 0.207031]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1188: [D loss: 0.678566, acc: 0.566406]  [A loss: 1.011952, acc: 0.109375]\n",
            "1189: [D loss: 0.680858, acc: 0.541016]  [A loss: 0.829953, acc: 0.308594]\n",
            "1190: [D loss: 0.695651, acc: 0.560547]  [A loss: 1.128176, acc: 0.058594]\n",
            "1191: [D loss: 0.668914, acc: 0.576172]  [A loss: 0.699749, acc: 0.515625]\n",
            "1192: [D loss: 0.708041, acc: 0.564453]  [A loss: 1.103873, acc: 0.050781]\n",
            "1193: [D loss: 0.674336, acc: 0.593750]  [A loss: 0.706184, acc: 0.484375]\n",
            "1194: [D loss: 0.716134, acc: 0.541016]  [A loss: 1.052891, acc: 0.058594]\n",
            "1195: [D loss: 0.664884, acc: 0.617188]  [A loss: 0.817390, acc: 0.320312]\n",
            "1196: [D loss: 0.672744, acc: 0.593750]  [A loss: 1.020314, acc: 0.132812]\n",
            "1197: [D loss: 0.659610, acc: 0.623047]  [A loss: 0.735468, acc: 0.457031]\n",
            "1198: [D loss: 0.727423, acc: 0.527344]  [A loss: 1.041731, acc: 0.089844]\n",
            "1199: [D loss: 0.673262, acc: 0.585938]  [A loss: 0.760763, acc: 0.398438]\n",
            "1200: [D loss: 0.694600, acc: 0.550781]  [A loss: 1.027367, acc: 0.113281]\n",
            "1201: [D loss: 0.684262, acc: 0.568359]  [A loss: 0.786830, acc: 0.386719]\n",
            "1202: [D loss: 0.694889, acc: 0.564453]  [A loss: 1.047645, acc: 0.105469]\n",
            "1203: [D loss: 0.682827, acc: 0.570312]  [A loss: 0.815029, acc: 0.304688]\n",
            "1204: [D loss: 0.702385, acc: 0.544922]  [A loss: 1.037754, acc: 0.082031]\n",
            "1205: [D loss: 0.671921, acc: 0.589844]  [A loss: 0.746861, acc: 0.382812]\n",
            "1206: [D loss: 0.710433, acc: 0.523438]  [A loss: 1.013386, acc: 0.085938]\n",
            "1207: [D loss: 0.676574, acc: 0.599609]  [A loss: 0.737264, acc: 0.425781]\n",
            "1208: [D loss: 0.696754, acc: 0.548828]  [A loss: 1.022539, acc: 0.078125]\n",
            "1209: [D loss: 0.676257, acc: 0.564453]  [A loss: 0.827207, acc: 0.292969]\n",
            "1210: [D loss: 0.693967, acc: 0.523438]  [A loss: 0.942122, acc: 0.167969]\n",
            "1211: [D loss: 0.706145, acc: 0.550781]  [A loss: 0.976353, acc: 0.121094]\n",
            "1212: [D loss: 0.659657, acc: 0.605469]  [A loss: 0.889971, acc: 0.234375]\n",
            "1213: [D loss: 0.698272, acc: 0.558594]  [A loss: 1.088547, acc: 0.082031]\n",
            "1214: [D loss: 0.678867, acc: 0.593750]  [A loss: 0.723531, acc: 0.503906]\n",
            "1215: [D loss: 0.727134, acc: 0.515625]  [A loss: 1.073133, acc: 0.058594]\n",
            "1216: [D loss: 0.678774, acc: 0.552734]  [A loss: 0.797922, acc: 0.320312]\n",
            "1217: [D loss: 0.702854, acc: 0.552734]  [A loss: 1.061751, acc: 0.082031]\n",
            "1218: [D loss: 0.672960, acc: 0.589844]  [A loss: 0.739823, acc: 0.457031]\n",
            "1219: [D loss: 0.693996, acc: 0.572266]  [A loss: 1.028579, acc: 0.066406]\n",
            "1220: [D loss: 0.671594, acc: 0.601562]  [A loss: 0.786705, acc: 0.343750]\n",
            "1221: [D loss: 0.683657, acc: 0.556641]  [A loss: 0.989491, acc: 0.109375]\n",
            "1222: [D loss: 0.667336, acc: 0.603516]  [A loss: 0.949705, acc: 0.132812]\n",
            "1223: [D loss: 0.673330, acc: 0.589844]  [A loss: 0.913215, acc: 0.144531]\n",
            "1224: [D loss: 0.682266, acc: 0.568359]  [A loss: 0.895705, acc: 0.218750]\n",
            "1225: [D loss: 0.676804, acc: 0.576172]  [A loss: 0.938482, acc: 0.128906]\n",
            "1226: [D loss: 0.671132, acc: 0.595703]  [A loss: 0.970165, acc: 0.136719]\n",
            "1227: [D loss: 0.659445, acc: 0.601562]  [A loss: 0.902493, acc: 0.218750]\n",
            "1228: [D loss: 0.667248, acc: 0.578125]  [A loss: 1.063594, acc: 0.101562]\n",
            "1229: [D loss: 0.689245, acc: 0.548828]  [A loss: 0.823464, acc: 0.300781]\n",
            "1230: [D loss: 0.684968, acc: 0.574219]  [A loss: 1.043249, acc: 0.109375]\n",
            "1231: [D loss: 0.669304, acc: 0.589844]  [A loss: 0.821518, acc: 0.343750]\n",
            "1232: [D loss: 0.703482, acc: 0.533203]  [A loss: 1.185095, acc: 0.035156]\n",
            "1233: [D loss: 0.682775, acc: 0.578125]  [A loss: 0.700430, acc: 0.531250]\n",
            "1234: [D loss: 0.720030, acc: 0.533203]  [A loss: 1.166695, acc: 0.042969]\n",
            "1235: [D loss: 0.683700, acc: 0.580078]  [A loss: 0.685410, acc: 0.539062]\n",
            "1236: [D loss: 0.718221, acc: 0.542969]  [A loss: 1.123149, acc: 0.066406]\n",
            "1237: [D loss: 0.692253, acc: 0.572266]  [A loss: 0.740477, acc: 0.406250]\n",
            "1238: [D loss: 0.695683, acc: 0.550781]  [A loss: 0.947362, acc: 0.152344]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1239: [D loss: 0.695527, acc: 0.535156]  [A loss: 0.762257, acc: 0.410156]\n",
            "1240: [D loss: 0.701379, acc: 0.537109]  [A loss: 0.930788, acc: 0.144531]\n",
            "1241: [D loss: 0.667017, acc: 0.583984]  [A loss: 0.825973, acc: 0.304688]\n",
            "1242: [D loss: 0.701255, acc: 0.541016]  [A loss: 0.976928, acc: 0.105469]\n",
            "1243: [D loss: 0.661249, acc: 0.599609]  [A loss: 0.792136, acc: 0.351562]\n",
            "1244: [D loss: 0.692402, acc: 0.562500]  [A loss: 0.982109, acc: 0.117188]\n",
            "1245: [D loss: 0.676783, acc: 0.582031]  [A loss: 0.831158, acc: 0.332031]\n",
            "1246: [D loss: 0.700708, acc: 0.537109]  [A loss: 1.020194, acc: 0.097656]\n",
            "1247: [D loss: 0.657221, acc: 0.619141]  [A loss: 0.859140, acc: 0.285156]\n",
            "1248: [D loss: 0.678737, acc: 0.583984]  [A loss: 0.918954, acc: 0.183594]\n",
            "1249: [D loss: 0.680465, acc: 0.556641]  [A loss: 0.887325, acc: 0.238281]\n",
            "1250: [D loss: 0.683860, acc: 0.564453]  [A loss: 0.905049, acc: 0.179688]\n",
            "1251: [D loss: 0.660783, acc: 0.580078]  [A loss: 0.914726, acc: 0.175781]\n",
            "1252: [D loss: 0.676588, acc: 0.562500]  [A loss: 0.907188, acc: 0.210938]\n",
            "1253: [D loss: 0.667158, acc: 0.621094]  [A loss: 0.896201, acc: 0.238281]\n",
            "1254: [D loss: 0.706427, acc: 0.539062]  [A loss: 1.026670, acc: 0.113281]\n",
            "1255: [D loss: 0.686311, acc: 0.537109]  [A loss: 0.828307, acc: 0.292969]\n",
            "1256: [D loss: 0.665039, acc: 0.595703]  [A loss: 1.046235, acc: 0.105469]\n",
            "1257: [D loss: 0.654835, acc: 0.617188]  [A loss: 0.733412, acc: 0.472656]\n",
            "1258: [D loss: 0.697086, acc: 0.542969]  [A loss: 1.212702, acc: 0.046875]\n",
            "1259: [D loss: 0.676387, acc: 0.582031]  [A loss: 0.683019, acc: 0.546875]\n",
            "1260: [D loss: 0.741164, acc: 0.523438]  [A loss: 1.127097, acc: 0.039062]\n",
            "1261: [D loss: 0.678280, acc: 0.554688]  [A loss: 0.717334, acc: 0.468750]\n",
            "1262: [D loss: 0.701376, acc: 0.548828]  [A loss: 1.056907, acc: 0.078125]\n",
            "1263: [D loss: 0.684225, acc: 0.537109]  [A loss: 0.815107, acc: 0.296875]\n",
            "1264: [D loss: 0.698266, acc: 0.541016]  [A loss: 0.949795, acc: 0.148438]\n",
            "1265: [D loss: 0.684290, acc: 0.537109]  [A loss: 0.884331, acc: 0.242188]\n",
            "1266: [D loss: 0.704357, acc: 0.537109]  [A loss: 0.934556, acc: 0.167969]\n",
            "1267: [D loss: 0.674134, acc: 0.576172]  [A loss: 0.888751, acc: 0.210938]\n",
            "1268: [D loss: 0.691016, acc: 0.554688]  [A loss: 0.917385, acc: 0.187500]\n",
            "1269: [D loss: 0.683170, acc: 0.576172]  [A loss: 0.994784, acc: 0.117188]\n",
            "1270: [D loss: 0.656569, acc: 0.619141]  [A loss: 0.801125, acc: 0.355469]\n",
            "1271: [D loss: 0.694134, acc: 0.541016]  [A loss: 0.993087, acc: 0.132812]\n",
            "1272: [D loss: 0.667343, acc: 0.585938]  [A loss: 0.856007, acc: 0.261719]\n",
            "1273: [D loss: 0.693873, acc: 0.537109]  [A loss: 1.031016, acc: 0.085938]\n",
            "1274: [D loss: 0.704727, acc: 0.513672]  [A loss: 0.858084, acc: 0.214844]\n",
            "1275: [D loss: 0.680601, acc: 0.580078]  [A loss: 0.967691, acc: 0.132812]\n",
            "1276: [D loss: 0.690057, acc: 0.568359]  [A loss: 0.896251, acc: 0.214844]\n",
            "1277: [D loss: 0.689192, acc: 0.570312]  [A loss: 1.029552, acc: 0.093750]\n",
            "1278: [D loss: 0.683026, acc: 0.550781]  [A loss: 0.862611, acc: 0.269531]\n",
            "1279: [D loss: 0.685655, acc: 0.562500]  [A loss: 1.022805, acc: 0.101562]\n",
            "1280: [D loss: 0.696601, acc: 0.568359]  [A loss: 0.863261, acc: 0.226562]\n",
            "1281: [D loss: 0.701888, acc: 0.539062]  [A loss: 1.089840, acc: 0.039062]\n",
            "1282: [D loss: 0.663963, acc: 0.615234]  [A loss: 0.692177, acc: 0.558594]\n",
            "1283: [D loss: 0.711075, acc: 0.529297]  [A loss: 1.222515, acc: 0.011719]\n",
            "1284: [D loss: 0.671286, acc: 0.576172]  [A loss: 0.735865, acc: 0.457031]\n",
            "1285: [D loss: 0.720459, acc: 0.505859]  [A loss: 1.091151, acc: 0.039062]\n",
            "1286: [D loss: 0.665473, acc: 0.597656]  [A loss: 0.740222, acc: 0.429688]\n",
            "1287: [D loss: 0.706485, acc: 0.539062]  [A loss: 1.027010, acc: 0.093750]\n",
            "1288: [D loss: 0.699561, acc: 0.531250]  [A loss: 0.763544, acc: 0.410156]\n",
            "1289: [D loss: 0.686688, acc: 0.558594]  [A loss: 0.990119, acc: 0.125000]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1290: [D loss: 0.686665, acc: 0.556641]  [A loss: 0.718560, acc: 0.468750]\n",
            "1291: [D loss: 0.720951, acc: 0.515625]  [A loss: 1.091277, acc: 0.093750]\n",
            "1292: [D loss: 0.657471, acc: 0.589844]  [A loss: 0.772492, acc: 0.382812]\n",
            "1293: [D loss: 0.739010, acc: 0.507812]  [A loss: 1.007309, acc: 0.121094]\n",
            "1294: [D loss: 0.698957, acc: 0.500000]  [A loss: 0.785871, acc: 0.343750]\n",
            "1295: [D loss: 0.685433, acc: 0.548828]  [A loss: 0.933589, acc: 0.160156]\n",
            "1296: [D loss: 0.681336, acc: 0.574219]  [A loss: 0.823065, acc: 0.300781]\n",
            "1297: [D loss: 0.686817, acc: 0.554688]  [A loss: 0.950246, acc: 0.140625]\n",
            "1298: [D loss: 0.659804, acc: 0.595703]  [A loss: 0.905393, acc: 0.171875]\n",
            "1299: [D loss: 0.672697, acc: 0.582031]  [A loss: 0.976383, acc: 0.113281]\n",
            "1300: [D loss: 0.677223, acc: 0.589844]  [A loss: 0.894587, acc: 0.222656]\n",
            "1301: [D loss: 0.686179, acc: 0.556641]  [A loss: 0.830166, acc: 0.265625]\n",
            "1302: [D loss: 0.701376, acc: 0.537109]  [A loss: 0.948610, acc: 0.144531]\n",
            "1303: [D loss: 0.666082, acc: 0.583984]  [A loss: 0.962006, acc: 0.121094]\n",
            "1304: [D loss: 0.682653, acc: 0.572266]  [A loss: 1.052664, acc: 0.082031]\n",
            "1305: [D loss: 0.697912, acc: 0.562500]  [A loss: 0.773811, acc: 0.371094]\n",
            "1306: [D loss: 0.677519, acc: 0.595703]  [A loss: 1.108756, acc: 0.089844]\n",
            "1307: [D loss: 0.693082, acc: 0.542969]  [A loss: 0.794655, acc: 0.359375]\n",
            "1308: [D loss: 0.677790, acc: 0.562500]  [A loss: 1.164387, acc: 0.031250]\n",
            "1309: [D loss: 0.682508, acc: 0.562500]  [A loss: 0.664429, acc: 0.605469]\n",
            "1310: [D loss: 0.716075, acc: 0.529297]  [A loss: 1.164069, acc: 0.031250]\n",
            "1311: [D loss: 0.688098, acc: 0.550781]  [A loss: 0.682976, acc: 0.535156]\n",
            "1312: [D loss: 0.710308, acc: 0.517578]  [A loss: 1.054170, acc: 0.078125]\n",
            "1313: [D loss: 0.675658, acc: 0.585938]  [A loss: 0.808385, acc: 0.312500]\n",
            "1314: [D loss: 0.682048, acc: 0.595703]  [A loss: 0.982329, acc: 0.113281]\n",
            "1315: [D loss: 0.676920, acc: 0.572266]  [A loss: 0.856595, acc: 0.246094]\n",
            "1316: [D loss: 0.694809, acc: 0.544922]  [A loss: 0.962300, acc: 0.156250]\n",
            "1317: [D loss: 0.674408, acc: 0.578125]  [A loss: 0.891339, acc: 0.207031]\n",
            "1318: [D loss: 0.685827, acc: 0.566406]  [A loss: 0.982203, acc: 0.125000]\n",
            "1319: [D loss: 0.673091, acc: 0.583984]  [A loss: 0.850861, acc: 0.265625]\n",
            "1320: [D loss: 0.694686, acc: 0.562500]  [A loss: 0.981602, acc: 0.117188]\n",
            "1321: [D loss: 0.698766, acc: 0.517578]  [A loss: 0.856685, acc: 0.296875]\n",
            "1322: [D loss: 0.669216, acc: 0.611328]  [A loss: 1.021046, acc: 0.082031]\n",
            "1323: [D loss: 0.680619, acc: 0.570312]  [A loss: 0.848393, acc: 0.246094]\n",
            "1324: [D loss: 0.703315, acc: 0.519531]  [A loss: 1.062133, acc: 0.078125]\n",
            "1325: [D loss: 0.665281, acc: 0.570312]  [A loss: 0.749291, acc: 0.437500]\n",
            "1326: [D loss: 0.715331, acc: 0.533203]  [A loss: 1.160756, acc: 0.058594]\n",
            "1327: [D loss: 0.666422, acc: 0.587891]  [A loss: 0.710543, acc: 0.472656]\n",
            "1328: [D loss: 0.729475, acc: 0.517578]  [A loss: 1.142466, acc: 0.031250]\n",
            "1329: [D loss: 0.665269, acc: 0.621094]  [A loss: 0.700366, acc: 0.527344]\n",
            "1330: [D loss: 0.701031, acc: 0.537109]  [A loss: 1.052402, acc: 0.097656]\n",
            "1331: [D loss: 0.681553, acc: 0.572266]  [A loss: 0.806043, acc: 0.324219]\n",
            "1332: [D loss: 0.719575, acc: 0.500000]  [A loss: 0.953404, acc: 0.179688]\n",
            "1333: [D loss: 0.668315, acc: 0.597656]  [A loss: 0.841713, acc: 0.273438]\n",
            "1334: [D loss: 0.680717, acc: 0.558594]  [A loss: 0.930749, acc: 0.156250]\n",
            "1335: [D loss: 0.673881, acc: 0.585938]  [A loss: 0.884751, acc: 0.222656]\n",
            "1336: [D loss: 0.677839, acc: 0.562500]  [A loss: 0.944181, acc: 0.148438]\n",
            "1337: [D loss: 0.682796, acc: 0.554688]  [A loss: 0.938114, acc: 0.136719]\n",
            "1338: [D loss: 0.663017, acc: 0.607422]  [A loss: 0.946833, acc: 0.160156]\n",
            "1339: [D loss: 0.660739, acc: 0.599609]  [A loss: 0.967165, acc: 0.167969]\n",
            "1340: [D loss: 0.665280, acc: 0.591797]  [A loss: 1.003268, acc: 0.128906]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1341: [D loss: 0.689025, acc: 0.576172]  [A loss: 1.007599, acc: 0.136719]\n",
            "1342: [D loss: 0.683281, acc: 0.591797]  [A loss: 0.921401, acc: 0.203125]\n",
            "1343: [D loss: 0.677730, acc: 0.552734]  [A loss: 0.926840, acc: 0.171875]\n",
            "1344: [D loss: 0.689535, acc: 0.568359]  [A loss: 0.950816, acc: 0.156250]\n",
            "1345: [D loss: 0.671125, acc: 0.578125]  [A loss: 0.829749, acc: 0.324219]\n",
            "1346: [D loss: 0.699866, acc: 0.546875]  [A loss: 1.208318, acc: 0.050781]\n",
            "1347: [D loss: 0.672563, acc: 0.621094]  [A loss: 0.624996, acc: 0.664062]\n",
            "1348: [D loss: 0.763524, acc: 0.519531]  [A loss: 1.193860, acc: 0.031250]\n",
            "1349: [D loss: 0.712822, acc: 0.513672]  [A loss: 0.684479, acc: 0.535156]\n",
            "1350: [D loss: 0.721188, acc: 0.523438]  [A loss: 1.091591, acc: 0.074219]\n",
            "1351: [D loss: 0.682532, acc: 0.560547]  [A loss: 0.787020, acc: 0.382812]\n",
            "1352: [D loss: 0.688893, acc: 0.562500]  [A loss: 0.902292, acc: 0.191406]\n",
            "1353: [D loss: 0.677795, acc: 0.556641]  [A loss: 0.834679, acc: 0.285156]\n",
            "1354: [D loss: 0.674555, acc: 0.564453]  [A loss: 0.945675, acc: 0.167969]\n",
            "1355: [D loss: 0.670596, acc: 0.574219]  [A loss: 0.855363, acc: 0.277344]\n",
            "1356: [D loss: 0.703416, acc: 0.511719]  [A loss: 0.984475, acc: 0.128906]\n",
            "1357: [D loss: 0.683615, acc: 0.542969]  [A loss: 0.881774, acc: 0.218750]\n",
            "1358: [D loss: 0.712029, acc: 0.550781]  [A loss: 0.970491, acc: 0.167969]\n",
            "1359: [D loss: 0.685505, acc: 0.548828]  [A loss: 0.910088, acc: 0.226562]\n",
            "1360: [D loss: 0.669091, acc: 0.587891]  [A loss: 0.885961, acc: 0.242188]\n",
            "1361: [D loss: 0.669604, acc: 0.580078]  [A loss: 0.886444, acc: 0.207031]\n",
            "1362: [D loss: 0.701485, acc: 0.505859]  [A loss: 0.949098, acc: 0.148438]\n",
            "1363: [D loss: 0.666477, acc: 0.589844]  [A loss: 0.952636, acc: 0.144531]\n",
            "1364: [D loss: 0.675561, acc: 0.601562]  [A loss: 0.925086, acc: 0.179688]\n",
            "1365: [D loss: 0.673026, acc: 0.582031]  [A loss: 0.931006, acc: 0.164062]\n",
            "1366: [D loss: 0.674186, acc: 0.583984]  [A loss: 0.962907, acc: 0.167969]\n",
            "1367: [D loss: 0.688811, acc: 0.548828]  [A loss: 0.890509, acc: 0.230469]\n",
            "1368: [D loss: 0.687884, acc: 0.544922]  [A loss: 0.973683, acc: 0.125000]\n",
            "1369: [D loss: 0.674162, acc: 0.599609]  [A loss: 0.926327, acc: 0.183594]\n",
            "1370: [D loss: 0.694227, acc: 0.535156]  [A loss: 1.009589, acc: 0.117188]\n",
            "1371: [D loss: 0.670406, acc: 0.587891]  [A loss: 0.775440, acc: 0.394531]\n",
            "1372: [D loss: 0.699208, acc: 0.558594]  [A loss: 1.281147, acc: 0.027344]\n",
            "1373: [D loss: 0.686649, acc: 0.556641]  [A loss: 0.634623, acc: 0.644531]\n",
            "1374: [D loss: 0.777079, acc: 0.523438]  [A loss: 1.284924, acc: 0.023438]\n",
            "1375: [D loss: 0.713285, acc: 0.480469]  [A loss: 0.711781, acc: 0.539062]\n",
            "1376: [D loss: 0.727005, acc: 0.513672]  [A loss: 1.138194, acc: 0.023438]\n",
            "1377: [D loss: 0.659525, acc: 0.603516]  [A loss: 0.797793, acc: 0.332031]\n",
            "1378: [D loss: 0.717485, acc: 0.525391]  [A loss: 1.028932, acc: 0.101562]\n",
            "1379: [D loss: 0.683668, acc: 0.542969]  [A loss: 0.757569, acc: 0.449219]\n",
            "1380: [D loss: 0.678090, acc: 0.562500]  [A loss: 0.967285, acc: 0.167969]\n",
            "1381: [D loss: 0.674663, acc: 0.587891]  [A loss: 0.806275, acc: 0.335938]\n",
            "1382: [D loss: 0.700319, acc: 0.552734]  [A loss: 1.006836, acc: 0.125000]\n",
            "1383: [D loss: 0.681214, acc: 0.562500]  [A loss: 0.853256, acc: 0.296875]\n",
            "1384: [D loss: 0.687158, acc: 0.554688]  [A loss: 0.950080, acc: 0.128906]\n",
            "1385: [D loss: 0.679647, acc: 0.574219]  [A loss: 0.796697, acc: 0.339844]\n",
            "1386: [D loss: 0.706982, acc: 0.541016]  [A loss: 0.969471, acc: 0.160156]\n",
            "1387: [D loss: 0.686487, acc: 0.552734]  [A loss: 0.729053, acc: 0.484375]\n",
            "1388: [D loss: 0.695310, acc: 0.548828]  [A loss: 1.131240, acc: 0.039062]\n",
            "1389: [D loss: 0.685386, acc: 0.566406]  [A loss: 0.719266, acc: 0.484375]\n",
            "1390: [D loss: 0.692965, acc: 0.539062]  [A loss: 1.122457, acc: 0.042969]\n",
            "1391: [D loss: 0.706741, acc: 0.533203]  [A loss: 0.742489, acc: 0.429688]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1392: [D loss: 0.726377, acc: 0.525391]  [A loss: 1.096967, acc: 0.050781]\n",
            "1393: [D loss: 0.690043, acc: 0.542969]  [A loss: 0.767505, acc: 0.386719]\n",
            "1394: [D loss: 0.697690, acc: 0.527344]  [A loss: 0.989573, acc: 0.128906]\n",
            "1395: [D loss: 0.677895, acc: 0.568359]  [A loss: 0.833471, acc: 0.304688]\n",
            "1396: [D loss: 0.695307, acc: 0.531250]  [A loss: 0.967221, acc: 0.121094]\n",
            "1397: [D loss: 0.685918, acc: 0.574219]  [A loss: 0.770050, acc: 0.367188]\n",
            "1398: [D loss: 0.694100, acc: 0.552734]  [A loss: 0.993399, acc: 0.128906]\n",
            "1399: [D loss: 0.677620, acc: 0.582031]  [A loss: 0.884834, acc: 0.230469]\n",
            "1400: [D loss: 0.698613, acc: 0.537109]  [A loss: 1.001343, acc: 0.109375]\n",
            "1401: [D loss: 0.670901, acc: 0.564453]  [A loss: 0.815711, acc: 0.347656]\n",
            "1402: [D loss: 0.713276, acc: 0.533203]  [A loss: 1.087363, acc: 0.074219]\n",
            "1403: [D loss: 0.693704, acc: 0.546875]  [A loss: 0.711497, acc: 0.468750]\n",
            "1404: [D loss: 0.717326, acc: 0.533203]  [A loss: 1.173069, acc: 0.035156]\n",
            "1405: [D loss: 0.678139, acc: 0.556641]  [A loss: 0.665108, acc: 0.582031]\n",
            "1406: [D loss: 0.725033, acc: 0.511719]  [A loss: 1.047556, acc: 0.074219]\n",
            "1407: [D loss: 0.677483, acc: 0.585938]  [A loss: 0.749794, acc: 0.437500]\n",
            "1408: [D loss: 0.693002, acc: 0.568359]  [A loss: 0.994211, acc: 0.089844]\n",
            "1409: [D loss: 0.682275, acc: 0.566406]  [A loss: 0.801804, acc: 0.335938]\n",
            "1410: [D loss: 0.691875, acc: 0.558594]  [A loss: 0.952159, acc: 0.152344]\n",
            "1411: [D loss: 0.674661, acc: 0.583984]  [A loss: 0.804180, acc: 0.316406]\n",
            "1412: [D loss: 0.682544, acc: 0.564453]  [A loss: 0.954704, acc: 0.140625]\n",
            "1413: [D loss: 0.694493, acc: 0.550781]  [A loss: 0.934919, acc: 0.164062]\n",
            "1414: [D loss: 0.697717, acc: 0.525391]  [A loss: 0.895873, acc: 0.250000]\n",
            "1415: [D loss: 0.677354, acc: 0.570312]  [A loss: 0.864430, acc: 0.238281]\n",
            "1416: [D loss: 0.690551, acc: 0.544922]  [A loss: 1.054124, acc: 0.093750]\n",
            "1417: [D loss: 0.691073, acc: 0.552734]  [A loss: 0.841840, acc: 0.285156]\n",
            "1418: [D loss: 0.699261, acc: 0.541016]  [A loss: 1.056361, acc: 0.097656]\n",
            "1419: [D loss: 0.664810, acc: 0.595703]  [A loss: 0.765171, acc: 0.406250]\n",
            "1420: [D loss: 0.698000, acc: 0.562500]  [A loss: 1.078725, acc: 0.089844]\n",
            "1421: [D loss: 0.674019, acc: 0.568359]  [A loss: 0.772181, acc: 0.367188]\n",
            "1422: [D loss: 0.691302, acc: 0.568359]  [A loss: 1.096408, acc: 0.074219]\n",
            "1423: [D loss: 0.681662, acc: 0.578125]  [A loss: 0.703804, acc: 0.503906]\n",
            "1424: [D loss: 0.698233, acc: 0.544922]  [A loss: 1.047441, acc: 0.074219]\n",
            "1425: [D loss: 0.665823, acc: 0.599609]  [A loss: 0.809216, acc: 0.316406]\n",
            "1426: [D loss: 0.695625, acc: 0.566406]  [A loss: 1.114005, acc: 0.066406]\n",
            "1427: [D loss: 0.675285, acc: 0.578125]  [A loss: 0.740690, acc: 0.421875]\n",
            "1428: [D loss: 0.706570, acc: 0.521484]  [A loss: 1.079612, acc: 0.058594]\n",
            "1429: [D loss: 0.672886, acc: 0.564453]  [A loss: 0.828971, acc: 0.273438]\n",
            "1430: [D loss: 0.706091, acc: 0.554688]  [A loss: 1.013096, acc: 0.109375]\n",
            "1431: [D loss: 0.684305, acc: 0.560547]  [A loss: 0.831691, acc: 0.292969]\n",
            "1432: [D loss: 0.667059, acc: 0.593750]  [A loss: 0.885440, acc: 0.234375]\n",
            "1433: [D loss: 0.668148, acc: 0.570312]  [A loss: 0.921433, acc: 0.167969]\n",
            "1434: [D loss: 0.693784, acc: 0.550781]  [A loss: 0.928922, acc: 0.160156]\n",
            "1435: [D loss: 0.679071, acc: 0.574219]  [A loss: 0.922054, acc: 0.152344]\n",
            "1436: [D loss: 0.686748, acc: 0.583984]  [A loss: 0.940591, acc: 0.156250]\n",
            "1437: [D loss: 0.694635, acc: 0.548828]  [A loss: 0.999735, acc: 0.117188]\n",
            "1438: [D loss: 0.682895, acc: 0.583984]  [A loss: 0.793070, acc: 0.347656]\n",
            "1439: [D loss: 0.693263, acc: 0.535156]  [A loss: 1.133556, acc: 0.050781]\n",
            "1440: [D loss: 0.671419, acc: 0.578125]  [A loss: 0.706532, acc: 0.484375]\n",
            "1441: [D loss: 0.729748, acc: 0.521484]  [A loss: 1.239217, acc: 0.054688]\n",
            "1442: [D loss: 0.672497, acc: 0.605469]  [A loss: 0.680578, acc: 0.554688]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1443: [D loss: 0.746023, acc: 0.525391]  [A loss: 1.080660, acc: 0.078125]\n",
            "1444: [D loss: 0.688964, acc: 0.544922]  [A loss: 0.782042, acc: 0.359375]\n",
            "1445: [D loss: 0.679629, acc: 0.556641]  [A loss: 0.911237, acc: 0.179688]\n",
            "1446: [D loss: 0.693719, acc: 0.535156]  [A loss: 0.901170, acc: 0.187500]\n",
            "1447: [D loss: 0.700715, acc: 0.562500]  [A loss: 0.889549, acc: 0.234375]\n",
            "1448: [D loss: 0.688156, acc: 0.554688]  [A loss: 1.005869, acc: 0.125000]\n",
            "1449: [D loss: 0.675333, acc: 0.607422]  [A loss: 0.770917, acc: 0.375000]\n",
            "1450: [D loss: 0.678854, acc: 0.572266]  [A loss: 1.036319, acc: 0.101562]\n",
            "1451: [D loss: 0.672047, acc: 0.574219]  [A loss: 0.847392, acc: 0.230469]\n",
            "1452: [D loss: 0.697476, acc: 0.529297]  [A loss: 0.952402, acc: 0.160156]\n",
            "1453: [D loss: 0.674321, acc: 0.585938]  [A loss: 0.851777, acc: 0.285156]\n",
            "1454: [D loss: 0.685978, acc: 0.558594]  [A loss: 0.991315, acc: 0.117188]\n",
            "1455: [D loss: 0.679256, acc: 0.568359]  [A loss: 0.800511, acc: 0.335938]\n",
            "1456: [D loss: 0.702705, acc: 0.562500]  [A loss: 1.110653, acc: 0.039062]\n",
            "1457: [D loss: 0.680239, acc: 0.560547]  [A loss: 0.717723, acc: 0.515625]\n",
            "1458: [D loss: 0.725242, acc: 0.511719]  [A loss: 1.095952, acc: 0.074219]\n",
            "1459: [D loss: 0.678630, acc: 0.574219]  [A loss: 0.709523, acc: 0.500000]\n",
            "1460: [D loss: 0.703952, acc: 0.535156]  [A loss: 1.161797, acc: 0.042969]\n",
            "1461: [D loss: 0.695070, acc: 0.546875]  [A loss: 0.704993, acc: 0.574219]\n",
            "1462: [D loss: 0.706187, acc: 0.535156]  [A loss: 1.001647, acc: 0.132812]\n",
            "1463: [D loss: 0.686860, acc: 0.572266]  [A loss: 0.772980, acc: 0.363281]\n",
            "1464: [D loss: 0.697927, acc: 0.552734]  [A loss: 1.016891, acc: 0.109375]\n",
            "1465: [D loss: 0.673234, acc: 0.580078]  [A loss: 0.800499, acc: 0.324219]\n",
            "1466: [D loss: 0.690190, acc: 0.564453]  [A loss: 0.994077, acc: 0.128906]\n",
            "1467: [D loss: 0.672584, acc: 0.611328]  [A loss: 0.758156, acc: 0.375000]\n",
            "1468: [D loss: 0.697917, acc: 0.550781]  [A loss: 1.025897, acc: 0.113281]\n",
            "1469: [D loss: 0.685298, acc: 0.580078]  [A loss: 0.777520, acc: 0.398438]\n",
            "1470: [D loss: 0.709428, acc: 0.542969]  [A loss: 1.039723, acc: 0.078125]\n",
            "1471: [D loss: 0.674432, acc: 0.597656]  [A loss: 0.775681, acc: 0.367188]\n",
            "1472: [D loss: 0.693072, acc: 0.566406]  [A loss: 1.056377, acc: 0.097656]\n",
            "1473: [D loss: 0.683026, acc: 0.556641]  [A loss: 0.745909, acc: 0.449219]\n",
            "1474: [D loss: 0.694144, acc: 0.542969]  [A loss: 1.118533, acc: 0.046875]\n",
            "1475: [D loss: 0.689070, acc: 0.564453]  [A loss: 0.752268, acc: 0.390625]\n",
            "1476: [D loss: 0.698201, acc: 0.546875]  [A loss: 1.100755, acc: 0.082031]\n",
            "1477: [D loss: 0.667080, acc: 0.582031]  [A loss: 0.763074, acc: 0.390625]\n",
            "1478: [D loss: 0.743424, acc: 0.498047]  [A loss: 1.029049, acc: 0.085938]\n",
            "1479: [D loss: 0.696320, acc: 0.527344]  [A loss: 0.814114, acc: 0.292969]\n",
            "1480: [D loss: 0.695493, acc: 0.548828]  [A loss: 1.001399, acc: 0.105469]\n",
            "1481: [D loss: 0.668884, acc: 0.589844]  [A loss: 0.802086, acc: 0.347656]\n",
            "1482: [D loss: 0.697892, acc: 0.533203]  [A loss: 0.972817, acc: 0.140625]\n",
            "1483: [D loss: 0.683458, acc: 0.576172]  [A loss: 0.804163, acc: 0.320312]\n",
            "1484: [D loss: 0.693714, acc: 0.542969]  [A loss: 1.007024, acc: 0.109375]\n",
            "1485: [D loss: 0.704554, acc: 0.539062]  [A loss: 0.797031, acc: 0.343750]\n",
            "1486: [D loss: 0.685896, acc: 0.572266]  [A loss: 0.952974, acc: 0.128906]\n",
            "1487: [D loss: 0.677562, acc: 0.572266]  [A loss: 0.871096, acc: 0.218750]\n",
            "1488: [D loss: 0.697973, acc: 0.539062]  [A loss: 0.974934, acc: 0.097656]\n",
            "1489: [D loss: 0.664379, acc: 0.597656]  [A loss: 0.825588, acc: 0.312500]\n",
            "1490: [D loss: 0.693930, acc: 0.556641]  [A loss: 1.010997, acc: 0.128906]\n",
            "1491: [D loss: 0.680571, acc: 0.558594]  [A loss: 0.782137, acc: 0.371094]\n",
            "1492: [D loss: 0.699733, acc: 0.525391]  [A loss: 1.190691, acc: 0.019531]\n",
            "1493: [D loss: 0.671920, acc: 0.583984]  [A loss: 0.689758, acc: 0.527344]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1494: [D loss: 0.718288, acc: 0.523438]  [A loss: 1.111270, acc: 0.046875]\n",
            "1495: [D loss: 0.686850, acc: 0.544922]  [A loss: 0.705814, acc: 0.523438]\n",
            "1496: [D loss: 0.711164, acc: 0.542969]  [A loss: 1.080809, acc: 0.039062]\n",
            "1497: [D loss: 0.687126, acc: 0.544922]  [A loss: 0.778187, acc: 0.347656]\n",
            "1498: [D loss: 0.680128, acc: 0.570312]  [A loss: 0.998513, acc: 0.121094]\n",
            "1499: [D loss: 0.683773, acc: 0.566406]  [A loss: 0.780245, acc: 0.375000]\n",
            "1500: [D loss: 0.684408, acc: 0.541016]  [A loss: 0.967239, acc: 0.125000]\n",
            "1501: [D loss: 0.682743, acc: 0.548828]  [A loss: 0.803941, acc: 0.296875]\n",
            "1502: [D loss: 0.692002, acc: 0.546875]  [A loss: 1.049575, acc: 0.074219]\n",
            "1503: [D loss: 0.672379, acc: 0.593750]  [A loss: 0.791120, acc: 0.351562]\n",
            "1504: [D loss: 0.687288, acc: 0.572266]  [A loss: 1.045952, acc: 0.101562]\n",
            "1505: [D loss: 0.676333, acc: 0.583984]  [A loss: 0.775157, acc: 0.386719]\n",
            "1506: [D loss: 0.698487, acc: 0.552734]  [A loss: 1.016235, acc: 0.089844]\n",
            "1507: [D loss: 0.686659, acc: 0.556641]  [A loss: 0.764063, acc: 0.421875]\n",
            "1508: [D loss: 0.691164, acc: 0.564453]  [A loss: 1.009383, acc: 0.113281]\n",
            "1509: [D loss: 0.676251, acc: 0.558594]  [A loss: 0.853143, acc: 0.250000]\n",
            "1510: [D loss: 0.698734, acc: 0.517578]  [A loss: 0.970992, acc: 0.128906]\n",
            "1511: [D loss: 0.677317, acc: 0.574219]  [A loss: 0.767728, acc: 0.378906]\n",
            "1512: [D loss: 0.711467, acc: 0.535156]  [A loss: 1.107998, acc: 0.062500]\n",
            "1513: [D loss: 0.687918, acc: 0.558594]  [A loss: 0.695488, acc: 0.503906]\n",
            "1514: [D loss: 0.706071, acc: 0.535156]  [A loss: 1.131395, acc: 0.050781]\n",
            "1515: [D loss: 0.683588, acc: 0.570312]  [A loss: 0.708022, acc: 0.515625]\n",
            "1516: [D loss: 0.715080, acc: 0.519531]  [A loss: 1.087716, acc: 0.046875]\n",
            "1517: [D loss: 0.674160, acc: 0.546875]  [A loss: 0.729963, acc: 0.460938]\n",
            "1518: [D loss: 0.714854, acc: 0.517578]  [A loss: 1.068965, acc: 0.085938]\n",
            "1519: [D loss: 0.674674, acc: 0.568359]  [A loss: 0.782676, acc: 0.335938]\n",
            "1520: [D loss: 0.704380, acc: 0.558594]  [A loss: 0.971605, acc: 0.132812]\n",
            "1521: [D loss: 0.686015, acc: 0.556641]  [A loss: 0.791601, acc: 0.343750]\n",
            "1522: [D loss: 0.698411, acc: 0.541016]  [A loss: 0.977749, acc: 0.125000]\n",
            "1523: [D loss: 0.685945, acc: 0.564453]  [A loss: 0.797765, acc: 0.343750]\n",
            "1524: [D loss: 0.697202, acc: 0.525391]  [A loss: 0.917191, acc: 0.183594]\n",
            "1525: [D loss: 0.678217, acc: 0.556641]  [A loss: 0.813774, acc: 0.304688]\n",
            "1526: [D loss: 0.696002, acc: 0.537109]  [A loss: 0.954482, acc: 0.136719]\n",
            "1527: [D loss: 0.670898, acc: 0.578125]  [A loss: 0.794172, acc: 0.332031]\n",
            "1528: [D loss: 0.695644, acc: 0.552734]  [A loss: 1.004488, acc: 0.113281]\n",
            "1529: [D loss: 0.679131, acc: 0.562500]  [A loss: 0.850693, acc: 0.250000]\n",
            "1530: [D loss: 0.697180, acc: 0.533203]  [A loss: 1.005373, acc: 0.101562]\n",
            "1531: [D loss: 0.694354, acc: 0.529297]  [A loss: 0.839631, acc: 0.246094]\n",
            "1532: [D loss: 0.671687, acc: 0.572266]  [A loss: 0.914494, acc: 0.203125]\n",
            "1533: [D loss: 0.672404, acc: 0.583984]  [A loss: 0.948783, acc: 0.140625]\n",
            "1534: [D loss: 0.713122, acc: 0.500000]  [A loss: 0.987195, acc: 0.164062]\n",
            "1535: [D loss: 0.684492, acc: 0.562500]  [A loss: 0.979812, acc: 0.152344]\n",
            "1536: [D loss: 0.683503, acc: 0.570312]  [A loss: 0.840811, acc: 0.261719]\n",
            "1537: [D loss: 0.702822, acc: 0.531250]  [A loss: 1.058128, acc: 0.085938]\n",
            "1538: [D loss: 0.690665, acc: 0.558594]  [A loss: 0.830294, acc: 0.281250]\n",
            "1539: [D loss: 0.696175, acc: 0.550781]  [A loss: 1.147808, acc: 0.054688]\n",
            "1540: [D loss: 0.685585, acc: 0.568359]  [A loss: 0.690706, acc: 0.539062]\n",
            "1541: [D loss: 0.715999, acc: 0.519531]  [A loss: 1.083476, acc: 0.070312]\n",
            "1542: [D loss: 0.694734, acc: 0.531250]  [A loss: 0.699061, acc: 0.488281]\n",
            "1543: [D loss: 0.711910, acc: 0.515625]  [A loss: 1.024757, acc: 0.082031]\n",
            "1544: [D loss: 0.686391, acc: 0.566406]  [A loss: 0.789311, acc: 0.355469]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1545: [D loss: 0.689655, acc: 0.556641]  [A loss: 0.945185, acc: 0.148438]\n",
            "1546: [D loss: 0.681704, acc: 0.593750]  [A loss: 0.827400, acc: 0.246094]\n",
            "1547: [D loss: 0.682125, acc: 0.560547]  [A loss: 0.994632, acc: 0.093750]\n",
            "1548: [D loss: 0.692701, acc: 0.541016]  [A loss: 0.845540, acc: 0.242188]\n",
            "1549: [D loss: 0.708963, acc: 0.521484]  [A loss: 1.066096, acc: 0.101562]\n",
            "1550: [D loss: 0.718706, acc: 0.509766]  [A loss: 0.802734, acc: 0.312500]\n",
            "1551: [D loss: 0.685178, acc: 0.556641]  [A loss: 0.995689, acc: 0.101562]\n",
            "1552: [D loss: 0.673035, acc: 0.585938]  [A loss: 0.738618, acc: 0.437500]\n",
            "1553: [D loss: 0.708744, acc: 0.525391]  [A loss: 1.028781, acc: 0.074219]\n",
            "1554: [D loss: 0.687546, acc: 0.562500]  [A loss: 0.727721, acc: 0.460938]\n",
            "1555: [D loss: 0.704855, acc: 0.527344]  [A loss: 1.055903, acc: 0.085938]\n",
            "1556: [D loss: 0.692210, acc: 0.552734]  [A loss: 0.755430, acc: 0.406250]\n",
            "1557: [D loss: 0.708085, acc: 0.507812]  [A loss: 1.044305, acc: 0.050781]\n",
            "1558: [D loss: 0.685746, acc: 0.544922]  [A loss: 0.698698, acc: 0.539062]\n",
            "1559: [D loss: 0.698877, acc: 0.529297]  [A loss: 0.977603, acc: 0.140625]\n",
            "1560: [D loss: 0.678861, acc: 0.566406]  [A loss: 0.735404, acc: 0.421875]\n",
            "1561: [D loss: 0.685901, acc: 0.580078]  [A loss: 1.002583, acc: 0.097656]\n",
            "1562: [D loss: 0.691543, acc: 0.529297]  [A loss: 0.805619, acc: 0.328125]\n",
            "1563: [D loss: 0.682563, acc: 0.560547]  [A loss: 0.860507, acc: 0.230469]\n",
            "1564: [D loss: 0.686471, acc: 0.541016]  [A loss: 0.914984, acc: 0.164062]\n",
            "1565: [D loss: 0.671014, acc: 0.576172]  [A loss: 0.934700, acc: 0.148438]\n",
            "1566: [D loss: 0.674564, acc: 0.564453]  [A loss: 0.827754, acc: 0.300781]\n",
            "1567: [D loss: 0.707182, acc: 0.527344]  [A loss: 1.020878, acc: 0.093750]\n",
            "1568: [D loss: 0.670594, acc: 0.599609]  [A loss: 0.758174, acc: 0.398438]\n",
            "1569: [D loss: 0.691980, acc: 0.556641]  [A loss: 1.062083, acc: 0.062500]\n",
            "1570: [D loss: 0.676211, acc: 0.576172]  [A loss: 0.753023, acc: 0.421875]\n",
            "1571: [D loss: 0.709156, acc: 0.537109]  [A loss: 1.026378, acc: 0.089844]\n",
            "1572: [D loss: 0.684549, acc: 0.572266]  [A loss: 0.785630, acc: 0.351562]\n",
            "1573: [D loss: 0.686363, acc: 0.546875]  [A loss: 1.042558, acc: 0.078125]\n",
            "1574: [D loss: 0.685130, acc: 0.544922]  [A loss: 0.767714, acc: 0.355469]\n",
            "1575: [D loss: 0.718655, acc: 0.511719]  [A loss: 1.056123, acc: 0.078125]\n",
            "1576: [D loss: 0.676586, acc: 0.583984]  [A loss: 0.675510, acc: 0.531250]\n",
            "1577: [D loss: 0.708953, acc: 0.533203]  [A loss: 1.095235, acc: 0.035156]\n",
            "1578: [D loss: 0.697310, acc: 0.552734]  [A loss: 0.719379, acc: 0.472656]\n",
            "1579: [D loss: 0.697030, acc: 0.548828]  [A loss: 1.030422, acc: 0.093750]\n",
            "1580: [D loss: 0.686774, acc: 0.550781]  [A loss: 0.766753, acc: 0.355469]\n",
            "1581: [D loss: 0.705330, acc: 0.537109]  [A loss: 0.997684, acc: 0.121094]\n",
            "1582: [D loss: 0.690922, acc: 0.554688]  [A loss: 0.783004, acc: 0.359375]\n",
            "1583: [D loss: 0.695899, acc: 0.539062]  [A loss: 0.947501, acc: 0.128906]\n",
            "1584: [D loss: 0.678730, acc: 0.589844]  [A loss: 0.951498, acc: 0.132812]\n",
            "1585: [D loss: 0.683062, acc: 0.583984]  [A loss: 0.937547, acc: 0.144531]\n",
            "1586: [D loss: 0.689223, acc: 0.548828]  [A loss: 0.823026, acc: 0.332031]\n",
            "1587: [D loss: 0.682507, acc: 0.566406]  [A loss: 0.977552, acc: 0.125000]\n",
            "1588: [D loss: 0.676769, acc: 0.613281]  [A loss: 0.804853, acc: 0.320312]\n",
            "1589: [D loss: 0.692282, acc: 0.570312]  [A loss: 1.005625, acc: 0.089844]\n",
            "1590: [D loss: 0.676625, acc: 0.583984]  [A loss: 0.754185, acc: 0.429688]\n",
            "1591: [D loss: 0.700799, acc: 0.564453]  [A loss: 1.107877, acc: 0.039062]\n",
            "1592: [D loss: 0.698802, acc: 0.539062]  [A loss: 0.682665, acc: 0.550781]\n",
            "1593: [D loss: 0.723116, acc: 0.517578]  [A loss: 1.055878, acc: 0.089844]\n",
            "1594: [D loss: 0.686691, acc: 0.572266]  [A loss: 0.735097, acc: 0.457031]\n",
            "1595: [D loss: 0.695756, acc: 0.537109]  [A loss: 1.053028, acc: 0.070312]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1596: [D loss: 0.691233, acc: 0.539062]  [A loss: 0.761189, acc: 0.371094]\n",
            "1597: [D loss: 0.697909, acc: 0.552734]  [A loss: 1.002836, acc: 0.089844]\n",
            "1598: [D loss: 0.693865, acc: 0.556641]  [A loss: 0.759152, acc: 0.402344]\n",
            "1599: [D loss: 0.696618, acc: 0.531250]  [A loss: 0.967015, acc: 0.121094]\n",
            "1600: [D loss: 0.694282, acc: 0.527344]  [A loss: 0.792106, acc: 0.296875]\n",
            "1601: [D loss: 0.689669, acc: 0.570312]  [A loss: 0.954228, acc: 0.140625]\n",
            "1602: [D loss: 0.683263, acc: 0.558594]  [A loss: 0.840547, acc: 0.257812]\n",
            "1603: [D loss: 0.694985, acc: 0.541016]  [A loss: 0.995170, acc: 0.097656]\n",
            "1604: [D loss: 0.680160, acc: 0.576172]  [A loss: 0.790400, acc: 0.339844]\n",
            "1605: [D loss: 0.709944, acc: 0.529297]  [A loss: 0.971286, acc: 0.125000]\n",
            "1606: [D loss: 0.676319, acc: 0.583984]  [A loss: 0.850674, acc: 0.269531]\n",
            "1607: [D loss: 0.690826, acc: 0.548828]  [A loss: 0.973182, acc: 0.140625]\n",
            "1608: [D loss: 0.662266, acc: 0.603516]  [A loss: 0.770779, acc: 0.378906]\n",
            "1609: [D loss: 0.694967, acc: 0.531250]  [A loss: 1.017115, acc: 0.097656]\n",
            "1610: [D loss: 0.671063, acc: 0.589844]  [A loss: 0.783593, acc: 0.371094]\n",
            "1611: [D loss: 0.695502, acc: 0.533203]  [A loss: 1.114017, acc: 0.085938]\n",
            "1612: [D loss: 0.689828, acc: 0.537109]  [A loss: 0.691898, acc: 0.542969]\n",
            "1613: [D loss: 0.694919, acc: 0.566406]  [A loss: 1.094876, acc: 0.042969]\n",
            "1614: [D loss: 0.681469, acc: 0.562500]  [A loss: 0.714599, acc: 0.503906]\n",
            "1615: [D loss: 0.691215, acc: 0.556641]  [A loss: 1.006644, acc: 0.085938]\n",
            "1616: [D loss: 0.681710, acc: 0.568359]  [A loss: 0.693313, acc: 0.523438]\n",
            "1617: [D loss: 0.725098, acc: 0.523438]  [A loss: 1.028559, acc: 0.085938]\n",
            "1618: [D loss: 0.679277, acc: 0.578125]  [A loss: 0.731938, acc: 0.441406]\n",
            "1619: [D loss: 0.716916, acc: 0.521484]  [A loss: 1.009930, acc: 0.101562]\n",
            "1620: [D loss: 0.689200, acc: 0.552734]  [A loss: 0.721264, acc: 0.476562]\n",
            "1621: [D loss: 0.706199, acc: 0.525391]  [A loss: 1.039871, acc: 0.085938]\n",
            "1622: [D loss: 0.688436, acc: 0.562500]  [A loss: 0.744713, acc: 0.371094]\n",
            "1623: [D loss: 0.679803, acc: 0.574219]  [A loss: 0.907783, acc: 0.160156]\n",
            "1624: [D loss: 0.694502, acc: 0.548828]  [A loss: 0.815851, acc: 0.300781]\n",
            "1625: [D loss: 0.682479, acc: 0.566406]  [A loss: 0.925358, acc: 0.140625]\n",
            "1626: [D loss: 0.683362, acc: 0.566406]  [A loss: 0.881060, acc: 0.199219]\n",
            "1627: [D loss: 0.700131, acc: 0.523438]  [A loss: 0.868236, acc: 0.230469]\n",
            "1628: [D loss: 0.693954, acc: 0.533203]  [A loss: 0.881992, acc: 0.179688]\n",
            "1629: [D loss: 0.691146, acc: 0.570312]  [A loss: 0.933904, acc: 0.171875]\n",
            "1630: [D loss: 0.684017, acc: 0.583984]  [A loss: 0.805541, acc: 0.300781]\n",
            "1631: [D loss: 0.676743, acc: 0.580078]  [A loss: 0.959402, acc: 0.109375]\n",
            "1632: [D loss: 0.682747, acc: 0.544922]  [A loss: 0.862378, acc: 0.203125]\n",
            "1633: [D loss: 0.676388, acc: 0.578125]  [A loss: 0.951441, acc: 0.167969]\n",
            "1634: [D loss: 0.678397, acc: 0.548828]  [A loss: 0.839730, acc: 0.296875]\n",
            "1635: [D loss: 0.698859, acc: 0.542969]  [A loss: 0.966872, acc: 0.132812]\n",
            "1636: [D loss: 0.674833, acc: 0.576172]  [A loss: 0.800464, acc: 0.324219]\n",
            "1637: [D loss: 0.690740, acc: 0.558594]  [A loss: 1.053672, acc: 0.082031]\n",
            "1638: [D loss: 0.697185, acc: 0.556641]  [A loss: 0.745291, acc: 0.414062]\n",
            "1639: [D loss: 0.711317, acc: 0.531250]  [A loss: 1.050636, acc: 0.070312]\n",
            "1640: [D loss: 0.690965, acc: 0.535156]  [A loss: 0.711177, acc: 0.472656]\n",
            "1641: [D loss: 0.709486, acc: 0.527344]  [A loss: 0.997961, acc: 0.097656]\n",
            "1642: [D loss: 0.693521, acc: 0.562500]  [A loss: 0.776447, acc: 0.351562]\n",
            "1643: [D loss: 0.685579, acc: 0.570312]  [A loss: 0.958398, acc: 0.117188]\n",
            "1644: [D loss: 0.683254, acc: 0.574219]  [A loss: 0.775348, acc: 0.371094]\n",
            "1645: [D loss: 0.707429, acc: 0.531250]  [A loss: 1.017602, acc: 0.101562]\n",
            "1646: [D loss: 0.679805, acc: 0.541016]  [A loss: 0.703557, acc: 0.492188]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1647: [D loss: 0.720439, acc: 0.529297]  [A loss: 1.071763, acc: 0.054688]\n",
            "1648: [D loss: 0.687547, acc: 0.552734]  [A loss: 0.697977, acc: 0.492188]\n",
            "1649: [D loss: 0.702262, acc: 0.535156]  [A loss: 1.022374, acc: 0.085938]\n",
            "1650: [D loss: 0.689993, acc: 0.552734]  [A loss: 0.735752, acc: 0.441406]\n",
            "1651: [D loss: 0.704561, acc: 0.529297]  [A loss: 0.948003, acc: 0.136719]\n",
            "1652: [D loss: 0.680022, acc: 0.562500]  [A loss: 0.783274, acc: 0.335938]\n",
            "1653: [D loss: 0.693712, acc: 0.552734]  [A loss: 0.960281, acc: 0.128906]\n",
            "1654: [D loss: 0.688284, acc: 0.541016]  [A loss: 0.821296, acc: 0.281250]\n",
            "1655: [D loss: 0.692932, acc: 0.554688]  [A loss: 0.973677, acc: 0.105469]\n",
            "1656: [D loss: 0.688622, acc: 0.562500]  [A loss: 0.778007, acc: 0.332031]\n",
            "1657: [D loss: 0.699219, acc: 0.570312]  [A loss: 0.966808, acc: 0.105469]\n",
            "1658: [D loss: 0.688465, acc: 0.544922]  [A loss: 0.752622, acc: 0.433594]\n",
            "1659: [D loss: 0.711126, acc: 0.509766]  [A loss: 1.027122, acc: 0.058594]\n",
            "1660: [D loss: 0.681443, acc: 0.548828]  [A loss: 0.733612, acc: 0.437500]\n",
            "1661: [D loss: 0.699060, acc: 0.541016]  [A loss: 0.973570, acc: 0.113281]\n",
            "1662: [D loss: 0.684791, acc: 0.566406]  [A loss: 0.779346, acc: 0.355469]\n",
            "1663: [D loss: 0.703651, acc: 0.541016]  [A loss: 1.001127, acc: 0.085938]\n",
            "1664: [D loss: 0.677360, acc: 0.570312]  [A loss: 0.780843, acc: 0.355469]\n",
            "1665: [D loss: 0.693824, acc: 0.556641]  [A loss: 0.960855, acc: 0.148438]\n",
            "1666: [D loss: 0.695124, acc: 0.539062]  [A loss: 0.782538, acc: 0.335938]\n",
            "1667: [D loss: 0.688266, acc: 0.552734]  [A loss: 1.017992, acc: 0.105469]\n",
            "1668: [D loss: 0.672795, acc: 0.576172]  [A loss: 0.742959, acc: 0.433594]\n",
            "1669: [D loss: 0.705685, acc: 0.539062]  [A loss: 0.999926, acc: 0.078125]\n",
            "1670: [D loss: 0.675204, acc: 0.580078]  [A loss: 0.771792, acc: 0.335938]\n",
            "1671: [D loss: 0.702458, acc: 0.554688]  [A loss: 1.031831, acc: 0.078125]\n",
            "1672: [D loss: 0.679900, acc: 0.556641]  [A loss: 0.776263, acc: 0.347656]\n",
            "1673: [D loss: 0.688019, acc: 0.578125]  [A loss: 1.035800, acc: 0.050781]\n",
            "1674: [D loss: 0.681786, acc: 0.568359]  [A loss: 0.740131, acc: 0.410156]\n",
            "1675: [D loss: 0.705541, acc: 0.515625]  [A loss: 1.034629, acc: 0.078125]\n",
            "1676: [D loss: 0.686386, acc: 0.580078]  [A loss: 0.751028, acc: 0.402344]\n",
            "1677: [D loss: 0.706204, acc: 0.527344]  [A loss: 1.006109, acc: 0.121094]\n",
            "1678: [D loss: 0.691393, acc: 0.550781]  [A loss: 0.744317, acc: 0.402344]\n",
            "1679: [D loss: 0.710320, acc: 0.511719]  [A loss: 1.038876, acc: 0.066406]\n",
            "1680: [D loss: 0.689161, acc: 0.544922]  [A loss: 0.779836, acc: 0.343750]\n",
            "1681: [D loss: 0.695580, acc: 0.539062]  [A loss: 0.945035, acc: 0.109375]\n",
            "1682: [D loss: 0.678041, acc: 0.556641]  [A loss: 0.820707, acc: 0.304688]\n",
            "1683: [D loss: 0.687515, acc: 0.554688]  [A loss: 0.877047, acc: 0.222656]\n",
            "1684: [D loss: 0.680648, acc: 0.566406]  [A loss: 0.853253, acc: 0.238281]\n",
            "1685: [D loss: 0.684783, acc: 0.570312]  [A loss: 0.927110, acc: 0.132812]\n",
            "1686: [D loss: 0.693450, acc: 0.546875]  [A loss: 0.901188, acc: 0.167969]\n",
            "1687: [D loss: 0.685777, acc: 0.587891]  [A loss: 0.842380, acc: 0.261719]\n",
            "1688: [D loss: 0.702043, acc: 0.533203]  [A loss: 1.016637, acc: 0.097656]\n",
            "1689: [D loss: 0.693908, acc: 0.566406]  [A loss: 0.830189, acc: 0.257812]\n",
            "1690: [D loss: 0.701869, acc: 0.546875]  [A loss: 0.989964, acc: 0.101562]\n",
            "1691: [D loss: 0.670324, acc: 0.583984]  [A loss: 0.821880, acc: 0.320312]\n",
            "1692: [D loss: 0.696878, acc: 0.527344]  [A loss: 1.132882, acc: 0.066406]\n",
            "1693: [D loss: 0.680832, acc: 0.552734]  [A loss: 0.640189, acc: 0.640625]\n",
            "1694: [D loss: 0.717038, acc: 0.531250]  [A loss: 1.080856, acc: 0.054688]\n",
            "1695: [D loss: 0.687870, acc: 0.564453]  [A loss: 0.689280, acc: 0.562500]\n",
            "1696: [D loss: 0.705726, acc: 0.533203]  [A loss: 0.961661, acc: 0.078125]\n",
            "1697: [D loss: 0.693498, acc: 0.556641]  [A loss: 0.795856, acc: 0.300781]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1698: [D loss: 0.711674, acc: 0.505859]  [A loss: 0.881939, acc: 0.160156]\n",
            "1699: [D loss: 0.683212, acc: 0.591797]  [A loss: 0.905384, acc: 0.199219]\n",
            "1700: [D loss: 0.694790, acc: 0.507812]  [A loss: 0.860175, acc: 0.230469]\n",
            "1701: [D loss: 0.668809, acc: 0.583984]  [A loss: 0.908169, acc: 0.152344]\n",
            "1702: [D loss: 0.676603, acc: 0.576172]  [A loss: 0.865679, acc: 0.214844]\n",
            "1703: [D loss: 0.673410, acc: 0.574219]  [A loss: 0.910961, acc: 0.171875]\n",
            "1704: [D loss: 0.672374, acc: 0.574219]  [A loss: 0.810832, acc: 0.277344]\n",
            "1705: [D loss: 0.692400, acc: 0.552734]  [A loss: 0.983239, acc: 0.128906]\n",
            "1706: [D loss: 0.683608, acc: 0.548828]  [A loss: 0.722374, acc: 0.464844]\n",
            "1707: [D loss: 0.694766, acc: 0.544922]  [A loss: 1.065125, acc: 0.039062]\n",
            "1708: [D loss: 0.669424, acc: 0.585938]  [A loss: 0.665956, acc: 0.621094]\n",
            "1709: [D loss: 0.726522, acc: 0.511719]  [A loss: 1.134204, acc: 0.050781]\n",
            "1710: [D loss: 0.679178, acc: 0.570312]  [A loss: 0.693102, acc: 0.523438]\n",
            "1711: [D loss: 0.701785, acc: 0.554688]  [A loss: 0.979739, acc: 0.082031]\n",
            "1712: [D loss: 0.676278, acc: 0.593750]  [A loss: 0.828377, acc: 0.304688]\n",
            "1713: [D loss: 0.693847, acc: 0.544922]  [A loss: 0.893079, acc: 0.191406]\n",
            "1714: [D loss: 0.678900, acc: 0.585938]  [A loss: 0.906613, acc: 0.187500]\n",
            "1715: [D loss: 0.681341, acc: 0.552734]  [A loss: 0.856151, acc: 0.207031]\n",
            "1716: [D loss: 0.693915, acc: 0.560547]  [A loss: 0.942653, acc: 0.113281]\n",
            "1717: [D loss: 0.681086, acc: 0.556641]  [A loss: 0.809250, acc: 0.296875]\n",
            "1718: [D loss: 0.687689, acc: 0.564453]  [A loss: 0.936838, acc: 0.164062]\n",
            "1719: [D loss: 0.696377, acc: 0.544922]  [A loss: 0.765465, acc: 0.406250]\n",
            "1720: [D loss: 0.716164, acc: 0.523438]  [A loss: 1.051114, acc: 0.085938]\n",
            "1721: [D loss: 0.681101, acc: 0.585938]  [A loss: 0.724981, acc: 0.429688]\n",
            "1722: [D loss: 0.706791, acc: 0.533203]  [A loss: 1.069693, acc: 0.050781]\n",
            "1723: [D loss: 0.676288, acc: 0.542969]  [A loss: 0.740752, acc: 0.460938]\n",
            "1724: [D loss: 0.704280, acc: 0.542969]  [A loss: 0.982585, acc: 0.113281]\n",
            "1725: [D loss: 0.681102, acc: 0.580078]  [A loss: 0.754878, acc: 0.457031]\n",
            "1726: [D loss: 0.701507, acc: 0.533203]  [A loss: 1.026179, acc: 0.101562]\n",
            "1727: [D loss: 0.688285, acc: 0.525391]  [A loss: 0.803205, acc: 0.296875]\n",
            "1728: [D loss: 0.700955, acc: 0.519531]  [A loss: 0.940063, acc: 0.136719]\n",
            "1729: [D loss: 0.676307, acc: 0.589844]  [A loss: 0.827075, acc: 0.308594]\n",
            "1730: [D loss: 0.694939, acc: 0.519531]  [A loss: 0.900261, acc: 0.164062]\n",
            "1731: [D loss: 0.685494, acc: 0.531250]  [A loss: 0.967463, acc: 0.121094]\n",
            "1732: [D loss: 0.677177, acc: 0.582031]  [A loss: 0.816395, acc: 0.324219]\n",
            "1733: [D loss: 0.700454, acc: 0.541016]  [A loss: 0.981594, acc: 0.121094]\n",
            "1734: [D loss: 0.683078, acc: 0.568359]  [A loss: 0.791010, acc: 0.312500]\n",
            "1735: [D loss: 0.685061, acc: 0.564453]  [A loss: 1.002072, acc: 0.109375]\n",
            "1736: [D loss: 0.695112, acc: 0.550781]  [A loss: 0.743935, acc: 0.421875]\n",
            "1737: [D loss: 0.706893, acc: 0.542969]  [A loss: 1.103320, acc: 0.050781]\n",
            "1738: [D loss: 0.689213, acc: 0.556641]  [A loss: 0.744817, acc: 0.437500]\n",
            "1739: [D loss: 0.705974, acc: 0.539062]  [A loss: 1.030965, acc: 0.093750]\n",
            "1740: [D loss: 0.679641, acc: 0.570312]  [A loss: 0.728523, acc: 0.480469]\n",
            "1741: [D loss: 0.680201, acc: 0.558594]  [A loss: 1.010989, acc: 0.101562]\n",
            "1742: [D loss: 0.675154, acc: 0.562500]  [A loss: 0.762807, acc: 0.390625]\n",
            "1743: [D loss: 0.685331, acc: 0.562500]  [A loss: 1.006401, acc: 0.097656]\n",
            "1744: [D loss: 0.686205, acc: 0.580078]  [A loss: 0.661021, acc: 0.605469]\n",
            "1745: [D loss: 0.717490, acc: 0.519531]  [A loss: 1.047462, acc: 0.074219]\n",
            "1746: [D loss: 0.677058, acc: 0.570312]  [A loss: 0.721706, acc: 0.503906]\n",
            "1747: [D loss: 0.701439, acc: 0.539062]  [A loss: 0.946640, acc: 0.144531]\n",
            "1748: [D loss: 0.695123, acc: 0.539062]  [A loss: 0.787552, acc: 0.339844]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1749: [D loss: 0.691430, acc: 0.544922]  [A loss: 0.910810, acc: 0.140625]\n",
            "1750: [D loss: 0.675779, acc: 0.582031]  [A loss: 0.874388, acc: 0.175781]\n",
            "1751: [D loss: 0.684670, acc: 0.560547]  [A loss: 0.905572, acc: 0.160156]\n",
            "1752: [D loss: 0.685368, acc: 0.542969]  [A loss: 0.823167, acc: 0.257812]\n",
            "1753: [D loss: 0.695766, acc: 0.541016]  [A loss: 0.936730, acc: 0.128906]\n",
            "1754: [D loss: 0.681199, acc: 0.556641]  [A loss: 0.773259, acc: 0.382812]\n",
            "1755: [D loss: 0.680166, acc: 0.578125]  [A loss: 0.937937, acc: 0.136719]\n",
            "1756: [D loss: 0.687067, acc: 0.556641]  [A loss: 0.830827, acc: 0.261719]\n",
            "1757: [D loss: 0.690531, acc: 0.556641]  [A loss: 0.898748, acc: 0.175781]\n",
            "1758: [D loss: 0.690497, acc: 0.541016]  [A loss: 0.820177, acc: 0.273438]\n",
            "1759: [D loss: 0.692239, acc: 0.548828]  [A loss: 0.895456, acc: 0.144531]\n",
            "1760: [D loss: 0.686312, acc: 0.548828]  [A loss: 0.829971, acc: 0.289062]\n",
            "1761: [D loss: 0.693211, acc: 0.546875]  [A loss: 0.894814, acc: 0.144531]\n",
            "1762: [D loss: 0.684886, acc: 0.558594]  [A loss: 0.851005, acc: 0.214844]\n",
            "1763: [D loss: 0.702911, acc: 0.535156]  [A loss: 0.946521, acc: 0.144531]\n",
            "1764: [D loss: 0.693283, acc: 0.542969]  [A loss: 0.850829, acc: 0.253906]\n",
            "1765: [D loss: 0.692815, acc: 0.539062]  [A loss: 0.989018, acc: 0.058594]\n",
            "1766: [D loss: 0.684056, acc: 0.554688]  [A loss: 0.865579, acc: 0.218750]\n",
            "1767: [D loss: 0.682278, acc: 0.558594]  [A loss: 0.980036, acc: 0.113281]\n",
            "1768: [D loss: 0.680758, acc: 0.568359]  [A loss: 0.807375, acc: 0.257812]\n",
            "1769: [D loss: 0.698178, acc: 0.542969]  [A loss: 0.979365, acc: 0.140625]\n",
            "1770: [D loss: 0.682838, acc: 0.562500]  [A loss: 0.803162, acc: 0.312500]\n",
            "1771: [D loss: 0.688403, acc: 0.554688]  [A loss: 1.053786, acc: 0.097656]\n",
            "1772: [D loss: 0.684571, acc: 0.576172]  [A loss: 0.741248, acc: 0.449219]\n",
            "1773: [D loss: 0.706623, acc: 0.533203]  [A loss: 1.070089, acc: 0.035156]\n",
            "1774: [D loss: 0.661535, acc: 0.621094]  [A loss: 0.653300, acc: 0.617188]\n",
            "1775: [D loss: 0.714131, acc: 0.542969]  [A loss: 1.172895, acc: 0.039062]\n",
            "1776: [D loss: 0.689264, acc: 0.541016]  [A loss: 0.653199, acc: 0.648438]\n",
            "1777: [D loss: 0.730878, acc: 0.509766]  [A loss: 0.928995, acc: 0.125000]\n",
            "1778: [D loss: 0.672183, acc: 0.564453]  [A loss: 0.746650, acc: 0.398438]\n",
            "1779: [D loss: 0.692793, acc: 0.554688]  [A loss: 0.902190, acc: 0.179688]\n",
            "1780: [D loss: 0.675371, acc: 0.562500]  [A loss: 0.807395, acc: 0.332031]\n",
            "1781: [D loss: 0.703114, acc: 0.509766]  [A loss: 0.858299, acc: 0.183594]\n",
            "1782: [D loss: 0.675789, acc: 0.583984]  [A loss: 0.831915, acc: 0.265625]\n",
            "1783: [D loss: 0.705163, acc: 0.539062]  [A loss: 0.913081, acc: 0.148438]\n",
            "1784: [D loss: 0.684566, acc: 0.574219]  [A loss: 0.837041, acc: 0.253906]\n",
            "1785: [D loss: 0.686565, acc: 0.560547]  [A loss: 0.977502, acc: 0.101562]\n",
            "1786: [D loss: 0.695707, acc: 0.521484]  [A loss: 0.798139, acc: 0.316406]\n",
            "1787: [D loss: 0.703075, acc: 0.523438]  [A loss: 1.040383, acc: 0.097656]\n",
            "1788: [D loss: 0.705035, acc: 0.529297]  [A loss: 0.708410, acc: 0.507812]\n",
            "1789: [D loss: 0.705323, acc: 0.521484]  [A loss: 0.966878, acc: 0.117188]\n",
            "1790: [D loss: 0.683827, acc: 0.564453]  [A loss: 0.716017, acc: 0.449219]\n",
            "1791: [D loss: 0.704658, acc: 0.535156]  [A loss: 0.988233, acc: 0.097656]\n",
            "1792: [D loss: 0.667830, acc: 0.603516]  [A loss: 0.820607, acc: 0.281250]\n",
            "1793: [D loss: 0.671771, acc: 0.591797]  [A loss: 0.907421, acc: 0.171875]\n",
            "1794: [D loss: 0.683371, acc: 0.582031]  [A loss: 0.919433, acc: 0.203125]\n",
            "1795: [D loss: 0.674432, acc: 0.583984]  [A loss: 0.792684, acc: 0.324219]\n",
            "1796: [D loss: 0.704397, acc: 0.521484]  [A loss: 1.030534, acc: 0.066406]\n",
            "1797: [D loss: 0.684547, acc: 0.558594]  [A loss: 0.735828, acc: 0.433594]\n",
            "1798: [D loss: 0.699477, acc: 0.539062]  [A loss: 1.014145, acc: 0.093750]\n",
            "1799: [D loss: 0.690305, acc: 0.537109]  [A loss: 0.687244, acc: 0.558594]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1800: [D loss: 0.691275, acc: 0.537109]  [A loss: 1.004984, acc: 0.046875]\n",
            "1801: [D loss: 0.686403, acc: 0.550781]  [A loss: 0.764730, acc: 0.406250]\n",
            "1802: [D loss: 0.695282, acc: 0.529297]  [A loss: 0.961298, acc: 0.082031]\n",
            "1803: [D loss: 0.691210, acc: 0.554688]  [A loss: 0.807160, acc: 0.312500]\n",
            "1804: [D loss: 0.691842, acc: 0.550781]  [A loss: 0.928558, acc: 0.164062]\n",
            "1805: [D loss: 0.701967, acc: 0.533203]  [A loss: 0.767898, acc: 0.390625]\n",
            "1806: [D loss: 0.708101, acc: 0.507812]  [A loss: 0.970632, acc: 0.121094]\n",
            "1807: [D loss: 0.686885, acc: 0.541016]  [A loss: 0.736142, acc: 0.414062]\n",
            "1808: [D loss: 0.696415, acc: 0.542969]  [A loss: 0.963717, acc: 0.093750]\n",
            "1809: [D loss: 0.683204, acc: 0.539062]  [A loss: 0.754374, acc: 0.382812]\n",
            "1810: [D loss: 0.714942, acc: 0.525391]  [A loss: 1.009023, acc: 0.082031]\n",
            "1811: [D loss: 0.664175, acc: 0.609375]  [A loss: 0.722173, acc: 0.484375]\n",
            "1812: [D loss: 0.686009, acc: 0.550781]  [A loss: 0.949127, acc: 0.136719]\n",
            "1813: [D loss: 0.687868, acc: 0.550781]  [A loss: 0.816699, acc: 0.269531]\n",
            "1814: [D loss: 0.685544, acc: 0.541016]  [A loss: 0.892076, acc: 0.187500]\n",
            "1815: [D loss: 0.678861, acc: 0.564453]  [A loss: 0.877568, acc: 0.179688]\n",
            "1816: [D loss: 0.702373, acc: 0.521484]  [A loss: 0.836940, acc: 0.210938]\n",
            "1817: [D loss: 0.696666, acc: 0.556641]  [A loss: 0.940650, acc: 0.132812]\n",
            "1818: [D loss: 0.664019, acc: 0.599609]  [A loss: 0.774963, acc: 0.359375]\n",
            "1819: [D loss: 0.693583, acc: 0.539062]  [A loss: 0.974932, acc: 0.152344]\n",
            "1820: [D loss: 0.676574, acc: 0.585938]  [A loss: 0.753530, acc: 0.406250]\n",
            "1821: [D loss: 0.699836, acc: 0.517578]  [A loss: 1.011088, acc: 0.085938]\n",
            "1822: [D loss: 0.695910, acc: 0.541016]  [A loss: 0.714440, acc: 0.472656]\n",
            "1823: [D loss: 0.733939, acc: 0.515625]  [A loss: 1.044961, acc: 0.101562]\n",
            "1824: [D loss: 0.703181, acc: 0.513672]  [A loss: 0.802365, acc: 0.277344]\n",
            "1825: [D loss: 0.695186, acc: 0.544922]  [A loss: 0.867626, acc: 0.183594]\n",
            "1826: [D loss: 0.677101, acc: 0.576172]  [A loss: 0.810954, acc: 0.277344]\n",
            "1827: [D loss: 0.711976, acc: 0.505859]  [A loss: 0.894982, acc: 0.148438]\n",
            "1828: [D loss: 0.685220, acc: 0.570312]  [A loss: 0.791741, acc: 0.332031]\n",
            "1829: [D loss: 0.690996, acc: 0.552734]  [A loss: 0.935768, acc: 0.144531]\n",
            "1830: [D loss: 0.675498, acc: 0.566406]  [A loss: 0.828717, acc: 0.246094]\n",
            "1831: [D loss: 0.681789, acc: 0.566406]  [A loss: 0.967651, acc: 0.093750]\n",
            "1832: [D loss: 0.679461, acc: 0.576172]  [A loss: 0.760671, acc: 0.398438]\n",
            "1833: [D loss: 0.696197, acc: 0.562500]  [A loss: 1.059907, acc: 0.054688]\n",
            "1834: [D loss: 0.680683, acc: 0.572266]  [A loss: 0.697185, acc: 0.523438]\n",
            "1835: [D loss: 0.711679, acc: 0.535156]  [A loss: 1.044942, acc: 0.078125]\n",
            "1836: [D loss: 0.689249, acc: 0.525391]  [A loss: 0.690926, acc: 0.503906]\n",
            "1837: [D loss: 0.719718, acc: 0.533203]  [A loss: 1.018040, acc: 0.097656]\n",
            "1838: [D loss: 0.683105, acc: 0.572266]  [A loss: 0.769604, acc: 0.390625]\n",
            "1839: [D loss: 0.692080, acc: 0.558594]  [A loss: 0.960886, acc: 0.140625]\n",
            "1840: [D loss: 0.689992, acc: 0.541016]  [A loss: 0.742328, acc: 0.402344]\n",
            "1841: [D loss: 0.706552, acc: 0.562500]  [A loss: 1.002079, acc: 0.074219]\n",
            "1842: [D loss: 0.688078, acc: 0.546875]  [A loss: 0.783423, acc: 0.343750]\n",
            "1843: [D loss: 0.700714, acc: 0.537109]  [A loss: 0.906426, acc: 0.183594]\n",
            "1844: [D loss: 0.690642, acc: 0.558594]  [A loss: 0.822507, acc: 0.289062]\n",
            "1845: [D loss: 0.685973, acc: 0.593750]  [A loss: 0.880731, acc: 0.183594]\n",
            "1846: [D loss: 0.685960, acc: 0.560547]  [A loss: 0.851140, acc: 0.230469]\n",
            "1847: [D loss: 0.692500, acc: 0.558594]  [A loss: 0.942166, acc: 0.140625]\n",
            "1848: [D loss: 0.666113, acc: 0.619141]  [A loss: 0.787492, acc: 0.332031]\n",
            "1849: [D loss: 0.716948, acc: 0.505859]  [A loss: 0.961501, acc: 0.101562]\n",
            "1850: [D loss: 0.686555, acc: 0.550781]  [A loss: 0.840260, acc: 0.238281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1851: [D loss: 0.676695, acc: 0.560547]  [A loss: 0.890087, acc: 0.199219]\n",
            "1852: [D loss: 0.676491, acc: 0.591797]  [A loss: 0.856303, acc: 0.242188]\n",
            "1853: [D loss: 0.703429, acc: 0.529297]  [A loss: 0.869404, acc: 0.191406]\n",
            "1854: [D loss: 0.696594, acc: 0.527344]  [A loss: 0.824225, acc: 0.261719]\n",
            "1855: [D loss: 0.673011, acc: 0.595703]  [A loss: 0.972172, acc: 0.101562]\n",
            "1856: [D loss: 0.687452, acc: 0.564453]  [A loss: 0.761114, acc: 0.386719]\n",
            "1857: [D loss: 0.713116, acc: 0.517578]  [A loss: 1.001284, acc: 0.066406]\n",
            "1858: [D loss: 0.692851, acc: 0.572266]  [A loss: 0.763233, acc: 0.378906]\n",
            "1859: [D loss: 0.696083, acc: 0.539062]  [A loss: 0.932285, acc: 0.121094]\n",
            "1860: [D loss: 0.677655, acc: 0.566406]  [A loss: 0.851370, acc: 0.218750]\n",
            "1861: [D loss: 0.694167, acc: 0.558594]  [A loss: 0.853892, acc: 0.183594]\n",
            "1862: [D loss: 0.681792, acc: 0.589844]  [A loss: 0.941319, acc: 0.097656]\n",
            "1863: [D loss: 0.686884, acc: 0.560547]  [A loss: 0.805069, acc: 0.304688]\n",
            "1864: [D loss: 0.715065, acc: 0.501953]  [A loss: 0.964535, acc: 0.082031]\n",
            "1865: [D loss: 0.693504, acc: 0.552734]  [A loss: 0.784704, acc: 0.339844]\n",
            "1866: [D loss: 0.691539, acc: 0.525391]  [A loss: 0.858371, acc: 0.203125]\n",
            "1867: [D loss: 0.685336, acc: 0.560547]  [A loss: 0.852246, acc: 0.210938]\n",
            "1868: [D loss: 0.685309, acc: 0.570312]  [A loss: 0.872740, acc: 0.203125]\n",
            "1869: [D loss: 0.671905, acc: 0.572266]  [A loss: 0.812728, acc: 0.296875]\n",
            "1870: [D loss: 0.698952, acc: 0.531250]  [A loss: 0.970872, acc: 0.113281]\n",
            "1871: [D loss: 0.682023, acc: 0.548828]  [A loss: 0.750818, acc: 0.382812]\n",
            "1872: [D loss: 0.698300, acc: 0.542969]  [A loss: 0.976843, acc: 0.074219]\n",
            "1873: [D loss: 0.683288, acc: 0.556641]  [A loss: 0.741701, acc: 0.414062]\n",
            "1874: [D loss: 0.699873, acc: 0.511719]  [A loss: 1.007249, acc: 0.085938]\n",
            "1875: [D loss: 0.684755, acc: 0.539062]  [A loss: 0.708291, acc: 0.472656]\n",
            "1876: [D loss: 0.699159, acc: 0.544922]  [A loss: 0.979173, acc: 0.093750]\n",
            "1877: [D loss: 0.675260, acc: 0.574219]  [A loss: 0.789342, acc: 0.343750]\n",
            "1878: [D loss: 0.681018, acc: 0.564453]  [A loss: 0.978243, acc: 0.113281]\n",
            "1879: [D loss: 0.677425, acc: 0.587891]  [A loss: 0.818925, acc: 0.285156]\n",
            "1880: [D loss: 0.699755, acc: 0.546875]  [A loss: 0.968067, acc: 0.117188]\n",
            "1881: [D loss: 0.681653, acc: 0.562500]  [A loss: 0.764146, acc: 0.386719]\n",
            "1882: [D loss: 0.697626, acc: 0.562500]  [A loss: 0.982690, acc: 0.093750]\n",
            "1883: [D loss: 0.679143, acc: 0.595703]  [A loss: 0.771030, acc: 0.367188]\n",
            "1884: [D loss: 0.686923, acc: 0.566406]  [A loss: 1.005587, acc: 0.101562]\n",
            "1885: [D loss: 0.682571, acc: 0.558594]  [A loss: 0.737885, acc: 0.429688]\n",
            "1886: [D loss: 0.689237, acc: 0.548828]  [A loss: 0.911397, acc: 0.148438]\n",
            "1887: [D loss: 0.676365, acc: 0.576172]  [A loss: 0.810352, acc: 0.269531]\n",
            "1888: [D loss: 0.690690, acc: 0.572266]  [A loss: 0.949245, acc: 0.152344]\n",
            "1889: [D loss: 0.680745, acc: 0.552734]  [A loss: 0.758061, acc: 0.402344]\n",
            "1890: [D loss: 0.713711, acc: 0.521484]  [A loss: 0.984807, acc: 0.089844]\n",
            "1891: [D loss: 0.694349, acc: 0.546875]  [A loss: 0.814018, acc: 0.296875]\n",
            "1892: [D loss: 0.698397, acc: 0.558594]  [A loss: 0.896665, acc: 0.164062]\n",
            "1893: [D loss: 0.679537, acc: 0.562500]  [A loss: 0.818277, acc: 0.308594]\n",
            "1894: [D loss: 0.685861, acc: 0.560547]  [A loss: 0.912383, acc: 0.207031]\n",
            "1895: [D loss: 0.689035, acc: 0.554688]  [A loss: 0.838171, acc: 0.308594]\n",
            "1896: [D loss: 0.705586, acc: 0.513672]  [A loss: 0.892245, acc: 0.175781]\n",
            "1897: [D loss: 0.691114, acc: 0.535156]  [A loss: 0.812551, acc: 0.304688]\n",
            "1898: [D loss: 0.693630, acc: 0.533203]  [A loss: 0.932826, acc: 0.183594]\n",
            "1899: [D loss: 0.687495, acc: 0.576172]  [A loss: 0.872179, acc: 0.230469]\n",
            "1900: [D loss: 0.690032, acc: 0.531250]  [A loss: 0.861647, acc: 0.234375]\n",
            "1901: [D loss: 0.679225, acc: 0.564453]  [A loss: 0.960868, acc: 0.101562]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1902: [D loss: 0.691005, acc: 0.539062]  [A loss: 0.837326, acc: 0.246094]\n",
            "1903: [D loss: 0.708307, acc: 0.511719]  [A loss: 1.022623, acc: 0.101562]\n",
            "1904: [D loss: 0.682074, acc: 0.548828]  [A loss: 0.679799, acc: 0.554688]\n",
            "1905: [D loss: 0.713501, acc: 0.519531]  [A loss: 1.074334, acc: 0.039062]\n",
            "1906: [D loss: 0.695124, acc: 0.531250]  [A loss: 0.695274, acc: 0.542969]\n",
            "1907: [D loss: 0.705580, acc: 0.544922]  [A loss: 0.924795, acc: 0.109375]\n",
            "1908: [D loss: 0.687386, acc: 0.556641]  [A loss: 0.761329, acc: 0.402344]\n",
            "1909: [D loss: 0.696736, acc: 0.541016]  [A loss: 0.911073, acc: 0.148438]\n",
            "1910: [D loss: 0.686315, acc: 0.546875]  [A loss: 0.825275, acc: 0.253906]\n",
            "1911: [D loss: 0.685447, acc: 0.539062]  [A loss: 0.853228, acc: 0.195312]\n",
            "1912: [D loss: 0.683168, acc: 0.527344]  [A loss: 0.828743, acc: 0.250000]\n",
            "1913: [D loss: 0.681480, acc: 0.583984]  [A loss: 0.795989, acc: 0.320312]\n",
            "1914: [D loss: 0.683770, acc: 0.595703]  [A loss: 0.938637, acc: 0.171875]\n",
            "1915: [D loss: 0.689070, acc: 0.546875]  [A loss: 0.831678, acc: 0.250000]\n",
            "1916: [D loss: 0.729887, acc: 0.501953]  [A loss: 0.916190, acc: 0.132812]\n",
            "1917: [D loss: 0.689325, acc: 0.556641]  [A loss: 0.908856, acc: 0.156250]\n",
            "1918: [D loss: 0.695964, acc: 0.521484]  [A loss: 0.784864, acc: 0.312500]\n",
            "1919: [D loss: 0.696649, acc: 0.560547]  [A loss: 0.895952, acc: 0.171875]\n",
            "1920: [D loss: 0.692042, acc: 0.533203]  [A loss: 0.899285, acc: 0.167969]\n",
            "1921: [D loss: 0.690630, acc: 0.537109]  [A loss: 0.860007, acc: 0.175781]\n",
            "1922: [D loss: 0.710858, acc: 0.500000]  [A loss: 0.850748, acc: 0.199219]\n",
            "1923: [D loss: 0.692863, acc: 0.535156]  [A loss: 0.935875, acc: 0.117188]\n",
            "1924: [D loss: 0.679890, acc: 0.578125]  [A loss: 0.705033, acc: 0.535156]\n",
            "1925: [D loss: 0.708277, acc: 0.507812]  [A loss: 0.979441, acc: 0.078125]\n",
            "1926: [D loss: 0.680699, acc: 0.541016]  [A loss: 0.715573, acc: 0.453125]\n",
            "1927: [D loss: 0.698724, acc: 0.527344]  [A loss: 0.977153, acc: 0.105469]\n",
            "1928: [D loss: 0.671986, acc: 0.587891]  [A loss: 0.765651, acc: 0.378906]\n",
            "1929: [D loss: 0.719789, acc: 0.503906]  [A loss: 0.972193, acc: 0.097656]\n",
            "1930: [D loss: 0.689762, acc: 0.531250]  [A loss: 0.724327, acc: 0.457031]\n",
            "1931: [D loss: 0.706870, acc: 0.523438]  [A loss: 0.963462, acc: 0.109375]\n",
            "1932: [D loss: 0.689851, acc: 0.544922]  [A loss: 0.747083, acc: 0.425781]\n",
            "1933: [D loss: 0.709080, acc: 0.509766]  [A loss: 0.967943, acc: 0.097656]\n",
            "1934: [D loss: 0.687036, acc: 0.529297]  [A loss: 0.754550, acc: 0.375000]\n",
            "1935: [D loss: 0.689767, acc: 0.544922]  [A loss: 0.940607, acc: 0.117188]\n",
            "1936: [D loss: 0.691862, acc: 0.542969]  [A loss: 0.726040, acc: 0.453125]\n",
            "1937: [D loss: 0.697521, acc: 0.535156]  [A loss: 0.949267, acc: 0.117188]\n",
            "1938: [D loss: 0.676345, acc: 0.578125]  [A loss: 0.753863, acc: 0.382812]\n",
            "1939: [D loss: 0.702708, acc: 0.513672]  [A loss: 0.933315, acc: 0.113281]\n",
            "1940: [D loss: 0.692950, acc: 0.544922]  [A loss: 0.787486, acc: 0.312500]\n",
            "1941: [D loss: 0.694720, acc: 0.550781]  [A loss: 0.910817, acc: 0.128906]\n",
            "1942: [D loss: 0.693080, acc: 0.529297]  [A loss: 0.779283, acc: 0.335938]\n",
            "1943: [D loss: 0.701580, acc: 0.529297]  [A loss: 0.896082, acc: 0.148438]\n",
            "1944: [D loss: 0.692599, acc: 0.539062]  [A loss: 0.818636, acc: 0.261719]\n",
            "1945: [D loss: 0.692329, acc: 0.535156]  [A loss: 0.806174, acc: 0.269531]\n",
            "1946: [D loss: 0.686713, acc: 0.568359]  [A loss: 0.875736, acc: 0.199219]\n",
            "1947: [D loss: 0.685764, acc: 0.541016]  [A loss: 0.788333, acc: 0.332031]\n",
            "1948: [D loss: 0.699566, acc: 0.519531]  [A loss: 0.921422, acc: 0.171875]\n",
            "1949: [D loss: 0.681350, acc: 0.564453]  [A loss: 0.767286, acc: 0.382812]\n",
            "1950: [D loss: 0.687995, acc: 0.556641]  [A loss: 0.908144, acc: 0.179688]\n",
            "1951: [D loss: 0.702171, acc: 0.521484]  [A loss: 0.743684, acc: 0.429688]\n",
            "1952: [D loss: 0.699021, acc: 0.523438]  [A loss: 0.901028, acc: 0.148438]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1953: [D loss: 0.691313, acc: 0.529297]  [A loss: 0.786516, acc: 0.339844]\n",
            "1954: [D loss: 0.706206, acc: 0.500000]  [A loss: 0.973999, acc: 0.066406]\n",
            "1955: [D loss: 0.693840, acc: 0.525391]  [A loss: 0.787856, acc: 0.355469]\n",
            "1956: [D loss: 0.700117, acc: 0.517578]  [A loss: 0.919014, acc: 0.121094]\n",
            "1957: [D loss: 0.690534, acc: 0.542969]  [A loss: 0.743959, acc: 0.414062]\n",
            "1958: [D loss: 0.711751, acc: 0.535156]  [A loss: 0.944863, acc: 0.128906]\n",
            "1959: [D loss: 0.656325, acc: 0.632812]  [A loss: 0.712232, acc: 0.511719]\n",
            "1960: [D loss: 0.710393, acc: 0.531250]  [A loss: 0.969092, acc: 0.140625]\n",
            "1961: [D loss: 0.679703, acc: 0.560547]  [A loss: 0.811031, acc: 0.300781]\n",
            "1962: [D loss: 0.697635, acc: 0.548828]  [A loss: 0.961231, acc: 0.093750]\n",
            "1963: [D loss: 0.670905, acc: 0.613281]  [A loss: 0.748112, acc: 0.382812]\n",
            "1964: [D loss: 0.691642, acc: 0.556641]  [A loss: 0.940219, acc: 0.156250]\n",
            "1965: [D loss: 0.682621, acc: 0.591797]  [A loss: 0.775131, acc: 0.378906]\n",
            "1966: [D loss: 0.720125, acc: 0.501953]  [A loss: 0.915722, acc: 0.175781]\n",
            "1967: [D loss: 0.690962, acc: 0.541016]  [A loss: 0.796985, acc: 0.300781]\n",
            "1968: [D loss: 0.686419, acc: 0.556641]  [A loss: 0.927376, acc: 0.140625]\n",
            "1969: [D loss: 0.687668, acc: 0.550781]  [A loss: 0.791767, acc: 0.316406]\n",
            "1970: [D loss: 0.692001, acc: 0.544922]  [A loss: 0.898282, acc: 0.148438]\n",
            "1971: [D loss: 0.693812, acc: 0.542969]  [A loss: 0.780739, acc: 0.343750]\n",
            "1972: [D loss: 0.698018, acc: 0.531250]  [A loss: 0.933714, acc: 0.171875]\n",
            "1973: [D loss: 0.680081, acc: 0.556641]  [A loss: 0.769964, acc: 0.378906]\n",
            "1974: [D loss: 0.675343, acc: 0.564453]  [A loss: 0.895458, acc: 0.156250]\n",
            "1975: [D loss: 0.681949, acc: 0.560547]  [A loss: 0.806898, acc: 0.316406]\n",
            "1976: [D loss: 0.697014, acc: 0.525391]  [A loss: 0.901521, acc: 0.160156]\n",
            "1977: [D loss: 0.674925, acc: 0.583984]  [A loss: 0.805393, acc: 0.269531]\n",
            "1978: [D loss: 0.686179, acc: 0.552734]  [A loss: 0.998422, acc: 0.085938]\n",
            "1979: [D loss: 0.668707, acc: 0.568359]  [A loss: 0.697982, acc: 0.507812]\n",
            "1980: [D loss: 0.718886, acc: 0.509766]  [A loss: 0.946232, acc: 0.097656]\n",
            "1981: [D loss: 0.694006, acc: 0.529297]  [A loss: 0.773289, acc: 0.351562]\n",
            "1982: [D loss: 0.704036, acc: 0.527344]  [A loss: 0.952597, acc: 0.109375]\n",
            "1983: [D loss: 0.681665, acc: 0.568359]  [A loss: 0.763051, acc: 0.394531]\n",
            "1984: [D loss: 0.720820, acc: 0.498047]  [A loss: 0.999678, acc: 0.042969]\n",
            "1985: [D loss: 0.673582, acc: 0.585938]  [A loss: 0.714064, acc: 0.496094]\n",
            "1986: [D loss: 0.688462, acc: 0.566406]  [A loss: 0.948525, acc: 0.128906]\n",
            "1987: [D loss: 0.675558, acc: 0.591797]  [A loss: 0.784527, acc: 0.332031]\n",
            "1988: [D loss: 0.696060, acc: 0.546875]  [A loss: 0.919211, acc: 0.144531]\n",
            "1989: [D loss: 0.679331, acc: 0.572266]  [A loss: 0.865713, acc: 0.164062]\n",
            "1990: [D loss: 0.684238, acc: 0.548828]  [A loss: 0.816244, acc: 0.253906]\n",
            "1991: [D loss: 0.703724, acc: 0.544922]  [A loss: 0.837769, acc: 0.234375]\n",
            "1992: [D loss: 0.700678, acc: 0.523438]  [A loss: 0.879121, acc: 0.160156]\n",
            "1993: [D loss: 0.685596, acc: 0.552734]  [A loss: 0.816701, acc: 0.238281]\n",
            "1994: [D loss: 0.688677, acc: 0.539062]  [A loss: 0.860098, acc: 0.238281]\n",
            "1995: [D loss: 0.672463, acc: 0.576172]  [A loss: 0.818476, acc: 0.238281]\n",
            "1996: [D loss: 0.691786, acc: 0.527344]  [A loss: 0.911178, acc: 0.183594]\n",
            "1997: [D loss: 0.705604, acc: 0.525391]  [A loss: 0.827496, acc: 0.242188]\n",
            "1998: [D loss: 0.696816, acc: 0.523438]  [A loss: 0.931343, acc: 0.187500]\n",
            "1999: [D loss: 0.687143, acc: 0.560547]  [A loss: 0.805001, acc: 0.289062]\n",
            "2000: [D loss: 0.680203, acc: 0.572266]  [A loss: 0.921284, acc: 0.167969]\n",
            "2001: [D loss: 0.680235, acc: 0.548828]  [A loss: 0.822094, acc: 0.304688]\n",
            "2002: [D loss: 0.685318, acc: 0.554688]  [A loss: 0.859298, acc: 0.218750]\n",
            "2003: [D loss: 0.676767, acc: 0.566406]  [A loss: 0.891704, acc: 0.171875]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2004: [D loss: 0.691693, acc: 0.552734]  [A loss: 0.873486, acc: 0.214844]\n",
            "2005: [D loss: 0.697638, acc: 0.546875]  [A loss: 0.785690, acc: 0.332031]\n",
            "2006: [D loss: 0.679831, acc: 0.580078]  [A loss: 0.936717, acc: 0.132812]\n",
            "2007: [D loss: 0.689084, acc: 0.537109]  [A loss: 0.853351, acc: 0.199219]\n",
            "2008: [D loss: 0.700674, acc: 0.521484]  [A loss: 0.976886, acc: 0.105469]\n",
            "2009: [D loss: 0.697856, acc: 0.548828]  [A loss: 0.745103, acc: 0.410156]\n",
            "2010: [D loss: 0.716290, acc: 0.501953]  [A loss: 1.037873, acc: 0.042969]\n",
            "2011: [D loss: 0.688510, acc: 0.550781]  [A loss: 0.688971, acc: 0.535156]\n",
            "2012: [D loss: 0.733595, acc: 0.513672]  [A loss: 0.975015, acc: 0.070312]\n",
            "2013: [D loss: 0.694874, acc: 0.535156]  [A loss: 0.796927, acc: 0.304688]\n",
            "2014: [D loss: 0.711944, acc: 0.505859]  [A loss: 0.932661, acc: 0.128906]\n",
            "2015: [D loss: 0.668924, acc: 0.583984]  [A loss: 0.786112, acc: 0.335938]\n",
            "2016: [D loss: 0.711821, acc: 0.539062]  [A loss: 0.863811, acc: 0.195312]\n",
            "2017: [D loss: 0.690366, acc: 0.525391]  [A loss: 0.782228, acc: 0.320312]\n",
            "2018: [D loss: 0.705609, acc: 0.505859]  [A loss: 0.906188, acc: 0.113281]\n",
            "2019: [D loss: 0.697506, acc: 0.531250]  [A loss: 0.769804, acc: 0.347656]\n",
            "2020: [D loss: 0.692650, acc: 0.527344]  [A loss: 0.920479, acc: 0.109375]\n",
            "2021: [D loss: 0.684257, acc: 0.542969]  [A loss: 0.813799, acc: 0.253906]\n",
            "2022: [D loss: 0.683865, acc: 0.541016]  [A loss: 0.894965, acc: 0.179688]\n",
            "2023: [D loss: 0.677104, acc: 0.574219]  [A loss: 0.794019, acc: 0.308594]\n",
            "2024: [D loss: 0.692551, acc: 0.541016]  [A loss: 0.930138, acc: 0.148438]\n",
            "2025: [D loss: 0.692895, acc: 0.548828]  [A loss: 0.798171, acc: 0.304688]\n",
            "2026: [D loss: 0.686726, acc: 0.560547]  [A loss: 0.809675, acc: 0.261719]\n",
            "2027: [D loss: 0.704656, acc: 0.527344]  [A loss: 0.955422, acc: 0.105469]\n",
            "2028: [D loss: 0.695572, acc: 0.531250]  [A loss: 0.745196, acc: 0.410156]\n",
            "2029: [D loss: 0.695148, acc: 0.531250]  [A loss: 0.926680, acc: 0.125000]\n",
            "2030: [D loss: 0.665561, acc: 0.609375]  [A loss: 0.779382, acc: 0.359375]\n",
            "2031: [D loss: 0.709733, acc: 0.501953]  [A loss: 0.919877, acc: 0.140625]\n",
            "2032: [D loss: 0.696284, acc: 0.523438]  [A loss: 0.783732, acc: 0.296875]\n",
            "2033: [D loss: 0.696855, acc: 0.531250]  [A loss: 0.925624, acc: 0.117188]\n",
            "2034: [D loss: 0.678658, acc: 0.570312]  [A loss: 0.779985, acc: 0.343750]\n",
            "2035: [D loss: 0.688225, acc: 0.548828]  [A loss: 0.888544, acc: 0.167969]\n",
            "2036: [D loss: 0.681309, acc: 0.566406]  [A loss: 0.882303, acc: 0.156250]\n",
            "2037: [D loss: 0.693442, acc: 0.527344]  [A loss: 0.914094, acc: 0.187500]\n",
            "2038: [D loss: 0.679881, acc: 0.597656]  [A loss: 0.780360, acc: 0.347656]\n",
            "2039: [D loss: 0.693784, acc: 0.515625]  [A loss: 0.947276, acc: 0.132812]\n",
            "2040: [D loss: 0.685772, acc: 0.546875]  [A loss: 0.754216, acc: 0.382812]\n",
            "2041: [D loss: 0.704045, acc: 0.531250]  [A loss: 1.030420, acc: 0.078125]\n",
            "2042: [D loss: 0.697122, acc: 0.546875]  [A loss: 0.681259, acc: 0.546875]\n",
            "2043: [D loss: 0.703472, acc: 0.535156]  [A loss: 1.017544, acc: 0.089844]\n",
            "2044: [D loss: 0.699373, acc: 0.537109]  [A loss: 0.685493, acc: 0.554688]\n",
            "2045: [D loss: 0.705479, acc: 0.529297]  [A loss: 0.968799, acc: 0.093750]\n",
            "2046: [D loss: 0.698182, acc: 0.527344]  [A loss: 0.747605, acc: 0.382812]\n",
            "2047: [D loss: 0.691859, acc: 0.546875]  [A loss: 0.893956, acc: 0.121094]\n",
            "2048: [D loss: 0.683815, acc: 0.582031]  [A loss: 0.823400, acc: 0.222656]\n",
            "2049: [D loss: 0.688082, acc: 0.541016]  [A loss: 0.872116, acc: 0.195312]\n",
            "2050: [D loss: 0.691356, acc: 0.513672]  [A loss: 0.810278, acc: 0.250000]\n",
            "2051: [D loss: 0.690247, acc: 0.556641]  [A loss: 0.841441, acc: 0.222656]\n",
            "2052: [D loss: 0.696504, acc: 0.554688]  [A loss: 0.874113, acc: 0.183594]\n",
            "2053: [D loss: 0.693112, acc: 0.501953]  [A loss: 0.803576, acc: 0.277344]\n",
            "2054: [D loss: 0.689590, acc: 0.558594]  [A loss: 0.884272, acc: 0.164062]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2055: [D loss: 0.695211, acc: 0.517578]  [A loss: 0.804820, acc: 0.273438]\n",
            "2056: [D loss: 0.699307, acc: 0.552734]  [A loss: 0.834827, acc: 0.246094]\n",
            "2057: [D loss: 0.681527, acc: 0.580078]  [A loss: 0.823737, acc: 0.246094]\n",
            "2058: [D loss: 0.689665, acc: 0.521484]  [A loss: 0.841013, acc: 0.207031]\n",
            "2059: [D loss: 0.687587, acc: 0.554688]  [A loss: 0.805363, acc: 0.257812]\n",
            "2060: [D loss: 0.692185, acc: 0.552734]  [A loss: 0.869501, acc: 0.160156]\n",
            "2061: [D loss: 0.689831, acc: 0.521484]  [A loss: 0.764031, acc: 0.363281]\n",
            "2062: [D loss: 0.698235, acc: 0.515625]  [A loss: 0.967695, acc: 0.105469]\n",
            "2063: [D loss: 0.697546, acc: 0.521484]  [A loss: 0.717296, acc: 0.453125]\n",
            "2064: [D loss: 0.703041, acc: 0.539062]  [A loss: 0.998548, acc: 0.066406]\n",
            "2065: [D loss: 0.689386, acc: 0.550781]  [A loss: 0.701370, acc: 0.496094]\n",
            "2066: [D loss: 0.711659, acc: 0.515625]  [A loss: 0.894551, acc: 0.140625]\n",
            "2067: [D loss: 0.689264, acc: 0.539062]  [A loss: 0.730087, acc: 0.421875]\n",
            "2068: [D loss: 0.701549, acc: 0.542969]  [A loss: 0.856081, acc: 0.164062]\n",
            "2069: [D loss: 0.696187, acc: 0.509766]  [A loss: 0.823593, acc: 0.253906]\n",
            "2070: [D loss: 0.708777, acc: 0.523438]  [A loss: 0.890197, acc: 0.121094]\n",
            "2071: [D loss: 0.689270, acc: 0.548828]  [A loss: 0.797316, acc: 0.316406]\n",
            "2072: [D loss: 0.710107, acc: 0.498047]  [A loss: 0.974306, acc: 0.058594]\n",
            "2073: [D loss: 0.681683, acc: 0.589844]  [A loss: 0.703916, acc: 0.511719]\n",
            "2074: [D loss: 0.695339, acc: 0.533203]  [A loss: 0.945899, acc: 0.082031]\n",
            "2075: [D loss: 0.693196, acc: 0.552734]  [A loss: 0.797863, acc: 0.253906]\n",
            "2076: [D loss: 0.697877, acc: 0.558594]  [A loss: 0.838982, acc: 0.199219]\n",
            "2077: [D loss: 0.683819, acc: 0.535156]  [A loss: 0.854123, acc: 0.183594]\n",
            "2078: [D loss: 0.702595, acc: 0.519531]  [A loss: 0.916460, acc: 0.121094]\n",
            "2079: [D loss: 0.684305, acc: 0.570312]  [A loss: 0.744718, acc: 0.378906]\n",
            "2080: [D loss: 0.714520, acc: 0.509766]  [A loss: 0.957991, acc: 0.132812]\n",
            "2081: [D loss: 0.683710, acc: 0.542969]  [A loss: 0.722003, acc: 0.484375]\n",
            "2082: [D loss: 0.696747, acc: 0.550781]  [A loss: 0.930347, acc: 0.132812]\n",
            "2083: [D loss: 0.688427, acc: 0.548828]  [A loss: 0.788662, acc: 0.277344]\n",
            "2084: [D loss: 0.707564, acc: 0.521484]  [A loss: 0.916350, acc: 0.121094]\n",
            "2085: [D loss: 0.685924, acc: 0.556641]  [A loss: 0.793606, acc: 0.300781]\n",
            "2086: [D loss: 0.685112, acc: 0.576172]  [A loss: 0.856281, acc: 0.167969]\n",
            "2087: [D loss: 0.675014, acc: 0.558594]  [A loss: 0.837815, acc: 0.210938]\n",
            "2088: [D loss: 0.675261, acc: 0.583984]  [A loss: 0.879439, acc: 0.179688]\n",
            "2089: [D loss: 0.682067, acc: 0.537109]  [A loss: 0.828371, acc: 0.250000]\n",
            "2090: [D loss: 0.688083, acc: 0.533203]  [A loss: 0.936734, acc: 0.128906]\n",
            "2091: [D loss: 0.686671, acc: 0.535156]  [A loss: 0.814585, acc: 0.285156]\n",
            "2092: [D loss: 0.687499, acc: 0.578125]  [A loss: 0.841276, acc: 0.230469]\n",
            "2093: [D loss: 0.690419, acc: 0.550781]  [A loss: 0.883974, acc: 0.179688]\n",
            "2094: [D loss: 0.685839, acc: 0.548828]  [A loss: 0.833778, acc: 0.242188]\n",
            "2095: [D loss: 0.699334, acc: 0.537109]  [A loss: 0.927821, acc: 0.117188]\n",
            "2096: [D loss: 0.681080, acc: 0.570312]  [A loss: 0.859641, acc: 0.195312]\n",
            "2097: [D loss: 0.696378, acc: 0.535156]  [A loss: 0.873610, acc: 0.152344]\n",
            "2098: [D loss: 0.705771, acc: 0.517578]  [A loss: 0.756990, acc: 0.417969]\n",
            "2099: [D loss: 0.694956, acc: 0.552734]  [A loss: 1.026021, acc: 0.082031]\n",
            "2100: [D loss: 0.677199, acc: 0.572266]  [A loss: 0.665447, acc: 0.613281]\n",
            "2101: [D loss: 0.730489, acc: 0.509766]  [A loss: 1.112399, acc: 0.042969]\n",
            "2102: [D loss: 0.691630, acc: 0.539062]  [A loss: 0.694826, acc: 0.519531]\n",
            "2103: [D loss: 0.712377, acc: 0.513672]  [A loss: 0.912787, acc: 0.113281]\n",
            "2104: [D loss: 0.687068, acc: 0.556641]  [A loss: 0.786690, acc: 0.292969]\n",
            "2105: [D loss: 0.698255, acc: 0.541016]  [A loss: 0.857082, acc: 0.226562]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2106: [D loss: 0.696040, acc: 0.531250]  [A loss: 0.833430, acc: 0.230469]\n",
            "2107: [D loss: 0.696089, acc: 0.533203]  [A loss: 0.878105, acc: 0.125000]\n",
            "2108: [D loss: 0.691166, acc: 0.533203]  [A loss: 0.889962, acc: 0.156250]\n",
            "2109: [D loss: 0.682678, acc: 0.572266]  [A loss: 0.801373, acc: 0.273438]\n",
            "2110: [D loss: 0.703410, acc: 0.509766]  [A loss: 0.857293, acc: 0.214844]\n",
            "2111: [D loss: 0.680824, acc: 0.568359]  [A loss: 0.834193, acc: 0.253906]\n",
            "2112: [D loss: 0.688300, acc: 0.568359]  [A loss: 0.842043, acc: 0.238281]\n",
            "2113: [D loss: 0.694864, acc: 0.533203]  [A loss: 0.835222, acc: 0.210938]\n",
            "2114: [D loss: 0.687951, acc: 0.531250]  [A loss: 0.820196, acc: 0.250000]\n",
            "2115: [D loss: 0.686274, acc: 0.544922]  [A loss: 0.770470, acc: 0.343750]\n",
            "2116: [D loss: 0.699685, acc: 0.535156]  [A loss: 0.937268, acc: 0.125000]\n",
            "2117: [D loss: 0.687776, acc: 0.535156]  [A loss: 0.777430, acc: 0.304688]\n",
            "2118: [D loss: 0.700341, acc: 0.550781]  [A loss: 0.982368, acc: 0.113281]\n",
            "2119: [D loss: 0.699826, acc: 0.525391]  [A loss: 0.689045, acc: 0.554688]\n",
            "2120: [D loss: 0.708615, acc: 0.527344]  [A loss: 0.922122, acc: 0.093750]\n",
            "2121: [D loss: 0.681760, acc: 0.562500]  [A loss: 0.755949, acc: 0.378906]\n",
            "2122: [D loss: 0.701862, acc: 0.535156]  [A loss: 0.930589, acc: 0.105469]\n",
            "2123: [D loss: 0.691839, acc: 0.523438]  [A loss: 0.754114, acc: 0.398438]\n",
            "2124: [D loss: 0.707331, acc: 0.511719]  [A loss: 0.943375, acc: 0.109375]\n",
            "2125: [D loss: 0.686213, acc: 0.572266]  [A loss: 0.778020, acc: 0.289062]\n",
            "2126: [D loss: 0.690550, acc: 0.562500]  [A loss: 0.868120, acc: 0.164062]\n",
            "2127: [D loss: 0.673617, acc: 0.585938]  [A loss: 0.795938, acc: 0.296875]\n",
            "2128: [D loss: 0.696076, acc: 0.529297]  [A loss: 0.915531, acc: 0.125000]\n",
            "2129: [D loss: 0.679037, acc: 0.587891]  [A loss: 0.758687, acc: 0.375000]\n",
            "2130: [D loss: 0.706461, acc: 0.498047]  [A loss: 0.904902, acc: 0.132812]\n",
            "2131: [D loss: 0.697916, acc: 0.548828]  [A loss: 0.753312, acc: 0.394531]\n",
            "2132: [D loss: 0.692320, acc: 0.548828]  [A loss: 0.923621, acc: 0.117188]\n",
            "2133: [D loss: 0.685876, acc: 0.537109]  [A loss: 0.793616, acc: 0.304688]\n",
            "2134: [D loss: 0.686609, acc: 0.556641]  [A loss: 0.858223, acc: 0.214844]\n",
            "2135: [D loss: 0.682474, acc: 0.574219]  [A loss: 0.784522, acc: 0.339844]\n",
            "2136: [D loss: 0.687422, acc: 0.564453]  [A loss: 0.877513, acc: 0.167969]\n",
            "2137: [D loss: 0.700578, acc: 0.533203]  [A loss: 0.743989, acc: 0.421875]\n",
            "2138: [D loss: 0.690976, acc: 0.542969]  [A loss: 0.901440, acc: 0.156250]\n",
            "2139: [D loss: 0.683967, acc: 0.554688]  [A loss: 0.795196, acc: 0.339844]\n",
            "2140: [D loss: 0.686588, acc: 0.541016]  [A loss: 0.940223, acc: 0.121094]\n",
            "2141: [D loss: 0.700979, acc: 0.539062]  [A loss: 0.779325, acc: 0.335938]\n",
            "2142: [D loss: 0.715171, acc: 0.505859]  [A loss: 0.977579, acc: 0.082031]\n",
            "2143: [D loss: 0.680571, acc: 0.541016]  [A loss: 0.712841, acc: 0.457031]\n",
            "2144: [D loss: 0.724145, acc: 0.525391]  [A loss: 0.982441, acc: 0.054688]\n",
            "2145: [D loss: 0.688024, acc: 0.552734]  [A loss: 0.769237, acc: 0.332031]\n",
            "2146: [D loss: 0.693471, acc: 0.537109]  [A loss: 0.915165, acc: 0.097656]\n",
            "2147: [D loss: 0.683139, acc: 0.542969]  [A loss: 0.850146, acc: 0.191406]\n",
            "2148: [D loss: 0.688737, acc: 0.564453]  [A loss: 0.849574, acc: 0.218750]\n",
            "2149: [D loss: 0.681694, acc: 0.558594]  [A loss: 0.819413, acc: 0.273438]\n",
            "2150: [D loss: 0.698141, acc: 0.546875]  [A loss: 0.882355, acc: 0.144531]\n",
            "2151: [D loss: 0.689906, acc: 0.556641]  [A loss: 0.788451, acc: 0.343750]\n",
            "2152: [D loss: 0.691314, acc: 0.541016]  [A loss: 0.874634, acc: 0.164062]\n",
            "2153: [D loss: 0.687783, acc: 0.568359]  [A loss: 0.798446, acc: 0.300781]\n",
            "2154: [D loss: 0.695727, acc: 0.550781]  [A loss: 0.905636, acc: 0.117188]\n",
            "2155: [D loss: 0.689509, acc: 0.539062]  [A loss: 0.728913, acc: 0.464844]\n",
            "2156: [D loss: 0.696455, acc: 0.527344]  [A loss: 0.973171, acc: 0.078125]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2157: [D loss: 0.678359, acc: 0.583984]  [A loss: 0.699545, acc: 0.503906]\n",
            "2158: [D loss: 0.706474, acc: 0.535156]  [A loss: 1.017636, acc: 0.050781]\n",
            "2159: [D loss: 0.690246, acc: 0.539062]  [A loss: 0.687753, acc: 0.562500]\n",
            "2160: [D loss: 0.704438, acc: 0.517578]  [A loss: 0.930671, acc: 0.070312]\n",
            "2161: [D loss: 0.684600, acc: 0.572266]  [A loss: 0.775358, acc: 0.292969]\n",
            "2162: [D loss: 0.694624, acc: 0.535156]  [A loss: 0.882876, acc: 0.156250]\n",
            "2163: [D loss: 0.686927, acc: 0.556641]  [A loss: 0.769015, acc: 0.347656]\n",
            "2164: [D loss: 0.709084, acc: 0.511719]  [A loss: 0.881600, acc: 0.148438]\n",
            "2165: [D loss: 0.686622, acc: 0.537109]  [A loss: 0.797962, acc: 0.273438]\n",
            "2166: [D loss: 0.695550, acc: 0.548828]  [A loss: 0.867029, acc: 0.183594]\n",
            "2167: [D loss: 0.689747, acc: 0.531250]  [A loss: 0.771989, acc: 0.375000]\n",
            "2168: [D loss: 0.695502, acc: 0.519531]  [A loss: 0.900879, acc: 0.175781]\n",
            "2169: [D loss: 0.699698, acc: 0.542969]  [A loss: 0.757716, acc: 0.378906]\n",
            "2170: [D loss: 0.705841, acc: 0.498047]  [A loss: 0.964922, acc: 0.054688]\n",
            "2171: [D loss: 0.690938, acc: 0.535156]  [A loss: 0.747339, acc: 0.367188]\n",
            "2172: [D loss: 0.694086, acc: 0.531250]  [A loss: 0.911380, acc: 0.113281]\n",
            "2173: [D loss: 0.681241, acc: 0.550781]  [A loss: 0.740470, acc: 0.433594]\n",
            "2174: [D loss: 0.692635, acc: 0.527344]  [A loss: 0.914606, acc: 0.101562]\n",
            "2175: [D loss: 0.685097, acc: 0.566406]  [A loss: 0.816065, acc: 0.253906]\n",
            "2176: [D loss: 0.708434, acc: 0.533203]  [A loss: 0.840423, acc: 0.250000]\n",
            "2177: [D loss: 0.695278, acc: 0.552734]  [A loss: 0.909017, acc: 0.156250]\n",
            "2178: [D loss: 0.691752, acc: 0.541016]  [A loss: 0.843262, acc: 0.207031]\n",
            "2179: [D loss: 0.693353, acc: 0.572266]  [A loss: 0.906660, acc: 0.167969]\n",
            "2180: [D loss: 0.691555, acc: 0.537109]  [A loss: 0.830758, acc: 0.218750]\n",
            "2181: [D loss: 0.680429, acc: 0.552734]  [A loss: 0.899694, acc: 0.128906]\n",
            "2182: [D loss: 0.689955, acc: 0.515625]  [A loss: 0.804310, acc: 0.277344]\n",
            "2183: [D loss: 0.700701, acc: 0.519531]  [A loss: 0.926614, acc: 0.101562]\n",
            "2184: [D loss: 0.681123, acc: 0.574219]  [A loss: 0.797243, acc: 0.289062]\n",
            "2185: [D loss: 0.692401, acc: 0.511719]  [A loss: 0.939376, acc: 0.136719]\n",
            "2186: [D loss: 0.689239, acc: 0.539062]  [A loss: 0.725765, acc: 0.449219]\n",
            "2187: [D loss: 0.701739, acc: 0.537109]  [A loss: 0.921481, acc: 0.125000]\n",
            "2188: [D loss: 0.683121, acc: 0.546875]  [A loss: 0.751192, acc: 0.363281]\n",
            "2189: [D loss: 0.702874, acc: 0.535156]  [A loss: 1.024615, acc: 0.027344]\n",
            "2190: [D loss: 0.706181, acc: 0.501953]  [A loss: 0.639003, acc: 0.679688]\n",
            "2191: [D loss: 0.734395, acc: 0.509766]  [A loss: 1.061145, acc: 0.042969]\n",
            "2192: [D loss: 0.695773, acc: 0.541016]  [A loss: 0.665641, acc: 0.585938]\n",
            "2193: [D loss: 0.716675, acc: 0.500000]  [A loss: 0.868192, acc: 0.136719]\n",
            "2194: [D loss: 0.690730, acc: 0.535156]  [A loss: 0.766369, acc: 0.347656]\n",
            "2195: [D loss: 0.700907, acc: 0.535156]  [A loss: 0.798861, acc: 0.242188]\n",
            "2196: [D loss: 0.693634, acc: 0.542969]  [A loss: 0.810805, acc: 0.265625]\n",
            "2197: [D loss: 0.690491, acc: 0.548828]  [A loss: 0.813714, acc: 0.277344]\n",
            "2198: [D loss: 0.694038, acc: 0.517578]  [A loss: 0.828723, acc: 0.191406]\n",
            "2199: [D loss: 0.698685, acc: 0.537109]  [A loss: 0.782419, acc: 0.308594]\n",
            "2200: [D loss: 0.687359, acc: 0.570312]  [A loss: 0.865556, acc: 0.156250]\n",
            "2201: [D loss: 0.697236, acc: 0.515625]  [A loss: 0.803980, acc: 0.269531]\n",
            "2202: [D loss: 0.681688, acc: 0.531250]  [A loss: 0.851105, acc: 0.195312]\n",
            "2203: [D loss: 0.679368, acc: 0.574219]  [A loss: 0.834627, acc: 0.289062]\n",
            "2204: [D loss: 0.690623, acc: 0.552734]  [A loss: 0.825529, acc: 0.265625]\n",
            "2205: [D loss: 0.686834, acc: 0.535156]  [A loss: 0.872983, acc: 0.175781]\n",
            "2206: [D loss: 0.672957, acc: 0.554688]  [A loss: 0.784847, acc: 0.343750]\n",
            "2207: [D loss: 0.712080, acc: 0.539062]  [A loss: 0.866802, acc: 0.140625]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2208: [D loss: 0.686296, acc: 0.548828]  [A loss: 0.834013, acc: 0.226562]\n",
            "2209: [D loss: 0.683043, acc: 0.556641]  [A loss: 0.849395, acc: 0.195312]\n",
            "2210: [D loss: 0.689593, acc: 0.542969]  [A loss: 0.841121, acc: 0.199219]\n",
            "2211: [D loss: 0.687241, acc: 0.544922]  [A loss: 0.840512, acc: 0.222656]\n",
            "2212: [D loss: 0.694584, acc: 0.546875]  [A loss: 0.870421, acc: 0.195312]\n",
            "2213: [D loss: 0.698934, acc: 0.531250]  [A loss: 0.841718, acc: 0.218750]\n",
            "2214: [D loss: 0.684046, acc: 0.539062]  [A loss: 0.840492, acc: 0.222656]\n",
            "2215: [D loss: 0.688646, acc: 0.523438]  [A loss: 0.861601, acc: 0.164062]\n",
            "2216: [D loss: 0.689879, acc: 0.541016]  [A loss: 0.801358, acc: 0.289062]\n",
            "2217: [D loss: 0.687141, acc: 0.552734]  [A loss: 0.960199, acc: 0.113281]\n",
            "2218: [D loss: 0.684615, acc: 0.568359]  [A loss: 0.695364, acc: 0.539062]\n",
            "2219: [D loss: 0.710000, acc: 0.544922]  [A loss: 0.991998, acc: 0.062500]\n",
            "2220: [D loss: 0.684044, acc: 0.560547]  [A loss: 0.732717, acc: 0.425781]\n",
            "2221: [D loss: 0.709528, acc: 0.521484]  [A loss: 0.926225, acc: 0.117188]\n",
            "2222: [D loss: 0.683492, acc: 0.554688]  [A loss: 0.749214, acc: 0.378906]\n",
            "2223: [D loss: 0.699175, acc: 0.525391]  [A loss: 0.921420, acc: 0.152344]\n",
            "2224: [D loss: 0.687913, acc: 0.550781]  [A loss: 0.719958, acc: 0.445312]\n",
            "2225: [D loss: 0.709767, acc: 0.525391]  [A loss: 0.908041, acc: 0.097656]\n",
            "2226: [D loss: 0.697200, acc: 0.519531]  [A loss: 0.777076, acc: 0.363281]\n",
            "2227: [D loss: 0.707800, acc: 0.531250]  [A loss: 0.860618, acc: 0.222656]\n",
            "2228: [D loss: 0.696573, acc: 0.531250]  [A loss: 0.793418, acc: 0.304688]\n",
            "2229: [D loss: 0.703780, acc: 0.539062]  [A loss: 0.840334, acc: 0.210938]\n",
            "2230: [D loss: 0.690013, acc: 0.556641]  [A loss: 0.811038, acc: 0.277344]\n",
            "2231: [D loss: 0.697505, acc: 0.513672]  [A loss: 0.861328, acc: 0.183594]\n",
            "2232: [D loss: 0.687631, acc: 0.542969]  [A loss: 0.837299, acc: 0.214844]\n",
            "2233: [D loss: 0.690201, acc: 0.554688]  [A loss: 0.822440, acc: 0.234375]\n",
            "2234: [D loss: 0.703892, acc: 0.525391]  [A loss: 0.849141, acc: 0.250000]\n",
            "2235: [D loss: 0.679685, acc: 0.580078]  [A loss: 0.861119, acc: 0.191406]\n",
            "2236: [D loss: 0.694079, acc: 0.535156]  [A loss: 0.893975, acc: 0.156250]\n",
            "2237: [D loss: 0.692863, acc: 0.539062]  [A loss: 0.801215, acc: 0.257812]\n",
            "2238: [D loss: 0.700910, acc: 0.511719]  [A loss: 0.943608, acc: 0.089844]\n",
            "2239: [D loss: 0.685773, acc: 0.570312]  [A loss: 0.769915, acc: 0.355469]\n",
            "2240: [D loss: 0.703140, acc: 0.519531]  [A loss: 0.931887, acc: 0.101562]\n",
            "2241: [D loss: 0.689036, acc: 0.554688]  [A loss: 0.719932, acc: 0.464844]\n",
            "2242: [D loss: 0.717829, acc: 0.494141]  [A loss: 0.948661, acc: 0.070312]\n",
            "2243: [D loss: 0.689032, acc: 0.537109]  [A loss: 0.781572, acc: 0.320312]\n",
            "2244: [D loss: 0.693530, acc: 0.542969]  [A loss: 0.897767, acc: 0.152344]\n",
            "2245: [D loss: 0.682234, acc: 0.548828]  [A loss: 0.730792, acc: 0.460938]\n",
            "2246: [D loss: 0.716492, acc: 0.513672]  [A loss: 0.935232, acc: 0.082031]\n",
            "2247: [D loss: 0.687443, acc: 0.537109]  [A loss: 0.773787, acc: 0.312500]\n",
            "2248: [D loss: 0.686813, acc: 0.537109]  [A loss: 0.894418, acc: 0.156250]\n",
            "2249: [D loss: 0.695818, acc: 0.517578]  [A loss: 0.778725, acc: 0.281250]\n",
            "2250: [D loss: 0.695934, acc: 0.533203]  [A loss: 0.865890, acc: 0.175781]\n",
            "2251: [D loss: 0.689564, acc: 0.542969]  [A loss: 0.748868, acc: 0.398438]\n",
            "2252: [D loss: 0.709071, acc: 0.523438]  [A loss: 0.991255, acc: 0.050781]\n",
            "2253: [D loss: 0.680725, acc: 0.558594]  [A loss: 0.697443, acc: 0.480469]\n",
            "2254: [D loss: 0.716867, acc: 0.523438]  [A loss: 0.956079, acc: 0.070312]\n",
            "2255: [D loss: 0.681726, acc: 0.568359]  [A loss: 0.702146, acc: 0.496094]\n",
            "2256: [D loss: 0.725149, acc: 0.492188]  [A loss: 0.976722, acc: 0.066406]\n",
            "2257: [D loss: 0.686580, acc: 0.542969]  [A loss: 0.703635, acc: 0.476562]\n",
            "2258: [D loss: 0.708084, acc: 0.519531]  [A loss: 1.005124, acc: 0.046875]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2259: [D loss: 0.691636, acc: 0.537109]  [A loss: 0.683432, acc: 0.554688]\n",
            "2260: [D loss: 0.714220, acc: 0.515625]  [A loss: 0.941813, acc: 0.125000]\n",
            "2261: [D loss: 0.697348, acc: 0.513672]  [A loss: 0.744025, acc: 0.378906]\n",
            "2262: [D loss: 0.695815, acc: 0.542969]  [A loss: 0.879975, acc: 0.148438]\n",
            "2263: [D loss: 0.681832, acc: 0.560547]  [A loss: 0.769228, acc: 0.355469]\n",
            "2264: [D loss: 0.712360, acc: 0.527344]  [A loss: 0.841794, acc: 0.238281]\n",
            "2265: [D loss: 0.692131, acc: 0.541016]  [A loss: 0.809580, acc: 0.242188]\n",
            "2266: [D loss: 0.700446, acc: 0.521484]  [A loss: 0.850586, acc: 0.183594]\n",
            "2267: [D loss: 0.688284, acc: 0.523438]  [A loss: 0.830369, acc: 0.238281]\n",
            "2268: [D loss: 0.702484, acc: 0.517578]  [A loss: 0.841316, acc: 0.203125]\n",
            "2269: [D loss: 0.695818, acc: 0.521484]  [A loss: 0.777043, acc: 0.316406]\n",
            "2270: [D loss: 0.692548, acc: 0.541016]  [A loss: 0.874717, acc: 0.203125]\n",
            "2271: [D loss: 0.679629, acc: 0.541016]  [A loss: 0.802578, acc: 0.257812]\n",
            "2272: [D loss: 0.697302, acc: 0.523438]  [A loss: 0.828291, acc: 0.210938]\n",
            "2273: [D loss: 0.698292, acc: 0.515625]  [A loss: 0.869502, acc: 0.144531]\n",
            "2274: [D loss: 0.684457, acc: 0.589844]  [A loss: 0.795816, acc: 0.261719]\n",
            "2275: [D loss: 0.697335, acc: 0.548828]  [A loss: 0.937996, acc: 0.109375]\n",
            "2276: [D loss: 0.706341, acc: 0.513672]  [A loss: 0.673929, acc: 0.605469]\n",
            "2277: [D loss: 0.713018, acc: 0.494141]  [A loss: 0.947595, acc: 0.062500]\n",
            "2278: [D loss: 0.685524, acc: 0.564453]  [A loss: 0.708691, acc: 0.460938]\n",
            "2279: [D loss: 0.689777, acc: 0.544922]  [A loss: 0.917964, acc: 0.121094]\n",
            "2280: [D loss: 0.684601, acc: 0.537109]  [A loss: 0.736463, acc: 0.398438]\n",
            "2281: [D loss: 0.706994, acc: 0.505859]  [A loss: 0.906423, acc: 0.125000]\n",
            "2282: [D loss: 0.697038, acc: 0.531250]  [A loss: 0.757151, acc: 0.339844]\n",
            "2283: [D loss: 0.694908, acc: 0.535156]  [A loss: 0.875414, acc: 0.148438]\n",
            "2284: [D loss: 0.709391, acc: 0.496094]  [A loss: 0.856330, acc: 0.164062]\n",
            "2285: [D loss: 0.691210, acc: 0.544922]  [A loss: 0.794065, acc: 0.273438]\n",
            "2286: [D loss: 0.695147, acc: 0.541016]  [A loss: 0.878739, acc: 0.164062]\n",
            "2287: [D loss: 0.690701, acc: 0.537109]  [A loss: 0.801882, acc: 0.273438]\n",
            "2288: [D loss: 0.700766, acc: 0.544922]  [A loss: 0.813928, acc: 0.218750]\n",
            "2289: [D loss: 0.683064, acc: 0.558594]  [A loss: 0.827445, acc: 0.226562]\n",
            "2290: [D loss: 0.681894, acc: 0.535156]  [A loss: 0.861319, acc: 0.164062]\n",
            "2291: [D loss: 0.684131, acc: 0.541016]  [A loss: 0.836591, acc: 0.191406]\n",
            "2292: [D loss: 0.693131, acc: 0.578125]  [A loss: 0.874969, acc: 0.144531]\n",
            "2293: [D loss: 0.677483, acc: 0.580078]  [A loss: 0.846886, acc: 0.261719]\n",
            "2294: [D loss: 0.695712, acc: 0.537109]  [A loss: 0.941347, acc: 0.089844]\n",
            "2295: [D loss: 0.684613, acc: 0.541016]  [A loss: 0.842280, acc: 0.242188]\n",
            "2296: [D loss: 0.706435, acc: 0.492188]  [A loss: 0.926790, acc: 0.113281]\n",
            "2297: [D loss: 0.695384, acc: 0.525391]  [A loss: 0.690772, acc: 0.550781]\n",
            "2298: [D loss: 0.710642, acc: 0.494141]  [A loss: 0.985057, acc: 0.074219]\n",
            "2299: [D loss: 0.696951, acc: 0.542969]  [A loss: 0.705291, acc: 0.468750]\n",
            "2300: [D loss: 0.711492, acc: 0.492188]  [A loss: 0.946101, acc: 0.085938]\n",
            "2301: [D loss: 0.698883, acc: 0.498047]  [A loss: 0.727377, acc: 0.394531]\n",
            "2302: [D loss: 0.692517, acc: 0.525391]  [A loss: 0.861200, acc: 0.160156]\n",
            "2303: [D loss: 0.693062, acc: 0.533203]  [A loss: 0.805858, acc: 0.230469]\n",
            "2304: [D loss: 0.696587, acc: 0.541016]  [A loss: 0.852194, acc: 0.160156]\n",
            "2305: [D loss: 0.678837, acc: 0.580078]  [A loss: 0.754923, acc: 0.375000]\n",
            "2306: [D loss: 0.692368, acc: 0.527344]  [A loss: 0.930687, acc: 0.105469]\n",
            "2307: [D loss: 0.677520, acc: 0.570312]  [A loss: 0.733628, acc: 0.437500]\n",
            "2308: [D loss: 0.702523, acc: 0.503906]  [A loss: 0.957548, acc: 0.101562]\n",
            "2309: [D loss: 0.693505, acc: 0.541016]  [A loss: 0.696241, acc: 0.539062]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2310: [D loss: 0.705700, acc: 0.515625]  [A loss: 0.960509, acc: 0.117188]\n",
            "2311: [D loss: 0.694626, acc: 0.523438]  [A loss: 0.709116, acc: 0.519531]\n",
            "2312: [D loss: 0.735816, acc: 0.498047]  [A loss: 0.946976, acc: 0.085938]\n",
            "2313: [D loss: 0.693915, acc: 0.515625]  [A loss: 0.695358, acc: 0.515625]\n",
            "2314: [D loss: 0.714568, acc: 0.515625]  [A loss: 0.997110, acc: 0.054688]\n",
            "2315: [D loss: 0.694830, acc: 0.519531]  [A loss: 0.734236, acc: 0.421875]\n",
            "2316: [D loss: 0.703782, acc: 0.509766]  [A loss: 0.839634, acc: 0.214844]\n",
            "2317: [D loss: 0.684707, acc: 0.558594]  [A loss: 0.764376, acc: 0.328125]\n",
            "2318: [D loss: 0.702995, acc: 0.503906]  [A loss: 0.809973, acc: 0.257812]\n",
            "2319: [D loss: 0.692341, acc: 0.509766]  [A loss: 0.841892, acc: 0.230469]\n",
            "2320: [D loss: 0.698624, acc: 0.527344]  [A loss: 0.774288, acc: 0.335938]\n",
            "2321: [D loss: 0.696645, acc: 0.552734]  [A loss: 0.925301, acc: 0.101562]\n",
            "2322: [D loss: 0.696391, acc: 0.488281]  [A loss: 0.757714, acc: 0.355469]\n",
            "2323: [D loss: 0.708083, acc: 0.509766]  [A loss: 0.919086, acc: 0.128906]\n",
            "2324: [D loss: 0.697344, acc: 0.564453]  [A loss: 0.732915, acc: 0.453125]\n",
            "2325: [D loss: 0.699859, acc: 0.519531]  [A loss: 0.898997, acc: 0.105469]\n",
            "2326: [D loss: 0.707771, acc: 0.492188]  [A loss: 0.743731, acc: 0.406250]\n",
            "2327: [D loss: 0.707678, acc: 0.523438]  [A loss: 0.898323, acc: 0.121094]\n",
            "2328: [D loss: 0.691847, acc: 0.550781]  [A loss: 0.736214, acc: 0.398438]\n",
            "2329: [D loss: 0.694474, acc: 0.525391]  [A loss: 0.941189, acc: 0.078125]\n",
            "2330: [D loss: 0.687449, acc: 0.541016]  [A loss: 0.764470, acc: 0.343750]\n",
            "2331: [D loss: 0.709999, acc: 0.503906]  [A loss: 0.804500, acc: 0.253906]\n",
            "2332: [D loss: 0.694026, acc: 0.507812]  [A loss: 0.808437, acc: 0.250000]\n",
            "2333: [D loss: 0.697054, acc: 0.535156]  [A loss: 0.992866, acc: 0.093750]\n",
            "2334: [D loss: 0.688435, acc: 0.527344]  [A loss: 0.757614, acc: 0.359375]\n",
            "2335: [D loss: 0.688754, acc: 0.537109]  [A loss: 0.898844, acc: 0.125000]\n",
            "2336: [D loss: 0.692529, acc: 0.544922]  [A loss: 0.742988, acc: 0.406250]\n",
            "2337: [D loss: 0.690200, acc: 0.544922]  [A loss: 0.910338, acc: 0.128906]\n",
            "2338: [D loss: 0.685165, acc: 0.546875]  [A loss: 0.735614, acc: 0.378906]\n",
            "2339: [D loss: 0.709045, acc: 0.480469]  [A loss: 0.909802, acc: 0.121094]\n",
            "2340: [D loss: 0.702070, acc: 0.492188]  [A loss: 0.753491, acc: 0.363281]\n",
            "2341: [D loss: 0.690707, acc: 0.558594]  [A loss: 0.862984, acc: 0.179688]\n",
            "2342: [D loss: 0.694374, acc: 0.558594]  [A loss: 0.760028, acc: 0.359375]\n",
            "2343: [D loss: 0.710823, acc: 0.513672]  [A loss: 1.028753, acc: 0.050781]\n",
            "2344: [D loss: 0.690972, acc: 0.531250]  [A loss: 0.615875, acc: 0.738281]\n",
            "2345: [D loss: 0.718675, acc: 0.519531]  [A loss: 0.990224, acc: 0.070312]\n",
            "2346: [D loss: 0.688508, acc: 0.523438]  [A loss: 0.723534, acc: 0.437500]\n",
            "2347: [D loss: 0.710832, acc: 0.507812]  [A loss: 0.864500, acc: 0.156250]\n",
            "2348: [D loss: 0.693268, acc: 0.535156]  [A loss: 0.757231, acc: 0.359375]\n",
            "2349: [D loss: 0.684102, acc: 0.550781]  [A loss: 0.841098, acc: 0.207031]\n",
            "2350: [D loss: 0.690283, acc: 0.568359]  [A loss: 0.809054, acc: 0.285156]\n",
            "2351: [D loss: 0.690842, acc: 0.576172]  [A loss: 0.793578, acc: 0.316406]\n",
            "2352: [D loss: 0.698285, acc: 0.539062]  [A loss: 0.860866, acc: 0.160156]\n",
            "2353: [D loss: 0.687622, acc: 0.548828]  [A loss: 0.805406, acc: 0.226562]\n",
            "2354: [D loss: 0.692892, acc: 0.556641]  [A loss: 0.903439, acc: 0.125000]\n",
            "2355: [D loss: 0.701744, acc: 0.513672]  [A loss: 0.823226, acc: 0.246094]\n",
            "2356: [D loss: 0.698305, acc: 0.527344]  [A loss: 0.850125, acc: 0.183594]\n",
            "2357: [D loss: 0.687533, acc: 0.527344]  [A loss: 0.806063, acc: 0.277344]\n",
            "2358: [D loss: 0.685882, acc: 0.570312]  [A loss: 0.839310, acc: 0.203125]\n",
            "2359: [D loss: 0.683624, acc: 0.558594]  [A loss: 0.824401, acc: 0.242188]\n",
            "2360: [D loss: 0.689180, acc: 0.535156]  [A loss: 0.780424, acc: 0.296875]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2361: [D loss: 0.704901, acc: 0.531250]  [A loss: 1.000608, acc: 0.042969]\n",
            "2362: [D loss: 0.690782, acc: 0.554688]  [A loss: 0.701496, acc: 0.480469]\n",
            "2363: [D loss: 0.703140, acc: 0.513672]  [A loss: 0.970242, acc: 0.105469]\n",
            "2364: [D loss: 0.687886, acc: 0.587891]  [A loss: 0.723920, acc: 0.449219]\n",
            "2365: [D loss: 0.711908, acc: 0.507812]  [A loss: 0.950915, acc: 0.078125]\n",
            "2366: [D loss: 0.681572, acc: 0.570312]  [A loss: 0.761634, acc: 0.355469]\n",
            "2367: [D loss: 0.699713, acc: 0.525391]  [A loss: 0.843559, acc: 0.203125]\n",
            "2368: [D loss: 0.692563, acc: 0.529297]  [A loss: 0.823390, acc: 0.230469]\n",
            "2369: [D loss: 0.697867, acc: 0.523438]  [A loss: 0.823056, acc: 0.250000]\n",
            "2370: [D loss: 0.698053, acc: 0.533203]  [A loss: 0.895397, acc: 0.148438]\n",
            "2371: [D loss: 0.690617, acc: 0.523438]  [A loss: 0.792139, acc: 0.339844]\n",
            "2372: [D loss: 0.699901, acc: 0.541016]  [A loss: 0.893865, acc: 0.156250]\n",
            "2373: [D loss: 0.698165, acc: 0.494141]  [A loss: 0.819772, acc: 0.207031]\n",
            "2374: [D loss: 0.697741, acc: 0.527344]  [A loss: 0.831467, acc: 0.214844]\n",
            "2375: [D loss: 0.697700, acc: 0.531250]  [A loss: 0.859271, acc: 0.191406]\n",
            "2376: [D loss: 0.689040, acc: 0.568359]  [A loss: 0.818387, acc: 0.289062]\n",
            "2377: [D loss: 0.691883, acc: 0.523438]  [A loss: 0.807500, acc: 0.296875]\n",
            "2378: [D loss: 0.685444, acc: 0.539062]  [A loss: 0.873871, acc: 0.179688]\n",
            "2379: [D loss: 0.688630, acc: 0.537109]  [A loss: 0.804611, acc: 0.296875]\n",
            "2380: [D loss: 0.703763, acc: 0.500000]  [A loss: 0.901977, acc: 0.132812]\n",
            "2381: [D loss: 0.698696, acc: 0.511719]  [A loss: 0.694092, acc: 0.531250]\n",
            "2382: [D loss: 0.730053, acc: 0.498047]  [A loss: 1.047343, acc: 0.042969]\n",
            "2383: [D loss: 0.696380, acc: 0.546875]  [A loss: 0.638083, acc: 0.671875]\n",
            "2384: [D loss: 0.731294, acc: 0.519531]  [A loss: 0.980452, acc: 0.089844]\n",
            "2385: [D loss: 0.694091, acc: 0.544922]  [A loss: 0.735194, acc: 0.402344]\n",
            "2386: [D loss: 0.702129, acc: 0.509766]  [A loss: 0.861723, acc: 0.191406]\n",
            "2387: [D loss: 0.683233, acc: 0.548828]  [A loss: 0.788012, acc: 0.308594]\n",
            "2388: [D loss: 0.692108, acc: 0.523438]  [A loss: 0.837075, acc: 0.175781]\n",
            "2389: [D loss: 0.682942, acc: 0.587891]  [A loss: 0.807926, acc: 0.253906]\n",
            "2390: [D loss: 0.698666, acc: 0.515625]  [A loss: 0.823873, acc: 0.246094]\n",
            "2391: [D loss: 0.688379, acc: 0.548828]  [A loss: 0.811290, acc: 0.230469]\n",
            "2392: [D loss: 0.704965, acc: 0.498047]  [A loss: 0.770674, acc: 0.335938]\n",
            "2393: [D loss: 0.704039, acc: 0.527344]  [A loss: 0.865083, acc: 0.183594]\n",
            "2394: [D loss: 0.695162, acc: 0.533203]  [A loss: 0.775107, acc: 0.324219]\n",
            "2395: [D loss: 0.693582, acc: 0.535156]  [A loss: 0.912187, acc: 0.113281]\n",
            "2396: [D loss: 0.699724, acc: 0.527344]  [A loss: 0.779392, acc: 0.261719]\n",
            "2397: [D loss: 0.704267, acc: 0.503906]  [A loss: 0.867253, acc: 0.148438]\n",
            "2398: [D loss: 0.684883, acc: 0.556641]  [A loss: 0.766065, acc: 0.343750]\n",
            "2399: [D loss: 0.695535, acc: 0.537109]  [A loss: 0.834802, acc: 0.210938]\n",
            "2400: [D loss: 0.696217, acc: 0.515625]  [A loss: 0.775732, acc: 0.296875]\n",
            "2401: [D loss: 0.698674, acc: 0.537109]  [A loss: 0.922297, acc: 0.101562]\n",
            "2402: [D loss: 0.683083, acc: 0.550781]  [A loss: 0.747567, acc: 0.390625]\n",
            "2403: [D loss: 0.708638, acc: 0.521484]  [A loss: 0.900540, acc: 0.109375]\n",
            "2404: [D loss: 0.690889, acc: 0.541016]  [A loss: 0.786892, acc: 0.265625]\n",
            "2405: [D loss: 0.709925, acc: 0.503906]  [A loss: 0.970343, acc: 0.117188]\n",
            "2406: [D loss: 0.689406, acc: 0.554688]  [A loss: 0.690411, acc: 0.546875]\n",
            "2407: [D loss: 0.718273, acc: 0.513672]  [A loss: 1.007810, acc: 0.085938]\n",
            "2408: [D loss: 0.693780, acc: 0.515625]  [A loss: 0.709399, acc: 0.476562]\n",
            "2409: [D loss: 0.719102, acc: 0.527344]  [A loss: 0.872098, acc: 0.148438]\n",
            "2410: [D loss: 0.683670, acc: 0.578125]  [A loss: 0.771563, acc: 0.312500]\n",
            "2411: [D loss: 0.696327, acc: 0.546875]  [A loss: 0.879732, acc: 0.160156]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2412: [D loss: 0.690310, acc: 0.537109]  [A loss: 0.767204, acc: 0.355469]\n",
            "2413: [D loss: 0.704608, acc: 0.519531]  [A loss: 0.889589, acc: 0.136719]\n",
            "2414: [D loss: 0.687455, acc: 0.560547]  [A loss: 0.773809, acc: 0.332031]\n",
            "2415: [D loss: 0.712906, acc: 0.507812]  [A loss: 0.825376, acc: 0.226562]\n",
            "2416: [D loss: 0.694197, acc: 0.541016]  [A loss: 0.813926, acc: 0.238281]\n",
            "2417: [D loss: 0.692852, acc: 0.537109]  [A loss: 0.809076, acc: 0.246094]\n",
            "2418: [D loss: 0.695936, acc: 0.517578]  [A loss: 0.846982, acc: 0.175781]\n",
            "2419: [D loss: 0.691073, acc: 0.550781]  [A loss: 0.787693, acc: 0.277344]\n",
            "2420: [D loss: 0.713695, acc: 0.523438]  [A loss: 0.854394, acc: 0.167969]\n",
            "2421: [D loss: 0.691621, acc: 0.529297]  [A loss: 0.760381, acc: 0.355469]\n",
            "2422: [D loss: 0.698900, acc: 0.535156]  [A loss: 0.868490, acc: 0.167969]\n",
            "2423: [D loss: 0.701116, acc: 0.509766]  [A loss: 0.787257, acc: 0.292969]\n",
            "2424: [D loss: 0.699524, acc: 0.541016]  [A loss: 0.907663, acc: 0.125000]\n",
            "2425: [D loss: 0.682187, acc: 0.548828]  [A loss: 0.777641, acc: 0.308594]\n",
            "2426: [D loss: 0.689483, acc: 0.552734]  [A loss: 0.882516, acc: 0.199219]\n",
            "2427: [D loss: 0.708178, acc: 0.531250]  [A loss: 0.791979, acc: 0.312500]\n",
            "2428: [D loss: 0.691087, acc: 0.576172]  [A loss: 0.927658, acc: 0.132812]\n",
            "2429: [D loss: 0.693119, acc: 0.517578]  [A loss: 0.828551, acc: 0.261719]\n",
            "2430: [D loss: 0.698083, acc: 0.515625]  [A loss: 0.850505, acc: 0.218750]\n",
            "2431: [D loss: 0.701455, acc: 0.513672]  [A loss: 0.854114, acc: 0.195312]\n",
            "2432: [D loss: 0.698139, acc: 0.513672]  [A loss: 0.825896, acc: 0.242188]\n",
            "2433: [D loss: 0.687837, acc: 0.572266]  [A loss: 0.819463, acc: 0.246094]\n",
            "2434: [D loss: 0.701697, acc: 0.519531]  [A loss: 0.966522, acc: 0.058594]\n",
            "2435: [D loss: 0.692377, acc: 0.537109]  [A loss: 0.733566, acc: 0.441406]\n",
            "2436: [D loss: 0.711293, acc: 0.509766]  [A loss: 1.011222, acc: 0.054688]\n",
            "2437: [D loss: 0.700276, acc: 0.507812]  [A loss: 0.689579, acc: 0.535156]\n",
            "2438: [D loss: 0.726363, acc: 0.476562]  [A loss: 1.078597, acc: 0.050781]\n",
            "2439: [D loss: 0.697663, acc: 0.527344]  [A loss: 0.679247, acc: 0.539062]\n",
            "2440: [D loss: 0.708637, acc: 0.525391]  [A loss: 0.921285, acc: 0.113281]\n",
            "2441: [D loss: 0.691109, acc: 0.523438]  [A loss: 0.723228, acc: 0.453125]\n",
            "2442: [D loss: 0.704729, acc: 0.521484]  [A loss: 0.858389, acc: 0.195312]\n",
            "2443: [D loss: 0.692715, acc: 0.541016]  [A loss: 0.758634, acc: 0.320312]\n",
            "2444: [D loss: 0.705927, acc: 0.521484]  [A loss: 0.917076, acc: 0.109375]\n",
            "2445: [D loss: 0.681147, acc: 0.560547]  [A loss: 0.727845, acc: 0.445312]\n",
            "2446: [D loss: 0.692253, acc: 0.542969]  [A loss: 0.891429, acc: 0.175781]\n",
            "2447: [D loss: 0.675736, acc: 0.570312]  [A loss: 0.821088, acc: 0.269531]\n",
            "2448: [D loss: 0.696548, acc: 0.529297]  [A loss: 0.834998, acc: 0.234375]\n",
            "2449: [D loss: 0.705112, acc: 0.509766]  [A loss: 0.845157, acc: 0.199219]\n",
            "2450: [D loss: 0.691198, acc: 0.542969]  [A loss: 0.831964, acc: 0.226562]\n",
            "2451: [D loss: 0.701030, acc: 0.511719]  [A loss: 0.857490, acc: 0.179688]\n",
            "2452: [D loss: 0.701234, acc: 0.511719]  [A loss: 0.875971, acc: 0.152344]\n",
            "2453: [D loss: 0.699822, acc: 0.515625]  [A loss: 0.817223, acc: 0.257812]\n",
            "2454: [D loss: 0.694759, acc: 0.535156]  [A loss: 0.894518, acc: 0.144531]\n",
            "2455: [D loss: 0.684921, acc: 0.564453]  [A loss: 0.745828, acc: 0.398438]\n",
            "2456: [D loss: 0.715872, acc: 0.519531]  [A loss: 0.884297, acc: 0.117188]\n",
            "2457: [D loss: 0.686191, acc: 0.541016]  [A loss: 0.745294, acc: 0.402344]\n",
            "2458: [D loss: 0.697215, acc: 0.521484]  [A loss: 0.921270, acc: 0.105469]\n",
            "2459: [D loss: 0.693387, acc: 0.521484]  [A loss: 0.740882, acc: 0.406250]\n",
            "2460: [D loss: 0.700910, acc: 0.517578]  [A loss: 0.890336, acc: 0.179688]\n",
            "2461: [D loss: 0.679914, acc: 0.552734]  [A loss: 0.713044, acc: 0.464844]\n",
            "2462: [D loss: 0.708810, acc: 0.480469]  [A loss: 0.906860, acc: 0.132812]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2463: [D loss: 0.694210, acc: 0.527344]  [A loss: 0.692177, acc: 0.515625]\n",
            "2464: [D loss: 0.706732, acc: 0.531250]  [A loss: 0.903418, acc: 0.140625]\n",
            "2465: [D loss: 0.686009, acc: 0.544922]  [A loss: 0.765063, acc: 0.371094]\n",
            "2466: [D loss: 0.699522, acc: 0.535156]  [A loss: 0.870929, acc: 0.191406]\n",
            "2467: [D loss: 0.693891, acc: 0.521484]  [A loss: 0.800210, acc: 0.300781]\n",
            "2468: [D loss: 0.701195, acc: 0.484375]  [A loss: 0.854599, acc: 0.148438]\n",
            "2469: [D loss: 0.694396, acc: 0.525391]  [A loss: 0.829825, acc: 0.207031]\n",
            "2470: [D loss: 0.699197, acc: 0.517578]  [A loss: 0.865847, acc: 0.179688]\n",
            "2471: [D loss: 0.696315, acc: 0.533203]  [A loss: 0.843870, acc: 0.187500]\n",
            "2472: [D loss: 0.693516, acc: 0.537109]  [A loss: 0.829253, acc: 0.191406]\n",
            "2473: [D loss: 0.693847, acc: 0.519531]  [A loss: 0.913270, acc: 0.136719]\n",
            "2474: [D loss: 0.698541, acc: 0.529297]  [A loss: 0.768057, acc: 0.363281]\n",
            "2475: [D loss: 0.695536, acc: 0.556641]  [A loss: 0.959114, acc: 0.085938]\n",
            "2476: [D loss: 0.697098, acc: 0.531250]  [A loss: 0.691976, acc: 0.539062]\n",
            "2477: [D loss: 0.708946, acc: 0.527344]  [A loss: 1.028237, acc: 0.054688]\n",
            "2478: [D loss: 0.698332, acc: 0.544922]  [A loss: 0.691834, acc: 0.480469]\n",
            "2479: [D loss: 0.700573, acc: 0.533203]  [A loss: 0.901709, acc: 0.140625]\n",
            "2480: [D loss: 0.684649, acc: 0.556641]  [A loss: 0.731302, acc: 0.410156]\n",
            "2481: [D loss: 0.714166, acc: 0.488281]  [A loss: 0.875029, acc: 0.171875]\n",
            "2482: [D loss: 0.686221, acc: 0.539062]  [A loss: 0.814412, acc: 0.238281]\n",
            "2483: [D loss: 0.686753, acc: 0.550781]  [A loss: 0.857424, acc: 0.175781]\n",
            "2484: [D loss: 0.688506, acc: 0.548828]  [A loss: 0.827266, acc: 0.207031]\n",
            "2485: [D loss: 0.698133, acc: 0.513672]  [A loss: 0.905363, acc: 0.128906]\n",
            "2486: [D loss: 0.699497, acc: 0.523438]  [A loss: 0.800724, acc: 0.292969]\n",
            "2487: [D loss: 0.693627, acc: 0.552734]  [A loss: 0.844635, acc: 0.230469]\n",
            "2488: [D loss: 0.680476, acc: 0.564453]  [A loss: 0.826884, acc: 0.261719]\n",
            "2489: [D loss: 0.705521, acc: 0.501953]  [A loss: 0.880004, acc: 0.152344]\n",
            "2490: [D loss: 0.680715, acc: 0.576172]  [A loss: 0.792412, acc: 0.316406]\n",
            "2491: [D loss: 0.707733, acc: 0.527344]  [A loss: 0.965296, acc: 0.082031]\n",
            "2492: [D loss: 0.688843, acc: 0.550781]  [A loss: 0.713993, acc: 0.476562]\n",
            "2493: [D loss: 0.703810, acc: 0.527344]  [A loss: 0.921034, acc: 0.082031]\n",
            "2494: [D loss: 0.693947, acc: 0.539062]  [A loss: 0.814731, acc: 0.261719]\n",
            "2495: [D loss: 0.701167, acc: 0.527344]  [A loss: 0.909479, acc: 0.140625]\n",
            "2496: [D loss: 0.699547, acc: 0.513672]  [A loss: 0.813171, acc: 0.261719]\n",
            "2497: [D loss: 0.697818, acc: 0.537109]  [A loss: 0.861921, acc: 0.191406]\n",
            "2498: [D loss: 0.690864, acc: 0.537109]  [A loss: 0.823524, acc: 0.222656]\n",
            "2499: [D loss: 0.689992, acc: 0.523438]  [A loss: 0.871442, acc: 0.132812]\n",
            "2500: [D loss: 0.700851, acc: 0.519531]  [A loss: 0.786706, acc: 0.339844]\n",
            "2501: [D loss: 0.696448, acc: 0.527344]  [A loss: 0.825189, acc: 0.226562]\n",
            "2502: [D loss: 0.694523, acc: 0.517578]  [A loss: 0.838273, acc: 0.242188]\n",
            "2503: [D loss: 0.699825, acc: 0.519531]  [A loss: 0.823767, acc: 0.222656]\n",
            "2504: [D loss: 0.698908, acc: 0.531250]  [A loss: 0.801483, acc: 0.277344]\n",
            "2505: [D loss: 0.708951, acc: 0.501953]  [A loss: 0.789063, acc: 0.273438]\n",
            "2506: [D loss: 0.689706, acc: 0.548828]  [A loss: 0.877284, acc: 0.171875]\n",
            "2507: [D loss: 0.709981, acc: 0.490234]  [A loss: 0.866877, acc: 0.171875]\n",
            "2508: [D loss: 0.687369, acc: 0.539062]  [A loss: 0.869105, acc: 0.187500]\n",
            "2509: [D loss: 0.687995, acc: 0.554688]  [A loss: 0.801448, acc: 0.312500]\n",
            "2510: [D loss: 0.703186, acc: 0.535156]  [A loss: 0.833872, acc: 0.242188]\n",
            "2511: [D loss: 0.706020, acc: 0.511719]  [A loss: 0.912314, acc: 0.105469]\n",
            "2512: [D loss: 0.693444, acc: 0.511719]  [A loss: 0.862953, acc: 0.167969]\n",
            "2513: [D loss: 0.697202, acc: 0.554688]  [A loss: 0.859400, acc: 0.175781]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2514: [D loss: 0.685283, acc: 0.541016]  [A loss: 0.820493, acc: 0.218750]\n",
            "2515: [D loss: 0.695722, acc: 0.544922]  [A loss: 0.915954, acc: 0.167969]\n",
            "2516: [D loss: 0.690270, acc: 0.558594]  [A loss: 0.721204, acc: 0.437500]\n",
            "2517: [D loss: 0.718004, acc: 0.515625]  [A loss: 1.025281, acc: 0.046875]\n",
            "2518: [D loss: 0.687876, acc: 0.533203]  [A loss: 0.706317, acc: 0.460938]\n",
            "2519: [D loss: 0.708736, acc: 0.519531]  [A loss: 1.125441, acc: 0.035156]\n",
            "2520: [D loss: 0.700179, acc: 0.517578]  [A loss: 0.636898, acc: 0.648438]\n",
            "2521: [D loss: 0.726481, acc: 0.511719]  [A loss: 0.934417, acc: 0.097656]\n",
            "2522: [D loss: 0.696928, acc: 0.523438]  [A loss: 0.778706, acc: 0.312500]\n",
            "2523: [D loss: 0.703981, acc: 0.521484]  [A loss: 0.866390, acc: 0.156250]\n",
            "2524: [D loss: 0.694782, acc: 0.501953]  [A loss: 0.792451, acc: 0.281250]\n",
            "2525: [D loss: 0.700022, acc: 0.507812]  [A loss: 0.862624, acc: 0.175781]\n",
            "2526: [D loss: 0.702527, acc: 0.500000]  [A loss: 0.817775, acc: 0.246094]\n",
            "2527: [D loss: 0.706761, acc: 0.505859]  [A loss: 0.814612, acc: 0.300781]\n",
            "2528: [D loss: 0.686500, acc: 0.552734]  [A loss: 0.841267, acc: 0.261719]\n",
            "2529: [D loss: 0.693764, acc: 0.558594]  [A loss: 0.812963, acc: 0.257812]\n",
            "2530: [D loss: 0.710778, acc: 0.521484]  [A loss: 0.871965, acc: 0.171875]\n",
            "2531: [D loss: 0.686269, acc: 0.552734]  [A loss: 0.776474, acc: 0.339844]\n",
            "2532: [D loss: 0.703727, acc: 0.517578]  [A loss: 0.910051, acc: 0.117188]\n",
            "2533: [D loss: 0.694501, acc: 0.531250]  [A loss: 0.760707, acc: 0.355469]\n",
            "2534: [D loss: 0.697865, acc: 0.546875]  [A loss: 0.913812, acc: 0.144531]\n",
            "2535: [D loss: 0.683879, acc: 0.554688]  [A loss: 0.742968, acc: 0.394531]\n",
            "2536: [D loss: 0.708072, acc: 0.535156]  [A loss: 0.929400, acc: 0.117188]\n",
            "2537: [D loss: 0.699821, acc: 0.505859]  [A loss: 0.645123, acc: 0.664062]\n",
            "2538: [D loss: 0.723534, acc: 0.500000]  [A loss: 0.967837, acc: 0.089844]\n",
            "2539: [D loss: 0.699127, acc: 0.531250]  [A loss: 0.661480, acc: 0.605469]\n",
            "2540: [D loss: 0.735849, acc: 0.501953]  [A loss: 0.942578, acc: 0.128906]\n",
            "2541: [D loss: 0.690615, acc: 0.535156]  [A loss: 0.736010, acc: 0.394531]\n",
            "2542: [D loss: 0.700260, acc: 0.537109]  [A loss: 0.895122, acc: 0.171875]\n",
            "2543: [D loss: 0.698715, acc: 0.529297]  [A loss: 0.748756, acc: 0.367188]\n",
            "2544: [D loss: 0.695432, acc: 0.527344]  [A loss: 0.855171, acc: 0.203125]\n",
            "2545: [D loss: 0.716008, acc: 0.501953]  [A loss: 0.828111, acc: 0.203125]\n",
            "2546: [D loss: 0.695301, acc: 0.546875]  [A loss: 0.762084, acc: 0.328125]\n",
            "2547: [D loss: 0.698301, acc: 0.533203]  [A loss: 0.846815, acc: 0.187500]\n",
            "2548: [D loss: 0.694854, acc: 0.541016]  [A loss: 0.765817, acc: 0.324219]\n",
            "2549: [D loss: 0.696915, acc: 0.537109]  [A loss: 0.882772, acc: 0.167969]\n",
            "2550: [D loss: 0.675326, acc: 0.593750]  [A loss: 0.796257, acc: 0.269531]\n",
            "2551: [D loss: 0.684334, acc: 0.572266]  [A loss: 0.821712, acc: 0.226562]\n",
            "2552: [D loss: 0.692222, acc: 0.548828]  [A loss: 0.863052, acc: 0.183594]\n",
            "2553: [D loss: 0.690791, acc: 0.552734]  [A loss: 0.787192, acc: 0.316406]\n",
            "2554: [D loss: 0.698602, acc: 0.535156]  [A loss: 0.844499, acc: 0.214844]\n",
            "2555: [D loss: 0.689508, acc: 0.529297]  [A loss: 0.804011, acc: 0.246094]\n",
            "2556: [D loss: 0.687149, acc: 0.554688]  [A loss: 0.880585, acc: 0.140625]\n",
            "2557: [D loss: 0.689291, acc: 0.546875]  [A loss: 0.790687, acc: 0.304688]\n",
            "2558: [D loss: 0.695730, acc: 0.505859]  [A loss: 0.909219, acc: 0.085938]\n",
            "2559: [D loss: 0.698917, acc: 0.519531]  [A loss: 0.870210, acc: 0.179688]\n",
            "2560: [D loss: 0.694872, acc: 0.523438]  [A loss: 0.758212, acc: 0.402344]\n",
            "2561: [D loss: 0.712383, acc: 0.500000]  [A loss: 0.887494, acc: 0.140625]\n",
            "2562: [D loss: 0.684119, acc: 0.550781]  [A loss: 0.692203, acc: 0.527344]\n",
            "2563: [D loss: 0.723391, acc: 0.480469]  [A loss: 0.969433, acc: 0.074219]\n",
            "2564: [D loss: 0.694787, acc: 0.542969]  [A loss: 0.720874, acc: 0.457031]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2565: [D loss: 0.720753, acc: 0.507812]  [A loss: 0.880111, acc: 0.144531]\n",
            "2566: [D loss: 0.697616, acc: 0.552734]  [A loss: 0.773956, acc: 0.351562]\n",
            "2567: [D loss: 0.701838, acc: 0.515625]  [A loss: 0.842480, acc: 0.234375]\n",
            "2568: [D loss: 0.703248, acc: 0.500000]  [A loss: 0.859655, acc: 0.203125]\n",
            "2569: [D loss: 0.701014, acc: 0.515625]  [A loss: 0.783794, acc: 0.285156]\n",
            "2570: [D loss: 0.701646, acc: 0.517578]  [A loss: 0.867558, acc: 0.187500]\n",
            "2571: [D loss: 0.688062, acc: 0.544922]  [A loss: 0.770989, acc: 0.335938]\n",
            "2572: [D loss: 0.701785, acc: 0.511719]  [A loss: 0.901444, acc: 0.136719]\n",
            "2573: [D loss: 0.685774, acc: 0.541016]  [A loss: 0.781315, acc: 0.300781]\n",
            "2574: [D loss: 0.699186, acc: 0.535156]  [A loss: 0.883940, acc: 0.148438]\n",
            "2575: [D loss: 0.698964, acc: 0.515625]  [A loss: 0.714919, acc: 0.417969]\n",
            "2576: [D loss: 0.706765, acc: 0.523438]  [A loss: 0.984215, acc: 0.078125]\n",
            "2577: [D loss: 0.697000, acc: 0.517578]  [A loss: 0.790470, acc: 0.332031]\n",
            "2578: [D loss: 0.700233, acc: 0.515625]  [A loss: 0.917127, acc: 0.117188]\n",
            "2579: [D loss: 0.694531, acc: 0.544922]  [A loss: 0.739939, acc: 0.421875]\n",
            "2580: [D loss: 0.701964, acc: 0.539062]  [A loss: 1.033215, acc: 0.062500]\n",
            "2581: [D loss: 0.694694, acc: 0.535156]  [A loss: 0.679192, acc: 0.546875]\n",
            "2582: [D loss: 0.713952, acc: 0.509766]  [A loss: 0.927108, acc: 0.125000]\n",
            "2583: [D loss: 0.698380, acc: 0.544922]  [A loss: 0.725494, acc: 0.414062]\n",
            "2584: [D loss: 0.692659, acc: 0.566406]  [A loss: 0.850147, acc: 0.191406]\n",
            "2585: [D loss: 0.693151, acc: 0.533203]  [A loss: 0.764868, acc: 0.386719]\n",
            "2586: [D loss: 0.706382, acc: 0.503906]  [A loss: 0.871647, acc: 0.164062]\n",
            "2587: [D loss: 0.704733, acc: 0.480469]  [A loss: 0.784018, acc: 0.269531]\n",
            "2588: [D loss: 0.707754, acc: 0.511719]  [A loss: 0.896522, acc: 0.121094]\n",
            "2589: [D loss: 0.705425, acc: 0.466797]  [A loss: 0.788340, acc: 0.304688]\n",
            "2590: [D loss: 0.695007, acc: 0.542969]  [A loss: 0.854035, acc: 0.183594]\n",
            "2591: [D loss: 0.696800, acc: 0.527344]  [A loss: 0.815988, acc: 0.238281]\n",
            "2592: [D loss: 0.697566, acc: 0.525391]  [A loss: 0.773320, acc: 0.308594]\n",
            "2593: [D loss: 0.689259, acc: 0.539062]  [A loss: 0.884058, acc: 0.167969]\n",
            "2594: [D loss: 0.694804, acc: 0.519531]  [A loss: 0.806573, acc: 0.289062]\n",
            "2595: [D loss: 0.702205, acc: 0.527344]  [A loss: 0.874346, acc: 0.164062]\n",
            "2596: [D loss: 0.693857, acc: 0.529297]  [A loss: 0.811511, acc: 0.246094]\n",
            "2597: [D loss: 0.698296, acc: 0.533203]  [A loss: 0.908546, acc: 0.132812]\n",
            "2598: [D loss: 0.700198, acc: 0.519531]  [A loss: 0.785381, acc: 0.289062]\n",
            "2599: [D loss: 0.688343, acc: 0.544922]  [A loss: 0.850271, acc: 0.222656]\n",
            "2600: [D loss: 0.682961, acc: 0.570312]  [A loss: 0.789991, acc: 0.289062]\n",
            "2601: [D loss: 0.713242, acc: 0.484375]  [A loss: 0.935842, acc: 0.117188]\n",
            "2602: [D loss: 0.680290, acc: 0.578125]  [A loss: 0.689989, acc: 0.550781]\n",
            "2603: [D loss: 0.731075, acc: 0.472656]  [A loss: 0.951000, acc: 0.105469]\n",
            "2604: [D loss: 0.696037, acc: 0.539062]  [A loss: 0.741477, acc: 0.421875]\n",
            "2605: [D loss: 0.694002, acc: 0.546875]  [A loss: 0.943973, acc: 0.128906]\n",
            "2606: [D loss: 0.697904, acc: 0.488281]  [A loss: 0.727968, acc: 0.437500]\n",
            "2607: [D loss: 0.707761, acc: 0.521484]  [A loss: 0.946954, acc: 0.125000]\n",
            "2608: [D loss: 0.698150, acc: 0.535156]  [A loss: 0.690539, acc: 0.531250]\n",
            "2609: [D loss: 0.706476, acc: 0.521484]  [A loss: 0.866526, acc: 0.191406]\n",
            "2610: [D loss: 0.689176, acc: 0.531250]  [A loss: 0.779945, acc: 0.343750]\n",
            "2611: [D loss: 0.710417, acc: 0.523438]  [A loss: 0.869978, acc: 0.167969]\n",
            "2612: [D loss: 0.689834, acc: 0.541016]  [A loss: 0.802403, acc: 0.300781]\n",
            "2613: [D loss: 0.689102, acc: 0.544922]  [A loss: 0.856843, acc: 0.183594]\n",
            "2614: [D loss: 0.703613, acc: 0.501953]  [A loss: 0.789467, acc: 0.308594]\n",
            "2615: [D loss: 0.692029, acc: 0.539062]  [A loss: 0.884412, acc: 0.183594]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2616: [D loss: 0.691389, acc: 0.533203]  [A loss: 0.777508, acc: 0.312500]\n",
            "2617: [D loss: 0.717435, acc: 0.484375]  [A loss: 0.910706, acc: 0.128906]\n",
            "2618: [D loss: 0.686660, acc: 0.564453]  [A loss: 0.801602, acc: 0.273438]\n",
            "2619: [D loss: 0.685677, acc: 0.548828]  [A loss: 0.897968, acc: 0.160156]\n",
            "2620: [D loss: 0.684881, acc: 0.542969]  [A loss: 0.755235, acc: 0.371094]\n",
            "2621: [D loss: 0.718455, acc: 0.515625]  [A loss: 0.924107, acc: 0.132812]\n",
            "2622: [D loss: 0.688690, acc: 0.529297]  [A loss: 0.705551, acc: 0.468750]\n",
            "2623: [D loss: 0.715279, acc: 0.496094]  [A loss: 0.906018, acc: 0.128906]\n",
            "2624: [D loss: 0.692960, acc: 0.564453]  [A loss: 0.681939, acc: 0.570312]\n",
            "2625: [D loss: 0.733508, acc: 0.484375]  [A loss: 0.944218, acc: 0.101562]\n",
            "2626: [D loss: 0.703740, acc: 0.498047]  [A loss: 0.763173, acc: 0.375000]\n",
            "2627: [D loss: 0.702574, acc: 0.505859]  [A loss: 0.843093, acc: 0.183594]\n",
            "2628: [D loss: 0.695032, acc: 0.541016]  [A loss: 0.763802, acc: 0.328125]\n",
            "2629: [D loss: 0.703508, acc: 0.500000]  [A loss: 0.834895, acc: 0.195312]\n",
            "2630: [D loss: 0.704223, acc: 0.515625]  [A loss: 0.748834, acc: 0.378906]\n",
            "2631: [D loss: 0.700605, acc: 0.517578]  [A loss: 0.942706, acc: 0.121094]\n",
            "2632: [D loss: 0.680949, acc: 0.570312]  [A loss: 0.750932, acc: 0.394531]\n",
            "2633: [D loss: 0.709200, acc: 0.519531]  [A loss: 0.929218, acc: 0.097656]\n",
            "2634: [D loss: 0.693250, acc: 0.511719]  [A loss: 0.693885, acc: 0.496094]\n",
            "2635: [D loss: 0.714203, acc: 0.513672]  [A loss: 1.006613, acc: 0.066406]\n",
            "2636: [D loss: 0.692234, acc: 0.542969]  [A loss: 0.741416, acc: 0.406250]\n",
            "2637: [D loss: 0.703578, acc: 0.527344]  [A loss: 0.938660, acc: 0.148438]\n",
            "2638: [D loss: 0.699197, acc: 0.505859]  [A loss: 0.741158, acc: 0.410156]\n",
            "2639: [D loss: 0.711917, acc: 0.519531]  [A loss: 0.886028, acc: 0.179688]\n",
            "2640: [D loss: 0.697520, acc: 0.490234]  [A loss: 0.793318, acc: 0.273438]\n",
            "2641: [D loss: 0.688699, acc: 0.537109]  [A loss: 0.787667, acc: 0.304688]\n",
            "2642: [D loss: 0.701377, acc: 0.507812]  [A loss: 0.899954, acc: 0.148438]\n",
            "2643: [D loss: 0.687567, acc: 0.558594]  [A loss: 0.719509, acc: 0.488281]\n",
            "2644: [D loss: 0.697268, acc: 0.542969]  [A loss: 0.907341, acc: 0.144531]\n",
            "2645: [D loss: 0.686224, acc: 0.527344]  [A loss: 0.798751, acc: 0.296875]\n",
            "2646: [D loss: 0.698314, acc: 0.552734]  [A loss: 0.831646, acc: 0.222656]\n",
            "2647: [D loss: 0.694670, acc: 0.523438]  [A loss: 0.806545, acc: 0.234375]\n",
            "2648: [D loss: 0.679986, acc: 0.556641]  [A loss: 0.878985, acc: 0.132812]\n",
            "2649: [D loss: 0.690574, acc: 0.537109]  [A loss: 0.838701, acc: 0.210938]\n",
            "2650: [D loss: 0.701385, acc: 0.541016]  [A loss: 0.848774, acc: 0.226562]\n",
            "2651: [D loss: 0.687723, acc: 0.564453]  [A loss: 0.780080, acc: 0.371094]\n",
            "2652: [D loss: 0.694489, acc: 0.537109]  [A loss: 0.866746, acc: 0.226562]\n",
            "2653: [D loss: 0.693989, acc: 0.535156]  [A loss: 0.794205, acc: 0.304688]\n",
            "2654: [D loss: 0.701635, acc: 0.533203]  [A loss: 0.970804, acc: 0.105469]\n",
            "2655: [D loss: 0.702913, acc: 0.513672]  [A loss: 0.661486, acc: 0.613281]\n",
            "2656: [D loss: 0.715782, acc: 0.503906]  [A loss: 1.034810, acc: 0.035156]\n",
            "2657: [D loss: 0.690825, acc: 0.527344]  [A loss: 0.704042, acc: 0.539062]\n",
            "2658: [D loss: 0.718609, acc: 0.515625]  [A loss: 0.934667, acc: 0.132812]\n",
            "2659: [D loss: 0.680867, acc: 0.546875]  [A loss: 0.711677, acc: 0.468750]\n",
            "2660: [D loss: 0.717755, acc: 0.511719]  [A loss: 0.861054, acc: 0.171875]\n",
            "2661: [D loss: 0.683655, acc: 0.564453]  [A loss: 0.764254, acc: 0.328125]\n",
            "2662: [D loss: 0.706524, acc: 0.525391]  [A loss: 0.787462, acc: 0.312500]\n",
            "2663: [D loss: 0.696453, acc: 0.537109]  [A loss: 0.790653, acc: 0.261719]\n",
            "2664: [D loss: 0.696664, acc: 0.521484]  [A loss: 0.827005, acc: 0.222656]\n",
            "2665: [D loss: 0.695311, acc: 0.554688]  [A loss: 0.835254, acc: 0.199219]\n",
            "2666: [D loss: 0.695069, acc: 0.523438]  [A loss: 0.833053, acc: 0.195312]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2667: [D loss: 0.683584, acc: 0.566406]  [A loss: 0.784418, acc: 0.308594]\n",
            "2668: [D loss: 0.690039, acc: 0.550781]  [A loss: 0.862295, acc: 0.160156]\n",
            "2669: [D loss: 0.688771, acc: 0.548828]  [A loss: 0.795930, acc: 0.320312]\n",
            "2670: [D loss: 0.706544, acc: 0.496094]  [A loss: 0.854432, acc: 0.187500]\n",
            "2671: [D loss: 0.698593, acc: 0.535156]  [A loss: 0.830913, acc: 0.257812]\n",
            "2672: [D loss: 0.684989, acc: 0.572266]  [A loss: 0.892952, acc: 0.187500]\n",
            "2673: [D loss: 0.699175, acc: 0.525391]  [A loss: 0.759040, acc: 0.406250]\n",
            "2674: [D loss: 0.708411, acc: 0.503906]  [A loss: 0.972950, acc: 0.062500]\n",
            "2675: [D loss: 0.687257, acc: 0.558594]  [A loss: 0.720855, acc: 0.460938]\n",
            "2676: [D loss: 0.711368, acc: 0.494141]  [A loss: 0.930281, acc: 0.109375]\n",
            "2677: [D loss: 0.699053, acc: 0.515625]  [A loss: 0.715075, acc: 0.480469]\n",
            "2678: [D loss: 0.719826, acc: 0.509766]  [A loss: 0.987978, acc: 0.062500]\n",
            "2679: [D loss: 0.688553, acc: 0.537109]  [A loss: 0.711359, acc: 0.464844]\n",
            "2680: [D loss: 0.711658, acc: 0.531250]  [A loss: 0.995047, acc: 0.066406]\n",
            "2681: [D loss: 0.708184, acc: 0.468750]  [A loss: 0.734602, acc: 0.406250]\n",
            "2682: [D loss: 0.706255, acc: 0.507812]  [A loss: 0.858545, acc: 0.183594]\n",
            "2683: [D loss: 0.698429, acc: 0.503906]  [A loss: 0.741516, acc: 0.402344]\n",
            "2684: [D loss: 0.710271, acc: 0.503906]  [A loss: 0.921118, acc: 0.136719]\n",
            "2685: [D loss: 0.689790, acc: 0.535156]  [A loss: 0.732508, acc: 0.445312]\n",
            "2686: [D loss: 0.695876, acc: 0.529297]  [A loss: 0.848055, acc: 0.214844]\n",
            "2687: [D loss: 0.700628, acc: 0.513672]  [A loss: 0.748138, acc: 0.414062]\n",
            "2688: [D loss: 0.723514, acc: 0.480469]  [A loss: 0.893167, acc: 0.128906]\n",
            "2689: [D loss: 0.705272, acc: 0.513672]  [A loss: 0.754792, acc: 0.359375]\n",
            "2690: [D loss: 0.709975, acc: 0.517578]  [A loss: 0.808403, acc: 0.257812]\n",
            "2691: [D loss: 0.701889, acc: 0.511719]  [A loss: 0.851513, acc: 0.183594]\n",
            "2692: [D loss: 0.690601, acc: 0.552734]  [A loss: 0.812294, acc: 0.261719]\n",
            "2693: [D loss: 0.704961, acc: 0.523438]  [A loss: 0.872371, acc: 0.187500]\n",
            "2694: [D loss: 0.695381, acc: 0.533203]  [A loss: 0.796715, acc: 0.285156]\n",
            "2695: [D loss: 0.683314, acc: 0.572266]  [A loss: 0.859570, acc: 0.183594]\n",
            "2696: [D loss: 0.695094, acc: 0.527344]  [A loss: 0.806179, acc: 0.242188]\n",
            "2697: [D loss: 0.705195, acc: 0.515625]  [A loss: 0.837970, acc: 0.214844]\n",
            "2698: [D loss: 0.698138, acc: 0.548828]  [A loss: 0.857763, acc: 0.203125]\n",
            "2699: [D loss: 0.699176, acc: 0.507812]  [A loss: 0.820083, acc: 0.238281]\n",
            "2700: [D loss: 0.697914, acc: 0.527344]  [A loss: 0.873812, acc: 0.156250]\n",
            "2701: [D loss: 0.696512, acc: 0.535156]  [A loss: 0.757719, acc: 0.371094]\n",
            "2702: [D loss: 0.707557, acc: 0.509766]  [A loss: 0.964287, acc: 0.109375]\n",
            "2703: [D loss: 0.691990, acc: 0.521484]  [A loss: 0.697281, acc: 0.503906]\n",
            "2704: [D loss: 0.716737, acc: 0.513672]  [A loss: 0.926512, acc: 0.125000]\n",
            "2705: [D loss: 0.696420, acc: 0.527344]  [A loss: 0.768702, acc: 0.359375]\n",
            "2706: [D loss: 0.691189, acc: 0.513672]  [A loss: 0.865440, acc: 0.199219]\n",
            "2707: [D loss: 0.684581, acc: 0.562500]  [A loss: 0.774573, acc: 0.328125]\n",
            "2708: [D loss: 0.703184, acc: 0.529297]  [A loss: 0.895638, acc: 0.179688]\n",
            "2709: [D loss: 0.693928, acc: 0.533203]  [A loss: 0.770247, acc: 0.312500]\n",
            "2710: [D loss: 0.701345, acc: 0.525391]  [A loss: 0.916675, acc: 0.121094]\n",
            "2711: [D loss: 0.695223, acc: 0.523438]  [A loss: 0.731397, acc: 0.441406]\n",
            "2712: [D loss: 0.716234, acc: 0.515625]  [A loss: 0.944522, acc: 0.109375]\n",
            "2713: [D loss: 0.704602, acc: 0.496094]  [A loss: 0.687571, acc: 0.515625]\n",
            "2714: [D loss: 0.738231, acc: 0.500000]  [A loss: 0.981699, acc: 0.070312]\n",
            "2715: [D loss: 0.691245, acc: 0.548828]  [A loss: 0.710499, acc: 0.500000]\n",
            "2716: [D loss: 0.684421, acc: 0.552734]  [A loss: 0.829494, acc: 0.261719]\n",
            "2717: [D loss: 0.703683, acc: 0.525391]  [A loss: 0.825704, acc: 0.238281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2718: [D loss: 0.693289, acc: 0.541016]  [A loss: 0.773431, acc: 0.351562]\n",
            "2719: [D loss: 0.695756, acc: 0.542969]  [A loss: 0.857311, acc: 0.187500]\n",
            "2720: [D loss: 0.684467, acc: 0.554688]  [A loss: 0.799810, acc: 0.273438]\n",
            "2721: [D loss: 0.700280, acc: 0.523438]  [A loss: 0.857183, acc: 0.195312]\n",
            "2722: [D loss: 0.706492, acc: 0.503906]  [A loss: 0.864514, acc: 0.171875]\n",
            "2723: [D loss: 0.684238, acc: 0.552734]  [A loss: 0.822641, acc: 0.222656]\n",
            "2724: [D loss: 0.697671, acc: 0.535156]  [A loss: 0.805406, acc: 0.273438]\n",
            "2725: [D loss: 0.706564, acc: 0.529297]  [A loss: 0.947293, acc: 0.140625]\n",
            "2726: [D loss: 0.703387, acc: 0.496094]  [A loss: 0.688101, acc: 0.554688]\n",
            "2727: [D loss: 0.714094, acc: 0.515625]  [A loss: 0.947518, acc: 0.097656]\n",
            "2728: [D loss: 0.676644, acc: 0.568359]  [A loss: 0.740330, acc: 0.417969]\n",
            "2729: [D loss: 0.717753, acc: 0.503906]  [A loss: 0.862902, acc: 0.199219]\n",
            "2730: [D loss: 0.707533, acc: 0.511719]  [A loss: 0.768992, acc: 0.351562]\n",
            "2731: [D loss: 0.697732, acc: 0.511719]  [A loss: 0.857074, acc: 0.171875]\n",
            "2732: [D loss: 0.707586, acc: 0.507812]  [A loss: 0.744962, acc: 0.398438]\n",
            "2733: [D loss: 0.702945, acc: 0.529297]  [A loss: 0.855110, acc: 0.203125]\n",
            "2734: [D loss: 0.699731, acc: 0.517578]  [A loss: 0.801528, acc: 0.312500]\n",
            "2735: [D loss: 0.700605, acc: 0.525391]  [A loss: 0.856652, acc: 0.191406]\n",
            "2736: [D loss: 0.705307, acc: 0.466797]  [A loss: 0.800811, acc: 0.265625]\n",
            "2737: [D loss: 0.697390, acc: 0.542969]  [A loss: 0.817051, acc: 0.253906]\n",
            "2738: [D loss: 0.689016, acc: 0.531250]  [A loss: 0.866918, acc: 0.171875]\n",
            "2739: [D loss: 0.694000, acc: 0.546875]  [A loss: 0.727925, acc: 0.417969]\n",
            "2740: [D loss: 0.711433, acc: 0.507812]  [A loss: 0.957408, acc: 0.105469]\n",
            "2741: [D loss: 0.699829, acc: 0.525391]  [A loss: 0.697527, acc: 0.488281]\n",
            "2742: [D loss: 0.711656, acc: 0.511719]  [A loss: 0.950513, acc: 0.082031]\n",
            "2743: [D loss: 0.701883, acc: 0.505859]  [A loss: 0.733177, acc: 0.425781]\n",
            "2744: [D loss: 0.710584, acc: 0.523438]  [A loss: 0.851473, acc: 0.175781]\n",
            "2745: [D loss: 0.683492, acc: 0.550781]  [A loss: 0.765168, acc: 0.351562]\n",
            "2746: [D loss: 0.722485, acc: 0.488281]  [A loss: 0.917881, acc: 0.144531]\n",
            "2747: [D loss: 0.690507, acc: 0.542969]  [A loss: 0.736223, acc: 0.417969]\n",
            "2748: [D loss: 0.725449, acc: 0.482422]  [A loss: 0.879041, acc: 0.152344]\n",
            "2749: [D loss: 0.688902, acc: 0.580078]  [A loss: 0.738652, acc: 0.429688]\n",
            "2750: [D loss: 0.692306, acc: 0.544922]  [A loss: 0.842578, acc: 0.250000]\n",
            "2751: [D loss: 0.685739, acc: 0.585938]  [A loss: 0.780166, acc: 0.292969]\n",
            "2752: [D loss: 0.697698, acc: 0.529297]  [A loss: 0.895300, acc: 0.167969]\n",
            "2753: [D loss: 0.680465, acc: 0.566406]  [A loss: 0.706323, acc: 0.515625]\n",
            "2754: [D loss: 0.713176, acc: 0.515625]  [A loss: 1.028600, acc: 0.066406]\n",
            "2755: [D loss: 0.690492, acc: 0.544922]  [A loss: 0.689801, acc: 0.523438]\n",
            "2756: [D loss: 0.730344, acc: 0.490234]  [A loss: 0.931872, acc: 0.101562]\n",
            "2757: [D loss: 0.689632, acc: 0.527344]  [A loss: 0.718510, acc: 0.421875]\n",
            "2758: [D loss: 0.703985, acc: 0.539062]  [A loss: 0.875378, acc: 0.164062]\n",
            "2759: [D loss: 0.705616, acc: 0.517578]  [A loss: 0.767855, acc: 0.367188]\n",
            "2760: [D loss: 0.707137, acc: 0.498047]  [A loss: 0.813030, acc: 0.234375]\n",
            "2761: [D loss: 0.700308, acc: 0.552734]  [A loss: 0.776268, acc: 0.324219]\n",
            "2762: [D loss: 0.690021, acc: 0.556641]  [A loss: 0.885314, acc: 0.195312]\n",
            "2763: [D loss: 0.693158, acc: 0.542969]  [A loss: 0.762486, acc: 0.355469]\n",
            "2764: [D loss: 0.701044, acc: 0.539062]  [A loss: 0.864135, acc: 0.187500]\n",
            "2765: [D loss: 0.675563, acc: 0.578125]  [A loss: 0.776131, acc: 0.320312]\n",
            "2766: [D loss: 0.698708, acc: 0.544922]  [A loss: 0.888316, acc: 0.160156]\n",
            "2767: [D loss: 0.687769, acc: 0.550781]  [A loss: 0.774784, acc: 0.289062]\n",
            "2768: [D loss: 0.700543, acc: 0.537109]  [A loss: 0.870986, acc: 0.199219]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2769: [D loss: 0.700718, acc: 0.515625]  [A loss: 0.789107, acc: 0.289062]\n",
            "2770: [D loss: 0.690800, acc: 0.535156]  [A loss: 0.904888, acc: 0.136719]\n",
            "2771: [D loss: 0.685961, acc: 0.529297]  [A loss: 0.785120, acc: 0.296875]\n",
            "2772: [D loss: 0.706401, acc: 0.523438]  [A loss: 0.895748, acc: 0.152344]\n",
            "2773: [D loss: 0.690363, acc: 0.525391]  [A loss: 0.777326, acc: 0.394531]\n",
            "2774: [D loss: 0.721882, acc: 0.490234]  [A loss: 1.018127, acc: 0.050781]\n",
            "2775: [D loss: 0.692328, acc: 0.527344]  [A loss: 0.693376, acc: 0.500000]\n",
            "2776: [D loss: 0.723681, acc: 0.535156]  [A loss: 1.005922, acc: 0.042969]\n",
            "2777: [D loss: 0.696533, acc: 0.500000]  [A loss: 0.760861, acc: 0.351562]\n",
            "2778: [D loss: 0.712232, acc: 0.521484]  [A loss: 0.876880, acc: 0.121094]\n",
            "2779: [D loss: 0.686466, acc: 0.562500]  [A loss: 0.747834, acc: 0.378906]\n",
            "2780: [D loss: 0.707428, acc: 0.521484]  [A loss: 0.811525, acc: 0.265625]\n",
            "2781: [D loss: 0.688757, acc: 0.544922]  [A loss: 0.801921, acc: 0.289062]\n",
            "2782: [D loss: 0.691209, acc: 0.558594]  [A loss: 0.816352, acc: 0.230469]\n",
            "2783: [D loss: 0.703693, acc: 0.509766]  [A loss: 0.805514, acc: 0.277344]\n",
            "2784: [D loss: 0.708416, acc: 0.529297]  [A loss: 0.893972, acc: 0.167969]\n",
            "2785: [D loss: 0.682389, acc: 0.531250]  [A loss: 0.735960, acc: 0.421875]\n",
            "2786: [D loss: 0.715149, acc: 0.531250]  [A loss: 0.903952, acc: 0.136719]\n",
            "2787: [D loss: 0.695746, acc: 0.546875]  [A loss: 0.716212, acc: 0.453125]\n",
            "2788: [D loss: 0.690619, acc: 0.531250]  [A loss: 0.947321, acc: 0.085938]\n",
            "2789: [D loss: 0.693925, acc: 0.527344]  [A loss: 0.718592, acc: 0.453125]\n",
            "2790: [D loss: 0.708707, acc: 0.533203]  [A loss: 0.891380, acc: 0.167969]\n",
            "2791: [D loss: 0.693888, acc: 0.525391]  [A loss: 0.752239, acc: 0.394531]\n",
            "2792: [D loss: 0.720553, acc: 0.501953]  [A loss: 0.916382, acc: 0.117188]\n",
            "2793: [D loss: 0.695185, acc: 0.525391]  [A loss: 0.707631, acc: 0.472656]\n",
            "2794: [D loss: 0.708311, acc: 0.507812]  [A loss: 0.929865, acc: 0.101562]\n",
            "2795: [D loss: 0.690945, acc: 0.550781]  [A loss: 0.739319, acc: 0.433594]\n",
            "2796: [D loss: 0.703156, acc: 0.505859]  [A loss: 0.873207, acc: 0.175781]\n",
            "2797: [D loss: 0.699108, acc: 0.498047]  [A loss: 0.765561, acc: 0.328125]\n",
            "2798: [D loss: 0.708001, acc: 0.542969]  [A loss: 0.855767, acc: 0.183594]\n",
            "2799: [D loss: 0.674724, acc: 0.568359]  [A loss: 0.757250, acc: 0.382812]\n",
            "2800: [D loss: 0.702171, acc: 0.515625]  [A loss: 0.802948, acc: 0.257812]\n",
            "2801: [D loss: 0.696734, acc: 0.550781]  [A loss: 0.812858, acc: 0.261719]\n",
            "2802: [D loss: 0.681920, acc: 0.562500]  [A loss: 0.843128, acc: 0.218750]\n",
            "2803: [D loss: 0.702380, acc: 0.515625]  [A loss: 0.804971, acc: 0.277344]\n",
            "2804: [D loss: 0.707711, acc: 0.498047]  [A loss: 0.876235, acc: 0.140625]\n",
            "2805: [D loss: 0.698942, acc: 0.523438]  [A loss: 0.792144, acc: 0.285156]\n",
            "2806: [D loss: 0.704948, acc: 0.558594]  [A loss: 0.873751, acc: 0.160156]\n",
            "2807: [D loss: 0.686153, acc: 0.560547]  [A loss: 0.776174, acc: 0.355469]\n",
            "2808: [D loss: 0.702465, acc: 0.527344]  [A loss: 0.960768, acc: 0.117188]\n",
            "2809: [D loss: 0.692211, acc: 0.515625]  [A loss: 0.723443, acc: 0.480469]\n",
            "2810: [D loss: 0.704058, acc: 0.505859]  [A loss: 0.967870, acc: 0.093750]\n",
            "2811: [D loss: 0.684665, acc: 0.556641]  [A loss: 0.711867, acc: 0.472656]\n",
            "2812: [D loss: 0.712604, acc: 0.533203]  [A loss: 0.927481, acc: 0.113281]\n",
            "2813: [D loss: 0.702053, acc: 0.513672]  [A loss: 0.728359, acc: 0.417969]\n",
            "2814: [D loss: 0.693951, acc: 0.556641]  [A loss: 0.969322, acc: 0.082031]\n",
            "2815: [D loss: 0.714679, acc: 0.478516]  [A loss: 0.732022, acc: 0.464844]\n",
            "2816: [D loss: 0.706545, acc: 0.511719]  [A loss: 0.953264, acc: 0.132812]\n",
            "2817: [D loss: 0.707837, acc: 0.498047]  [A loss: 0.688437, acc: 0.542969]\n",
            "2818: [D loss: 0.722465, acc: 0.500000]  [A loss: 0.899408, acc: 0.128906]\n",
            "2819: [D loss: 0.696311, acc: 0.531250]  [A loss: 0.720247, acc: 0.457031]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2820: [D loss: 0.715893, acc: 0.492188]  [A loss: 0.890615, acc: 0.148438]\n",
            "2821: [D loss: 0.698068, acc: 0.546875]  [A loss: 0.728080, acc: 0.429688]\n",
            "2822: [D loss: 0.702718, acc: 0.517578]  [A loss: 0.856272, acc: 0.164062]\n",
            "2823: [D loss: 0.690940, acc: 0.537109]  [A loss: 0.812393, acc: 0.261719]\n",
            "2824: [D loss: 0.698732, acc: 0.517578]  [A loss: 0.848365, acc: 0.210938]\n",
            "2825: [D loss: 0.695438, acc: 0.529297]  [A loss: 0.756609, acc: 0.351562]\n",
            "2826: [D loss: 0.709846, acc: 0.503906]  [A loss: 0.977387, acc: 0.089844]\n",
            "2827: [D loss: 0.681567, acc: 0.570312]  [A loss: 0.724935, acc: 0.464844]\n",
            "2828: [D loss: 0.708035, acc: 0.496094]  [A loss: 0.880918, acc: 0.148438]\n",
            "2829: [D loss: 0.704437, acc: 0.525391]  [A loss: 0.731960, acc: 0.437500]\n",
            "2830: [D loss: 0.694561, acc: 0.535156]  [A loss: 0.860826, acc: 0.191406]\n",
            "2831: [D loss: 0.704985, acc: 0.505859]  [A loss: 0.758414, acc: 0.371094]\n",
            "2832: [D loss: 0.702160, acc: 0.535156]  [A loss: 0.856872, acc: 0.175781]\n",
            "2833: [D loss: 0.699901, acc: 0.531250]  [A loss: 0.782985, acc: 0.320312]\n",
            "2834: [D loss: 0.706088, acc: 0.515625]  [A loss: 0.856876, acc: 0.191406]\n",
            "2835: [D loss: 0.695004, acc: 0.523438]  [A loss: 0.716605, acc: 0.468750]\n",
            "2836: [D loss: 0.719126, acc: 0.488281]  [A loss: 0.965563, acc: 0.070312]\n",
            "2837: [D loss: 0.698018, acc: 0.511719]  [A loss: 0.713715, acc: 0.460938]\n",
            "2838: [D loss: 0.695304, acc: 0.531250]  [A loss: 0.903789, acc: 0.140625]\n",
            "2839: [D loss: 0.693121, acc: 0.519531]  [A loss: 0.760513, acc: 0.359375]\n",
            "2840: [D loss: 0.714070, acc: 0.500000]  [A loss: 0.958268, acc: 0.097656]\n",
            "2841: [D loss: 0.702826, acc: 0.521484]  [A loss: 0.742096, acc: 0.410156]\n",
            "2842: [D loss: 0.698687, acc: 0.546875]  [A loss: 0.852514, acc: 0.148438]\n",
            "2843: [D loss: 0.697465, acc: 0.519531]  [A loss: 0.799879, acc: 0.292969]\n",
            "2844: [D loss: 0.687519, acc: 0.548828]  [A loss: 0.834292, acc: 0.296875]\n",
            "2845: [D loss: 0.700252, acc: 0.515625]  [A loss: 0.824908, acc: 0.214844]\n",
            "2846: [D loss: 0.688333, acc: 0.533203]  [A loss: 0.775174, acc: 0.328125]\n",
            "2847: [D loss: 0.694654, acc: 0.576172]  [A loss: 0.864729, acc: 0.167969]\n",
            "2848: [D loss: 0.689627, acc: 0.552734]  [A loss: 0.746347, acc: 0.382812]\n",
            "2849: [D loss: 0.708262, acc: 0.513672]  [A loss: 0.966323, acc: 0.082031]\n",
            "2850: [D loss: 0.711291, acc: 0.478516]  [A loss: 0.677221, acc: 0.574219]\n",
            "2851: [D loss: 0.706400, acc: 0.515625]  [A loss: 0.948107, acc: 0.089844]\n",
            "2852: [D loss: 0.690125, acc: 0.552734]  [A loss: 0.666433, acc: 0.601562]\n",
            "2853: [D loss: 0.716184, acc: 0.513672]  [A loss: 0.873204, acc: 0.160156]\n",
            "2854: [D loss: 0.706966, acc: 0.527344]  [A loss: 0.731860, acc: 0.425781]\n",
            "2855: [D loss: 0.707847, acc: 0.525391]  [A loss: 0.865491, acc: 0.140625]\n",
            "2856: [D loss: 0.687317, acc: 0.544922]  [A loss: 0.731430, acc: 0.445312]\n",
            "2857: [D loss: 0.699826, acc: 0.515625]  [A loss: 0.876393, acc: 0.125000]\n",
            "2858: [D loss: 0.702654, acc: 0.501953]  [A loss: 0.781465, acc: 0.296875]\n",
            "2859: [D loss: 0.705377, acc: 0.482422]  [A loss: 0.857810, acc: 0.195312]\n",
            "2860: [D loss: 0.687647, acc: 0.521484]  [A loss: 0.780801, acc: 0.339844]\n",
            "2861: [D loss: 0.715604, acc: 0.501953]  [A loss: 0.826597, acc: 0.203125]\n",
            "2862: [D loss: 0.702605, acc: 0.507812]  [A loss: 0.840059, acc: 0.195312]\n",
            "2863: [D loss: 0.698440, acc: 0.517578]  [A loss: 0.826005, acc: 0.230469]\n",
            "2864: [D loss: 0.702773, acc: 0.486328]  [A loss: 0.794186, acc: 0.285156]\n",
            "2865: [D loss: 0.705209, acc: 0.503906]  [A loss: 0.811053, acc: 0.250000]\n",
            "2866: [D loss: 0.686475, acc: 0.525391]  [A loss: 0.863243, acc: 0.183594]\n",
            "2867: [D loss: 0.686144, acc: 0.550781]  [A loss: 0.776245, acc: 0.332031]\n",
            "2868: [D loss: 0.703215, acc: 0.519531]  [A loss: 0.956614, acc: 0.148438]\n",
            "2869: [D loss: 0.706766, acc: 0.496094]  [A loss: 0.681935, acc: 0.539062]\n",
            "2870: [D loss: 0.725495, acc: 0.494141]  [A loss: 1.048739, acc: 0.039062]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2871: [D loss: 0.708636, acc: 0.496094]  [A loss: 0.642363, acc: 0.660156]\n",
            "2872: [D loss: 0.727197, acc: 0.509766]  [A loss: 0.911375, acc: 0.125000]\n",
            "2873: [D loss: 0.690461, acc: 0.550781]  [A loss: 0.713120, acc: 0.460938]\n",
            "2874: [D loss: 0.690266, acc: 0.541016]  [A loss: 0.832611, acc: 0.230469]\n",
            "2875: [D loss: 0.696962, acc: 0.513672]  [A loss: 0.733908, acc: 0.410156]\n",
            "2876: [D loss: 0.699587, acc: 0.525391]  [A loss: 0.872517, acc: 0.144531]\n",
            "2877: [D loss: 0.692211, acc: 0.542969]  [A loss: 0.760493, acc: 0.355469]\n",
            "2878: [D loss: 0.702128, acc: 0.539062]  [A loss: 0.873091, acc: 0.203125]\n",
            "2879: [D loss: 0.697331, acc: 0.503906]  [A loss: 0.786119, acc: 0.304688]\n",
            "2880: [D loss: 0.706301, acc: 0.505859]  [A loss: 0.832163, acc: 0.203125]\n",
            "2881: [D loss: 0.699293, acc: 0.542969]  [A loss: 0.831983, acc: 0.238281]\n",
            "2882: [D loss: 0.700608, acc: 0.527344]  [A loss: 0.809074, acc: 0.246094]\n",
            "2883: [D loss: 0.700431, acc: 0.515625]  [A loss: 0.885025, acc: 0.156250]\n",
            "2884: [D loss: 0.689624, acc: 0.544922]  [A loss: 0.814319, acc: 0.257812]\n",
            "2885: [D loss: 0.691849, acc: 0.539062]  [A loss: 0.811075, acc: 0.273438]\n",
            "2886: [D loss: 0.706936, acc: 0.509766]  [A loss: 0.772223, acc: 0.347656]\n",
            "2887: [D loss: 0.701072, acc: 0.519531]  [A loss: 0.906393, acc: 0.128906]\n",
            "2888: [D loss: 0.704972, acc: 0.515625]  [A loss: 0.745651, acc: 0.402344]\n",
            "2889: [D loss: 0.720073, acc: 0.490234]  [A loss: 0.992149, acc: 0.078125]\n",
            "2890: [D loss: 0.699580, acc: 0.513672]  [A loss: 0.689685, acc: 0.535156]\n",
            "2891: [D loss: 0.709428, acc: 0.494141]  [A loss: 0.904369, acc: 0.097656]\n",
            "2892: [D loss: 0.698888, acc: 0.494141]  [A loss: 0.747555, acc: 0.394531]\n",
            "2893: [D loss: 0.693482, acc: 0.513672]  [A loss: 0.924782, acc: 0.093750]\n",
            "2894: [D loss: 0.692199, acc: 0.519531]  [A loss: 0.755122, acc: 0.347656]\n",
            "2895: [D loss: 0.693750, acc: 0.535156]  [A loss: 0.883781, acc: 0.164062]\n",
            "2896: [D loss: 0.692908, acc: 0.541016]  [A loss: 0.773318, acc: 0.347656]\n",
            "2897: [D loss: 0.701415, acc: 0.501953]  [A loss: 0.882207, acc: 0.167969]\n",
            "2898: [D loss: 0.691414, acc: 0.535156]  [A loss: 0.742398, acc: 0.414062]\n",
            "2899: [D loss: 0.693988, acc: 0.541016]  [A loss: 0.904697, acc: 0.105469]\n",
            "2900: [D loss: 0.695092, acc: 0.529297]  [A loss: 0.731731, acc: 0.410156]\n",
            "2901: [D loss: 0.701771, acc: 0.517578]  [A loss: 0.869001, acc: 0.183594]\n",
            "2902: [D loss: 0.704456, acc: 0.503906]  [A loss: 0.789347, acc: 0.308594]\n",
            "2903: [D loss: 0.714327, acc: 0.484375]  [A loss: 0.884933, acc: 0.132812]\n",
            "2904: [D loss: 0.695808, acc: 0.523438]  [A loss: 0.763820, acc: 0.351562]\n",
            "2905: [D loss: 0.706606, acc: 0.509766]  [A loss: 0.939689, acc: 0.066406]\n",
            "2906: [D loss: 0.708580, acc: 0.480469]  [A loss: 0.704007, acc: 0.484375]\n",
            "2907: [D loss: 0.702593, acc: 0.535156]  [A loss: 0.929050, acc: 0.113281]\n",
            "2908: [D loss: 0.688489, acc: 0.550781]  [A loss: 0.690684, acc: 0.554688]\n",
            "2909: [D loss: 0.721705, acc: 0.513672]  [A loss: 0.941762, acc: 0.089844]\n",
            "2910: [D loss: 0.699683, acc: 0.533203]  [A loss: 0.727926, acc: 0.429688]\n",
            "2911: [D loss: 0.699418, acc: 0.513672]  [A loss: 0.842530, acc: 0.167969]\n",
            "2912: [D loss: 0.697033, acc: 0.542969]  [A loss: 0.792851, acc: 0.281250]\n",
            "2913: [D loss: 0.688159, acc: 0.562500]  [A loss: 0.804207, acc: 0.289062]\n",
            "2914: [D loss: 0.692782, acc: 0.552734]  [A loss: 0.780701, acc: 0.332031]\n",
            "2915: [D loss: 0.702090, acc: 0.533203]  [A loss: 0.828576, acc: 0.234375]\n",
            "2916: [D loss: 0.688767, acc: 0.560547]  [A loss: 0.765071, acc: 0.382812]\n",
            "2917: [D loss: 0.680785, acc: 0.556641]  [A loss: 0.846896, acc: 0.218750]\n",
            "2918: [D loss: 0.697778, acc: 0.501953]  [A loss: 0.774479, acc: 0.312500]\n",
            "2919: [D loss: 0.693531, acc: 0.521484]  [A loss: 0.825189, acc: 0.238281]\n",
            "2920: [D loss: 0.700889, acc: 0.513672]  [A loss: 0.822603, acc: 0.238281]\n",
            "2921: [D loss: 0.704418, acc: 0.515625]  [A loss: 0.885969, acc: 0.140625]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2922: [D loss: 0.679622, acc: 0.576172]  [A loss: 0.730210, acc: 0.449219]\n",
            "2923: [D loss: 0.692540, acc: 0.539062]  [A loss: 0.992726, acc: 0.070312]\n",
            "2924: [D loss: 0.701488, acc: 0.515625]  [A loss: 0.625369, acc: 0.691406]\n",
            "2925: [D loss: 0.762004, acc: 0.484375]  [A loss: 1.065381, acc: 0.027344]\n",
            "2926: [D loss: 0.699472, acc: 0.517578]  [A loss: 0.705146, acc: 0.476562]\n",
            "2927: [D loss: 0.715546, acc: 0.509766]  [A loss: 0.858129, acc: 0.171875]\n",
            "2928: [D loss: 0.694830, acc: 0.537109]  [A loss: 0.778863, acc: 0.320312]\n",
            "2929: [D loss: 0.702539, acc: 0.511719]  [A loss: 0.821049, acc: 0.246094]\n",
            "2930: [D loss: 0.696274, acc: 0.519531]  [A loss: 0.783432, acc: 0.300781]\n",
            "2931: [D loss: 0.698184, acc: 0.533203]  [A loss: 0.830068, acc: 0.195312]\n",
            "2932: [D loss: 0.695659, acc: 0.527344]  [A loss: 0.843718, acc: 0.207031]\n",
            "2933: [D loss: 0.704121, acc: 0.513672]  [A loss: 0.780673, acc: 0.332031]\n",
            "2934: [D loss: 0.696230, acc: 0.531250]  [A loss: 0.846451, acc: 0.167969]\n",
            "2935: [D loss: 0.694848, acc: 0.537109]  [A loss: 0.787034, acc: 0.285156]\n",
            "2936: [D loss: 0.702748, acc: 0.535156]  [A loss: 0.866741, acc: 0.175781]\n",
            "2937: [D loss: 0.710248, acc: 0.498047]  [A loss: 0.753319, acc: 0.339844]\n",
            "2938: [D loss: 0.713527, acc: 0.541016]  [A loss: 0.948062, acc: 0.097656]\n",
            "2939: [D loss: 0.700818, acc: 0.521484]  [A loss: 0.708730, acc: 0.488281]\n",
            "2940: [D loss: 0.702628, acc: 0.521484]  [A loss: 0.871008, acc: 0.203125]\n",
            "2941: [D loss: 0.694549, acc: 0.511719]  [A loss: 0.754801, acc: 0.363281]\n",
            "2942: [D loss: 0.679286, acc: 0.550781]  [A loss: 0.861538, acc: 0.222656]\n",
            "2943: [D loss: 0.709302, acc: 0.521484]  [A loss: 0.792685, acc: 0.296875]\n",
            "2944: [D loss: 0.712669, acc: 0.523438]  [A loss: 0.794464, acc: 0.296875]\n",
            "2945: [D loss: 0.704693, acc: 0.490234]  [A loss: 0.850587, acc: 0.199219]\n",
            "2946: [D loss: 0.686260, acc: 0.527344]  [A loss: 0.781358, acc: 0.308594]\n",
            "2947: [D loss: 0.695366, acc: 0.531250]  [A loss: 0.836676, acc: 0.242188]\n",
            "2948: [D loss: 0.697700, acc: 0.523438]  [A loss: 0.770037, acc: 0.335938]\n",
            "2949: [D loss: 0.703980, acc: 0.515625]  [A loss: 0.931588, acc: 0.093750]\n",
            "2950: [D loss: 0.691987, acc: 0.535156]  [A loss: 0.695536, acc: 0.542969]\n",
            "2951: [D loss: 0.728233, acc: 0.505859]  [A loss: 0.996978, acc: 0.042969]\n",
            "2952: [D loss: 0.694490, acc: 0.517578]  [A loss: 0.675159, acc: 0.578125]\n",
            "2953: [D loss: 0.706719, acc: 0.529297]  [A loss: 0.889369, acc: 0.171875]\n",
            "2954: [D loss: 0.700495, acc: 0.509766]  [A loss: 0.745949, acc: 0.410156]\n",
            "2955: [D loss: 0.710869, acc: 0.515625]  [A loss: 0.850463, acc: 0.164062]\n",
            "2956: [D loss: 0.686645, acc: 0.552734]  [A loss: 0.763418, acc: 0.382812]\n",
            "2957: [D loss: 0.707057, acc: 0.515625]  [A loss: 0.839970, acc: 0.281250]\n",
            "2958: [D loss: 0.693831, acc: 0.537109]  [A loss: 0.801879, acc: 0.289062]\n",
            "2959: [D loss: 0.705242, acc: 0.521484]  [A loss: 0.800686, acc: 0.265625]\n",
            "2960: [D loss: 0.696332, acc: 0.544922]  [A loss: 0.861012, acc: 0.199219]\n",
            "2961: [D loss: 0.687785, acc: 0.539062]  [A loss: 0.807695, acc: 0.253906]\n",
            "2962: [D loss: 0.705005, acc: 0.519531]  [A loss: 0.857114, acc: 0.183594]\n",
            "2963: [D loss: 0.693305, acc: 0.535156]  [A loss: 0.769238, acc: 0.351562]\n",
            "2964: [D loss: 0.707197, acc: 0.531250]  [A loss: 0.906547, acc: 0.132812]\n",
            "2965: [D loss: 0.692189, acc: 0.533203]  [A loss: 0.782972, acc: 0.324219]\n",
            "2966: [D loss: 0.716728, acc: 0.521484]  [A loss: 0.950175, acc: 0.109375]\n",
            "2967: [D loss: 0.699636, acc: 0.531250]  [A loss: 0.693450, acc: 0.542969]\n",
            "2968: [D loss: 0.702553, acc: 0.529297]  [A loss: 0.889422, acc: 0.117188]\n",
            "2969: [D loss: 0.695031, acc: 0.529297]  [A loss: 0.745780, acc: 0.386719]\n",
            "2970: [D loss: 0.705969, acc: 0.521484]  [A loss: 0.908595, acc: 0.105469]\n",
            "2971: [D loss: 0.701119, acc: 0.509766]  [A loss: 0.787483, acc: 0.285156]\n",
            "2972: [D loss: 0.711770, acc: 0.464844]  [A loss: 0.834724, acc: 0.214844]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2973: [D loss: 0.708443, acc: 0.521484]  [A loss: 0.824946, acc: 0.230469]\n",
            "2974: [D loss: 0.697511, acc: 0.519531]  [A loss: 0.830800, acc: 0.222656]\n",
            "2975: [D loss: 0.707344, acc: 0.494141]  [A loss: 0.898850, acc: 0.132812]\n",
            "2976: [D loss: 0.692366, acc: 0.539062]  [A loss: 0.763332, acc: 0.328125]\n",
            "2977: [D loss: 0.725418, acc: 0.503906]  [A loss: 0.949212, acc: 0.101562]\n",
            "2978: [D loss: 0.691436, acc: 0.531250]  [A loss: 0.684168, acc: 0.523438]\n",
            "2979: [D loss: 0.692912, acc: 0.541016]  [A loss: 0.915358, acc: 0.128906]\n",
            "2980: [D loss: 0.679764, acc: 0.556641]  [A loss: 0.708038, acc: 0.500000]\n",
            "2981: [D loss: 0.730558, acc: 0.500000]  [A loss: 0.959313, acc: 0.078125]\n",
            "2982: [D loss: 0.687891, acc: 0.552734]  [A loss: 0.738318, acc: 0.410156]\n",
            "2983: [D loss: 0.697906, acc: 0.537109]  [A loss: 0.857728, acc: 0.226562]\n",
            "2984: [D loss: 0.683391, acc: 0.552734]  [A loss: 0.767069, acc: 0.328125]\n",
            "2985: [D loss: 0.695195, acc: 0.564453]  [A loss: 0.835761, acc: 0.218750]\n",
            "2986: [D loss: 0.684410, acc: 0.582031]  [A loss: 0.866545, acc: 0.187500]\n",
            "2987: [D loss: 0.695463, acc: 0.500000]  [A loss: 0.775647, acc: 0.332031]\n",
            "2988: [D loss: 0.685776, acc: 0.548828]  [A loss: 0.954802, acc: 0.101562]\n",
            "2989: [D loss: 0.686873, acc: 0.519531]  [A loss: 0.689109, acc: 0.507812]\n",
            "2990: [D loss: 0.719469, acc: 0.539062]  [A loss: 0.945087, acc: 0.125000]\n",
            "2991: [D loss: 0.687639, acc: 0.505859]  [A loss: 0.730915, acc: 0.433594]\n",
            "2992: [D loss: 0.704057, acc: 0.541016]  [A loss: 0.922932, acc: 0.140625]\n",
            "2993: [D loss: 0.692852, acc: 0.544922]  [A loss: 0.682122, acc: 0.523438]\n",
            "2994: [D loss: 0.722843, acc: 0.494141]  [A loss: 0.920215, acc: 0.160156]\n",
            "2995: [D loss: 0.697128, acc: 0.537109]  [A loss: 0.750585, acc: 0.367188]\n",
            "2996: [D loss: 0.742477, acc: 0.466797]  [A loss: 0.903429, acc: 0.125000]\n",
            "2997: [D loss: 0.690222, acc: 0.544922]  [A loss: 0.758798, acc: 0.355469]\n",
            "2998: [D loss: 0.706756, acc: 0.503906]  [A loss: 0.873592, acc: 0.164062]\n",
            "2999: [D loss: 0.690389, acc: 0.531250]  [A loss: 0.720884, acc: 0.437500]\n",
            "3000: [D loss: 0.708666, acc: 0.527344]  [A loss: 0.848284, acc: 0.195312]\n",
            "3001: [D loss: 0.695665, acc: 0.521484]  [A loss: 0.764223, acc: 0.355469]\n",
            "3002: [D loss: 0.696126, acc: 0.535156]  [A loss: 0.862945, acc: 0.148438]\n",
            "3003: [D loss: 0.706622, acc: 0.519531]  [A loss: 0.729011, acc: 0.398438]\n",
            "3004: [D loss: 0.702496, acc: 0.509766]  [A loss: 0.906453, acc: 0.128906]\n",
            "3005: [D loss: 0.681298, acc: 0.542969]  [A loss: 0.779324, acc: 0.312500]\n",
            "3006: [D loss: 0.697641, acc: 0.517578]  [A loss: 0.797884, acc: 0.257812]\n",
            "3007: [D loss: 0.690405, acc: 0.560547]  [A loss: 0.832722, acc: 0.207031]\n",
            "3008: [D loss: 0.680232, acc: 0.566406]  [A loss: 0.792658, acc: 0.269531]\n",
            "3009: [D loss: 0.702554, acc: 0.521484]  [A loss: 0.850819, acc: 0.187500]\n",
            "3010: [D loss: 0.690988, acc: 0.539062]  [A loss: 0.789248, acc: 0.292969]\n",
            "3011: [D loss: 0.710081, acc: 0.496094]  [A loss: 0.888393, acc: 0.160156]\n",
            "3012: [D loss: 0.690584, acc: 0.556641]  [A loss: 0.768790, acc: 0.355469]\n",
            "3013: [D loss: 0.711399, acc: 0.515625]  [A loss: 0.977559, acc: 0.066406]\n",
            "3014: [D loss: 0.702304, acc: 0.505859]  [A loss: 0.612591, acc: 0.730469]\n",
            "3015: [D loss: 0.746523, acc: 0.490234]  [A loss: 1.023342, acc: 0.031250]\n",
            "3016: [D loss: 0.706742, acc: 0.498047]  [A loss: 0.693592, acc: 0.492188]\n",
            "3017: [D loss: 0.731251, acc: 0.482422]  [A loss: 0.943146, acc: 0.121094]\n",
            "3018: [D loss: 0.686333, acc: 0.539062]  [A loss: 0.741407, acc: 0.417969]\n",
            "3019: [D loss: 0.697157, acc: 0.539062]  [A loss: 0.859031, acc: 0.117188]\n",
            "3020: [D loss: 0.695080, acc: 0.537109]  [A loss: 0.783715, acc: 0.296875]\n",
            "3021: [D loss: 0.696005, acc: 0.523438]  [A loss: 0.844231, acc: 0.199219]\n",
            "3022: [D loss: 0.699766, acc: 0.519531]  [A loss: 0.844134, acc: 0.226562]\n",
            "3023: [D loss: 0.705164, acc: 0.525391]  [A loss: 0.859124, acc: 0.191406]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3024: [D loss: 0.701661, acc: 0.515625]  [A loss: 0.774728, acc: 0.328125]\n",
            "3025: [D loss: 0.695817, acc: 0.523438]  [A loss: 0.849504, acc: 0.156250]\n",
            "3026: [D loss: 0.695708, acc: 0.521484]  [A loss: 0.765448, acc: 0.328125]\n",
            "3027: [D loss: 0.696769, acc: 0.521484]  [A loss: 0.883729, acc: 0.113281]\n",
            "3028: [D loss: 0.687575, acc: 0.537109]  [A loss: 0.759579, acc: 0.382812]\n",
            "3029: [D loss: 0.697473, acc: 0.535156]  [A loss: 0.933804, acc: 0.085938]\n",
            "3030: [D loss: 0.698205, acc: 0.511719]  [A loss: 0.776488, acc: 0.285156]\n",
            "3031: [D loss: 0.710010, acc: 0.501953]  [A loss: 0.867402, acc: 0.195312]\n",
            "3032: [D loss: 0.696353, acc: 0.519531]  [A loss: 0.741770, acc: 0.394531]\n",
            "3033: [D loss: 0.688624, acc: 0.513672]  [A loss: 0.851107, acc: 0.183594]\n",
            "3034: [D loss: 0.690206, acc: 0.566406]  [A loss: 0.801198, acc: 0.253906]\n",
            "3035: [D loss: 0.691477, acc: 0.548828]  [A loss: 0.832539, acc: 0.183594]\n",
            "3036: [D loss: 0.687262, acc: 0.539062]  [A loss: 0.807848, acc: 0.300781]\n",
            "3037: [D loss: 0.704162, acc: 0.501953]  [A loss: 0.899872, acc: 0.148438]\n",
            "3038: [D loss: 0.691128, acc: 0.539062]  [A loss: 0.703884, acc: 0.535156]\n",
            "3039: [D loss: 0.705309, acc: 0.517578]  [A loss: 0.965571, acc: 0.074219]\n",
            "3040: [D loss: 0.698498, acc: 0.533203]  [A loss: 0.711595, acc: 0.476562]\n",
            "3041: [D loss: 0.693495, acc: 0.544922]  [A loss: 0.965390, acc: 0.089844]\n",
            "3042: [D loss: 0.696698, acc: 0.527344]  [A loss: 0.630122, acc: 0.699219]\n",
            "3043: [D loss: 0.740588, acc: 0.484375]  [A loss: 0.950341, acc: 0.082031]\n",
            "3044: [D loss: 0.682987, acc: 0.562500]  [A loss: 0.733974, acc: 0.402344]\n",
            "3045: [D loss: 0.700942, acc: 0.517578]  [A loss: 0.852969, acc: 0.199219]\n",
            "3046: [D loss: 0.687161, acc: 0.546875]  [A loss: 0.799640, acc: 0.261719]\n",
            "3047: [D loss: 0.702064, acc: 0.542969]  [A loss: 0.874574, acc: 0.171875]\n",
            "3048: [D loss: 0.702599, acc: 0.503906]  [A loss: 0.819458, acc: 0.257812]\n",
            "3049: [D loss: 0.697024, acc: 0.541016]  [A loss: 0.769241, acc: 0.351562]\n",
            "3050: [D loss: 0.694221, acc: 0.533203]  [A loss: 0.820008, acc: 0.246094]\n",
            "3051: [D loss: 0.703555, acc: 0.500000]  [A loss: 0.786466, acc: 0.320312]\n",
            "3052: [D loss: 0.697285, acc: 0.548828]  [A loss: 0.848828, acc: 0.234375]\n",
            "3053: [D loss: 0.693383, acc: 0.500000]  [A loss: 0.826656, acc: 0.261719]\n",
            "3054: [D loss: 0.698584, acc: 0.496094]  [A loss: 0.852620, acc: 0.187500]\n",
            "3055: [D loss: 0.684967, acc: 0.539062]  [A loss: 0.831420, acc: 0.238281]\n",
            "3056: [D loss: 0.711917, acc: 0.503906]  [A loss: 0.789121, acc: 0.347656]\n",
            "3057: [D loss: 0.700251, acc: 0.529297]  [A loss: 0.812490, acc: 0.246094]\n",
            "3058: [D loss: 0.694175, acc: 0.541016]  [A loss: 0.802664, acc: 0.300781]\n",
            "3059: [D loss: 0.701271, acc: 0.511719]  [A loss: 0.801153, acc: 0.304688]\n",
            "3060: [D loss: 0.711601, acc: 0.521484]  [A loss: 0.845219, acc: 0.207031]\n",
            "3061: [D loss: 0.701892, acc: 0.535156]  [A loss: 0.891930, acc: 0.156250]\n",
            "3062: [D loss: 0.696188, acc: 0.519531]  [A loss: 0.789611, acc: 0.312500]\n",
            "3063: [D loss: 0.719630, acc: 0.482422]  [A loss: 0.911052, acc: 0.164062]\n",
            "3064: [D loss: 0.697675, acc: 0.533203]  [A loss: 0.714448, acc: 0.460938]\n",
            "3065: [D loss: 0.712877, acc: 0.509766]  [A loss: 0.960600, acc: 0.082031]\n",
            "3066: [D loss: 0.684557, acc: 0.556641]  [A loss: 0.699041, acc: 0.523438]\n",
            "3067: [D loss: 0.721319, acc: 0.505859]  [A loss: 0.977946, acc: 0.070312]\n",
            "3068: [D loss: 0.707352, acc: 0.507812]  [A loss: 0.728471, acc: 0.425781]\n",
            "3069: [D loss: 0.716204, acc: 0.505859]  [A loss: 0.811353, acc: 0.246094]\n",
            "3070: [D loss: 0.694227, acc: 0.529297]  [A loss: 0.770566, acc: 0.332031]\n",
            "3071: [D loss: 0.698595, acc: 0.519531]  [A loss: 0.841390, acc: 0.171875]\n",
            "3072: [D loss: 0.691590, acc: 0.515625]  [A loss: 0.807858, acc: 0.238281]\n",
            "3073: [D loss: 0.705204, acc: 0.517578]  [A loss: 0.915058, acc: 0.125000]\n",
            "3074: [D loss: 0.700129, acc: 0.470703]  [A loss: 0.722973, acc: 0.437500]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3075: [D loss: 0.709006, acc: 0.533203]  [A loss: 0.973600, acc: 0.082031]\n",
            "3076: [D loss: 0.690062, acc: 0.541016]  [A loss: 0.708114, acc: 0.468750]\n",
            "3077: [D loss: 0.704024, acc: 0.519531]  [A loss: 0.907151, acc: 0.117188]\n",
            "3078: [D loss: 0.700759, acc: 0.501953]  [A loss: 0.724949, acc: 0.449219]\n",
            "3079: [D loss: 0.694909, acc: 0.554688]  [A loss: 0.846966, acc: 0.183594]\n",
            "3080: [D loss: 0.685149, acc: 0.554688]  [A loss: 0.745531, acc: 0.417969]\n",
            "3081: [D loss: 0.701179, acc: 0.505859]  [A loss: 0.879711, acc: 0.136719]\n",
            "3082: [D loss: 0.693069, acc: 0.544922]  [A loss: 0.701083, acc: 0.511719]\n",
            "3083: [D loss: 0.714021, acc: 0.509766]  [A loss: 0.838480, acc: 0.210938]\n",
            "3084: [D loss: 0.700880, acc: 0.511719]  [A loss: 0.731502, acc: 0.445312]\n",
            "3085: [D loss: 0.706140, acc: 0.515625]  [A loss: 0.954275, acc: 0.070312]\n",
            "3086: [D loss: 0.696353, acc: 0.511719]  [A loss: 0.677490, acc: 0.558594]\n",
            "3087: [D loss: 0.727886, acc: 0.486328]  [A loss: 0.947694, acc: 0.089844]\n",
            "3088: [D loss: 0.694387, acc: 0.537109]  [A loss: 0.735644, acc: 0.402344]\n",
            "3089: [D loss: 0.694221, acc: 0.521484]  [A loss: 0.860231, acc: 0.167969]\n",
            "3090: [D loss: 0.689825, acc: 0.544922]  [A loss: 0.764887, acc: 0.347656]\n",
            "3091: [D loss: 0.701824, acc: 0.523438]  [A loss: 0.860210, acc: 0.171875]\n",
            "3092: [D loss: 0.696256, acc: 0.544922]  [A loss: 0.726281, acc: 0.457031]\n",
            "3093: [D loss: 0.709526, acc: 0.521484]  [A loss: 0.866753, acc: 0.195312]\n",
            "3094: [D loss: 0.697633, acc: 0.544922]  [A loss: 0.747539, acc: 0.386719]\n",
            "3095: [D loss: 0.701544, acc: 0.531250]  [A loss: 0.869188, acc: 0.160156]\n",
            "3096: [D loss: 0.695391, acc: 0.500000]  [A loss: 0.700236, acc: 0.523438]\n",
            "3097: [D loss: 0.703848, acc: 0.505859]  [A loss: 0.890764, acc: 0.156250]\n",
            "3098: [D loss: 0.699988, acc: 0.509766]  [A loss: 0.732085, acc: 0.410156]\n",
            "3099: [D loss: 0.722508, acc: 0.480469]  [A loss: 0.861594, acc: 0.183594]\n",
            "3100: [D loss: 0.697488, acc: 0.523438]  [A loss: 0.734810, acc: 0.410156]\n",
            "3101: [D loss: 0.708657, acc: 0.494141]  [A loss: 0.959888, acc: 0.085938]\n",
            "3102: [D loss: 0.684556, acc: 0.556641]  [A loss: 0.716606, acc: 0.464844]\n",
            "3103: [D loss: 0.715874, acc: 0.492188]  [A loss: 0.883865, acc: 0.125000]\n",
            "3104: [D loss: 0.701420, acc: 0.500000]  [A loss: 0.793220, acc: 0.265625]\n",
            "3105: [D loss: 0.695053, acc: 0.548828]  [A loss: 0.856808, acc: 0.183594]\n",
            "3106: [D loss: 0.696156, acc: 0.529297]  [A loss: 0.813464, acc: 0.246094]\n",
            "3107: [D loss: 0.699855, acc: 0.513672]  [A loss: 0.761944, acc: 0.351562]\n",
            "3108: [D loss: 0.715134, acc: 0.517578]  [A loss: 0.907230, acc: 0.082031]\n",
            "3109: [D loss: 0.696095, acc: 0.513672]  [A loss: 0.723774, acc: 0.464844]\n",
            "3110: [D loss: 0.710325, acc: 0.509766]  [A loss: 0.907122, acc: 0.093750]\n",
            "3111: [D loss: 0.688549, acc: 0.527344]  [A loss: 0.743283, acc: 0.367188]\n",
            "3112: [D loss: 0.699285, acc: 0.517578]  [A loss: 0.879414, acc: 0.152344]\n",
            "3113: [D loss: 0.697631, acc: 0.519531]  [A loss: 0.742804, acc: 0.414062]\n",
            "3114: [D loss: 0.700936, acc: 0.527344]  [A loss: 0.846476, acc: 0.199219]\n",
            "3115: [D loss: 0.688940, acc: 0.537109]  [A loss: 0.773867, acc: 0.324219]\n",
            "3116: [D loss: 0.694926, acc: 0.533203]  [A loss: 0.860277, acc: 0.203125]\n",
            "3117: [D loss: 0.681781, acc: 0.554688]  [A loss: 0.782283, acc: 0.320312]\n",
            "3118: [D loss: 0.694600, acc: 0.527344]  [A loss: 0.725007, acc: 0.449219]\n",
            "3119: [D loss: 0.682633, acc: 0.556641]  [A loss: 0.918303, acc: 0.144531]\n",
            "3120: [D loss: 0.693818, acc: 0.527344]  [A loss: 0.725858, acc: 0.464844]\n",
            "3121: [D loss: 0.707685, acc: 0.507812]  [A loss: 0.866192, acc: 0.148438]\n",
            "3122: [D loss: 0.688534, acc: 0.515625]  [A loss: 0.758828, acc: 0.394531]\n",
            "3123: [D loss: 0.706260, acc: 0.501953]  [A loss: 0.870215, acc: 0.160156]\n",
            "3124: [D loss: 0.687112, acc: 0.548828]  [A loss: 0.733142, acc: 0.429688]\n",
            "3125: [D loss: 0.725610, acc: 0.515625]  [A loss: 0.973748, acc: 0.101562]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3126: [D loss: 0.692875, acc: 0.531250]  [A loss: 0.710236, acc: 0.433594]\n",
            "3127: [D loss: 0.708978, acc: 0.525391]  [A loss: 0.853819, acc: 0.191406]\n",
            "3128: [D loss: 0.696178, acc: 0.533203]  [A loss: 0.777304, acc: 0.300781]\n",
            "3129: [D loss: 0.719591, acc: 0.478516]  [A loss: 0.821666, acc: 0.214844]\n",
            "3130: [D loss: 0.680858, acc: 0.587891]  [A loss: 0.761183, acc: 0.335938]\n",
            "3131: [D loss: 0.706546, acc: 0.535156]  [A loss: 0.850604, acc: 0.234375]\n",
            "3132: [D loss: 0.681367, acc: 0.558594]  [A loss: 0.801980, acc: 0.277344]\n",
            "3133: [D loss: 0.702398, acc: 0.511719]  [A loss: 0.768837, acc: 0.347656]\n",
            "3134: [D loss: 0.698412, acc: 0.535156]  [A loss: 0.810663, acc: 0.308594]\n",
            "3135: [D loss: 0.697358, acc: 0.523438]  [A loss: 0.800006, acc: 0.246094]\n",
            "3136: [D loss: 0.691328, acc: 0.558594]  [A loss: 0.799539, acc: 0.304688]\n",
            "3137: [D loss: 0.703028, acc: 0.482422]  [A loss: 0.822044, acc: 0.214844]\n",
            "3138: [D loss: 0.689235, acc: 0.548828]  [A loss: 0.769650, acc: 0.363281]\n",
            "3139: [D loss: 0.707425, acc: 0.519531]  [A loss: 0.903872, acc: 0.125000]\n",
            "3140: [D loss: 0.699359, acc: 0.523438]  [A loss: 0.770827, acc: 0.316406]\n",
            "3141: [D loss: 0.692547, acc: 0.519531]  [A loss: 0.856646, acc: 0.175781]\n",
            "3142: [D loss: 0.692219, acc: 0.531250]  [A loss: 0.807357, acc: 0.242188]\n",
            "3143: [D loss: 0.707612, acc: 0.492188]  [A loss: 0.816089, acc: 0.281250]\n",
            "3144: [D loss: 0.690192, acc: 0.546875]  [A loss: 0.874504, acc: 0.218750]\n",
            "3145: [D loss: 0.703566, acc: 0.529297]  [A loss: 0.813527, acc: 0.269531]\n",
            "3146: [D loss: 0.688297, acc: 0.542969]  [A loss: 0.822442, acc: 0.257812]\n",
            "3147: [D loss: 0.693490, acc: 0.517578]  [A loss: 0.834259, acc: 0.210938]\n",
            "3148: [D loss: 0.688986, acc: 0.550781]  [A loss: 0.848361, acc: 0.195312]\n",
            "3149: [D loss: 0.686859, acc: 0.558594]  [A loss: 0.848270, acc: 0.226562]\n",
            "3150: [D loss: 0.699858, acc: 0.519531]  [A loss: 0.738572, acc: 0.406250]\n",
            "3151: [D loss: 0.709114, acc: 0.490234]  [A loss: 0.862139, acc: 0.191406]\n",
            "3152: [D loss: 0.699087, acc: 0.535156]  [A loss: 0.760821, acc: 0.402344]\n",
            "3153: [D loss: 0.711762, acc: 0.484375]  [A loss: 0.913687, acc: 0.121094]\n",
            "3154: [D loss: 0.696046, acc: 0.517578]  [A loss: 0.737180, acc: 0.429688]\n",
            "3155: [D loss: 0.696716, acc: 0.537109]  [A loss: 0.915921, acc: 0.132812]\n",
            "3156: [D loss: 0.695978, acc: 0.517578]  [A loss: 0.818889, acc: 0.250000]\n",
            "3157: [D loss: 0.722930, acc: 0.464844]  [A loss: 0.889529, acc: 0.191406]\n",
            "3158: [D loss: 0.697616, acc: 0.533203]  [A loss: 0.718997, acc: 0.414062]\n",
            "3159: [D loss: 0.709163, acc: 0.517578]  [A loss: 0.908393, acc: 0.164062]\n",
            "3160: [D loss: 0.705162, acc: 0.496094]  [A loss: 0.787430, acc: 0.300781]\n",
            "3161: [D loss: 0.705275, acc: 0.494141]  [A loss: 0.886148, acc: 0.136719]\n",
            "3162: [D loss: 0.681672, acc: 0.574219]  [A loss: 0.848734, acc: 0.207031]\n",
            "3163: [D loss: 0.703789, acc: 0.490234]  [A loss: 0.768517, acc: 0.367188]\n",
            "3164: [D loss: 0.697598, acc: 0.537109]  [A loss: 0.907842, acc: 0.128906]\n",
            "3165: [D loss: 0.700595, acc: 0.501953]  [A loss: 0.772060, acc: 0.308594]\n",
            "3166: [D loss: 0.698958, acc: 0.531250]  [A loss: 1.000237, acc: 0.062500]\n",
            "3167: [D loss: 0.693220, acc: 0.535156]  [A loss: 0.691341, acc: 0.546875]\n",
            "3168: [D loss: 0.719103, acc: 0.492188]  [A loss: 0.897663, acc: 0.140625]\n",
            "3169: [D loss: 0.695826, acc: 0.523438]  [A loss: 0.735561, acc: 0.441406]\n",
            "3170: [D loss: 0.718126, acc: 0.500000]  [A loss: 0.916662, acc: 0.101562]\n",
            "3171: [D loss: 0.703012, acc: 0.513672]  [A loss: 0.714118, acc: 0.484375]\n",
            "3172: [D loss: 0.714152, acc: 0.486328]  [A loss: 0.918414, acc: 0.093750]\n",
            "3173: [D loss: 0.700105, acc: 0.525391]  [A loss: 0.719176, acc: 0.437500]\n",
            "3174: [D loss: 0.702611, acc: 0.542969]  [A loss: 0.869452, acc: 0.195312]\n",
            "3175: [D loss: 0.705595, acc: 0.513672]  [A loss: 0.782528, acc: 0.277344]\n",
            "3176: [D loss: 0.696979, acc: 0.535156]  [A loss: 0.847140, acc: 0.187500]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3177: [D loss: 0.699793, acc: 0.505859]  [A loss: 0.753290, acc: 0.328125]\n",
            "3178: [D loss: 0.699260, acc: 0.527344]  [A loss: 0.883745, acc: 0.144531]\n",
            "3179: [D loss: 0.696336, acc: 0.496094]  [A loss: 0.741546, acc: 0.402344]\n",
            "3180: [D loss: 0.712278, acc: 0.521484]  [A loss: 0.813144, acc: 0.238281]\n",
            "3181: [D loss: 0.682517, acc: 0.562500]  [A loss: 0.829741, acc: 0.210938]\n",
            "3182: [D loss: 0.695079, acc: 0.550781]  [A loss: 0.861636, acc: 0.183594]\n",
            "3183: [D loss: 0.691641, acc: 0.560547]  [A loss: 0.793424, acc: 0.289062]\n",
            "3184: [D loss: 0.701244, acc: 0.529297]  [A loss: 0.893175, acc: 0.160156]\n",
            "3185: [D loss: 0.687351, acc: 0.552734]  [A loss: 0.742061, acc: 0.394531]\n",
            "3186: [D loss: 0.702125, acc: 0.531250]  [A loss: 0.867982, acc: 0.187500]\n",
            "3187: [D loss: 0.701516, acc: 0.515625]  [A loss: 0.818659, acc: 0.253906]\n",
            "3188: [D loss: 0.686982, acc: 0.562500]  [A loss: 0.790077, acc: 0.285156]\n",
            "3189: [D loss: 0.688383, acc: 0.548828]  [A loss: 0.869566, acc: 0.156250]\n",
            "3190: [D loss: 0.703543, acc: 0.525391]  [A loss: 0.770842, acc: 0.363281]\n",
            "3191: [D loss: 0.704536, acc: 0.515625]  [A loss: 0.911546, acc: 0.125000]\n",
            "3192: [D loss: 0.679391, acc: 0.574219]  [A loss: 0.711977, acc: 0.468750]\n",
            "3193: [D loss: 0.718173, acc: 0.505859]  [A loss: 0.998388, acc: 0.058594]\n",
            "3194: [D loss: 0.689908, acc: 0.541016]  [A loss: 0.634896, acc: 0.703125]\n",
            "3195: [D loss: 0.712318, acc: 0.523438]  [A loss: 0.896295, acc: 0.140625]\n",
            "3196: [D loss: 0.703006, acc: 0.511719]  [A loss: 0.733773, acc: 0.402344]\n",
            "3197: [D loss: 0.705350, acc: 0.501953]  [A loss: 0.847256, acc: 0.203125]\n",
            "3198: [D loss: 0.688720, acc: 0.544922]  [A loss: 0.758898, acc: 0.343750]\n",
            "3199: [D loss: 0.695292, acc: 0.517578]  [A loss: 0.934604, acc: 0.101562]\n",
            "3200: [D loss: 0.687462, acc: 0.560547]  [A loss: 0.749971, acc: 0.378906]\n",
            "3201: [D loss: 0.714355, acc: 0.500000]  [A loss: 0.847074, acc: 0.171875]\n",
            "3202: [D loss: 0.683224, acc: 0.554688]  [A loss: 0.756241, acc: 0.332031]\n",
            "3203: [D loss: 0.714922, acc: 0.500000]  [A loss: 0.939527, acc: 0.093750]\n",
            "3204: [D loss: 0.695765, acc: 0.535156]  [A loss: 0.706341, acc: 0.500000]\n",
            "3205: [D loss: 0.733089, acc: 0.492188]  [A loss: 0.895832, acc: 0.160156]\n",
            "3206: [D loss: 0.694309, acc: 0.535156]  [A loss: 0.774768, acc: 0.339844]\n",
            "3207: [D loss: 0.696124, acc: 0.539062]  [A loss: 0.878958, acc: 0.152344]\n",
            "3208: [D loss: 0.704571, acc: 0.529297]  [A loss: 0.760055, acc: 0.367188]\n",
            "3209: [D loss: 0.693211, acc: 0.523438]  [A loss: 0.860105, acc: 0.175781]\n",
            "3210: [D loss: 0.693233, acc: 0.509766]  [A loss: 0.700177, acc: 0.523438]\n",
            "3211: [D loss: 0.719457, acc: 0.513672]  [A loss: 0.921587, acc: 0.105469]\n",
            "3212: [D loss: 0.701402, acc: 0.488281]  [A loss: 0.713609, acc: 0.492188]\n",
            "3213: [D loss: 0.722275, acc: 0.500000]  [A loss: 0.842716, acc: 0.214844]\n",
            "3214: [D loss: 0.703100, acc: 0.505859]  [A loss: 0.749711, acc: 0.367188]\n",
            "3215: [D loss: 0.719265, acc: 0.500000]  [A loss: 0.825987, acc: 0.226562]\n",
            "3216: [D loss: 0.692950, acc: 0.550781]  [A loss: 0.761789, acc: 0.320312]\n",
            "3217: [D loss: 0.693994, acc: 0.546875]  [A loss: 0.846333, acc: 0.195312]\n",
            "3218: [D loss: 0.688052, acc: 0.533203]  [A loss: 0.777751, acc: 0.312500]\n",
            "3219: [D loss: 0.687829, acc: 0.542969]  [A loss: 0.809238, acc: 0.320312]\n",
            "3220: [D loss: 0.702223, acc: 0.515625]  [A loss: 0.749108, acc: 0.382812]\n",
            "3221: [D loss: 0.702110, acc: 0.527344]  [A loss: 0.890802, acc: 0.167969]\n",
            "3222: [D loss: 0.696679, acc: 0.509766]  [A loss: 0.765839, acc: 0.359375]\n",
            "3223: [D loss: 0.696952, acc: 0.525391]  [A loss: 0.856352, acc: 0.167969]\n",
            "3224: [D loss: 0.685165, acc: 0.546875]  [A loss: 0.775554, acc: 0.300781]\n",
            "3225: [D loss: 0.708972, acc: 0.507812]  [A loss: 0.899277, acc: 0.132812]\n",
            "3226: [D loss: 0.688126, acc: 0.554688]  [A loss: 0.765693, acc: 0.378906]\n",
            "3227: [D loss: 0.706682, acc: 0.542969]  [A loss: 0.841025, acc: 0.207031]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3228: [D loss: 0.707330, acc: 0.515625]  [A loss: 0.851437, acc: 0.199219]\n",
            "3229: [D loss: 0.705910, acc: 0.494141]  [A loss: 0.843693, acc: 0.195312]\n",
            "3230: [D loss: 0.696649, acc: 0.505859]  [A loss: 0.810404, acc: 0.273438]\n",
            "3231: [D loss: 0.701473, acc: 0.521484]  [A loss: 0.895963, acc: 0.144531]\n",
            "3232: [D loss: 0.705956, acc: 0.517578]  [A loss: 0.686751, acc: 0.503906]\n",
            "3233: [D loss: 0.710838, acc: 0.507812]  [A loss: 0.950816, acc: 0.113281]\n",
            "3234: [D loss: 0.700247, acc: 0.503906]  [A loss: 0.695937, acc: 0.519531]\n",
            "3235: [D loss: 0.727296, acc: 0.501953]  [A loss: 0.960165, acc: 0.085938]\n",
            "3236: [D loss: 0.696730, acc: 0.533203]  [A loss: 0.777943, acc: 0.339844]\n",
            "3237: [D loss: 0.703494, acc: 0.523438]  [A loss: 0.832265, acc: 0.269531]\n",
            "3238: [D loss: 0.710826, acc: 0.507812]  [A loss: 0.773926, acc: 0.312500]\n",
            "3239: [D loss: 0.708691, acc: 0.511719]  [A loss: 0.861066, acc: 0.164062]\n",
            "3240: [D loss: 0.711054, acc: 0.498047]  [A loss: 0.788649, acc: 0.304688]\n",
            "3241: [D loss: 0.701449, acc: 0.537109]  [A loss: 0.871115, acc: 0.164062]\n",
            "3242: [D loss: 0.687039, acc: 0.531250]  [A loss: 0.808436, acc: 0.265625]\n",
            "3243: [D loss: 0.706358, acc: 0.509766]  [A loss: 0.855536, acc: 0.187500]\n",
            "3244: [D loss: 0.701388, acc: 0.500000]  [A loss: 0.798530, acc: 0.289062]\n",
            "3245: [D loss: 0.702148, acc: 0.527344]  [A loss: 0.837675, acc: 0.199219]\n",
            "3246: [D loss: 0.693272, acc: 0.562500]  [A loss: 0.754046, acc: 0.343750]\n",
            "3247: [D loss: 0.704773, acc: 0.509766]  [A loss: 0.898035, acc: 0.144531]\n",
            "3248: [D loss: 0.693477, acc: 0.513672]  [A loss: 0.709935, acc: 0.460938]\n",
            "3249: [D loss: 0.702285, acc: 0.529297]  [A loss: 0.912657, acc: 0.093750]\n",
            "3250: [D loss: 0.689381, acc: 0.556641]  [A loss: 0.696527, acc: 0.539062]\n",
            "3251: [D loss: 0.713714, acc: 0.511719]  [A loss: 0.863894, acc: 0.164062]\n",
            "3252: [D loss: 0.688051, acc: 0.537109]  [A loss: 0.751096, acc: 0.382812]\n",
            "3253: [D loss: 0.696692, acc: 0.542969]  [A loss: 0.837232, acc: 0.191406]\n",
            "3254: [D loss: 0.696736, acc: 0.513672]  [A loss: 0.748922, acc: 0.355469]\n",
            "3255: [D loss: 0.692041, acc: 0.513672]  [A loss: 0.834794, acc: 0.230469]\n",
            "3256: [D loss: 0.695385, acc: 0.519531]  [A loss: 0.727849, acc: 0.460938]\n",
            "3257: [D loss: 0.696678, acc: 0.521484]  [A loss: 0.864076, acc: 0.140625]\n",
            "3258: [D loss: 0.686272, acc: 0.544922]  [A loss: 0.717935, acc: 0.476562]\n",
            "3259: [D loss: 0.723519, acc: 0.500000]  [A loss: 0.929942, acc: 0.105469]\n",
            "3260: [D loss: 0.690739, acc: 0.535156]  [A loss: 0.695240, acc: 0.542969]\n",
            "3261: [D loss: 0.713296, acc: 0.533203]  [A loss: 0.893642, acc: 0.140625]\n",
            "3262: [D loss: 0.698131, acc: 0.519531]  [A loss: 0.730694, acc: 0.445312]\n",
            "3263: [D loss: 0.708570, acc: 0.507812]  [A loss: 0.822369, acc: 0.222656]\n",
            "3264: [D loss: 0.701037, acc: 0.503906]  [A loss: 0.809540, acc: 0.226562]\n",
            "3265: [D loss: 0.696237, acc: 0.517578]  [A loss: 0.804526, acc: 0.246094]\n",
            "3266: [D loss: 0.701797, acc: 0.521484]  [A loss: 0.812280, acc: 0.250000]\n",
            "3267: [D loss: 0.693984, acc: 0.513672]  [A loss: 0.785329, acc: 0.281250]\n",
            "3268: [D loss: 0.699022, acc: 0.501953]  [A loss: 0.838805, acc: 0.242188]\n",
            "3269: [D loss: 0.694078, acc: 0.527344]  [A loss: 0.786165, acc: 0.281250]\n",
            "3270: [D loss: 0.708168, acc: 0.542969]  [A loss: 1.020485, acc: 0.039062]\n",
            "3271: [D loss: 0.693406, acc: 0.550781]  [A loss: 0.699857, acc: 0.492188]\n",
            "3272: [D loss: 0.711553, acc: 0.480469]  [A loss: 0.856772, acc: 0.171875]\n",
            "3273: [D loss: 0.719379, acc: 0.468750]  [A loss: 0.744929, acc: 0.421875]\n",
            "3274: [D loss: 0.712739, acc: 0.517578]  [A loss: 0.946390, acc: 0.078125]\n",
            "3275: [D loss: 0.705601, acc: 0.503906]  [A loss: 0.673576, acc: 0.535156]\n",
            "3276: [D loss: 0.719367, acc: 0.509766]  [A loss: 0.920550, acc: 0.109375]\n",
            "3277: [D loss: 0.694820, acc: 0.533203]  [A loss: 0.746445, acc: 0.398438]\n",
            "3278: [D loss: 0.699206, acc: 0.525391]  [A loss: 0.783049, acc: 0.296875]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3279: [D loss: 0.692530, acc: 0.527344]  [A loss: 0.797828, acc: 0.281250]\n",
            "3280: [D loss: 0.689567, acc: 0.548828]  [A loss: 0.806072, acc: 0.265625]\n",
            "3281: [D loss: 0.695644, acc: 0.523438]  [A loss: 0.796696, acc: 0.285156]\n",
            "3282: [D loss: 0.678170, acc: 0.564453]  [A loss: 0.825852, acc: 0.250000]\n",
            "3283: [D loss: 0.700326, acc: 0.515625]  [A loss: 0.854075, acc: 0.191406]\n",
            "3284: [D loss: 0.703149, acc: 0.511719]  [A loss: 0.788500, acc: 0.265625]\n",
            "3285: [D loss: 0.710500, acc: 0.505859]  [A loss: 0.871186, acc: 0.156250]\n",
            "3286: [D loss: 0.706939, acc: 0.476562]  [A loss: 0.786963, acc: 0.277344]\n",
            "3287: [D loss: 0.709778, acc: 0.478516]  [A loss: 0.870226, acc: 0.160156]\n",
            "3288: [D loss: 0.689196, acc: 0.548828]  [A loss: 0.716600, acc: 0.468750]\n",
            "3289: [D loss: 0.705055, acc: 0.527344]  [A loss: 0.968786, acc: 0.070312]\n",
            "3290: [D loss: 0.700263, acc: 0.525391]  [A loss: 0.672990, acc: 0.597656]\n",
            "3291: [D loss: 0.717035, acc: 0.529297]  [A loss: 0.895080, acc: 0.089844]\n",
            "3292: [D loss: 0.709843, acc: 0.462891]  [A loss: 0.781270, acc: 0.308594]\n",
            "3293: [D loss: 0.690811, acc: 0.539062]  [A loss: 0.812123, acc: 0.238281]\n",
            "3294: [D loss: 0.704449, acc: 0.509766]  [A loss: 0.819021, acc: 0.226562]\n",
            "3295: [D loss: 0.694912, acc: 0.529297]  [A loss: 0.752601, acc: 0.359375]\n",
            "3296: [D loss: 0.695380, acc: 0.533203]  [A loss: 0.876332, acc: 0.167969]\n",
            "3297: [D loss: 0.698728, acc: 0.541016]  [A loss: 0.720671, acc: 0.464844]\n",
            "3298: [D loss: 0.712115, acc: 0.527344]  [A loss: 0.889605, acc: 0.132812]\n",
            "3299: [D loss: 0.693787, acc: 0.527344]  [A loss: 0.756659, acc: 0.351562]\n",
            "3300: [D loss: 0.710659, acc: 0.505859]  [A loss: 0.918518, acc: 0.113281]\n",
            "3301: [D loss: 0.702661, acc: 0.513672]  [A loss: 0.741224, acc: 0.406250]\n",
            "3302: [D loss: 0.703636, acc: 0.523438]  [A loss: 0.857027, acc: 0.140625]\n",
            "3303: [D loss: 0.685149, acc: 0.556641]  [A loss: 0.765098, acc: 0.355469]\n",
            "3304: [D loss: 0.690165, acc: 0.546875]  [A loss: 0.790808, acc: 0.269531]\n",
            "3305: [D loss: 0.695457, acc: 0.519531]  [A loss: 0.822206, acc: 0.265625]\n",
            "3306: [D loss: 0.700352, acc: 0.529297]  [A loss: 0.764634, acc: 0.316406]\n",
            "3307: [D loss: 0.698095, acc: 0.531250]  [A loss: 0.844099, acc: 0.218750]\n",
            "3308: [D loss: 0.697412, acc: 0.523438]  [A loss: 0.729721, acc: 0.402344]\n",
            "3309: [D loss: 0.684633, acc: 0.558594]  [A loss: 0.878326, acc: 0.156250]\n",
            "3310: [D loss: 0.698632, acc: 0.513672]  [A loss: 0.813686, acc: 0.242188]\n",
            "3311: [D loss: 0.691161, acc: 0.542969]  [A loss: 0.785154, acc: 0.289062]\n",
            "3312: [D loss: 0.710291, acc: 0.515625]  [A loss: 0.885475, acc: 0.136719]\n",
            "3313: [D loss: 0.707791, acc: 0.494141]  [A loss: 0.800365, acc: 0.304688]\n",
            "3314: [D loss: 0.698767, acc: 0.546875]  [A loss: 0.901734, acc: 0.156250]\n",
            "3315: [D loss: 0.681144, acc: 0.578125]  [A loss: 0.745048, acc: 0.382812]\n",
            "3316: [D loss: 0.699092, acc: 0.537109]  [A loss: 0.929647, acc: 0.089844]\n",
            "3317: [D loss: 0.704609, acc: 0.498047]  [A loss: 0.687706, acc: 0.515625]\n",
            "3318: [D loss: 0.713633, acc: 0.517578]  [A loss: 0.945966, acc: 0.082031]\n",
            "3319: [D loss: 0.701186, acc: 0.533203]  [A loss: 0.717139, acc: 0.441406]\n",
            "3320: [D loss: 0.712181, acc: 0.509766]  [A loss: 0.882309, acc: 0.136719]\n",
            "3321: [D loss: 0.687874, acc: 0.523438]  [A loss: 0.807041, acc: 0.261719]\n",
            "3322: [D loss: 0.706203, acc: 0.496094]  [A loss: 0.847564, acc: 0.183594]\n",
            "3323: [D loss: 0.698948, acc: 0.533203]  [A loss: 0.783446, acc: 0.281250]\n",
            "3324: [D loss: 0.702850, acc: 0.521484]  [A loss: 0.845592, acc: 0.183594]\n",
            "3325: [D loss: 0.696526, acc: 0.503906]  [A loss: 0.824574, acc: 0.242188]\n",
            "3326: [D loss: 0.699195, acc: 0.531250]  [A loss: 0.867378, acc: 0.171875]\n",
            "3327: [D loss: 0.699769, acc: 0.527344]  [A loss: 0.789551, acc: 0.289062]\n",
            "3328: [D loss: 0.683645, acc: 0.574219]  [A loss: 0.795729, acc: 0.285156]\n",
            "3329: [D loss: 0.706562, acc: 0.511719]  [A loss: 0.866684, acc: 0.167969]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3330: [D loss: 0.684797, acc: 0.552734]  [A loss: 0.743810, acc: 0.398438]\n",
            "3331: [D loss: 0.687844, acc: 0.541016]  [A loss: 0.887404, acc: 0.140625]\n",
            "3332: [D loss: 0.703578, acc: 0.507812]  [A loss: 0.763139, acc: 0.324219]\n",
            "3333: [D loss: 0.700540, acc: 0.505859]  [A loss: 0.921797, acc: 0.136719]\n",
            "3334: [D loss: 0.689384, acc: 0.539062]  [A loss: 0.755495, acc: 0.347656]\n",
            "3335: [D loss: 0.715844, acc: 0.486328]  [A loss: 0.951666, acc: 0.062500]\n",
            "3336: [D loss: 0.693286, acc: 0.505859]  [A loss: 0.667325, acc: 0.562500]\n",
            "3337: [D loss: 0.716425, acc: 0.509766]  [A loss: 0.940154, acc: 0.097656]\n",
            "3338: [D loss: 0.691896, acc: 0.537109]  [A loss: 0.759561, acc: 0.347656]\n",
            "3339: [D loss: 0.706873, acc: 0.523438]  [A loss: 0.951612, acc: 0.074219]\n",
            "3340: [D loss: 0.700517, acc: 0.529297]  [A loss: 0.700953, acc: 0.500000]\n",
            "3341: [D loss: 0.708046, acc: 0.505859]  [A loss: 0.909235, acc: 0.109375]\n",
            "3342: [D loss: 0.688887, acc: 0.558594]  [A loss: 0.740519, acc: 0.390625]\n",
            "3343: [D loss: 0.712850, acc: 0.511719]  [A loss: 0.852388, acc: 0.210938]\n",
            "3344: [D loss: 0.686310, acc: 0.570312]  [A loss: 0.725724, acc: 0.425781]\n",
            "3345: [D loss: 0.711697, acc: 0.537109]  [A loss: 0.871612, acc: 0.152344]\n",
            "3346: [D loss: 0.688649, acc: 0.531250]  [A loss: 0.772625, acc: 0.324219]\n",
            "3347: [D loss: 0.701748, acc: 0.515625]  [A loss: 0.871441, acc: 0.179688]\n",
            "3348: [D loss: 0.717215, acc: 0.486328]  [A loss: 0.890483, acc: 0.128906]\n",
            "3349: [D loss: 0.695062, acc: 0.535156]  [A loss: 0.812191, acc: 0.261719]\n",
            "3350: [D loss: 0.696565, acc: 0.533203]  [A loss: 0.900741, acc: 0.179688]\n",
            "3351: [D loss: 0.695846, acc: 0.503906]  [A loss: 0.767370, acc: 0.292969]\n",
            "3352: [D loss: 0.691474, acc: 0.537109]  [A loss: 0.817142, acc: 0.257812]\n",
            "3353: [D loss: 0.698009, acc: 0.517578]  [A loss: 0.835167, acc: 0.226562]\n",
            "3354: [D loss: 0.717630, acc: 0.476562]  [A loss: 0.888371, acc: 0.152344]\n",
            "3355: [D loss: 0.691083, acc: 0.527344]  [A loss: 0.777371, acc: 0.324219]\n",
            "3356: [D loss: 0.699618, acc: 0.527344]  [A loss: 0.882368, acc: 0.152344]\n",
            "3357: [D loss: 0.708194, acc: 0.466797]  [A loss: 0.675627, acc: 0.546875]\n",
            "3358: [D loss: 0.718361, acc: 0.500000]  [A loss: 0.967866, acc: 0.082031]\n",
            "3359: [D loss: 0.702711, acc: 0.511719]  [A loss: 0.708219, acc: 0.488281]\n",
            "3360: [D loss: 0.712760, acc: 0.519531]  [A loss: 0.865610, acc: 0.156250]\n",
            "3361: [D loss: 0.701429, acc: 0.501953]  [A loss: 0.811946, acc: 0.281250]\n",
            "3362: [D loss: 0.699125, acc: 0.519531]  [A loss: 0.820846, acc: 0.250000]\n",
            "3363: [D loss: 0.709182, acc: 0.484375]  [A loss: 0.783928, acc: 0.300781]\n",
            "3364: [D loss: 0.699632, acc: 0.503906]  [A loss: 0.895039, acc: 0.140625]\n",
            "3365: [D loss: 0.704625, acc: 0.492188]  [A loss: 0.746869, acc: 0.406250]\n",
            "3366: [D loss: 0.707281, acc: 0.525391]  [A loss: 0.868369, acc: 0.152344]\n",
            "3367: [D loss: 0.696372, acc: 0.523438]  [A loss: 0.840936, acc: 0.207031]\n",
            "3368: [D loss: 0.699658, acc: 0.498047]  [A loss: 0.808533, acc: 0.246094]\n",
            "3369: [D loss: 0.692804, acc: 0.544922]  [A loss: 0.812866, acc: 0.269531]\n",
            "3370: [D loss: 0.696442, acc: 0.515625]  [A loss: 0.924447, acc: 0.105469]\n",
            "3371: [D loss: 0.692565, acc: 0.546875]  [A loss: 0.740989, acc: 0.429688]\n",
            "3372: [D loss: 0.701781, acc: 0.492188]  [A loss: 0.933883, acc: 0.097656]\n",
            "3373: [D loss: 0.694580, acc: 0.523438]  [A loss: 0.725165, acc: 0.476562]\n",
            "3374: [D loss: 0.721590, acc: 0.498047]  [A loss: 0.894702, acc: 0.148438]\n",
            "3375: [D loss: 0.685668, acc: 0.570312]  [A loss: 0.691933, acc: 0.484375]\n",
            "3376: [D loss: 0.702706, acc: 0.523438]  [A loss: 0.945636, acc: 0.101562]\n",
            "3377: [D loss: 0.698947, acc: 0.521484]  [A loss: 0.708339, acc: 0.503906]\n",
            "3378: [D loss: 0.707479, acc: 0.513672]  [A loss: 0.835393, acc: 0.246094]\n",
            "3379: [D loss: 0.702757, acc: 0.498047]  [A loss: 0.780715, acc: 0.324219]\n",
            "3380: [D loss: 0.709605, acc: 0.492188]  [A loss: 0.843286, acc: 0.191406]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3381: [D loss: 0.707219, acc: 0.509766]  [A loss: 0.796339, acc: 0.230469]\n",
            "3382: [D loss: 0.706460, acc: 0.505859]  [A loss: 0.843304, acc: 0.226562]\n",
            "3383: [D loss: 0.697546, acc: 0.525391]  [A loss: 0.737359, acc: 0.402344]\n",
            "3384: [D loss: 0.707363, acc: 0.488281]  [A loss: 0.927606, acc: 0.082031]\n",
            "3385: [D loss: 0.691135, acc: 0.519531]  [A loss: 0.686703, acc: 0.531250]\n",
            "3386: [D loss: 0.719712, acc: 0.484375]  [A loss: 0.962404, acc: 0.066406]\n",
            "3387: [D loss: 0.694514, acc: 0.531250]  [A loss: 0.727843, acc: 0.441406]\n",
            "3388: [D loss: 0.705026, acc: 0.517578]  [A loss: 0.846364, acc: 0.175781]\n",
            "3389: [D loss: 0.702289, acc: 0.511719]  [A loss: 0.795658, acc: 0.261719]\n",
            "3390: [D loss: 0.702832, acc: 0.521484]  [A loss: 0.848553, acc: 0.195312]\n",
            "3391: [D loss: 0.703725, acc: 0.490234]  [A loss: 0.812292, acc: 0.218750]\n",
            "3392: [D loss: 0.700125, acc: 0.523438]  [A loss: 0.847956, acc: 0.234375]\n",
            "3393: [D loss: 0.712208, acc: 0.488281]  [A loss: 0.788709, acc: 0.273438]\n",
            "3394: [D loss: 0.715654, acc: 0.484375]  [A loss: 0.927077, acc: 0.085938]\n",
            "3395: [D loss: 0.715170, acc: 0.478516]  [A loss: 0.668852, acc: 0.605469]\n",
            "3396: [D loss: 0.722930, acc: 0.505859]  [A loss: 0.906250, acc: 0.121094]\n",
            "3397: [D loss: 0.704660, acc: 0.500000]  [A loss: 0.726446, acc: 0.417969]\n",
            "3398: [D loss: 0.705757, acc: 0.482422]  [A loss: 0.782131, acc: 0.285156]\n",
            "3399: [D loss: 0.694816, acc: 0.503906]  [A loss: 0.765718, acc: 0.332031]\n",
            "3400: [D loss: 0.707956, acc: 0.478516]  [A loss: 0.804299, acc: 0.230469]\n",
            "3401: [D loss: 0.694953, acc: 0.527344]  [A loss: 0.756158, acc: 0.378906]\n",
            "3402: [D loss: 0.701954, acc: 0.519531]  [A loss: 0.886312, acc: 0.140625]\n",
            "3403: [D loss: 0.690601, acc: 0.523438]  [A loss: 0.738610, acc: 0.398438]\n",
            "3404: [D loss: 0.704473, acc: 0.515625]  [A loss: 0.831942, acc: 0.203125]\n",
            "3405: [D loss: 0.693535, acc: 0.554688]  [A loss: 0.859289, acc: 0.183594]\n",
            "3406: [D loss: 0.688043, acc: 0.529297]  [A loss: 0.801014, acc: 0.265625]\n",
            "3407: [D loss: 0.699661, acc: 0.500000]  [A loss: 0.851729, acc: 0.164062]\n",
            "3408: [D loss: 0.691243, acc: 0.537109]  [A loss: 0.775283, acc: 0.332031]\n",
            "3409: [D loss: 0.703420, acc: 0.513672]  [A loss: 0.907523, acc: 0.093750]\n",
            "3410: [D loss: 0.701515, acc: 0.505859]  [A loss: 0.731057, acc: 0.449219]\n",
            "3411: [D loss: 0.725191, acc: 0.492188]  [A loss: 0.942580, acc: 0.082031]\n",
            "3412: [D loss: 0.690575, acc: 0.558594]  [A loss: 0.746342, acc: 0.402344]\n",
            "3413: [D loss: 0.704495, acc: 0.511719]  [A loss: 0.805933, acc: 0.257812]\n",
            "3414: [D loss: 0.712151, acc: 0.494141]  [A loss: 0.857724, acc: 0.160156]\n",
            "3415: [D loss: 0.708447, acc: 0.484375]  [A loss: 0.765931, acc: 0.351562]\n",
            "3416: [D loss: 0.705691, acc: 0.503906]  [A loss: 0.833748, acc: 0.171875]\n",
            "3417: [D loss: 0.702151, acc: 0.519531]  [A loss: 0.800552, acc: 0.261719]\n",
            "3418: [D loss: 0.682211, acc: 0.554688]  [A loss: 0.835106, acc: 0.171875]\n",
            "3419: [D loss: 0.686288, acc: 0.550781]  [A loss: 0.857659, acc: 0.160156]\n",
            "3420: [D loss: 0.715996, acc: 0.468750]  [A loss: 0.776160, acc: 0.339844]\n",
            "3421: [D loss: 0.696993, acc: 0.548828]  [A loss: 0.872454, acc: 0.167969]\n",
            "3422: [D loss: 0.707188, acc: 0.494141]  [A loss: 0.857108, acc: 0.171875]\n",
            "3423: [D loss: 0.682878, acc: 0.583984]  [A loss: 0.876666, acc: 0.148438]\n",
            "3424: [D loss: 0.696024, acc: 0.501953]  [A loss: 0.810813, acc: 0.242188]\n",
            "3425: [D loss: 0.700364, acc: 0.521484]  [A loss: 0.867290, acc: 0.156250]\n",
            "3426: [D loss: 0.689957, acc: 0.519531]  [A loss: 0.685413, acc: 0.566406]\n",
            "3427: [D loss: 0.726602, acc: 0.505859]  [A loss: 0.962024, acc: 0.062500]\n",
            "3428: [D loss: 0.702677, acc: 0.519531]  [A loss: 0.732639, acc: 0.460938]\n",
            "3429: [D loss: 0.724010, acc: 0.498047]  [A loss: 1.001644, acc: 0.046875]\n",
            "3430: [D loss: 0.694745, acc: 0.535156]  [A loss: 0.653204, acc: 0.621094]\n",
            "3431: [D loss: 0.728688, acc: 0.498047]  [A loss: 1.025223, acc: 0.066406]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3432: [D loss: 0.692685, acc: 0.548828]  [A loss: 0.695556, acc: 0.554688]\n",
            "3433: [D loss: 0.713041, acc: 0.519531]  [A loss: 0.803275, acc: 0.265625]\n",
            "3434: [D loss: 0.710577, acc: 0.511719]  [A loss: 0.801857, acc: 0.265625]\n",
            "3435: [D loss: 0.708888, acc: 0.490234]  [A loss: 0.829509, acc: 0.199219]\n",
            "3436: [D loss: 0.708870, acc: 0.517578]  [A loss: 0.807804, acc: 0.222656]\n",
            "3437: [D loss: 0.697424, acc: 0.519531]  [A loss: 0.819027, acc: 0.222656]\n",
            "3438: [D loss: 0.690931, acc: 0.535156]  [A loss: 0.773627, acc: 0.281250]\n",
            "3439: [D loss: 0.694653, acc: 0.523438]  [A loss: 0.823204, acc: 0.238281]\n",
            "3440: [D loss: 0.697480, acc: 0.527344]  [A loss: 0.766464, acc: 0.355469]\n",
            "3441: [D loss: 0.689727, acc: 0.531250]  [A loss: 0.831988, acc: 0.203125]\n",
            "3442: [D loss: 0.694282, acc: 0.529297]  [A loss: 0.816005, acc: 0.273438]\n",
            "3443: [D loss: 0.696563, acc: 0.494141]  [A loss: 0.818381, acc: 0.242188]\n",
            "3444: [D loss: 0.695007, acc: 0.542969]  [A loss: 0.842806, acc: 0.195312]\n",
            "3445: [D loss: 0.709772, acc: 0.513672]  [A loss: 0.801926, acc: 0.285156]\n",
            "3446: [D loss: 0.705753, acc: 0.507812]  [A loss: 0.908498, acc: 0.113281]\n",
            "3447: [D loss: 0.704237, acc: 0.507812]  [A loss: 0.715774, acc: 0.460938]\n",
            "3448: [D loss: 0.726049, acc: 0.480469]  [A loss: 0.901513, acc: 0.140625]\n",
            "3449: [D loss: 0.687053, acc: 0.564453]  [A loss: 0.760227, acc: 0.367188]\n",
            "3450: [D loss: 0.697478, acc: 0.515625]  [A loss: 0.939727, acc: 0.078125]\n",
            "3451: [D loss: 0.692061, acc: 0.517578]  [A loss: 0.703677, acc: 0.480469]\n",
            "3452: [D loss: 0.713306, acc: 0.529297]  [A loss: 0.881593, acc: 0.152344]\n",
            "3453: [D loss: 0.698675, acc: 0.515625]  [A loss: 0.704407, acc: 0.515625]\n",
            "3454: [D loss: 0.734742, acc: 0.480469]  [A loss: 0.946133, acc: 0.082031]\n",
            "3455: [D loss: 0.703682, acc: 0.503906]  [A loss: 0.694644, acc: 0.519531]\n",
            "3456: [D loss: 0.702729, acc: 0.519531]  [A loss: 0.846533, acc: 0.187500]\n",
            "3457: [D loss: 0.698404, acc: 0.511719]  [A loss: 0.741021, acc: 0.394531]\n",
            "3458: [D loss: 0.722097, acc: 0.498047]  [A loss: 0.932924, acc: 0.128906]\n",
            "3459: [D loss: 0.705589, acc: 0.488281]  [A loss: 0.766808, acc: 0.312500]\n",
            "3460: [D loss: 0.708021, acc: 0.501953]  [A loss: 0.805056, acc: 0.246094]\n",
            "3461: [D loss: 0.688589, acc: 0.541016]  [A loss: 0.789775, acc: 0.261719]\n",
            "3462: [D loss: 0.694959, acc: 0.533203]  [A loss: 0.823262, acc: 0.207031]\n",
            "3463: [D loss: 0.682197, acc: 0.552734]  [A loss: 0.798575, acc: 0.261719]\n",
            "3464: [D loss: 0.696250, acc: 0.517578]  [A loss: 0.859488, acc: 0.179688]\n",
            "3465: [D loss: 0.695436, acc: 0.542969]  [A loss: 0.801294, acc: 0.285156]\n",
            "3466: [D loss: 0.698134, acc: 0.531250]  [A loss: 0.942818, acc: 0.093750]\n",
            "3467: [D loss: 0.693684, acc: 0.541016]  [A loss: 0.778079, acc: 0.312500]\n",
            "3468: [D loss: 0.701485, acc: 0.535156]  [A loss: 0.868045, acc: 0.167969]\n",
            "3469: [D loss: 0.688097, acc: 0.562500]  [A loss: 0.736778, acc: 0.417969]\n",
            "3470: [D loss: 0.706983, acc: 0.531250]  [A loss: 0.908510, acc: 0.132812]\n",
            "3471: [D loss: 0.694459, acc: 0.539062]  [A loss: 0.777631, acc: 0.289062]\n",
            "3472: [D loss: 0.701129, acc: 0.523438]  [A loss: 0.898017, acc: 0.140625]\n",
            "3473: [D loss: 0.680488, acc: 0.562500]  [A loss: 0.778568, acc: 0.332031]\n",
            "3474: [D loss: 0.703569, acc: 0.517578]  [A loss: 0.859303, acc: 0.152344]\n",
            "3475: [D loss: 0.699442, acc: 0.517578]  [A loss: 0.830919, acc: 0.230469]\n",
            "3476: [D loss: 0.695930, acc: 0.525391]  [A loss: 0.858731, acc: 0.195312]\n",
            "3477: [D loss: 0.696664, acc: 0.527344]  [A loss: 0.755411, acc: 0.375000]\n",
            "3478: [D loss: 0.710456, acc: 0.533203]  [A loss: 0.831240, acc: 0.234375]\n",
            "3479: [D loss: 0.683417, acc: 0.574219]  [A loss: 0.818425, acc: 0.273438]\n",
            "3480: [D loss: 0.693330, acc: 0.544922]  [A loss: 0.775261, acc: 0.375000]\n",
            "3481: [D loss: 0.729756, acc: 0.517578]  [A loss: 0.998351, acc: 0.039062]\n",
            "3482: [D loss: 0.699254, acc: 0.507812]  [A loss: 0.638638, acc: 0.667969]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3483: [D loss: 0.734249, acc: 0.496094]  [A loss: 0.985266, acc: 0.062500]\n",
            "3484: [D loss: 0.683963, acc: 0.548828]  [A loss: 0.715008, acc: 0.441406]\n",
            "3485: [D loss: 0.730838, acc: 0.464844]  [A loss: 0.858472, acc: 0.132812]\n",
            "3486: [D loss: 0.701754, acc: 0.482422]  [A loss: 0.737997, acc: 0.398438]\n",
            "3487: [D loss: 0.698794, acc: 0.541016]  [A loss: 0.877805, acc: 0.136719]\n",
            "3488: [D loss: 0.691906, acc: 0.560547]  [A loss: 0.797879, acc: 0.292969]\n",
            "3489: [D loss: 0.708785, acc: 0.492188]  [A loss: 0.814293, acc: 0.238281]\n",
            "3490: [D loss: 0.687924, acc: 0.564453]  [A loss: 0.727663, acc: 0.449219]\n",
            "3491: [D loss: 0.711161, acc: 0.496094]  [A loss: 0.872927, acc: 0.179688]\n",
            "3492: [D loss: 0.694732, acc: 0.544922]  [A loss: 0.777802, acc: 0.324219]\n",
            "3493: [D loss: 0.698723, acc: 0.486328]  [A loss: 0.780750, acc: 0.308594]\n",
            "3494: [D loss: 0.698008, acc: 0.541016]  [A loss: 0.861146, acc: 0.183594]\n",
            "3495: [D loss: 0.683313, acc: 0.566406]  [A loss: 0.759799, acc: 0.359375]\n",
            "3496: [D loss: 0.726586, acc: 0.490234]  [A loss: 0.926267, acc: 0.125000]\n",
            "3497: [D loss: 0.698801, acc: 0.521484]  [A loss: 0.734149, acc: 0.414062]\n",
            "3498: [D loss: 0.719537, acc: 0.511719]  [A loss: 0.937102, acc: 0.062500]\n",
            "3499: [D loss: 0.685901, acc: 0.548828]  [A loss: 0.755463, acc: 0.359375]\n",
            "3500: [D loss: 0.719991, acc: 0.490234]  [A loss: 0.900734, acc: 0.097656]\n",
            "3501: [D loss: 0.705800, acc: 0.484375]  [A loss: 0.711782, acc: 0.464844]\n",
            "3502: [D loss: 0.718569, acc: 0.478516]  [A loss: 0.861219, acc: 0.156250]\n",
            "3503: [D loss: 0.695064, acc: 0.537109]  [A loss: 0.765027, acc: 0.367188]\n",
            "3504: [D loss: 0.703676, acc: 0.537109]  [A loss: 0.809938, acc: 0.250000]\n",
            "3505: [D loss: 0.695928, acc: 0.507812]  [A loss: 0.774865, acc: 0.339844]\n",
            "3506: [D loss: 0.706312, acc: 0.482422]  [A loss: 0.795923, acc: 0.261719]\n",
            "3507: [D loss: 0.692232, acc: 0.537109]  [A loss: 0.810804, acc: 0.265625]\n",
            "3508: [D loss: 0.694925, acc: 0.521484]  [A loss: 0.804070, acc: 0.265625]\n",
            "3509: [D loss: 0.687777, acc: 0.533203]  [A loss: 0.828173, acc: 0.246094]\n",
            "3510: [D loss: 0.698418, acc: 0.535156]  [A loss: 0.786973, acc: 0.292969]\n",
            "3511: [D loss: 0.700190, acc: 0.513672]  [A loss: 0.866320, acc: 0.171875]\n",
            "3512: [D loss: 0.690494, acc: 0.548828]  [A loss: 0.746259, acc: 0.417969]\n",
            "3513: [D loss: 0.708361, acc: 0.501953]  [A loss: 0.968258, acc: 0.066406]\n",
            "3514: [D loss: 0.694153, acc: 0.527344]  [A loss: 0.652016, acc: 0.605469]\n",
            "3515: [D loss: 0.723470, acc: 0.517578]  [A loss: 0.898093, acc: 0.136719]\n",
            "3516: [D loss: 0.691588, acc: 0.537109]  [A loss: 0.739334, acc: 0.402344]\n",
            "3517: [D loss: 0.701204, acc: 0.517578]  [A loss: 0.847985, acc: 0.164062]\n",
            "3518: [D loss: 0.693271, acc: 0.531250]  [A loss: 0.764849, acc: 0.328125]\n",
            "3519: [D loss: 0.699581, acc: 0.515625]  [A loss: 0.832174, acc: 0.234375]\n",
            "3520: [D loss: 0.691046, acc: 0.548828]  [A loss: 0.795774, acc: 0.289062]\n",
            "3521: [D loss: 0.688479, acc: 0.574219]  [A loss: 0.849698, acc: 0.195312]\n",
            "3522: [D loss: 0.712373, acc: 0.494141]  [A loss: 0.860907, acc: 0.160156]\n",
            "3523: [D loss: 0.686822, acc: 0.574219]  [A loss: 0.779170, acc: 0.320312]\n",
            "3524: [D loss: 0.717937, acc: 0.519531]  [A loss: 0.911779, acc: 0.117188]\n",
            "3525: [D loss: 0.700321, acc: 0.517578]  [A loss: 0.757862, acc: 0.398438]\n",
            "3526: [D loss: 0.692515, acc: 0.541016]  [A loss: 0.878089, acc: 0.156250]\n",
            "3527: [D loss: 0.698428, acc: 0.521484]  [A loss: 0.822884, acc: 0.261719]\n",
            "3528: [D loss: 0.710715, acc: 0.521484]  [A loss: 0.804841, acc: 0.246094]\n",
            "3529: [D loss: 0.711286, acc: 0.486328]  [A loss: 0.849554, acc: 0.187500]\n",
            "3530: [D loss: 0.703231, acc: 0.511719]  [A loss: 0.784685, acc: 0.324219]\n",
            "3531: [D loss: 0.687485, acc: 0.535156]  [A loss: 0.863104, acc: 0.191406]\n",
            "3532: [D loss: 0.698449, acc: 0.529297]  [A loss: 0.844514, acc: 0.195312]\n",
            "3533: [D loss: 0.699689, acc: 0.554688]  [A loss: 0.844638, acc: 0.222656]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3534: [D loss: 0.702687, acc: 0.501953]  [A loss: 0.816251, acc: 0.257812]\n",
            "3535: [D loss: 0.691381, acc: 0.533203]  [A loss: 0.921415, acc: 0.132812]\n",
            "3536: [D loss: 0.689555, acc: 0.539062]  [A loss: 0.717701, acc: 0.437500]\n",
            "3537: [D loss: 0.704699, acc: 0.533203]  [A loss: 0.897137, acc: 0.105469]\n",
            "3538: [D loss: 0.688198, acc: 0.531250]  [A loss: 0.748572, acc: 0.386719]\n",
            "3539: [D loss: 0.698816, acc: 0.529297]  [A loss: 0.878117, acc: 0.191406]\n",
            "3540: [D loss: 0.700817, acc: 0.509766]  [A loss: 0.757018, acc: 0.355469]\n",
            "3541: [D loss: 0.698359, acc: 0.537109]  [A loss: 0.945067, acc: 0.082031]\n",
            "3542: [D loss: 0.700767, acc: 0.476562]  [A loss: 0.710508, acc: 0.460938]\n",
            "3543: [D loss: 0.718775, acc: 0.517578]  [A loss: 1.010864, acc: 0.046875]\n",
            "3544: [D loss: 0.705611, acc: 0.519531]  [A loss: 0.734281, acc: 0.378906]\n",
            "3545: [D loss: 0.728292, acc: 0.480469]  [A loss: 0.855748, acc: 0.167969]\n",
            "3546: [D loss: 0.677692, acc: 0.591797]  [A loss: 0.732966, acc: 0.429688]\n",
            "3547: [D loss: 0.704151, acc: 0.531250]  [A loss: 0.855719, acc: 0.187500]\n",
            "3548: [D loss: 0.698895, acc: 0.535156]  [A loss: 0.767955, acc: 0.351562]\n",
            "3549: [D loss: 0.701701, acc: 0.505859]  [A loss: 0.857599, acc: 0.183594]\n",
            "3550: [D loss: 0.679761, acc: 0.554688]  [A loss: 0.794378, acc: 0.312500]\n",
            "3551: [D loss: 0.684843, acc: 0.574219]  [A loss: 0.758989, acc: 0.343750]\n",
            "3552: [D loss: 0.708832, acc: 0.515625]  [A loss: 0.864439, acc: 0.203125]\n",
            "3553: [D loss: 0.696370, acc: 0.537109]  [A loss: 0.814514, acc: 0.265625]\n",
            "3554: [D loss: 0.694102, acc: 0.511719]  [A loss: 0.789183, acc: 0.285156]\n",
            "3555: [D loss: 0.711293, acc: 0.507812]  [A loss: 0.869799, acc: 0.156250]\n",
            "3556: [D loss: 0.687459, acc: 0.560547]  [A loss: 0.750116, acc: 0.367188]\n",
            "3557: [D loss: 0.694903, acc: 0.548828]  [A loss: 0.927059, acc: 0.160156]\n",
            "3558: [D loss: 0.704720, acc: 0.533203]  [A loss: 0.681175, acc: 0.566406]\n",
            "3559: [D loss: 0.735295, acc: 0.492188]  [A loss: 0.927396, acc: 0.093750]\n",
            "3560: [D loss: 0.695516, acc: 0.521484]  [A loss: 0.722516, acc: 0.437500]\n",
            "3561: [D loss: 0.699276, acc: 0.511719]  [A loss: 0.848071, acc: 0.203125]\n",
            "3562: [D loss: 0.698238, acc: 0.537109]  [A loss: 0.780846, acc: 0.324219]\n",
            "3563: [D loss: 0.704511, acc: 0.539062]  [A loss: 0.841581, acc: 0.226562]\n",
            "3564: [D loss: 0.694634, acc: 0.490234]  [A loss: 0.768983, acc: 0.320312]\n",
            "3565: [D loss: 0.706687, acc: 0.509766]  [A loss: 0.899306, acc: 0.117188]\n",
            "3566: [D loss: 0.704755, acc: 0.503906]  [A loss: 0.777426, acc: 0.320312]\n",
            "3567: [D loss: 0.694204, acc: 0.544922]  [A loss: 0.833979, acc: 0.230469]\n",
            "3568: [D loss: 0.693868, acc: 0.519531]  [A loss: 0.772136, acc: 0.335938]\n",
            "3569: [D loss: 0.696039, acc: 0.537109]  [A loss: 0.839282, acc: 0.183594]\n",
            "3570: [D loss: 0.701371, acc: 0.509766]  [A loss: 0.776000, acc: 0.320312]\n",
            "3571: [D loss: 0.705078, acc: 0.521484]  [A loss: 0.916857, acc: 0.132812]\n",
            "3572: [D loss: 0.703911, acc: 0.501953]  [A loss: 0.681190, acc: 0.558594]\n",
            "3573: [D loss: 0.701856, acc: 0.527344]  [A loss: 0.848593, acc: 0.191406]\n",
            "3574: [D loss: 0.699471, acc: 0.498047]  [A loss: 0.712275, acc: 0.515625]\n",
            "3575: [D loss: 0.694378, acc: 0.527344]  [A loss: 0.898093, acc: 0.148438]\n",
            "3576: [D loss: 0.695400, acc: 0.501953]  [A loss: 0.739278, acc: 0.406250]\n",
            "3577: [D loss: 0.719446, acc: 0.503906]  [A loss: 0.890139, acc: 0.125000]\n",
            "3578: [D loss: 0.694974, acc: 0.539062]  [A loss: 0.797397, acc: 0.269531]\n",
            "3579: [D loss: 0.703417, acc: 0.500000]  [A loss: 0.846995, acc: 0.191406]\n",
            "3580: [D loss: 0.703818, acc: 0.515625]  [A loss: 0.756230, acc: 0.371094]\n",
            "3581: [D loss: 0.717035, acc: 0.490234]  [A loss: 0.811131, acc: 0.234375]\n",
            "3582: [D loss: 0.693932, acc: 0.542969]  [A loss: 0.746534, acc: 0.394531]\n",
            "3583: [D loss: 0.706382, acc: 0.503906]  [A loss: 0.866940, acc: 0.171875]\n",
            "3584: [D loss: 0.697971, acc: 0.523438]  [A loss: 0.821075, acc: 0.265625]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3585: [D loss: 0.700804, acc: 0.509766]  [A loss: 0.804354, acc: 0.265625]\n",
            "3586: [D loss: 0.688148, acc: 0.531250]  [A loss: 0.799518, acc: 0.269531]\n",
            "3587: [D loss: 0.702148, acc: 0.531250]  [A loss: 0.859625, acc: 0.183594]\n",
            "3588: [D loss: 0.696039, acc: 0.519531]  [A loss: 0.793474, acc: 0.257812]\n",
            "3589: [D loss: 0.695773, acc: 0.507812]  [A loss: 0.835965, acc: 0.207031]\n",
            "3590: [D loss: 0.686785, acc: 0.537109]  [A loss: 0.803090, acc: 0.281250]\n",
            "3591: [D loss: 0.701415, acc: 0.541016]  [A loss: 0.818364, acc: 0.265625]\n",
            "3592: [D loss: 0.689430, acc: 0.542969]  [A loss: 0.808070, acc: 0.250000]\n",
            "3593: [D loss: 0.712580, acc: 0.488281]  [A loss: 0.830206, acc: 0.222656]\n",
            "3594: [D loss: 0.704977, acc: 0.529297]  [A loss: 0.939964, acc: 0.078125]\n",
            "3595: [D loss: 0.697469, acc: 0.503906]  [A loss: 0.663549, acc: 0.570312]\n",
            "3596: [D loss: 0.743986, acc: 0.523438]  [A loss: 1.094582, acc: 0.046875]\n",
            "3597: [D loss: 0.703239, acc: 0.482422]  [A loss: 0.710983, acc: 0.453125]\n",
            "3598: [D loss: 0.703035, acc: 0.533203]  [A loss: 0.862542, acc: 0.160156]\n",
            "3599: [D loss: 0.711693, acc: 0.482422]  [A loss: 0.761311, acc: 0.335938]\n",
            "3600: [D loss: 0.708624, acc: 0.525391]  [A loss: 0.768102, acc: 0.371094]\n",
            "3601: [D loss: 0.695293, acc: 0.529297]  [A loss: 0.801462, acc: 0.250000]\n",
            "3602: [D loss: 0.692128, acc: 0.541016]  [A loss: 0.786177, acc: 0.316406]\n",
            "3603: [D loss: 0.701423, acc: 0.515625]  [A loss: 0.826051, acc: 0.230469]\n",
            "3604: [D loss: 0.704504, acc: 0.501953]  [A loss: 0.742059, acc: 0.417969]\n",
            "3605: [D loss: 0.711894, acc: 0.498047]  [A loss: 0.787324, acc: 0.312500]\n",
            "3606: [D loss: 0.705974, acc: 0.511719]  [A loss: 0.811937, acc: 0.289062]\n",
            "3607: [D loss: 0.699283, acc: 0.507812]  [A loss: 0.780244, acc: 0.324219]\n",
            "3608: [D loss: 0.693658, acc: 0.523438]  [A loss: 0.835176, acc: 0.226562]\n",
            "3609: [D loss: 0.701691, acc: 0.527344]  [A loss: 0.793273, acc: 0.257812]\n",
            "3610: [D loss: 0.716641, acc: 0.486328]  [A loss: 0.832594, acc: 0.226562]\n",
            "3611: [D loss: 0.703799, acc: 0.498047]  [A loss: 0.812841, acc: 0.269531]\n",
            "3612: [D loss: 0.690734, acc: 0.548828]  [A loss: 0.796657, acc: 0.269531]\n",
            "3613: [D loss: 0.717043, acc: 0.509766]  [A loss: 0.853118, acc: 0.238281]\n",
            "3614: [D loss: 0.704068, acc: 0.527344]  [A loss: 0.817866, acc: 0.246094]\n",
            "3615: [D loss: 0.687439, acc: 0.558594]  [A loss: 0.795471, acc: 0.292969]\n",
            "3616: [D loss: 0.695155, acc: 0.533203]  [A loss: 0.795764, acc: 0.292969]\n",
            "3617: [D loss: 0.711304, acc: 0.501953]  [A loss: 0.845070, acc: 0.195312]\n",
            "3618: [D loss: 0.700428, acc: 0.533203]  [A loss: 0.824068, acc: 0.234375]\n",
            "3619: [D loss: 0.683929, acc: 0.546875]  [A loss: 0.817393, acc: 0.246094]\n",
            "3620: [D loss: 0.700744, acc: 0.533203]  [A loss: 0.885506, acc: 0.140625]\n",
            "3621: [D loss: 0.706868, acc: 0.476562]  [A loss: 0.739295, acc: 0.398438]\n",
            "3622: [D loss: 0.720251, acc: 0.453125]  [A loss: 0.973974, acc: 0.074219]\n",
            "3623: [D loss: 0.699399, acc: 0.503906]  [A loss: 0.689353, acc: 0.542969]\n",
            "3624: [D loss: 0.718980, acc: 0.500000]  [A loss: 0.923517, acc: 0.109375]\n",
            "3625: [D loss: 0.694610, acc: 0.535156]  [A loss: 0.715850, acc: 0.468750]\n",
            "3626: [D loss: 0.711414, acc: 0.509766]  [A loss: 0.941434, acc: 0.097656]\n",
            "3627: [D loss: 0.711984, acc: 0.490234]  [A loss: 0.763832, acc: 0.347656]\n",
            "3628: [D loss: 0.711568, acc: 0.494141]  [A loss: 0.866110, acc: 0.144531]\n",
            "3629: [D loss: 0.687019, acc: 0.562500]  [A loss: 0.774465, acc: 0.289062]\n",
            "3630: [D loss: 0.701650, acc: 0.521484]  [A loss: 0.896299, acc: 0.148438]\n",
            "3631: [D loss: 0.706348, acc: 0.494141]  [A loss: 0.774323, acc: 0.328125]\n",
            "3632: [D loss: 0.687700, acc: 0.568359]  [A loss: 0.827148, acc: 0.296875]\n",
            "3633: [D loss: 0.704902, acc: 0.517578]  [A loss: 0.871819, acc: 0.214844]\n",
            "3634: [D loss: 0.681703, acc: 0.578125]  [A loss: 0.764093, acc: 0.386719]\n",
            "3635: [D loss: 0.692175, acc: 0.521484]  [A loss: 0.877763, acc: 0.183594]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3636: [D loss: 0.704790, acc: 0.498047]  [A loss: 0.746091, acc: 0.414062]\n",
            "3637: [D loss: 0.703899, acc: 0.529297]  [A loss: 0.929339, acc: 0.105469]\n",
            "3638: [D loss: 0.680780, acc: 0.546875]  [A loss: 0.709951, acc: 0.523438]\n",
            "3639: [D loss: 0.715673, acc: 0.521484]  [A loss: 0.878510, acc: 0.191406]\n",
            "3640: [D loss: 0.702412, acc: 0.500000]  [A loss: 0.721703, acc: 0.449219]\n",
            "3641: [D loss: 0.700439, acc: 0.507812]  [A loss: 0.901498, acc: 0.121094]\n",
            "3642: [D loss: 0.694112, acc: 0.513672]  [A loss: 0.708677, acc: 0.500000]\n",
            "3643: [D loss: 0.720108, acc: 0.488281]  [A loss: 0.963802, acc: 0.097656]\n",
            "3644: [D loss: 0.698204, acc: 0.513672]  [A loss: 0.724149, acc: 0.429688]\n",
            "3645: [D loss: 0.698798, acc: 0.513672]  [A loss: 0.845206, acc: 0.234375]\n",
            "3646: [D loss: 0.693444, acc: 0.541016]  [A loss: 0.759796, acc: 0.359375]\n",
            "3647: [D loss: 0.703396, acc: 0.505859]  [A loss: 0.851947, acc: 0.171875]\n",
            "3648: [D loss: 0.692174, acc: 0.533203]  [A loss: 0.755078, acc: 0.375000]\n",
            "3649: [D loss: 0.707144, acc: 0.525391]  [A loss: 0.863998, acc: 0.164062]\n",
            "3650: [D loss: 0.692140, acc: 0.554688]  [A loss: 0.800274, acc: 0.277344]\n",
            "3651: [D loss: 0.706902, acc: 0.511719]  [A loss: 0.853174, acc: 0.195312]\n",
            "3652: [D loss: 0.694877, acc: 0.527344]  [A loss: 0.799303, acc: 0.269531]\n",
            "3653: [D loss: 0.694173, acc: 0.527344]  [A loss: 0.819722, acc: 0.277344]\n",
            "3654: [D loss: 0.706384, acc: 0.544922]  [A loss: 0.921252, acc: 0.128906]\n",
            "3655: [D loss: 0.677041, acc: 0.580078]  [A loss: 0.700778, acc: 0.527344]\n",
            "3656: [D loss: 0.710347, acc: 0.509766]  [A loss: 0.865713, acc: 0.230469]\n",
            "3657: [D loss: 0.693362, acc: 0.542969]  [A loss: 0.801627, acc: 0.300781]\n",
            "3658: [D loss: 0.708360, acc: 0.498047]  [A loss: 0.814472, acc: 0.281250]\n",
            "3659: [D loss: 0.710986, acc: 0.488281]  [A loss: 0.843815, acc: 0.214844]\n",
            "3660: [D loss: 0.699744, acc: 0.503906]  [A loss: 0.784146, acc: 0.355469]\n",
            "3661: [D loss: 0.719289, acc: 0.472656]  [A loss: 0.781081, acc: 0.324219]\n",
            "3662: [D loss: 0.704909, acc: 0.494141]  [A loss: 0.912054, acc: 0.152344]\n",
            "3663: [D loss: 0.697122, acc: 0.525391]  [A loss: 0.731508, acc: 0.453125]\n",
            "3664: [D loss: 0.710316, acc: 0.513672]  [A loss: 0.832731, acc: 0.234375]\n",
            "3665: [D loss: 0.703590, acc: 0.527344]  [A loss: 0.852780, acc: 0.175781]\n",
            "3666: [D loss: 0.696300, acc: 0.511719]  [A loss: 0.784226, acc: 0.312500]\n",
            "3667: [D loss: 0.700131, acc: 0.519531]  [A loss: 0.840106, acc: 0.175781]\n",
            "3668: [D loss: 0.693569, acc: 0.517578]  [A loss: 0.794097, acc: 0.292969]\n",
            "3669: [D loss: 0.708884, acc: 0.490234]  [A loss: 0.888481, acc: 0.152344]\n",
            "3670: [D loss: 0.691711, acc: 0.539062]  [A loss: 0.722614, acc: 0.449219]\n",
            "3671: [D loss: 0.705720, acc: 0.519531]  [A loss: 0.850692, acc: 0.183594]\n",
            "3672: [D loss: 0.705565, acc: 0.517578]  [A loss: 0.765061, acc: 0.343750]\n",
            "3673: [D loss: 0.702438, acc: 0.548828]  [A loss: 0.861866, acc: 0.199219]\n",
            "3674: [D loss: 0.681809, acc: 0.570312]  [A loss: 0.774000, acc: 0.332031]\n",
            "3675: [D loss: 0.697637, acc: 0.535156]  [A loss: 0.874218, acc: 0.191406]\n",
            "3676: [D loss: 0.693879, acc: 0.537109]  [A loss: 0.751349, acc: 0.382812]\n",
            "3677: [D loss: 0.694906, acc: 0.546875]  [A loss: 0.996218, acc: 0.082031]\n",
            "3678: [D loss: 0.687455, acc: 0.541016]  [A loss: 0.656881, acc: 0.644531]\n",
            "3679: [D loss: 0.734798, acc: 0.509766]  [A loss: 0.965181, acc: 0.070312]\n",
            "3680: [D loss: 0.704304, acc: 0.490234]  [A loss: 0.715771, acc: 0.480469]\n",
            "3681: [D loss: 0.712744, acc: 0.525391]  [A loss: 0.861157, acc: 0.171875]\n",
            "3682: [D loss: 0.698483, acc: 0.521484]  [A loss: 0.709763, acc: 0.492188]\n",
            "3683: [D loss: 0.724006, acc: 0.521484]  [A loss: 0.911492, acc: 0.132812]\n",
            "3684: [D loss: 0.699093, acc: 0.527344]  [A loss: 0.761110, acc: 0.363281]\n",
            "3685: [D loss: 0.690295, acc: 0.533203]  [A loss: 0.825880, acc: 0.253906]\n",
            "3686: [D loss: 0.693485, acc: 0.507812]  [A loss: 0.774398, acc: 0.367188]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3687: [D loss: 0.697902, acc: 0.523438]  [A loss: 0.844961, acc: 0.222656]\n",
            "3688: [D loss: 0.704249, acc: 0.511719]  [A loss: 0.768322, acc: 0.347656]\n",
            "3689: [D loss: 0.700561, acc: 0.523438]  [A loss: 0.792570, acc: 0.292969]\n",
            "3690: [D loss: 0.703981, acc: 0.503906]  [A loss: 0.810339, acc: 0.238281]\n",
            "3691: [D loss: 0.706667, acc: 0.496094]  [A loss: 0.824847, acc: 0.195312]\n",
            "3692: [D loss: 0.694973, acc: 0.546875]  [A loss: 0.859092, acc: 0.164062]\n",
            "3693: [D loss: 0.698778, acc: 0.533203]  [A loss: 0.789808, acc: 0.312500]\n",
            "3694: [D loss: 0.703427, acc: 0.517578]  [A loss: 0.753267, acc: 0.355469]\n",
            "3695: [D loss: 0.711458, acc: 0.509766]  [A loss: 0.895371, acc: 0.148438]\n",
            "3696: [D loss: 0.684694, acc: 0.552734]  [A loss: 0.690164, acc: 0.535156]\n",
            "3697: [D loss: 0.715548, acc: 0.517578]  [A loss: 0.838955, acc: 0.167969]\n",
            "3698: [D loss: 0.706528, acc: 0.498047]  [A loss: 0.804010, acc: 0.246094]\n",
            "3699: [D loss: 0.696865, acc: 0.515625]  [A loss: 0.794778, acc: 0.304688]\n",
            "3700: [D loss: 0.695800, acc: 0.539062]  [A loss: 0.814832, acc: 0.253906]\n",
            "3701: [D loss: 0.697204, acc: 0.527344]  [A loss: 0.789617, acc: 0.292969]\n",
            "3702: [D loss: 0.719267, acc: 0.503906]  [A loss: 0.805037, acc: 0.269531]\n",
            "3703: [D loss: 0.699012, acc: 0.505859]  [A loss: 0.805577, acc: 0.269531]\n",
            "3704: [D loss: 0.704652, acc: 0.511719]  [A loss: 0.904472, acc: 0.144531]\n",
            "3705: [D loss: 0.700499, acc: 0.527344]  [A loss: 0.744190, acc: 0.328125]\n",
            "3706: [D loss: 0.697285, acc: 0.544922]  [A loss: 0.890067, acc: 0.152344]\n",
            "3707: [D loss: 0.704427, acc: 0.488281]  [A loss: 0.705433, acc: 0.484375]\n",
            "3708: [D loss: 0.726998, acc: 0.501953]  [A loss: 0.954531, acc: 0.097656]\n",
            "3709: [D loss: 0.694905, acc: 0.550781]  [A loss: 0.730334, acc: 0.429688]\n",
            "3710: [D loss: 0.709437, acc: 0.521484]  [A loss: 0.816174, acc: 0.222656]\n",
            "3711: [D loss: 0.706888, acc: 0.523438]  [A loss: 0.814076, acc: 0.265625]\n",
            "3712: [D loss: 0.690948, acc: 0.556641]  [A loss: 0.800439, acc: 0.250000]\n",
            "3713: [D loss: 0.704193, acc: 0.515625]  [A loss: 0.842803, acc: 0.191406]\n",
            "3714: [D loss: 0.691134, acc: 0.544922]  [A loss: 0.819285, acc: 0.238281]\n",
            "3715: [D loss: 0.695914, acc: 0.531250]  [A loss: 0.773907, acc: 0.328125]\n",
            "3716: [D loss: 0.695669, acc: 0.550781]  [A loss: 0.848244, acc: 0.187500]\n",
            "3717: [D loss: 0.693507, acc: 0.529297]  [A loss: 0.825834, acc: 0.242188]\n",
            "3718: [D loss: 0.706620, acc: 0.494141]  [A loss: 0.819155, acc: 0.265625]\n",
            "3719: [D loss: 0.696881, acc: 0.521484]  [A loss: 0.834347, acc: 0.250000]\n",
            "3720: [D loss: 0.703517, acc: 0.498047]  [A loss: 0.842100, acc: 0.191406]\n",
            "3721: [D loss: 0.697566, acc: 0.523438]  [A loss: 0.798441, acc: 0.328125]\n",
            "3722: [D loss: 0.706370, acc: 0.529297]  [A loss: 0.845669, acc: 0.207031]\n",
            "3723: [D loss: 0.712110, acc: 0.496094]  [A loss: 0.840132, acc: 0.191406]\n",
            "3724: [D loss: 0.688942, acc: 0.546875]  [A loss: 0.841014, acc: 0.199219]\n",
            "3725: [D loss: 0.713093, acc: 0.468750]  [A loss: 0.781372, acc: 0.316406]\n",
            "3726: [D loss: 0.713261, acc: 0.505859]  [A loss: 0.916395, acc: 0.101562]\n",
            "3727: [D loss: 0.699256, acc: 0.501953]  [A loss: 0.736743, acc: 0.421875]\n",
            "3728: [D loss: 0.706558, acc: 0.523438]  [A loss: 0.879086, acc: 0.125000]\n",
            "3729: [D loss: 0.697392, acc: 0.511719]  [A loss: 0.711408, acc: 0.464844]\n",
            "3730: [D loss: 0.719101, acc: 0.505859]  [A loss: 0.951617, acc: 0.085938]\n",
            "3731: [D loss: 0.700623, acc: 0.492188]  [A loss: 0.660043, acc: 0.605469]\n",
            "3732: [D loss: 0.710332, acc: 0.523438]  [A loss: 0.889540, acc: 0.117188]\n",
            "3733: [D loss: 0.700777, acc: 0.500000]  [A loss: 0.720336, acc: 0.468750]\n",
            "3734: [D loss: 0.713298, acc: 0.494141]  [A loss: 0.849238, acc: 0.199219]\n",
            "3735: [D loss: 0.691969, acc: 0.558594]  [A loss: 0.740278, acc: 0.425781]\n",
            "3736: [D loss: 0.690225, acc: 0.535156]  [A loss: 0.870515, acc: 0.175781]\n",
            "3737: [D loss: 0.706601, acc: 0.523438]  [A loss: 0.786173, acc: 0.265625]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3738: [D loss: 0.702091, acc: 0.509766]  [A loss: 0.833997, acc: 0.222656]\n",
            "3739: [D loss: 0.705160, acc: 0.511719]  [A loss: 0.721527, acc: 0.453125]\n",
            "3740: [D loss: 0.697428, acc: 0.533203]  [A loss: 0.843009, acc: 0.203125]\n",
            "3741: [D loss: 0.710599, acc: 0.478516]  [A loss: 0.802772, acc: 0.246094]\n",
            "3742: [D loss: 0.707275, acc: 0.519531]  [A loss: 0.929161, acc: 0.085938]\n",
            "3743: [D loss: 0.699208, acc: 0.498047]  [A loss: 0.733496, acc: 0.414062]\n",
            "3744: [D loss: 0.703502, acc: 0.546875]  [A loss: 0.850204, acc: 0.203125]\n",
            "3745: [D loss: 0.700813, acc: 0.517578]  [A loss: 0.776542, acc: 0.320312]\n",
            "3746: [D loss: 0.703183, acc: 0.513672]  [A loss: 0.855184, acc: 0.175781]\n",
            "3747: [D loss: 0.703701, acc: 0.478516]  [A loss: 0.708645, acc: 0.460938]\n",
            "3748: [D loss: 0.703644, acc: 0.531250]  [A loss: 0.908897, acc: 0.097656]\n",
            "3749: [D loss: 0.685461, acc: 0.546875]  [A loss: 0.694779, acc: 0.511719]\n",
            "3750: [D loss: 0.718602, acc: 0.490234]  [A loss: 0.893731, acc: 0.117188]\n",
            "3751: [D loss: 0.704460, acc: 0.511719]  [A loss: 0.708012, acc: 0.484375]\n",
            "3752: [D loss: 0.701581, acc: 0.507812]  [A loss: 0.862594, acc: 0.156250]\n",
            "3753: [D loss: 0.678241, acc: 0.564453]  [A loss: 0.776785, acc: 0.277344]\n",
            "3754: [D loss: 0.701592, acc: 0.544922]  [A loss: 0.780748, acc: 0.304688]\n",
            "3755: [D loss: 0.703828, acc: 0.490234]  [A loss: 0.880175, acc: 0.171875]\n",
            "3756: [D loss: 0.691603, acc: 0.539062]  [A loss: 0.739163, acc: 0.421875]\n",
            "3757: [D loss: 0.707607, acc: 0.515625]  [A loss: 0.927839, acc: 0.140625]\n",
            "3758: [D loss: 0.712813, acc: 0.488281]  [A loss: 0.702329, acc: 0.464844]\n",
            "3759: [D loss: 0.712289, acc: 0.496094]  [A loss: 0.875133, acc: 0.179688]\n",
            "3760: [D loss: 0.701555, acc: 0.513672]  [A loss: 0.765841, acc: 0.359375]\n",
            "3761: [D loss: 0.700834, acc: 0.503906]  [A loss: 0.828084, acc: 0.230469]\n",
            "3762: [D loss: 0.701356, acc: 0.513672]  [A loss: 0.872402, acc: 0.160156]\n",
            "3763: [D loss: 0.702603, acc: 0.480469]  [A loss: 0.791291, acc: 0.300781]\n",
            "3764: [D loss: 0.697380, acc: 0.525391]  [A loss: 0.833659, acc: 0.230469]\n",
            "3765: [D loss: 0.701349, acc: 0.509766]  [A loss: 0.755178, acc: 0.394531]\n",
            "3766: [D loss: 0.690946, acc: 0.552734]  [A loss: 0.817592, acc: 0.242188]\n",
            "3767: [D loss: 0.689780, acc: 0.542969]  [A loss: 0.777934, acc: 0.332031]\n",
            "3768: [D loss: 0.684894, acc: 0.564453]  [A loss: 0.817385, acc: 0.257812]\n",
            "3769: [D loss: 0.693794, acc: 0.515625]  [A loss: 0.753365, acc: 0.394531]\n",
            "3770: [D loss: 0.713861, acc: 0.498047]  [A loss: 0.928208, acc: 0.082031]\n",
            "3771: [D loss: 0.700928, acc: 0.529297]  [A loss: 0.730486, acc: 0.406250]\n",
            "3772: [D loss: 0.701770, acc: 0.539062]  [A loss: 0.918506, acc: 0.136719]\n",
            "3773: [D loss: 0.709459, acc: 0.503906]  [A loss: 0.745494, acc: 0.410156]\n",
            "3774: [D loss: 0.697669, acc: 0.554688]  [A loss: 0.836091, acc: 0.207031]\n",
            "3775: [D loss: 0.683519, acc: 0.570312]  [A loss: 0.687511, acc: 0.515625]\n",
            "3776: [D loss: 0.710195, acc: 0.521484]  [A loss: 0.981087, acc: 0.054688]\n",
            "3777: [D loss: 0.706940, acc: 0.527344]  [A loss: 0.727030, acc: 0.414062]\n",
            "3778: [D loss: 0.710107, acc: 0.511719]  [A loss: 0.848263, acc: 0.203125]\n",
            "3779: [D loss: 0.702193, acc: 0.511719]  [A loss: 0.736373, acc: 0.417969]\n",
            "3780: [D loss: 0.696850, acc: 0.509766]  [A loss: 0.818784, acc: 0.250000]\n",
            "3781: [D loss: 0.708092, acc: 0.498047]  [A loss: 0.814266, acc: 0.230469]\n",
            "3782: [D loss: 0.691451, acc: 0.556641]  [A loss: 0.786921, acc: 0.273438]\n",
            "3783: [D loss: 0.695526, acc: 0.531250]  [A loss: 0.808199, acc: 0.285156]\n",
            "3784: [D loss: 0.698620, acc: 0.513672]  [A loss: 0.795542, acc: 0.277344]\n",
            "3785: [D loss: 0.674762, acc: 0.589844]  [A loss: 0.823195, acc: 0.250000]\n",
            "3786: [D loss: 0.699912, acc: 0.511719]  [A loss: 0.763957, acc: 0.355469]\n",
            "3787: [D loss: 0.715460, acc: 0.517578]  [A loss: 0.906008, acc: 0.144531]\n",
            "3788: [D loss: 0.691698, acc: 0.531250]  [A loss: 0.712726, acc: 0.472656]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3789: [D loss: 0.702041, acc: 0.515625]  [A loss: 0.887143, acc: 0.140625]\n",
            "3790: [D loss: 0.706478, acc: 0.476562]  [A loss: 0.730126, acc: 0.476562]\n",
            "3791: [D loss: 0.700040, acc: 0.521484]  [A loss: 0.843243, acc: 0.183594]\n",
            "3792: [D loss: 0.695485, acc: 0.537109]  [A loss: 0.763625, acc: 0.359375]\n",
            "3793: [D loss: 0.710758, acc: 0.484375]  [A loss: 0.846466, acc: 0.238281]\n",
            "3794: [D loss: 0.696574, acc: 0.548828]  [A loss: 0.776810, acc: 0.335938]\n",
            "3795: [D loss: 0.709369, acc: 0.503906]  [A loss: 0.854964, acc: 0.171875]\n",
            "3796: [D loss: 0.690395, acc: 0.556641]  [A loss: 0.759541, acc: 0.371094]\n",
            "3797: [D loss: 0.714388, acc: 0.498047]  [A loss: 0.925498, acc: 0.125000]\n",
            "3798: [D loss: 0.689716, acc: 0.542969]  [A loss: 0.718143, acc: 0.464844]\n",
            "3799: [D loss: 0.715822, acc: 0.488281]  [A loss: 0.904809, acc: 0.117188]\n",
            "3800: [D loss: 0.689207, acc: 0.537109]  [A loss: 0.746806, acc: 0.378906]\n",
            "3801: [D loss: 0.708224, acc: 0.498047]  [A loss: 0.802899, acc: 0.250000]\n",
            "3802: [D loss: 0.698636, acc: 0.541016]  [A loss: 0.782984, acc: 0.312500]\n",
            "3803: [D loss: 0.705511, acc: 0.490234]  [A loss: 0.749472, acc: 0.382812]\n",
            "3804: [D loss: 0.699909, acc: 0.542969]  [A loss: 0.921769, acc: 0.117188]\n",
            "3805: [D loss: 0.702170, acc: 0.494141]  [A loss: 0.766381, acc: 0.332031]\n",
            "3806: [D loss: 0.711903, acc: 0.523438]  [A loss: 0.896696, acc: 0.136719]\n",
            "3807: [D loss: 0.696716, acc: 0.515625]  [A loss: 0.751187, acc: 0.363281]\n",
            "3808: [D loss: 0.696358, acc: 0.523438]  [A loss: 0.796501, acc: 0.273438]\n",
            "3809: [D loss: 0.696938, acc: 0.515625]  [A loss: 0.815562, acc: 0.289062]\n",
            "3810: [D loss: 0.704719, acc: 0.511719]  [A loss: 0.812486, acc: 0.238281]\n",
            "3811: [D loss: 0.683733, acc: 0.550781]  [A loss: 0.784884, acc: 0.296875]\n",
            "3812: [D loss: 0.712200, acc: 0.529297]  [A loss: 0.894373, acc: 0.125000]\n",
            "3813: [D loss: 0.696677, acc: 0.531250]  [A loss: 0.685816, acc: 0.480469]\n",
            "3814: [D loss: 0.710521, acc: 0.517578]  [A loss: 0.886603, acc: 0.175781]\n",
            "3815: [D loss: 0.699607, acc: 0.505859]  [A loss: 0.758023, acc: 0.390625]\n",
            "3816: [D loss: 0.716055, acc: 0.519531]  [A loss: 0.924008, acc: 0.101562]\n",
            "3817: [D loss: 0.715153, acc: 0.466797]  [A loss: 0.743177, acc: 0.355469]\n",
            "3818: [D loss: 0.719289, acc: 0.488281]  [A loss: 0.816731, acc: 0.281250]\n",
            "3819: [D loss: 0.715708, acc: 0.486328]  [A loss: 0.777578, acc: 0.312500]\n",
            "3820: [D loss: 0.709408, acc: 0.511719]  [A loss: 0.815046, acc: 0.257812]\n",
            "3821: [D loss: 0.701204, acc: 0.509766]  [A loss: 0.856681, acc: 0.175781]\n",
            "3822: [D loss: 0.714326, acc: 0.482422]  [A loss: 0.892979, acc: 0.125000]\n",
            "3823: [D loss: 0.689658, acc: 0.535156]  [A loss: 0.757223, acc: 0.386719]\n",
            "3824: [D loss: 0.707301, acc: 0.525391]  [A loss: 0.977104, acc: 0.082031]\n",
            "3825: [D loss: 0.696140, acc: 0.500000]  [A loss: 0.704323, acc: 0.449219]\n",
            "3826: [D loss: 0.711906, acc: 0.509766]  [A loss: 0.910262, acc: 0.125000]\n",
            "3827: [D loss: 0.699617, acc: 0.509766]  [A loss: 0.745156, acc: 0.375000]\n",
            "3828: [D loss: 0.704089, acc: 0.546875]  [A loss: 0.811855, acc: 0.218750]\n",
            "3829: [D loss: 0.696117, acc: 0.503906]  [A loss: 0.820915, acc: 0.226562]\n",
            "3830: [D loss: 0.714803, acc: 0.525391]  [A loss: 0.807272, acc: 0.296875]\n",
            "3831: [D loss: 0.696195, acc: 0.537109]  [A loss: 0.803860, acc: 0.281250]\n",
            "3832: [D loss: 0.707250, acc: 0.500000]  [A loss: 0.893129, acc: 0.132812]\n",
            "3833: [D loss: 0.706539, acc: 0.513672]  [A loss: 0.719662, acc: 0.460938]\n",
            "3834: [D loss: 0.713167, acc: 0.492188]  [A loss: 0.851999, acc: 0.187500]\n",
            "3835: [D loss: 0.688106, acc: 0.554688]  [A loss: 0.769027, acc: 0.332031]\n",
            "3836: [D loss: 0.699613, acc: 0.533203]  [A loss: 0.832319, acc: 0.179688]\n",
            "3837: [D loss: 0.702978, acc: 0.511719]  [A loss: 0.747716, acc: 0.410156]\n",
            "3838: [D loss: 0.686293, acc: 0.539062]  [A loss: 0.804233, acc: 0.308594]\n",
            "3839: [D loss: 0.685920, acc: 0.564453]  [A loss: 0.856511, acc: 0.226562]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3840: [D loss: 0.692538, acc: 0.542969]  [A loss: 0.848140, acc: 0.210938]\n",
            "3841: [D loss: 0.712451, acc: 0.494141]  [A loss: 0.794915, acc: 0.269531]\n",
            "3842: [D loss: 0.715736, acc: 0.488281]  [A loss: 0.935090, acc: 0.089844]\n",
            "3843: [D loss: 0.687754, acc: 0.531250]  [A loss: 0.723367, acc: 0.460938]\n",
            "3844: [D loss: 0.723251, acc: 0.501953]  [A loss: 0.926413, acc: 0.089844]\n",
            "3845: [D loss: 0.705693, acc: 0.490234]  [A loss: 0.719134, acc: 0.453125]\n",
            "3846: [D loss: 0.699360, acc: 0.548828]  [A loss: 0.871006, acc: 0.171875]\n",
            "3847: [D loss: 0.697388, acc: 0.503906]  [A loss: 0.757356, acc: 0.343750]\n",
            "3848: [D loss: 0.704203, acc: 0.523438]  [A loss: 0.854856, acc: 0.160156]\n",
            "3849: [D loss: 0.702217, acc: 0.501953]  [A loss: 0.789764, acc: 0.324219]\n",
            "3850: [D loss: 0.688859, acc: 0.537109]  [A loss: 0.862376, acc: 0.152344]\n",
            "3851: [D loss: 0.681190, acc: 0.570312]  [A loss: 0.820873, acc: 0.304688]\n",
            "3852: [D loss: 0.690636, acc: 0.539062]  [A loss: 0.739901, acc: 0.410156]\n",
            "3853: [D loss: 0.717975, acc: 0.505859]  [A loss: 0.952927, acc: 0.121094]\n",
            "3854: [D loss: 0.697910, acc: 0.507812]  [A loss: 0.732071, acc: 0.460938]\n",
            "3855: [D loss: 0.703188, acc: 0.513672]  [A loss: 0.901426, acc: 0.160156]\n",
            "3856: [D loss: 0.681109, acc: 0.544922]  [A loss: 0.730822, acc: 0.445312]\n",
            "3857: [D loss: 0.702927, acc: 0.482422]  [A loss: 0.944008, acc: 0.089844]\n",
            "3858: [D loss: 0.690624, acc: 0.537109]  [A loss: 0.666875, acc: 0.605469]\n",
            "3859: [D loss: 0.727039, acc: 0.501953]  [A loss: 0.955693, acc: 0.113281]\n",
            "3860: [D loss: 0.698145, acc: 0.527344]  [A loss: 0.688291, acc: 0.519531]\n",
            "3861: [D loss: 0.713076, acc: 0.482422]  [A loss: 0.839955, acc: 0.234375]\n",
            "3862: [D loss: 0.704183, acc: 0.521484]  [A loss: 0.750746, acc: 0.402344]\n",
            "3863: [D loss: 0.698770, acc: 0.542969]  [A loss: 0.862148, acc: 0.214844]\n",
            "3864: [D loss: 0.687927, acc: 0.548828]  [A loss: 0.769598, acc: 0.316406]\n",
            "3865: [D loss: 0.708208, acc: 0.531250]  [A loss: 0.838026, acc: 0.203125]\n",
            "3866: [D loss: 0.688390, acc: 0.572266]  [A loss: 0.777044, acc: 0.339844]\n",
            "3867: [D loss: 0.696502, acc: 0.531250]  [A loss: 0.869812, acc: 0.199219]\n",
            "3868: [D loss: 0.708050, acc: 0.472656]  [A loss: 0.767355, acc: 0.371094]\n",
            "3869: [D loss: 0.703925, acc: 0.542969]  [A loss: 0.877034, acc: 0.207031]\n",
            "3870: [D loss: 0.695197, acc: 0.525391]  [A loss: 0.801392, acc: 0.296875]\n",
            "3871: [D loss: 0.701157, acc: 0.529297]  [A loss: 0.822772, acc: 0.296875]\n",
            "3872: [D loss: 0.720659, acc: 0.480469]  [A loss: 0.770957, acc: 0.339844]\n",
            "3873: [D loss: 0.689856, acc: 0.537109]  [A loss: 0.873740, acc: 0.207031]\n",
            "3874: [D loss: 0.700883, acc: 0.503906]  [A loss: 0.729998, acc: 0.437500]\n",
            "3875: [D loss: 0.715068, acc: 0.476562]  [A loss: 0.981128, acc: 0.070312]\n",
            "3876: [D loss: 0.690134, acc: 0.539062]  [A loss: 0.647717, acc: 0.628906]\n",
            "3877: [D loss: 0.732125, acc: 0.509766]  [A loss: 1.023959, acc: 0.058594]\n",
            "3878: [D loss: 0.706599, acc: 0.490234]  [A loss: 0.688436, acc: 0.554688]\n",
            "3879: [D loss: 0.708661, acc: 0.500000]  [A loss: 0.800626, acc: 0.265625]\n",
            "3880: [D loss: 0.691414, acc: 0.521484]  [A loss: 0.736541, acc: 0.417969]\n",
            "3881: [D loss: 0.698155, acc: 0.523438]  [A loss: 0.785129, acc: 0.332031]\n",
            "3882: [D loss: 0.704078, acc: 0.527344]  [A loss: 0.820210, acc: 0.226562]\n",
            "3883: [D loss: 0.695859, acc: 0.527344]  [A loss: 0.808349, acc: 0.242188]\n",
            "3884: [D loss: 0.696344, acc: 0.544922]  [A loss: 0.878873, acc: 0.152344]\n",
            "3885: [D loss: 0.694271, acc: 0.501953]  [A loss: 0.779582, acc: 0.304688]\n",
            "3886: [D loss: 0.715591, acc: 0.509766]  [A loss: 0.909563, acc: 0.117188]\n",
            "3887: [D loss: 0.691876, acc: 0.519531]  [A loss: 0.728324, acc: 0.449219]\n",
            "3888: [D loss: 0.708232, acc: 0.529297]  [A loss: 0.878147, acc: 0.121094]\n",
            "3889: [D loss: 0.703280, acc: 0.501953]  [A loss: 0.733807, acc: 0.421875]\n",
            "3890: [D loss: 0.700896, acc: 0.515625]  [A loss: 0.991915, acc: 0.085938]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3891: [D loss: 0.699166, acc: 0.507812]  [A loss: 0.682479, acc: 0.542969]\n",
            "3892: [D loss: 0.719128, acc: 0.527344]  [A loss: 0.856762, acc: 0.210938]\n",
            "3893: [D loss: 0.700547, acc: 0.519531]  [A loss: 0.764358, acc: 0.359375]\n",
            "3894: [D loss: 0.697774, acc: 0.542969]  [A loss: 0.792403, acc: 0.292969]\n",
            "3895: [D loss: 0.713019, acc: 0.490234]  [A loss: 0.843074, acc: 0.210938]\n",
            "3896: [D loss: 0.694842, acc: 0.539062]  [A loss: 0.820052, acc: 0.242188]\n",
            "3897: [D loss: 0.696039, acc: 0.548828]  [A loss: 0.818812, acc: 0.277344]\n",
            "3898: [D loss: 0.698969, acc: 0.513672]  [A loss: 0.801849, acc: 0.257812]\n",
            "3899: [D loss: 0.696257, acc: 0.527344]  [A loss: 0.796649, acc: 0.304688]\n",
            "3900: [D loss: 0.696931, acc: 0.515625]  [A loss: 0.808385, acc: 0.265625]\n",
            "3901: [D loss: 0.702458, acc: 0.521484]  [A loss: 0.845207, acc: 0.195312]\n",
            "3902: [D loss: 0.690825, acc: 0.548828]  [A loss: 0.769946, acc: 0.382812]\n",
            "3903: [D loss: 0.707788, acc: 0.509766]  [A loss: 0.926034, acc: 0.085938]\n",
            "3904: [D loss: 0.703791, acc: 0.500000]  [A loss: 0.723881, acc: 0.445312]\n",
            "3905: [D loss: 0.701863, acc: 0.490234]  [A loss: 0.891482, acc: 0.105469]\n",
            "3906: [D loss: 0.703674, acc: 0.494141]  [A loss: 0.751399, acc: 0.382812]\n",
            "3907: [D loss: 0.713343, acc: 0.503906]  [A loss: 0.901529, acc: 0.164062]\n",
            "3908: [D loss: 0.715197, acc: 0.492188]  [A loss: 0.731985, acc: 0.449219]\n",
            "3909: [D loss: 0.704303, acc: 0.517578]  [A loss: 0.886379, acc: 0.144531]\n",
            "3910: [D loss: 0.687375, acc: 0.533203]  [A loss: 0.688757, acc: 0.535156]\n",
            "3911: [D loss: 0.695841, acc: 0.521484]  [A loss: 0.895905, acc: 0.132812]\n",
            "3912: [D loss: 0.686361, acc: 0.544922]  [A loss: 0.727366, acc: 0.417969]\n",
            "3913: [D loss: 0.705869, acc: 0.511719]  [A loss: 0.903653, acc: 0.121094]\n",
            "3914: [D loss: 0.693809, acc: 0.560547]  [A loss: 0.739043, acc: 0.390625]\n",
            "3915: [D loss: 0.701247, acc: 0.527344]  [A loss: 0.841271, acc: 0.222656]\n",
            "3916: [D loss: 0.684743, acc: 0.566406]  [A loss: 0.786290, acc: 0.324219]\n",
            "3917: [D loss: 0.700980, acc: 0.523438]  [A loss: 0.821312, acc: 0.250000]\n",
            "3918: [D loss: 0.705590, acc: 0.492188]  [A loss: 0.736062, acc: 0.390625]\n",
            "3919: [D loss: 0.698773, acc: 0.539062]  [A loss: 0.950787, acc: 0.140625]\n",
            "3920: [D loss: 0.700434, acc: 0.515625]  [A loss: 0.741711, acc: 0.390625]\n",
            "3921: [D loss: 0.717019, acc: 0.500000]  [A loss: 0.822583, acc: 0.246094]\n",
            "3922: [D loss: 0.703245, acc: 0.515625]  [A loss: 0.801810, acc: 0.265625]\n",
            "3923: [D loss: 0.692114, acc: 0.556641]  [A loss: 0.840634, acc: 0.210938]\n",
            "3924: [D loss: 0.689363, acc: 0.537109]  [A loss: 0.866808, acc: 0.175781]\n",
            "3925: [D loss: 0.695762, acc: 0.537109]  [A loss: 0.830007, acc: 0.222656]\n",
            "3926: [D loss: 0.698508, acc: 0.529297]  [A loss: 0.779602, acc: 0.324219]\n",
            "3927: [D loss: 0.704279, acc: 0.494141]  [A loss: 0.813075, acc: 0.269531]\n",
            "3928: [D loss: 0.698556, acc: 0.517578]  [A loss: 0.822635, acc: 0.277344]\n",
            "3929: [D loss: 0.697369, acc: 0.531250]  [A loss: 0.717428, acc: 0.453125]\n",
            "3930: [D loss: 0.709146, acc: 0.501953]  [A loss: 0.966407, acc: 0.066406]\n",
            "3931: [D loss: 0.718352, acc: 0.480469]  [A loss: 0.705589, acc: 0.511719]\n",
            "3932: [D loss: 0.705731, acc: 0.519531]  [A loss: 0.884471, acc: 0.140625]\n",
            "3933: [D loss: 0.705166, acc: 0.503906]  [A loss: 0.771994, acc: 0.335938]\n",
            "3934: [D loss: 0.704358, acc: 0.500000]  [A loss: 0.927362, acc: 0.113281]\n",
            "3935: [D loss: 0.718586, acc: 0.494141]  [A loss: 0.687767, acc: 0.570312]\n",
            "3936: [D loss: 0.706275, acc: 0.505859]  [A loss: 0.882045, acc: 0.132812]\n",
            "3937: [D loss: 0.701941, acc: 0.517578]  [A loss: 0.745204, acc: 0.375000]\n",
            "3938: [D loss: 0.705419, acc: 0.521484]  [A loss: 0.850422, acc: 0.179688]\n",
            "3939: [D loss: 0.701349, acc: 0.505859]  [A loss: 0.791344, acc: 0.308594]\n",
            "3940: [D loss: 0.690023, acc: 0.556641]  [A loss: 0.792257, acc: 0.300781]\n",
            "3941: [D loss: 0.706383, acc: 0.525391]  [A loss: 0.794599, acc: 0.304688]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3942: [D loss: 0.691888, acc: 0.523438]  [A loss: 0.788719, acc: 0.332031]\n",
            "3943: [D loss: 0.699811, acc: 0.533203]  [A loss: 0.852883, acc: 0.187500]\n",
            "3944: [D loss: 0.692019, acc: 0.517578]  [A loss: 0.826004, acc: 0.207031]\n",
            "3945: [D loss: 0.703418, acc: 0.531250]  [A loss: 0.829822, acc: 0.257812]\n",
            "3946: [D loss: 0.697118, acc: 0.509766]  [A loss: 0.813489, acc: 0.273438]\n",
            "3947: [D loss: 0.701150, acc: 0.521484]  [A loss: 0.779580, acc: 0.316406]\n",
            "3948: [D loss: 0.721048, acc: 0.484375]  [A loss: 0.798810, acc: 0.316406]\n",
            "3949: [D loss: 0.698747, acc: 0.560547]  [A loss: 0.871231, acc: 0.167969]\n",
            "3950: [D loss: 0.693772, acc: 0.537109]  [A loss: 0.731863, acc: 0.457031]\n",
            "3951: [D loss: 0.701423, acc: 0.515625]  [A loss: 0.951407, acc: 0.105469]\n",
            "3952: [D loss: 0.707311, acc: 0.505859]  [A loss: 0.716383, acc: 0.476562]\n",
            "3953: [D loss: 0.709778, acc: 0.521484]  [A loss: 0.887127, acc: 0.148438]\n",
            "3954: [D loss: 0.699640, acc: 0.539062]  [A loss: 0.744773, acc: 0.417969]\n",
            "3955: [D loss: 0.705992, acc: 0.537109]  [A loss: 0.798088, acc: 0.269531]\n",
            "3956: [D loss: 0.709595, acc: 0.505859]  [A loss: 0.903617, acc: 0.128906]\n",
            "3957: [D loss: 0.698710, acc: 0.523438]  [A loss: 0.794426, acc: 0.324219]\n",
            "3958: [D loss: 0.686135, acc: 0.564453]  [A loss: 0.898361, acc: 0.171875]\n",
            "3959: [D loss: 0.704169, acc: 0.515625]  [A loss: 0.748793, acc: 0.382812]\n",
            "3960: [D loss: 0.701645, acc: 0.531250]  [A loss: 0.854011, acc: 0.230469]\n",
            "3961: [D loss: 0.686766, acc: 0.548828]  [A loss: 0.733472, acc: 0.406250]\n",
            "3962: [D loss: 0.703593, acc: 0.511719]  [A loss: 0.880333, acc: 0.195312]\n",
            "3963: [D loss: 0.713561, acc: 0.488281]  [A loss: 0.715438, acc: 0.476562]\n",
            "3964: [D loss: 0.720405, acc: 0.501953]  [A loss: 0.985277, acc: 0.070312]\n",
            "3965: [D loss: 0.710158, acc: 0.525391]  [A loss: 0.680172, acc: 0.578125]\n",
            "3966: [D loss: 0.715820, acc: 0.492188]  [A loss: 0.844308, acc: 0.214844]\n",
            "3967: [D loss: 0.702419, acc: 0.511719]  [A loss: 0.739588, acc: 0.457031]\n",
            "3968: [D loss: 0.715173, acc: 0.541016]  [A loss: 0.888543, acc: 0.156250]\n",
            "3969: [D loss: 0.700854, acc: 0.515625]  [A loss: 0.715270, acc: 0.503906]\n",
            "3970: [D loss: 0.696329, acc: 0.527344]  [A loss: 0.827327, acc: 0.226562]\n",
            "3971: [D loss: 0.692268, acc: 0.515625]  [A loss: 0.744729, acc: 0.394531]\n",
            "3972: [D loss: 0.705757, acc: 0.531250]  [A loss: 0.863299, acc: 0.203125]\n",
            "3973: [D loss: 0.680326, acc: 0.572266]  [A loss: 0.783357, acc: 0.296875]\n",
            "3974: [D loss: 0.698520, acc: 0.501953]  [A loss: 0.800144, acc: 0.304688]\n",
            "3975: [D loss: 0.708468, acc: 0.517578]  [A loss: 0.842988, acc: 0.222656]\n",
            "3976: [D loss: 0.698750, acc: 0.525391]  [A loss: 0.786966, acc: 0.316406]\n",
            "3977: [D loss: 0.711627, acc: 0.496094]  [A loss: 0.741448, acc: 0.417969]\n",
            "3978: [D loss: 0.707667, acc: 0.521484]  [A loss: 0.873279, acc: 0.167969]\n",
            "3979: [D loss: 0.697766, acc: 0.492188]  [A loss: 0.798737, acc: 0.281250]\n",
            "3980: [D loss: 0.701320, acc: 0.529297]  [A loss: 0.840552, acc: 0.226562]\n",
            "3981: [D loss: 0.687255, acc: 0.552734]  [A loss: 0.806940, acc: 0.273438]\n",
            "3982: [D loss: 0.702139, acc: 0.548828]  [A loss: 0.809273, acc: 0.253906]\n",
            "3983: [D loss: 0.698667, acc: 0.542969]  [A loss: 0.853338, acc: 0.195312]\n",
            "3984: [D loss: 0.705963, acc: 0.498047]  [A loss: 0.702946, acc: 0.445312]\n",
            "3985: [D loss: 0.716904, acc: 0.488281]  [A loss: 0.899267, acc: 0.128906]\n",
            "3986: [D loss: 0.707228, acc: 0.521484]  [A loss: 0.745509, acc: 0.421875]\n",
            "3987: [D loss: 0.712313, acc: 0.501953]  [A loss: 0.884381, acc: 0.140625]\n",
            "3988: [D loss: 0.695752, acc: 0.507812]  [A loss: 0.764098, acc: 0.367188]\n",
            "3989: [D loss: 0.700736, acc: 0.517578]  [A loss: 0.843951, acc: 0.199219]\n",
            "3990: [D loss: 0.700289, acc: 0.511719]  [A loss: 0.830026, acc: 0.218750]\n",
            "3991: [D loss: 0.712655, acc: 0.509766]  [A loss: 0.769480, acc: 0.351562]\n",
            "3992: [D loss: 0.716262, acc: 0.496094]  [A loss: 0.859094, acc: 0.187500]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "3993: [D loss: 0.697868, acc: 0.523438]  [A loss: 0.768639, acc: 0.347656]\n",
            "3994: [D loss: 0.711650, acc: 0.498047]  [A loss: 0.834732, acc: 0.218750]\n",
            "3995: [D loss: 0.705053, acc: 0.501953]  [A loss: 0.809449, acc: 0.261719]\n",
            "3996: [D loss: 0.710024, acc: 0.476562]  [A loss: 0.821388, acc: 0.246094]\n",
            "3997: [D loss: 0.701047, acc: 0.515625]  [A loss: 0.851230, acc: 0.199219]\n",
            "3998: [D loss: 0.699276, acc: 0.529297]  [A loss: 0.780695, acc: 0.343750]\n",
            "3999: [D loss: 0.691997, acc: 0.541016]  [A loss: 0.953237, acc: 0.101562]\n",
            "4000: [D loss: 0.694542, acc: 0.523438]  [A loss: 0.729168, acc: 0.453125]\n",
            "4001: [D loss: 0.710725, acc: 0.496094]  [A loss: 0.903420, acc: 0.125000]\n",
            "4002: [D loss: 0.704713, acc: 0.490234]  [A loss: 0.683041, acc: 0.589844]\n",
            "4003: [D loss: 0.718995, acc: 0.501953]  [A loss: 0.923718, acc: 0.101562]\n",
            "4004: [D loss: 0.693194, acc: 0.546875]  [A loss: 0.635592, acc: 0.648438]\n",
            "4005: [D loss: 0.729533, acc: 0.511719]  [A loss: 1.038186, acc: 0.062500]\n",
            "4006: [D loss: 0.698798, acc: 0.537109]  [A loss: 0.711452, acc: 0.449219]\n",
            "4007: [D loss: 0.711463, acc: 0.496094]  [A loss: 0.844833, acc: 0.187500]\n",
            "4008: [D loss: 0.688227, acc: 0.544922]  [A loss: 0.751961, acc: 0.375000]\n",
            "4009: [D loss: 0.693340, acc: 0.550781]  [A loss: 0.801557, acc: 0.281250]\n",
            "4010: [D loss: 0.706200, acc: 0.517578]  [A loss: 0.780472, acc: 0.296875]\n",
            "4011: [D loss: 0.708667, acc: 0.492188]  [A loss: 0.791929, acc: 0.292969]\n",
            "4012: [D loss: 0.700597, acc: 0.515625]  [A loss: 0.849773, acc: 0.222656]\n",
            "4013: [D loss: 0.695393, acc: 0.515625]  [A loss: 0.782888, acc: 0.332031]\n",
            "4014: [D loss: 0.717933, acc: 0.498047]  [A loss: 0.831499, acc: 0.273438]\n",
            "4015: [D loss: 0.699556, acc: 0.513672]  [A loss: 0.741833, acc: 0.414062]\n",
            "4016: [D loss: 0.705207, acc: 0.513672]  [A loss: 0.843840, acc: 0.222656]\n",
            "4017: [D loss: 0.696357, acc: 0.498047]  [A loss: 0.743455, acc: 0.394531]\n",
            "4018: [D loss: 0.716968, acc: 0.472656]  [A loss: 0.811640, acc: 0.257812]\n",
            "4019: [D loss: 0.707484, acc: 0.480469]  [A loss: 0.821120, acc: 0.269531]\n",
            "4020: [D loss: 0.708566, acc: 0.490234]  [A loss: 0.787916, acc: 0.324219]\n",
            "4021: [D loss: 0.698615, acc: 0.541016]  [A loss: 0.813364, acc: 0.285156]\n",
            "4022: [D loss: 0.700891, acc: 0.513672]  [A loss: 0.821646, acc: 0.218750]\n",
            "4023: [D loss: 0.694455, acc: 0.533203]  [A loss: 0.856583, acc: 0.164062]\n",
            "4024: [D loss: 0.700329, acc: 0.490234]  [A loss: 0.767950, acc: 0.347656]\n",
            "4025: [D loss: 0.700010, acc: 0.519531]  [A loss: 0.864576, acc: 0.171875]\n",
            "4026: [D loss: 0.690471, acc: 0.539062]  [A loss: 0.730422, acc: 0.414062]\n",
            "4027: [D loss: 0.707103, acc: 0.513672]  [A loss: 0.899286, acc: 0.140625]\n",
            "4028: [D loss: 0.700282, acc: 0.517578]  [A loss: 0.688179, acc: 0.535156]\n",
            "4029: [D loss: 0.717364, acc: 0.523438]  [A loss: 0.981797, acc: 0.062500]\n",
            "4030: [D loss: 0.711645, acc: 0.505859]  [A loss: 0.710801, acc: 0.468750]\n",
            "4031: [D loss: 0.715770, acc: 0.480469]  [A loss: 0.859205, acc: 0.175781]\n",
            "4032: [D loss: 0.696029, acc: 0.535156]  [A loss: 0.730347, acc: 0.414062]\n",
            "4033: [D loss: 0.688517, acc: 0.541016]  [A loss: 0.812438, acc: 0.226562]\n",
            "4034: [D loss: 0.716582, acc: 0.468750]  [A loss: 0.775610, acc: 0.289062]\n",
            "4035: [D loss: 0.693803, acc: 0.542969]  [A loss: 0.845537, acc: 0.199219]\n",
            "4036: [D loss: 0.699110, acc: 0.544922]  [A loss: 0.798062, acc: 0.281250]\n",
            "4037: [D loss: 0.717383, acc: 0.464844]  [A loss: 0.775131, acc: 0.332031]\n",
            "4038: [D loss: 0.707620, acc: 0.507812]  [A loss: 0.874223, acc: 0.167969]\n",
            "4039: [D loss: 0.694903, acc: 0.525391]  [A loss: 0.795231, acc: 0.300781]\n",
            "4040: [D loss: 0.697111, acc: 0.552734]  [A loss: 0.792300, acc: 0.292969]\n",
            "4041: [D loss: 0.702831, acc: 0.498047]  [A loss: 0.852542, acc: 0.171875]\n",
            "4042: [D loss: 0.695633, acc: 0.501953]  [A loss: 0.883131, acc: 0.144531]\n",
            "4043: [D loss: 0.692492, acc: 0.546875]  [A loss: 0.774375, acc: 0.328125]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4044: [D loss: 0.704073, acc: 0.513672]  [A loss: 0.927491, acc: 0.113281]\n",
            "4045: [D loss: 0.690651, acc: 0.541016]  [A loss: 0.738773, acc: 0.417969]\n",
            "4046: [D loss: 0.721223, acc: 0.505859]  [A loss: 0.864944, acc: 0.207031]\n",
            "4047: [D loss: 0.690173, acc: 0.535156]  [A loss: 0.729129, acc: 0.414062]\n",
            "4048: [D loss: 0.710249, acc: 0.525391]  [A loss: 0.912878, acc: 0.121094]\n",
            "4049: [D loss: 0.695205, acc: 0.550781]  [A loss: 0.788209, acc: 0.292969]\n",
            "4050: [D loss: 0.711004, acc: 0.478516]  [A loss: 0.857683, acc: 0.191406]\n",
            "4051: [D loss: 0.694403, acc: 0.541016]  [A loss: 0.741468, acc: 0.433594]\n",
            "4052: [D loss: 0.690360, acc: 0.556641]  [A loss: 0.834198, acc: 0.222656]\n",
            "4053: [D loss: 0.696863, acc: 0.523438]  [A loss: 0.793631, acc: 0.296875]\n",
            "4054: [D loss: 0.704430, acc: 0.533203]  [A loss: 0.793314, acc: 0.308594]\n",
            "4055: [D loss: 0.699610, acc: 0.519531]  [A loss: 0.740197, acc: 0.437500]\n",
            "4056: [D loss: 0.692724, acc: 0.533203]  [A loss: 0.864386, acc: 0.179688]\n",
            "4057: [D loss: 0.698464, acc: 0.535156]  [A loss: 0.751273, acc: 0.355469]\n",
            "4058: [D loss: 0.699037, acc: 0.525391]  [A loss: 0.927940, acc: 0.128906]\n",
            "4059: [D loss: 0.707070, acc: 0.478516]  [A loss: 0.726968, acc: 0.437500]\n",
            "4060: [D loss: 0.714594, acc: 0.519531]  [A loss: 0.918179, acc: 0.144531]\n",
            "4061: [D loss: 0.697015, acc: 0.521484]  [A loss: 0.781353, acc: 0.308594]\n",
            "4062: [D loss: 0.712705, acc: 0.496094]  [A loss: 0.833130, acc: 0.171875]\n",
            "4063: [D loss: 0.715387, acc: 0.498047]  [A loss: 0.833416, acc: 0.207031]\n",
            "4064: [D loss: 0.704208, acc: 0.523438]  [A loss: 0.800182, acc: 0.320312]\n",
            "4065: [D loss: 0.699115, acc: 0.498047]  [A loss: 0.872168, acc: 0.183594]\n",
            "4066: [D loss: 0.711386, acc: 0.492188]  [A loss: 0.785960, acc: 0.281250]\n",
            "4067: [D loss: 0.709738, acc: 0.498047]  [A loss: 0.818346, acc: 0.269531]\n",
            "4068: [D loss: 0.707735, acc: 0.490234]  [A loss: 0.773762, acc: 0.343750]\n",
            "4069: [D loss: 0.699627, acc: 0.541016]  [A loss: 0.808915, acc: 0.246094]\n",
            "4070: [D loss: 0.699416, acc: 0.529297]  [A loss: 0.755969, acc: 0.382812]\n",
            "4071: [D loss: 0.709026, acc: 0.494141]  [A loss: 0.901884, acc: 0.132812]\n",
            "4072: [D loss: 0.700033, acc: 0.501953]  [A loss: 0.746420, acc: 0.390625]\n",
            "4073: [D loss: 0.723840, acc: 0.492188]  [A loss: 0.967356, acc: 0.093750]\n",
            "4074: [D loss: 0.703447, acc: 0.509766]  [A loss: 0.726920, acc: 0.417969]\n",
            "4075: [D loss: 0.710383, acc: 0.515625]  [A loss: 0.939494, acc: 0.101562]\n",
            "4076: [D loss: 0.694793, acc: 0.525391]  [A loss: 0.730234, acc: 0.429688]\n",
            "4077: [D loss: 0.701945, acc: 0.539062]  [A loss: 0.920564, acc: 0.152344]\n",
            "4078: [D loss: 0.694903, acc: 0.525391]  [A loss: 0.693506, acc: 0.519531]\n",
            "4079: [D loss: 0.715630, acc: 0.501953]  [A loss: 0.860493, acc: 0.195312]\n",
            "4080: [D loss: 0.706564, acc: 0.494141]  [A loss: 0.775556, acc: 0.347656]\n",
            "4081: [D loss: 0.695069, acc: 0.537109]  [A loss: 0.775591, acc: 0.328125]\n",
            "4082: [D loss: 0.698391, acc: 0.523438]  [A loss: 0.778349, acc: 0.324219]\n",
            "4083: [D loss: 0.703041, acc: 0.511719]  [A loss: 0.812478, acc: 0.265625]\n",
            "4084: [D loss: 0.702753, acc: 0.533203]  [A loss: 0.861018, acc: 0.195312]\n",
            "4085: [D loss: 0.712654, acc: 0.484375]  [A loss: 0.780460, acc: 0.316406]\n",
            "4086: [D loss: 0.708043, acc: 0.486328]  [A loss: 0.850542, acc: 0.207031]\n",
            "4087: [D loss: 0.703214, acc: 0.503906]  [A loss: 0.758834, acc: 0.332031]\n",
            "4088: [D loss: 0.698088, acc: 0.529297]  [A loss: 0.888729, acc: 0.152344]\n",
            "4089: [D loss: 0.687844, acc: 0.558594]  [A loss: 0.745178, acc: 0.410156]\n",
            "4090: [D loss: 0.700963, acc: 0.505859]  [A loss: 0.854687, acc: 0.203125]\n",
            "4091: [D loss: 0.712449, acc: 0.525391]  [A loss: 0.792773, acc: 0.324219]\n",
            "4092: [D loss: 0.700648, acc: 0.513672]  [A loss: 0.831804, acc: 0.250000]\n",
            "4093: [D loss: 0.694782, acc: 0.519531]  [A loss: 0.786318, acc: 0.339844]\n",
            "4094: [D loss: 0.702383, acc: 0.539062]  [A loss: 0.949514, acc: 0.101562]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4095: [D loss: 0.706804, acc: 0.480469]  [A loss: 0.681393, acc: 0.542969]\n",
            "4096: [D loss: 0.715989, acc: 0.509766]  [A loss: 0.869367, acc: 0.140625]\n",
            "4097: [D loss: 0.690074, acc: 0.531250]  [A loss: 0.743884, acc: 0.414062]\n",
            "4098: [D loss: 0.702881, acc: 0.531250]  [A loss: 0.851269, acc: 0.195312]\n",
            "4099: [D loss: 0.691871, acc: 0.519531]  [A loss: 0.776218, acc: 0.304688]\n",
            "4100: [D loss: 0.705624, acc: 0.529297]  [A loss: 0.930414, acc: 0.109375]\n",
            "4101: [D loss: 0.710856, acc: 0.509766]  [A loss: 0.719414, acc: 0.457031]\n",
            "4102: [D loss: 0.709414, acc: 0.535156]  [A loss: 0.792735, acc: 0.277344]\n",
            "4103: [D loss: 0.702081, acc: 0.531250]  [A loss: 0.768632, acc: 0.339844]\n",
            "4104: [D loss: 0.714562, acc: 0.509766]  [A loss: 0.842430, acc: 0.203125]\n",
            "4105: [D loss: 0.682053, acc: 0.542969]  [A loss: 0.797741, acc: 0.316406]\n",
            "4106: [D loss: 0.697005, acc: 0.533203]  [A loss: 0.911125, acc: 0.144531]\n",
            "4107: [D loss: 0.683929, acc: 0.566406]  [A loss: 0.747776, acc: 0.363281]\n",
            "4108: [D loss: 0.725013, acc: 0.488281]  [A loss: 0.937768, acc: 0.121094]\n",
            "4109: [D loss: 0.700693, acc: 0.517578]  [A loss: 0.721512, acc: 0.464844]\n",
            "4110: [D loss: 0.713980, acc: 0.496094]  [A loss: 0.883067, acc: 0.183594]\n",
            "4111: [D loss: 0.694426, acc: 0.503906]  [A loss: 0.727152, acc: 0.453125]\n",
            "4112: [D loss: 0.687691, acc: 0.558594]  [A loss: 0.943148, acc: 0.128906]\n",
            "4113: [D loss: 0.682744, acc: 0.546875]  [A loss: 0.726686, acc: 0.425781]\n",
            "4114: [D loss: 0.705016, acc: 0.523438]  [A loss: 0.854871, acc: 0.203125]\n",
            "4115: [D loss: 0.690503, acc: 0.535156]  [A loss: 0.727228, acc: 0.437500]\n",
            "4116: [D loss: 0.704604, acc: 0.529297]  [A loss: 0.883951, acc: 0.175781]\n",
            "4117: [D loss: 0.683232, acc: 0.589844]  [A loss: 0.727974, acc: 0.468750]\n",
            "4118: [D loss: 0.702816, acc: 0.511719]  [A loss: 0.872239, acc: 0.207031]\n",
            "4119: [D loss: 0.700566, acc: 0.501953]  [A loss: 0.774310, acc: 0.367188]\n",
            "4120: [D loss: 0.698902, acc: 0.541016]  [A loss: 0.816301, acc: 0.230469]\n",
            "4121: [D loss: 0.702020, acc: 0.501953]  [A loss: 0.802871, acc: 0.281250]\n",
            "4122: [D loss: 0.696831, acc: 0.537109]  [A loss: 0.843910, acc: 0.218750]\n",
            "4123: [D loss: 0.692612, acc: 0.531250]  [A loss: 0.795575, acc: 0.320312]\n",
            "4124: [D loss: 0.693203, acc: 0.544922]  [A loss: 0.900689, acc: 0.136719]\n",
            "4125: [D loss: 0.693881, acc: 0.544922]  [A loss: 0.711982, acc: 0.445312]\n",
            "4126: [D loss: 0.710277, acc: 0.500000]  [A loss: 0.941492, acc: 0.117188]\n",
            "4127: [D loss: 0.694089, acc: 0.513672]  [A loss: 0.699706, acc: 0.496094]\n",
            "4128: [D loss: 0.711567, acc: 0.511719]  [A loss: 0.926596, acc: 0.113281]\n",
            "4129: [D loss: 0.699871, acc: 0.546875]  [A loss: 0.727862, acc: 0.425781]\n",
            "4130: [D loss: 0.701545, acc: 0.531250]  [A loss: 0.853594, acc: 0.203125]\n",
            "4131: [D loss: 0.704979, acc: 0.513672]  [A loss: 0.759107, acc: 0.363281]\n",
            "4132: [D loss: 0.703300, acc: 0.521484]  [A loss: 0.962397, acc: 0.085938]\n",
            "4133: [D loss: 0.699444, acc: 0.513672]  [A loss: 0.716891, acc: 0.476562]\n",
            "4134: [D loss: 0.709059, acc: 0.519531]  [A loss: 0.840702, acc: 0.222656]\n",
            "4135: [D loss: 0.709069, acc: 0.511719]  [A loss: 0.772704, acc: 0.339844]\n",
            "4136: [D loss: 0.695529, acc: 0.519531]  [A loss: 0.823060, acc: 0.265625]\n",
            "4137: [D loss: 0.698249, acc: 0.533203]  [A loss: 0.806570, acc: 0.250000]\n",
            "4138: [D loss: 0.693519, acc: 0.542969]  [A loss: 0.829010, acc: 0.277344]\n",
            "4139: [D loss: 0.692401, acc: 0.517578]  [A loss: 0.801472, acc: 0.296875]\n",
            "4140: [D loss: 0.720628, acc: 0.486328]  [A loss: 0.753911, acc: 0.375000]\n",
            "4141: [D loss: 0.706595, acc: 0.511719]  [A loss: 0.926240, acc: 0.121094]\n",
            "4142: [D loss: 0.700698, acc: 0.507812]  [A loss: 0.735587, acc: 0.386719]\n",
            "4143: [D loss: 0.698285, acc: 0.523438]  [A loss: 0.977633, acc: 0.078125]\n",
            "4144: [D loss: 0.695678, acc: 0.505859]  [A loss: 0.717855, acc: 0.476562]\n",
            "4145: [D loss: 0.712896, acc: 0.505859]  [A loss: 0.876948, acc: 0.199219]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4146: [D loss: 0.710859, acc: 0.488281]  [A loss: 0.761028, acc: 0.335938]\n",
            "4147: [D loss: 0.700581, acc: 0.515625]  [A loss: 0.844860, acc: 0.195312]\n",
            "4148: [D loss: 0.701546, acc: 0.556641]  [A loss: 0.757414, acc: 0.375000]\n",
            "4149: [D loss: 0.719720, acc: 0.492188]  [A loss: 0.925938, acc: 0.101562]\n",
            "4150: [D loss: 0.697071, acc: 0.511719]  [A loss: 0.810154, acc: 0.253906]\n",
            "4151: [D loss: 0.706554, acc: 0.523438]  [A loss: 0.803655, acc: 0.304688]\n",
            "4152: [D loss: 0.691232, acc: 0.535156]  [A loss: 0.874991, acc: 0.164062]\n",
            "4153: [D loss: 0.703248, acc: 0.503906]  [A loss: 0.766093, acc: 0.375000]\n",
            "4154: [D loss: 0.700116, acc: 0.531250]  [A loss: 0.834253, acc: 0.230469]\n",
            "4155: [D loss: 0.699859, acc: 0.496094]  [A loss: 0.798745, acc: 0.292969]\n",
            "4156: [D loss: 0.707061, acc: 0.505859]  [A loss: 0.827076, acc: 0.238281]\n",
            "4157: [D loss: 0.693278, acc: 0.541016]  [A loss: 0.831559, acc: 0.234375]\n",
            "4158: [D loss: 0.707615, acc: 0.521484]  [A loss: 0.794102, acc: 0.300781]\n",
            "4159: [D loss: 0.701884, acc: 0.511719]  [A loss: 0.894051, acc: 0.156250]\n",
            "4160: [D loss: 0.712304, acc: 0.476562]  [A loss: 0.704517, acc: 0.496094]\n",
            "4161: [D loss: 0.702071, acc: 0.556641]  [A loss: 0.920332, acc: 0.105469]\n",
            "4162: [D loss: 0.702227, acc: 0.533203]  [A loss: 0.722692, acc: 0.464844]\n",
            "4163: [D loss: 0.708718, acc: 0.507812]  [A loss: 0.946598, acc: 0.085938]\n",
            "4164: [D loss: 0.692859, acc: 0.548828]  [A loss: 0.674455, acc: 0.609375]\n",
            "4165: [D loss: 0.715674, acc: 0.517578]  [A loss: 0.875346, acc: 0.164062]\n",
            "4166: [D loss: 0.694912, acc: 0.544922]  [A loss: 0.803877, acc: 0.281250]\n",
            "4167: [D loss: 0.694318, acc: 0.529297]  [A loss: 0.818458, acc: 0.261719]\n",
            "4168: [D loss: 0.698528, acc: 0.513672]  [A loss: 0.793893, acc: 0.281250]\n",
            "4169: [D loss: 0.715666, acc: 0.498047]  [A loss: 0.831773, acc: 0.199219]\n",
            "4170: [D loss: 0.697824, acc: 0.507812]  [A loss: 0.774352, acc: 0.363281]\n",
            "4171: [D loss: 0.693400, acc: 0.550781]  [A loss: 0.872922, acc: 0.164062]\n",
            "4172: [D loss: 0.698349, acc: 0.517578]  [A loss: 0.798022, acc: 0.285156]\n",
            "4173: [D loss: 0.690998, acc: 0.546875]  [A loss: 0.796517, acc: 0.324219]\n",
            "4174: [D loss: 0.703330, acc: 0.496094]  [A loss: 0.807329, acc: 0.277344]\n",
            "4175: [D loss: 0.701821, acc: 0.509766]  [A loss: 0.816304, acc: 0.269531]\n",
            "4176: [D loss: 0.710485, acc: 0.505859]  [A loss: 0.863125, acc: 0.183594]\n",
            "4177: [D loss: 0.705890, acc: 0.496094]  [A loss: 0.836574, acc: 0.238281]\n",
            "4178: [D loss: 0.694778, acc: 0.527344]  [A loss: 0.761695, acc: 0.347656]\n",
            "4179: [D loss: 0.693822, acc: 0.562500]  [A loss: 0.898735, acc: 0.183594]\n",
            "4180: [D loss: 0.700732, acc: 0.527344]  [A loss: 0.769654, acc: 0.367188]\n",
            "4181: [D loss: 0.715393, acc: 0.501953]  [A loss: 0.879802, acc: 0.179688]\n",
            "4182: [D loss: 0.691403, acc: 0.529297]  [A loss: 0.746224, acc: 0.386719]\n",
            "4183: [D loss: 0.734503, acc: 0.488281]  [A loss: 0.975113, acc: 0.082031]\n",
            "4184: [D loss: 0.704419, acc: 0.519531]  [A loss: 0.625974, acc: 0.699219]\n",
            "4185: [D loss: 0.717725, acc: 0.488281]  [A loss: 0.858573, acc: 0.167969]\n",
            "4186: [D loss: 0.700516, acc: 0.539062]  [A loss: 0.732195, acc: 0.472656]\n",
            "4187: [D loss: 0.714599, acc: 0.507812]  [A loss: 0.838750, acc: 0.269531]\n",
            "4188: [D loss: 0.703662, acc: 0.523438]  [A loss: 0.741479, acc: 0.382812]\n",
            "4189: [D loss: 0.703588, acc: 0.498047]  [A loss: 0.817683, acc: 0.253906]\n",
            "4190: [D loss: 0.712102, acc: 0.501953]  [A loss: 0.740829, acc: 0.398438]\n",
            "4191: [D loss: 0.702237, acc: 0.500000]  [A loss: 0.766144, acc: 0.351562]\n",
            "4192: [D loss: 0.704617, acc: 0.529297]  [A loss: 0.840018, acc: 0.195312]\n",
            "4193: [D loss: 0.703049, acc: 0.486328]  [A loss: 0.748734, acc: 0.378906]\n",
            "4194: [D loss: 0.712684, acc: 0.480469]  [A loss: 0.823307, acc: 0.230469]\n",
            "4195: [D loss: 0.697425, acc: 0.544922]  [A loss: 0.916653, acc: 0.117188]\n",
            "4196: [D loss: 0.695629, acc: 0.517578]  [A loss: 0.679790, acc: 0.527344]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4197: [D loss: 0.737615, acc: 0.496094]  [A loss: 0.946412, acc: 0.082031]\n",
            "4198: [D loss: 0.690320, acc: 0.527344]  [A loss: 0.725145, acc: 0.437500]\n",
            "4199: [D loss: 0.706039, acc: 0.511719]  [A loss: 0.848567, acc: 0.195312]\n",
            "4200: [D loss: 0.710479, acc: 0.457031]  [A loss: 0.787590, acc: 0.308594]\n",
            "4201: [D loss: 0.715369, acc: 0.527344]  [A loss: 0.793914, acc: 0.265625]\n",
            "4202: [D loss: 0.699984, acc: 0.509766]  [A loss: 0.817616, acc: 0.246094]\n",
            "4203: [D loss: 0.706975, acc: 0.511719]  [A loss: 0.780480, acc: 0.289062]\n",
            "4204: [D loss: 0.697727, acc: 0.556641]  [A loss: 0.815741, acc: 0.257812]\n",
            "4205: [D loss: 0.718565, acc: 0.494141]  [A loss: 0.743509, acc: 0.421875]\n",
            "4206: [D loss: 0.727770, acc: 0.490234]  [A loss: 1.010356, acc: 0.046875]\n",
            "4207: [D loss: 0.712563, acc: 0.505859]  [A loss: 0.697339, acc: 0.500000]\n",
            "4208: [D loss: 0.724816, acc: 0.501953]  [A loss: 0.810044, acc: 0.265625]\n",
            "4209: [D loss: 0.707349, acc: 0.490234]  [A loss: 0.844761, acc: 0.207031]\n",
            "4210: [D loss: 0.702363, acc: 0.501953]  [A loss: 0.792785, acc: 0.265625]\n",
            "4211: [D loss: 0.702249, acc: 0.509766]  [A loss: 0.836000, acc: 0.199219]\n",
            "4212: [D loss: 0.706571, acc: 0.494141]  [A loss: 0.793408, acc: 0.292969]\n",
            "4213: [D loss: 0.708526, acc: 0.523438]  [A loss: 0.793434, acc: 0.246094]\n",
            "4214: [D loss: 0.699942, acc: 0.531250]  [A loss: 0.766572, acc: 0.343750]\n",
            "4215: [D loss: 0.698063, acc: 0.535156]  [A loss: 0.835873, acc: 0.226562]\n",
            "4216: [D loss: 0.701900, acc: 0.490234]  [A loss: 0.785219, acc: 0.316406]\n",
            "4217: [D loss: 0.706541, acc: 0.500000]  [A loss: 0.850479, acc: 0.210938]\n",
            "4218: [D loss: 0.711632, acc: 0.509766]  [A loss: 0.747325, acc: 0.410156]\n",
            "4219: [D loss: 0.718240, acc: 0.484375]  [A loss: 0.855599, acc: 0.167969]\n",
            "4220: [D loss: 0.699687, acc: 0.515625]  [A loss: 0.736790, acc: 0.398438]\n",
            "4221: [D loss: 0.706732, acc: 0.494141]  [A loss: 0.883766, acc: 0.144531]\n",
            "4222: [D loss: 0.691390, acc: 0.533203]  [A loss: 0.784248, acc: 0.312500]\n",
            "4223: [D loss: 0.718475, acc: 0.486328]  [A loss: 0.905809, acc: 0.144531]\n",
            "4224: [D loss: 0.695553, acc: 0.548828]  [A loss: 0.716570, acc: 0.488281]\n",
            "4225: [D loss: 0.714991, acc: 0.500000]  [A loss: 0.854567, acc: 0.140625]\n",
            "4226: [D loss: 0.705233, acc: 0.498047]  [A loss: 0.822636, acc: 0.207031]\n",
            "4227: [D loss: 0.713376, acc: 0.496094]  [A loss: 0.778130, acc: 0.308594]\n",
            "4228: [D loss: 0.716138, acc: 0.488281]  [A loss: 0.889765, acc: 0.144531]\n",
            "4229: [D loss: 0.702063, acc: 0.531250]  [A loss: 0.743734, acc: 0.410156]\n",
            "4230: [D loss: 0.705853, acc: 0.533203]  [A loss: 0.900962, acc: 0.156250]\n",
            "4231: [D loss: 0.692607, acc: 0.537109]  [A loss: 0.713471, acc: 0.484375]\n",
            "4232: [D loss: 0.710712, acc: 0.500000]  [A loss: 0.930198, acc: 0.105469]\n",
            "4233: [D loss: 0.706524, acc: 0.505859]  [A loss: 0.761957, acc: 0.343750]\n",
            "4234: [D loss: 0.698543, acc: 0.527344]  [A loss: 0.887052, acc: 0.132812]\n",
            "4235: [D loss: 0.701996, acc: 0.498047]  [A loss: 0.747613, acc: 0.367188]\n",
            "4236: [D loss: 0.711832, acc: 0.529297]  [A loss: 0.880948, acc: 0.148438]\n",
            "4237: [D loss: 0.694423, acc: 0.542969]  [A loss: 0.788194, acc: 0.347656]\n",
            "4238: [D loss: 0.706196, acc: 0.503906]  [A loss: 0.830391, acc: 0.226562]\n",
            "4239: [D loss: 0.688448, acc: 0.539062]  [A loss: 0.797694, acc: 0.292969]\n",
            "4240: [D loss: 0.716328, acc: 0.498047]  [A loss: 0.897762, acc: 0.121094]\n",
            "4241: [D loss: 0.686022, acc: 0.548828]  [A loss: 0.739125, acc: 0.449219]\n",
            "4242: [D loss: 0.714419, acc: 0.490234]  [A loss: 0.953703, acc: 0.097656]\n",
            "4243: [D loss: 0.699716, acc: 0.484375]  [A loss: 0.702466, acc: 0.503906]\n",
            "4244: [D loss: 0.712361, acc: 0.503906]  [A loss: 0.907067, acc: 0.164062]\n",
            "4245: [D loss: 0.684924, acc: 0.546875]  [A loss: 0.720034, acc: 0.476562]\n",
            "4246: [D loss: 0.706662, acc: 0.527344]  [A loss: 0.829588, acc: 0.269531]\n",
            "4247: [D loss: 0.702670, acc: 0.486328]  [A loss: 0.741606, acc: 0.378906]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4248: [D loss: 0.693797, acc: 0.523438]  [A loss: 0.866953, acc: 0.164062]\n",
            "4249: [D loss: 0.690978, acc: 0.550781]  [A loss: 0.785865, acc: 0.285156]\n",
            "4250: [D loss: 0.697692, acc: 0.546875]  [A loss: 0.823810, acc: 0.257812]\n",
            "4251: [D loss: 0.693082, acc: 0.525391]  [A loss: 0.751388, acc: 0.394531]\n",
            "4252: [D loss: 0.698943, acc: 0.521484]  [A loss: 0.886784, acc: 0.125000]\n",
            "4253: [D loss: 0.701400, acc: 0.500000]  [A loss: 0.733224, acc: 0.429688]\n",
            "4254: [D loss: 0.699377, acc: 0.548828]  [A loss: 0.895230, acc: 0.105469]\n",
            "4255: [D loss: 0.703517, acc: 0.486328]  [A loss: 0.762920, acc: 0.363281]\n",
            "4256: [D loss: 0.709485, acc: 0.519531]  [A loss: 0.931527, acc: 0.113281]\n",
            "4257: [D loss: 0.708745, acc: 0.519531]  [A loss: 0.720683, acc: 0.417969]\n",
            "4258: [D loss: 0.713116, acc: 0.513672]  [A loss: 0.869343, acc: 0.187500]\n",
            "4259: [D loss: 0.702720, acc: 0.513672]  [A loss: 0.728196, acc: 0.429688]\n",
            "4260: [D loss: 0.718533, acc: 0.509766]  [A loss: 0.939607, acc: 0.097656]\n",
            "4261: [D loss: 0.687591, acc: 0.537109]  [A loss: 0.666937, acc: 0.613281]\n",
            "4262: [D loss: 0.720413, acc: 0.498047]  [A loss: 0.941686, acc: 0.085938]\n",
            "4263: [D loss: 0.707922, acc: 0.519531]  [A loss: 0.723209, acc: 0.417969]\n",
            "4264: [D loss: 0.705526, acc: 0.488281]  [A loss: 0.835424, acc: 0.210938]\n",
            "4265: [D loss: 0.691951, acc: 0.552734]  [A loss: 0.762847, acc: 0.343750]\n",
            "4266: [D loss: 0.709140, acc: 0.509766]  [A loss: 0.829734, acc: 0.222656]\n",
            "4267: [D loss: 0.698649, acc: 0.529297]  [A loss: 0.776187, acc: 0.308594]\n",
            "4268: [D loss: 0.695361, acc: 0.525391]  [A loss: 0.768123, acc: 0.328125]\n",
            "4269: [D loss: 0.679286, acc: 0.556641]  [A loss: 0.829348, acc: 0.257812]\n",
            "4270: [D loss: 0.708051, acc: 0.484375]  [A loss: 0.755161, acc: 0.339844]\n",
            "4271: [D loss: 0.698661, acc: 0.527344]  [A loss: 0.845526, acc: 0.195312]\n",
            "4272: [D loss: 0.694873, acc: 0.546875]  [A loss: 0.766614, acc: 0.363281]\n",
            "4273: [D loss: 0.709577, acc: 0.482422]  [A loss: 0.839350, acc: 0.167969]\n",
            "4274: [D loss: 0.698572, acc: 0.542969]  [A loss: 0.782624, acc: 0.300781]\n",
            "4275: [D loss: 0.689895, acc: 0.580078]  [A loss: 0.829502, acc: 0.207031]\n",
            "4276: [D loss: 0.696298, acc: 0.523438]  [A loss: 0.778773, acc: 0.355469]\n",
            "4277: [D loss: 0.692133, acc: 0.537109]  [A loss: 0.820399, acc: 0.250000]\n",
            "4278: [D loss: 0.695882, acc: 0.550781]  [A loss: 0.849861, acc: 0.214844]\n",
            "4279: [D loss: 0.700627, acc: 0.513672]  [A loss: 0.831950, acc: 0.257812]\n",
            "4280: [D loss: 0.697478, acc: 0.517578]  [A loss: 0.851378, acc: 0.187500]\n",
            "4281: [D loss: 0.712079, acc: 0.500000]  [A loss: 0.862477, acc: 0.148438]\n",
            "4282: [D loss: 0.710526, acc: 0.492188]  [A loss: 0.794694, acc: 0.296875]\n",
            "4283: [D loss: 0.700488, acc: 0.529297]  [A loss: 0.930004, acc: 0.113281]\n",
            "4284: [D loss: 0.713087, acc: 0.468750]  [A loss: 0.744164, acc: 0.437500]\n",
            "4285: [D loss: 0.713226, acc: 0.503906]  [A loss: 0.907341, acc: 0.113281]\n",
            "4286: [D loss: 0.709512, acc: 0.488281]  [A loss: 0.709942, acc: 0.484375]\n",
            "4287: [D loss: 0.715921, acc: 0.511719]  [A loss: 0.862014, acc: 0.144531]\n",
            "4288: [D loss: 0.702237, acc: 0.500000]  [A loss: 0.733235, acc: 0.394531]\n",
            "4289: [D loss: 0.707358, acc: 0.519531]  [A loss: 0.933859, acc: 0.089844]\n",
            "4290: [D loss: 0.696578, acc: 0.535156]  [A loss: 0.695113, acc: 0.496094]\n",
            "4291: [D loss: 0.715748, acc: 0.527344]  [A loss: 0.900525, acc: 0.117188]\n",
            "4292: [D loss: 0.692804, acc: 0.523438]  [A loss: 0.732175, acc: 0.375000]\n",
            "4293: [D loss: 0.704652, acc: 0.519531]  [A loss: 0.931404, acc: 0.109375]\n",
            "4294: [D loss: 0.699328, acc: 0.511719]  [A loss: 0.690184, acc: 0.519531]\n",
            "4295: [D loss: 0.718367, acc: 0.513672]  [A loss: 0.949353, acc: 0.074219]\n",
            "4296: [D loss: 0.692947, acc: 0.550781]  [A loss: 0.698616, acc: 0.511719]\n",
            "4297: [D loss: 0.710158, acc: 0.517578]  [A loss: 0.828040, acc: 0.218750]\n",
            "4298: [D loss: 0.696029, acc: 0.533203]  [A loss: 0.768490, acc: 0.339844]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4299: [D loss: 0.690182, acc: 0.550781]  [A loss: 0.841557, acc: 0.218750]\n",
            "4300: [D loss: 0.698553, acc: 0.511719]  [A loss: 0.772797, acc: 0.308594]\n",
            "4301: [D loss: 0.708462, acc: 0.501953]  [A loss: 0.828348, acc: 0.261719]\n",
            "4302: [D loss: 0.716529, acc: 0.486328]  [A loss: 0.773107, acc: 0.304688]\n",
            "4303: [D loss: 0.693315, acc: 0.554688]  [A loss: 0.855431, acc: 0.187500]\n",
            "4304: [D loss: 0.700921, acc: 0.505859]  [A loss: 0.743431, acc: 0.410156]\n",
            "4305: [D loss: 0.722072, acc: 0.501953]  [A loss: 0.897873, acc: 0.105469]\n",
            "4306: [D loss: 0.711718, acc: 0.472656]  [A loss: 0.773484, acc: 0.332031]\n",
            "4307: [D loss: 0.703517, acc: 0.517578]  [A loss: 0.847363, acc: 0.199219]\n",
            "4308: [D loss: 0.695629, acc: 0.515625]  [A loss: 0.797573, acc: 0.312500]\n",
            "4309: [D loss: 0.693294, acc: 0.527344]  [A loss: 0.807025, acc: 0.277344]\n",
            "4310: [D loss: 0.689976, acc: 0.558594]  [A loss: 0.866636, acc: 0.191406]\n",
            "4311: [D loss: 0.696554, acc: 0.533203]  [A loss: 0.741189, acc: 0.441406]\n",
            "4312: [D loss: 0.717308, acc: 0.503906]  [A loss: 0.912687, acc: 0.167969]\n",
            "4313: [D loss: 0.705618, acc: 0.484375]  [A loss: 0.757348, acc: 0.363281]\n",
            "4314: [D loss: 0.705289, acc: 0.490234]  [A loss: 0.862053, acc: 0.167969]\n",
            "4315: [D loss: 0.686441, acc: 0.564453]  [A loss: 0.787479, acc: 0.308594]\n",
            "4316: [D loss: 0.703332, acc: 0.535156]  [A loss: 0.845436, acc: 0.199219]\n",
            "4317: [D loss: 0.700997, acc: 0.517578]  [A loss: 0.810174, acc: 0.230469]\n",
            "4318: [D loss: 0.715754, acc: 0.482422]  [A loss: 0.872671, acc: 0.191406]\n",
            "4319: [D loss: 0.706910, acc: 0.500000]  [A loss: 0.730770, acc: 0.421875]\n",
            "4320: [D loss: 0.723921, acc: 0.511719]  [A loss: 1.027625, acc: 0.050781]\n",
            "4321: [D loss: 0.708465, acc: 0.515625]  [A loss: 0.662075, acc: 0.597656]\n",
            "4322: [D loss: 0.728594, acc: 0.488281]  [A loss: 0.888595, acc: 0.101562]\n",
            "4323: [D loss: 0.701980, acc: 0.527344]  [A loss: 0.709882, acc: 0.441406]\n",
            "4324: [D loss: 0.709665, acc: 0.531250]  [A loss: 0.871685, acc: 0.148438]\n",
            "4325: [D loss: 0.717240, acc: 0.486328]  [A loss: 0.723337, acc: 0.433594]\n",
            "4326: [D loss: 0.704492, acc: 0.523438]  [A loss: 0.851983, acc: 0.164062]\n",
            "4327: [D loss: 0.693113, acc: 0.509766]  [A loss: 0.747697, acc: 0.398438]\n",
            "4328: [D loss: 0.699036, acc: 0.501953]  [A loss: 0.889913, acc: 0.160156]\n",
            "4329: [D loss: 0.696173, acc: 0.542969]  [A loss: 0.783627, acc: 0.269531]\n",
            "4330: [D loss: 0.709292, acc: 0.498047]  [A loss: 0.840465, acc: 0.203125]\n",
            "4331: [D loss: 0.692475, acc: 0.544922]  [A loss: 0.733266, acc: 0.449219]\n",
            "4332: [D loss: 0.722589, acc: 0.509766]  [A loss: 0.941459, acc: 0.113281]\n",
            "4333: [D loss: 0.705570, acc: 0.511719]  [A loss: 0.746939, acc: 0.378906]\n",
            "4334: [D loss: 0.710941, acc: 0.496094]  [A loss: 0.847163, acc: 0.179688]\n",
            "4335: [D loss: 0.700903, acc: 0.527344]  [A loss: 0.815741, acc: 0.238281]\n",
            "4336: [D loss: 0.689429, acc: 0.533203]  [A loss: 0.810072, acc: 0.222656]\n",
            "4337: [D loss: 0.695912, acc: 0.529297]  [A loss: 0.816474, acc: 0.234375]\n",
            "4338: [D loss: 0.684235, acc: 0.556641]  [A loss: 0.736762, acc: 0.398438]\n",
            "4339: [D loss: 0.685736, acc: 0.548828]  [A loss: 0.858067, acc: 0.191406]\n",
            "4340: [D loss: 0.702898, acc: 0.505859]  [A loss: 0.732851, acc: 0.402344]\n",
            "4341: [D loss: 0.716711, acc: 0.501953]  [A loss: 0.902392, acc: 0.132812]\n",
            "4342: [D loss: 0.703542, acc: 0.505859]  [A loss: 0.685063, acc: 0.503906]\n",
            "4343: [D loss: 0.714273, acc: 0.492188]  [A loss: 0.917961, acc: 0.078125]\n",
            "4344: [D loss: 0.689962, acc: 0.539062]  [A loss: 0.697687, acc: 0.507812]\n",
            "4345: [D loss: 0.711867, acc: 0.527344]  [A loss: 0.875469, acc: 0.152344]\n",
            "4346: [D loss: 0.698419, acc: 0.523438]  [A loss: 0.731142, acc: 0.429688]\n",
            "4347: [D loss: 0.713999, acc: 0.503906]  [A loss: 0.911235, acc: 0.117188]\n",
            "4348: [D loss: 0.696385, acc: 0.533203]  [A loss: 0.726289, acc: 0.441406]\n",
            "4349: [D loss: 0.689886, acc: 0.527344]  [A loss: 0.830227, acc: 0.187500]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4350: [D loss: 0.701563, acc: 0.509766]  [A loss: 0.799222, acc: 0.300781]\n",
            "4351: [D loss: 0.710488, acc: 0.482422]  [A loss: 0.793134, acc: 0.289062]\n",
            "4352: [D loss: 0.713720, acc: 0.484375]  [A loss: 0.865503, acc: 0.199219]\n",
            "4353: [D loss: 0.703731, acc: 0.498047]  [A loss: 0.748754, acc: 0.371094]\n",
            "4354: [D loss: 0.706050, acc: 0.527344]  [A loss: 0.888024, acc: 0.140625]\n",
            "4355: [D loss: 0.691632, acc: 0.541016]  [A loss: 0.717704, acc: 0.457031]\n",
            "4356: [D loss: 0.713215, acc: 0.525391]  [A loss: 0.962887, acc: 0.050781]\n",
            "4357: [D loss: 0.699775, acc: 0.533203]  [A loss: 0.722561, acc: 0.464844]\n",
            "4358: [D loss: 0.706764, acc: 0.486328]  [A loss: 0.831735, acc: 0.199219]\n",
            "4359: [D loss: 0.696620, acc: 0.519531]  [A loss: 0.780289, acc: 0.296875]\n",
            "4360: [D loss: 0.693294, acc: 0.542969]  [A loss: 0.802903, acc: 0.277344]\n",
            "4361: [D loss: 0.698033, acc: 0.521484]  [A loss: 0.749309, acc: 0.398438]\n",
            "4362: [D loss: 0.697279, acc: 0.535156]  [A loss: 0.821242, acc: 0.257812]\n",
            "4363: [D loss: 0.699475, acc: 0.544922]  [A loss: 0.775774, acc: 0.328125]\n",
            "4364: [D loss: 0.698708, acc: 0.529297]  [A loss: 0.846348, acc: 0.203125]\n",
            "4365: [D loss: 0.692728, acc: 0.546875]  [A loss: 0.767829, acc: 0.328125]\n",
            "4366: [D loss: 0.701668, acc: 0.515625]  [A loss: 0.848186, acc: 0.210938]\n",
            "4367: [D loss: 0.699628, acc: 0.517578]  [A loss: 0.683315, acc: 0.523438]\n",
            "4368: [D loss: 0.732533, acc: 0.494141]  [A loss: 0.961701, acc: 0.089844]\n",
            "4369: [D loss: 0.713078, acc: 0.468750]  [A loss: 0.718336, acc: 0.429688]\n",
            "4370: [D loss: 0.712651, acc: 0.505859]  [A loss: 0.828069, acc: 0.210938]\n",
            "4371: [D loss: 0.695779, acc: 0.500000]  [A loss: 0.763214, acc: 0.347656]\n",
            "4372: [D loss: 0.708846, acc: 0.513672]  [A loss: 0.886265, acc: 0.160156]\n",
            "4373: [D loss: 0.698097, acc: 0.548828]  [A loss: 0.740950, acc: 0.371094]\n",
            "4374: [D loss: 0.701104, acc: 0.537109]  [A loss: 0.895805, acc: 0.156250]\n",
            "4375: [D loss: 0.691737, acc: 0.513672]  [A loss: 0.740241, acc: 0.421875]\n",
            "4376: [D loss: 0.710992, acc: 0.519531]  [A loss: 0.792699, acc: 0.296875]\n",
            "4377: [D loss: 0.699738, acc: 0.519531]  [A loss: 0.772598, acc: 0.324219]\n",
            "4378: [D loss: 0.700940, acc: 0.529297]  [A loss: 0.823754, acc: 0.226562]\n",
            "4379: [D loss: 0.696726, acc: 0.525391]  [A loss: 0.731842, acc: 0.449219]\n",
            "4380: [D loss: 0.712179, acc: 0.503906]  [A loss: 0.875470, acc: 0.121094]\n",
            "4381: [D loss: 0.692334, acc: 0.552734]  [A loss: 0.755892, acc: 0.386719]\n",
            "4382: [D loss: 0.692516, acc: 0.544922]  [A loss: 0.784629, acc: 0.273438]\n",
            "4383: [D loss: 0.689348, acc: 0.542969]  [A loss: 0.825967, acc: 0.238281]\n",
            "4384: [D loss: 0.694302, acc: 0.539062]  [A loss: 0.794013, acc: 0.269531]\n",
            "4385: [D loss: 0.709022, acc: 0.498047]  [A loss: 0.825892, acc: 0.210938]\n",
            "4386: [D loss: 0.711002, acc: 0.505859]  [A loss: 0.902838, acc: 0.117188]\n",
            "4387: [D loss: 0.683812, acc: 0.533203]  [A loss: 0.726723, acc: 0.453125]\n",
            "4388: [D loss: 0.721980, acc: 0.505859]  [A loss: 0.872472, acc: 0.156250]\n",
            "4389: [D loss: 0.692484, acc: 0.535156]  [A loss: 0.793736, acc: 0.320312]\n",
            "4390: [D loss: 0.706403, acc: 0.503906]  [A loss: 0.831413, acc: 0.214844]\n",
            "4391: [D loss: 0.692171, acc: 0.525391]  [A loss: 0.723967, acc: 0.453125]\n",
            "4392: [D loss: 0.706501, acc: 0.511719]  [A loss: 0.914329, acc: 0.148438]\n",
            "4393: [D loss: 0.690620, acc: 0.529297]  [A loss: 0.739006, acc: 0.386719]\n",
            "4394: [D loss: 0.702605, acc: 0.503906]  [A loss: 0.985562, acc: 0.042969]\n",
            "4395: [D loss: 0.701492, acc: 0.533203]  [A loss: 0.661787, acc: 0.636719]\n",
            "4396: [D loss: 0.714282, acc: 0.501953]  [A loss: 0.902136, acc: 0.085938]\n",
            "4397: [D loss: 0.692227, acc: 0.548828]  [A loss: 0.742261, acc: 0.375000]\n",
            "4398: [D loss: 0.702304, acc: 0.515625]  [A loss: 0.841235, acc: 0.171875]\n",
            "4399: [D loss: 0.698153, acc: 0.521484]  [A loss: 0.775015, acc: 0.371094]\n",
            "4400: [D loss: 0.707619, acc: 0.496094]  [A loss: 0.893860, acc: 0.093750]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4401: [D loss: 0.698169, acc: 0.486328]  [A loss: 0.730196, acc: 0.414062]\n",
            "4402: [D loss: 0.707487, acc: 0.515625]  [A loss: 0.938891, acc: 0.070312]\n",
            "4403: [D loss: 0.696839, acc: 0.525391]  [A loss: 0.697785, acc: 0.535156]\n",
            "4404: [D loss: 0.712870, acc: 0.511719]  [A loss: 0.873916, acc: 0.144531]\n",
            "4405: [D loss: 0.687488, acc: 0.535156]  [A loss: 0.687031, acc: 0.539062]\n",
            "4406: [D loss: 0.711969, acc: 0.517578]  [A loss: 0.924159, acc: 0.097656]\n",
            "4407: [D loss: 0.703201, acc: 0.521484]  [A loss: 0.681383, acc: 0.562500]\n",
            "4408: [D loss: 0.713374, acc: 0.515625]  [A loss: 0.856754, acc: 0.160156]\n",
            "4409: [D loss: 0.705654, acc: 0.472656]  [A loss: 0.757580, acc: 0.328125]\n",
            "4410: [D loss: 0.692747, acc: 0.533203]  [A loss: 0.854138, acc: 0.167969]\n",
            "4411: [D loss: 0.698130, acc: 0.505859]  [A loss: 0.764297, acc: 0.371094]\n",
            "4412: [D loss: 0.712176, acc: 0.500000]  [A loss: 0.817895, acc: 0.230469]\n",
            "4413: [D loss: 0.709436, acc: 0.494141]  [A loss: 0.736435, acc: 0.402344]\n",
            "4414: [D loss: 0.701391, acc: 0.542969]  [A loss: 0.908240, acc: 0.125000]\n",
            "4415: [D loss: 0.695111, acc: 0.550781]  [A loss: 0.702773, acc: 0.496094]\n",
            "4416: [D loss: 0.718879, acc: 0.503906]  [A loss: 0.844425, acc: 0.203125]\n",
            "4417: [D loss: 0.702711, acc: 0.529297]  [A loss: 0.809345, acc: 0.265625]\n",
            "4418: [D loss: 0.697131, acc: 0.521484]  [A loss: 0.848883, acc: 0.179688]\n",
            "4419: [D loss: 0.695361, acc: 0.521484]  [A loss: 0.762514, acc: 0.332031]\n",
            "4420: [D loss: 0.702092, acc: 0.525391]  [A loss: 0.812167, acc: 0.257812]\n",
            "4421: [D loss: 0.697536, acc: 0.529297]  [A loss: 0.805506, acc: 0.253906]\n",
            "4422: [D loss: 0.700753, acc: 0.507812]  [A loss: 0.835847, acc: 0.207031]\n",
            "4423: [D loss: 0.697587, acc: 0.531250]  [A loss: 0.739302, acc: 0.367188]\n",
            "4424: [D loss: 0.703410, acc: 0.513672]  [A loss: 0.840218, acc: 0.210938]\n",
            "4425: [D loss: 0.693729, acc: 0.533203]  [A loss: 0.711816, acc: 0.472656]\n",
            "4426: [D loss: 0.711206, acc: 0.515625]  [A loss: 0.850646, acc: 0.199219]\n",
            "4427: [D loss: 0.689951, acc: 0.550781]  [A loss: 0.753547, acc: 0.367188]\n",
            "4428: [D loss: 0.715227, acc: 0.500000]  [A loss: 0.870318, acc: 0.156250]\n",
            "4429: [D loss: 0.705746, acc: 0.507812]  [A loss: 0.741897, acc: 0.406250]\n",
            "4430: [D loss: 0.715225, acc: 0.486328]  [A loss: 0.881734, acc: 0.140625]\n",
            "4431: [D loss: 0.700560, acc: 0.527344]  [A loss: 0.747777, acc: 0.398438]\n",
            "4432: [D loss: 0.713658, acc: 0.496094]  [A loss: 0.822804, acc: 0.257812]\n",
            "4433: [D loss: 0.693554, acc: 0.537109]  [A loss: 0.818287, acc: 0.277344]\n",
            "4434: [D loss: 0.706169, acc: 0.509766]  [A loss: 0.842832, acc: 0.191406]\n",
            "4435: [D loss: 0.682459, acc: 0.556641]  [A loss: 0.777588, acc: 0.316406]\n",
            "4436: [D loss: 0.702415, acc: 0.494141]  [A loss: 0.876713, acc: 0.164062]\n",
            "4437: [D loss: 0.698220, acc: 0.537109]  [A loss: 0.696490, acc: 0.515625]\n",
            "4438: [D loss: 0.723094, acc: 0.490234]  [A loss: 0.993987, acc: 0.058594]\n",
            "4439: [D loss: 0.698480, acc: 0.525391]  [A loss: 0.696095, acc: 0.519531]\n",
            "4440: [D loss: 0.721431, acc: 0.509766]  [A loss: 0.836146, acc: 0.203125]\n",
            "4441: [D loss: 0.714324, acc: 0.498047]  [A loss: 0.893029, acc: 0.136719]\n",
            "4442: [D loss: 0.693629, acc: 0.537109]  [A loss: 0.739380, acc: 0.398438]\n",
            "4443: [D loss: 0.712422, acc: 0.521484]  [A loss: 0.927316, acc: 0.101562]\n",
            "4444: [D loss: 0.696459, acc: 0.539062]  [A loss: 0.687868, acc: 0.546875]\n",
            "4445: [D loss: 0.725931, acc: 0.486328]  [A loss: 0.941219, acc: 0.101562]\n",
            "4446: [D loss: 0.704948, acc: 0.509766]  [A loss: 0.704513, acc: 0.472656]\n",
            "4447: [D loss: 0.708124, acc: 0.515625]  [A loss: 0.852007, acc: 0.179688]\n",
            "4448: [D loss: 0.699250, acc: 0.525391]  [A loss: 0.717689, acc: 0.445312]\n",
            "4449: [D loss: 0.700435, acc: 0.529297]  [A loss: 0.871506, acc: 0.187500]\n",
            "4450: [D loss: 0.694736, acc: 0.533203]  [A loss: 0.734195, acc: 0.425781]\n",
            "4451: [D loss: 0.710395, acc: 0.490234]  [A loss: 0.806107, acc: 0.230469]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4452: [D loss: 0.688026, acc: 0.562500]  [A loss: 0.821965, acc: 0.218750]\n",
            "4453: [D loss: 0.698130, acc: 0.525391]  [A loss: 0.842503, acc: 0.203125]\n",
            "4454: [D loss: 0.696093, acc: 0.527344]  [A loss: 0.765899, acc: 0.335938]\n",
            "4455: [D loss: 0.705750, acc: 0.505859]  [A loss: 0.859687, acc: 0.183594]\n",
            "4456: [D loss: 0.703051, acc: 0.523438]  [A loss: 0.733707, acc: 0.429688]\n",
            "4457: [D loss: 0.721030, acc: 0.496094]  [A loss: 0.849679, acc: 0.183594]\n",
            "4458: [D loss: 0.691145, acc: 0.531250]  [A loss: 0.748713, acc: 0.410156]\n",
            "4459: [D loss: 0.713801, acc: 0.521484]  [A loss: 0.861698, acc: 0.160156]\n",
            "4460: [D loss: 0.692381, acc: 0.539062]  [A loss: 0.785188, acc: 0.300781]\n",
            "4461: [D loss: 0.686557, acc: 0.558594]  [A loss: 0.884747, acc: 0.140625]\n",
            "4462: [D loss: 0.696142, acc: 0.560547]  [A loss: 0.710815, acc: 0.496094]\n",
            "4463: [D loss: 0.702403, acc: 0.505859]  [A loss: 0.883029, acc: 0.136719]\n",
            "4464: [D loss: 0.697273, acc: 0.529297]  [A loss: 0.760196, acc: 0.339844]\n",
            "4465: [D loss: 0.699022, acc: 0.539062]  [A loss: 0.935562, acc: 0.097656]\n",
            "4466: [D loss: 0.699690, acc: 0.507812]  [A loss: 0.698716, acc: 0.507812]\n",
            "4467: [D loss: 0.719792, acc: 0.494141]  [A loss: 0.905216, acc: 0.140625]\n",
            "4468: [D loss: 0.691456, acc: 0.517578]  [A loss: 0.760979, acc: 0.375000]\n",
            "4469: [D loss: 0.705284, acc: 0.492188]  [A loss: 0.850421, acc: 0.199219]\n",
            "4470: [D loss: 0.699609, acc: 0.492188]  [A loss: 0.752711, acc: 0.390625]\n",
            "4471: [D loss: 0.698493, acc: 0.521484]  [A loss: 0.885933, acc: 0.167969]\n",
            "4472: [D loss: 0.707413, acc: 0.496094]  [A loss: 0.742320, acc: 0.386719]\n",
            "4473: [D loss: 0.693712, acc: 0.525391]  [A loss: 0.869265, acc: 0.179688]\n",
            "4474: [D loss: 0.689438, acc: 0.527344]  [A loss: 0.770608, acc: 0.339844]\n",
            "4475: [D loss: 0.710603, acc: 0.515625]  [A loss: 0.839477, acc: 0.210938]\n",
            "4476: [D loss: 0.704827, acc: 0.521484]  [A loss: 0.808673, acc: 0.281250]\n",
            "4477: [D loss: 0.701897, acc: 0.542969]  [A loss: 0.894513, acc: 0.160156]\n",
            "4478: [D loss: 0.696011, acc: 0.507812]  [A loss: 0.738302, acc: 0.429688]\n",
            "4479: [D loss: 0.703211, acc: 0.513672]  [A loss: 0.844264, acc: 0.191406]\n",
            "4480: [D loss: 0.697716, acc: 0.490234]  [A loss: 0.841627, acc: 0.203125]\n",
            "4481: [D loss: 0.696253, acc: 0.513672]  [A loss: 0.776554, acc: 0.351562]\n",
            "4482: [D loss: 0.709369, acc: 0.486328]  [A loss: 0.782522, acc: 0.289062]\n",
            "4483: [D loss: 0.704333, acc: 0.515625]  [A loss: 0.843177, acc: 0.222656]\n",
            "4484: [D loss: 0.708538, acc: 0.501953]  [A loss: 0.889842, acc: 0.128906]\n",
            "4485: [D loss: 0.695402, acc: 0.521484]  [A loss: 0.768673, acc: 0.320312]\n",
            "4486: [D loss: 0.703919, acc: 0.519531]  [A loss: 0.904242, acc: 0.121094]\n",
            "4487: [D loss: 0.704984, acc: 0.511719]  [A loss: 0.750799, acc: 0.386719]\n",
            "4488: [D loss: 0.696928, acc: 0.521484]  [A loss: 0.875367, acc: 0.156250]\n",
            "4489: [D loss: 0.700616, acc: 0.509766]  [A loss: 0.708989, acc: 0.484375]\n",
            "4490: [D loss: 0.724043, acc: 0.509766]  [A loss: 1.001943, acc: 0.039062]\n",
            "4491: [D loss: 0.700536, acc: 0.525391]  [A loss: 0.711370, acc: 0.476562]\n",
            "4492: [D loss: 0.712997, acc: 0.474609]  [A loss: 0.918431, acc: 0.105469]\n",
            "4493: [D loss: 0.698979, acc: 0.535156]  [A loss: 0.710154, acc: 0.488281]\n",
            "4494: [D loss: 0.710156, acc: 0.517578]  [A loss: 0.886196, acc: 0.140625]\n",
            "4495: [D loss: 0.693794, acc: 0.517578]  [A loss: 0.751514, acc: 0.390625]\n",
            "4496: [D loss: 0.704161, acc: 0.539062]  [A loss: 0.914371, acc: 0.113281]\n",
            "4497: [D loss: 0.713844, acc: 0.482422]  [A loss: 0.725979, acc: 0.429688]\n",
            "4498: [D loss: 0.706299, acc: 0.503906]  [A loss: 0.853641, acc: 0.167969]\n",
            "4499: [D loss: 0.710775, acc: 0.517578]  [A loss: 0.735938, acc: 0.410156]\n",
            "4500: [D loss: 0.698934, acc: 0.533203]  [A loss: 0.829706, acc: 0.238281]\n",
            "4501: [D loss: 0.687444, acc: 0.556641]  [A loss: 0.823610, acc: 0.261719]\n",
            "4502: [D loss: 0.698644, acc: 0.523438]  [A loss: 0.819100, acc: 0.242188]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4503: [D loss: 0.691998, acc: 0.523438]  [A loss: 0.800486, acc: 0.304688]\n",
            "4504: [D loss: 0.709493, acc: 0.500000]  [A loss: 0.900893, acc: 0.140625]\n",
            "4505: [D loss: 0.695560, acc: 0.544922]  [A loss: 0.754575, acc: 0.355469]\n",
            "4506: [D loss: 0.695494, acc: 0.554688]  [A loss: 0.903975, acc: 0.191406]\n",
            "4507: [D loss: 0.710888, acc: 0.460938]  [A loss: 0.723568, acc: 0.449219]\n",
            "4508: [D loss: 0.705421, acc: 0.515625]  [A loss: 0.915436, acc: 0.136719]\n",
            "4509: [D loss: 0.714054, acc: 0.486328]  [A loss: 0.740810, acc: 0.386719]\n",
            "4510: [D loss: 0.710656, acc: 0.501953]  [A loss: 0.864404, acc: 0.191406]\n",
            "4511: [D loss: 0.687399, acc: 0.527344]  [A loss: 0.813700, acc: 0.257812]\n",
            "4512: [D loss: 0.710438, acc: 0.472656]  [A loss: 0.832733, acc: 0.226562]\n",
            "4513: [D loss: 0.710368, acc: 0.500000]  [A loss: 0.946405, acc: 0.093750]\n",
            "4514: [D loss: 0.693459, acc: 0.548828]  [A loss: 0.752723, acc: 0.363281]\n",
            "4515: [D loss: 0.701548, acc: 0.529297]  [A loss: 0.910358, acc: 0.136719]\n",
            "4516: [D loss: 0.707245, acc: 0.480469]  [A loss: 0.705016, acc: 0.476562]\n",
            "4517: [D loss: 0.710142, acc: 0.507812]  [A loss: 0.893768, acc: 0.156250]\n",
            "4518: [D loss: 0.702792, acc: 0.517578]  [A loss: 0.702404, acc: 0.519531]\n",
            "4519: [D loss: 0.701978, acc: 0.515625]  [A loss: 0.855522, acc: 0.207031]\n",
            "4520: [D loss: 0.713398, acc: 0.480469]  [A loss: 0.774602, acc: 0.292969]\n",
            "4521: [D loss: 0.699097, acc: 0.521484]  [A loss: 0.883887, acc: 0.171875]\n",
            "4522: [D loss: 0.702730, acc: 0.517578]  [A loss: 0.767359, acc: 0.351562]\n",
            "4523: [D loss: 0.708331, acc: 0.511719]  [A loss: 0.897812, acc: 0.152344]\n",
            "4524: [D loss: 0.701114, acc: 0.517578]  [A loss: 0.692127, acc: 0.515625]\n",
            "4525: [D loss: 0.718227, acc: 0.480469]  [A loss: 0.883066, acc: 0.164062]\n",
            "4526: [D loss: 0.691337, acc: 0.546875]  [A loss: 0.746368, acc: 0.382812]\n",
            "4527: [D loss: 0.721421, acc: 0.498047]  [A loss: 0.932442, acc: 0.128906]\n",
            "4528: [D loss: 0.703232, acc: 0.533203]  [A loss: 0.707593, acc: 0.488281]\n",
            "4529: [D loss: 0.708279, acc: 0.505859]  [A loss: 0.865344, acc: 0.175781]\n",
            "4530: [D loss: 0.693519, acc: 0.521484]  [A loss: 0.758019, acc: 0.351562]\n",
            "4531: [D loss: 0.711662, acc: 0.509766]  [A loss: 0.832067, acc: 0.242188]\n",
            "4532: [D loss: 0.695151, acc: 0.550781]  [A loss: 0.756994, acc: 0.394531]\n",
            "4533: [D loss: 0.698162, acc: 0.542969]  [A loss: 0.804650, acc: 0.277344]\n",
            "4534: [D loss: 0.696547, acc: 0.484375]  [A loss: 0.741421, acc: 0.390625]\n",
            "4535: [D loss: 0.708402, acc: 0.523438]  [A loss: 0.873869, acc: 0.156250]\n",
            "4536: [D loss: 0.700982, acc: 0.496094]  [A loss: 0.771818, acc: 0.300781]\n",
            "4537: [D loss: 0.699406, acc: 0.541016]  [A loss: 0.865675, acc: 0.218750]\n",
            "4538: [D loss: 0.702686, acc: 0.513672]  [A loss: 0.706427, acc: 0.488281]\n",
            "4539: [D loss: 0.710856, acc: 0.521484]  [A loss: 0.840248, acc: 0.199219]\n",
            "4540: [D loss: 0.699030, acc: 0.505859]  [A loss: 0.748035, acc: 0.406250]\n",
            "4541: [D loss: 0.716827, acc: 0.474609]  [A loss: 0.853990, acc: 0.195312]\n",
            "4542: [D loss: 0.710444, acc: 0.498047]  [A loss: 0.827461, acc: 0.226562]\n",
            "4543: [D loss: 0.704886, acc: 0.525391]  [A loss: 0.764481, acc: 0.339844]\n",
            "4544: [D loss: 0.709393, acc: 0.515625]  [A loss: 0.879180, acc: 0.152344]\n",
            "4545: [D loss: 0.693103, acc: 0.539062]  [A loss: 0.716805, acc: 0.457031]\n",
            "4546: [D loss: 0.735506, acc: 0.478516]  [A loss: 0.940151, acc: 0.093750]\n",
            "4547: [D loss: 0.692363, acc: 0.544922]  [A loss: 0.725071, acc: 0.449219]\n",
            "4548: [D loss: 0.716501, acc: 0.539062]  [A loss: 0.890255, acc: 0.144531]\n",
            "4549: [D loss: 0.710242, acc: 0.482422]  [A loss: 0.749156, acc: 0.406250]\n",
            "4550: [D loss: 0.714936, acc: 0.509766]  [A loss: 0.907581, acc: 0.125000]\n",
            "4551: [D loss: 0.693088, acc: 0.509766]  [A loss: 0.739848, acc: 0.417969]\n",
            "4552: [D loss: 0.711191, acc: 0.511719]  [A loss: 0.800422, acc: 0.285156]\n",
            "4553: [D loss: 0.701864, acc: 0.496094]  [A loss: 0.799406, acc: 0.257812]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4554: [D loss: 0.691329, acc: 0.529297]  [A loss: 0.802685, acc: 0.281250]\n",
            "4555: [D loss: 0.703420, acc: 0.533203]  [A loss: 0.843017, acc: 0.234375]\n",
            "4556: [D loss: 0.700676, acc: 0.509766]  [A loss: 0.766752, acc: 0.363281]\n",
            "4557: [D loss: 0.691780, acc: 0.533203]  [A loss: 0.883240, acc: 0.156250]\n",
            "4558: [D loss: 0.695005, acc: 0.521484]  [A loss: 0.771330, acc: 0.351562]\n",
            "4559: [D loss: 0.695412, acc: 0.533203]  [A loss: 0.810480, acc: 0.273438]\n",
            "4560: [D loss: 0.703316, acc: 0.515625]  [A loss: 0.770476, acc: 0.335938]\n",
            "4561: [D loss: 0.719106, acc: 0.507812]  [A loss: 0.811133, acc: 0.257812]\n",
            "4562: [D loss: 0.685842, acc: 0.548828]  [A loss: 0.841262, acc: 0.203125]\n",
            "4563: [D loss: 0.690154, acc: 0.535156]  [A loss: 0.805136, acc: 0.289062]\n",
            "4564: [D loss: 0.692145, acc: 0.539062]  [A loss: 0.791046, acc: 0.304688]\n",
            "4565: [D loss: 0.714258, acc: 0.519531]  [A loss: 0.923536, acc: 0.085938]\n",
            "4566: [D loss: 0.685071, acc: 0.542969]  [A loss: 0.694591, acc: 0.523438]\n",
            "4567: [D loss: 0.731645, acc: 0.507812]  [A loss: 0.933102, acc: 0.125000]\n",
            "4568: [D loss: 0.705880, acc: 0.503906]  [A loss: 0.739831, acc: 0.398438]\n",
            "4569: [D loss: 0.712537, acc: 0.511719]  [A loss: 0.809531, acc: 0.273438]\n",
            "4570: [D loss: 0.700009, acc: 0.509766]  [A loss: 0.767431, acc: 0.382812]\n",
            "4571: [D loss: 0.705890, acc: 0.498047]  [A loss: 0.860582, acc: 0.171875]\n",
            "4572: [D loss: 0.696070, acc: 0.531250]  [A loss: 0.819594, acc: 0.207031]\n",
            "4573: [D loss: 0.687023, acc: 0.537109]  [A loss: 0.832937, acc: 0.191406]\n",
            "4574: [D loss: 0.689802, acc: 0.527344]  [A loss: 0.840079, acc: 0.214844]\n",
            "4575: [D loss: 0.703891, acc: 0.505859]  [A loss: 0.787777, acc: 0.292969]\n",
            "4576: [D loss: 0.714941, acc: 0.500000]  [A loss: 0.974231, acc: 0.078125]\n",
            "4577: [D loss: 0.707058, acc: 0.486328]  [A loss: 0.728831, acc: 0.390625]\n",
            "4578: [D loss: 0.721707, acc: 0.511719]  [A loss: 0.918324, acc: 0.113281]\n",
            "4579: [D loss: 0.691145, acc: 0.527344]  [A loss: 0.744216, acc: 0.402344]\n",
            "4580: [D loss: 0.702988, acc: 0.533203]  [A loss: 0.857870, acc: 0.214844]\n",
            "4581: [D loss: 0.701656, acc: 0.517578]  [A loss: 0.773716, acc: 0.316406]\n",
            "4582: [D loss: 0.704610, acc: 0.519531]  [A loss: 0.835981, acc: 0.222656]\n",
            "4583: [D loss: 0.696486, acc: 0.554688]  [A loss: 0.817564, acc: 0.265625]\n",
            "4584: [D loss: 0.704548, acc: 0.501953]  [A loss: 0.820652, acc: 0.246094]\n",
            "4585: [D loss: 0.696021, acc: 0.548828]  [A loss: 0.804766, acc: 0.285156]\n",
            "4586: [D loss: 0.697802, acc: 0.552734]  [A loss: 0.859337, acc: 0.191406]\n",
            "4587: [D loss: 0.683476, acc: 0.550781]  [A loss: 0.684613, acc: 0.550781]\n",
            "4588: [D loss: 0.736353, acc: 0.511719]  [A loss: 1.016466, acc: 0.054688]\n",
            "4589: [D loss: 0.703553, acc: 0.503906]  [A loss: 0.713724, acc: 0.441406]\n",
            "4590: [D loss: 0.704346, acc: 0.519531]  [A loss: 0.822440, acc: 0.226562]\n",
            "4591: [D loss: 0.696299, acc: 0.541016]  [A loss: 0.746675, acc: 0.398438]\n",
            "4592: [D loss: 0.716308, acc: 0.511719]  [A loss: 0.818451, acc: 0.257812]\n",
            "4593: [D loss: 0.697026, acc: 0.503906]  [A loss: 0.794708, acc: 0.296875]\n",
            "4594: [D loss: 0.705891, acc: 0.527344]  [A loss: 0.811873, acc: 0.300781]\n",
            "4595: [D loss: 0.699999, acc: 0.529297]  [A loss: 0.795977, acc: 0.308594]\n",
            "4596: [D loss: 0.704560, acc: 0.480469]  [A loss: 0.781026, acc: 0.332031]\n",
            "4597: [D loss: 0.698649, acc: 0.488281]  [A loss: 0.807839, acc: 0.296875]\n",
            "4598: [D loss: 0.716835, acc: 0.507812]  [A loss: 0.767056, acc: 0.351562]\n",
            "4599: [D loss: 0.708845, acc: 0.511719]  [A loss: 0.818925, acc: 0.281250]\n",
            "4600: [D loss: 0.695721, acc: 0.525391]  [A loss: 0.833113, acc: 0.195312]\n",
            "4601: [D loss: 0.712071, acc: 0.503906]  [A loss: 0.866120, acc: 0.171875]\n",
            "4602: [D loss: 0.695723, acc: 0.511719]  [A loss: 0.747183, acc: 0.406250]\n",
            "4603: [D loss: 0.715126, acc: 0.498047]  [A loss: 0.821063, acc: 0.238281]\n",
            "4604: [D loss: 0.696650, acc: 0.523438]  [A loss: 0.815027, acc: 0.250000]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4605: [D loss: 0.698485, acc: 0.519531]  [A loss: 0.847712, acc: 0.191406]\n",
            "4606: [D loss: 0.710189, acc: 0.503906]  [A loss: 0.715700, acc: 0.457031]\n",
            "4607: [D loss: 0.711945, acc: 0.496094]  [A loss: 0.834392, acc: 0.242188]\n",
            "4608: [D loss: 0.700041, acc: 0.529297]  [A loss: 0.812863, acc: 0.226562]\n",
            "4609: [D loss: 0.703122, acc: 0.496094]  [A loss: 0.794673, acc: 0.296875]\n",
            "4610: [D loss: 0.706073, acc: 0.542969]  [A loss: 0.868161, acc: 0.187500]\n",
            "4611: [D loss: 0.688206, acc: 0.548828]  [A loss: 0.805912, acc: 0.253906]\n",
            "4612: [D loss: 0.708103, acc: 0.498047]  [A loss: 0.810889, acc: 0.289062]\n",
            "4613: [D loss: 0.704782, acc: 0.486328]  [A loss: 0.810398, acc: 0.261719]\n",
            "4614: [D loss: 0.719426, acc: 0.492188]  [A loss: 0.839431, acc: 0.226562]\n",
            "4615: [D loss: 0.711793, acc: 0.503906]  [A loss: 0.807014, acc: 0.289062]\n",
            "4616: [D loss: 0.704887, acc: 0.537109]  [A loss: 0.897841, acc: 0.113281]\n",
            "4617: [D loss: 0.716388, acc: 0.496094]  [A loss: 0.741418, acc: 0.382812]\n",
            "4618: [D loss: 0.715444, acc: 0.484375]  [A loss: 0.969834, acc: 0.066406]\n",
            "4619: [D loss: 0.699945, acc: 0.519531]  [A loss: 0.724651, acc: 0.445312]\n",
            "4620: [D loss: 0.702819, acc: 0.513672]  [A loss: 0.826606, acc: 0.242188]\n",
            "4621: [D loss: 0.686076, acc: 0.541016]  [A loss: 0.777532, acc: 0.335938]\n",
            "4622: [D loss: 0.712708, acc: 0.498047]  [A loss: 0.914020, acc: 0.121094]\n",
            "4623: [D loss: 0.699907, acc: 0.527344]  [A loss: 0.754848, acc: 0.378906]\n",
            "4624: [D loss: 0.714733, acc: 0.498047]  [A loss: 0.884608, acc: 0.218750]\n",
            "4625: [D loss: 0.716900, acc: 0.501953]  [A loss: 0.818320, acc: 0.292969]\n",
            "4626: [D loss: 0.706155, acc: 0.501953]  [A loss: 0.849477, acc: 0.214844]\n",
            "4627: [D loss: 0.700855, acc: 0.501953]  [A loss: 0.786434, acc: 0.300781]\n",
            "4628: [D loss: 0.708226, acc: 0.513672]  [A loss: 0.780787, acc: 0.347656]\n",
            "4629: [D loss: 0.714026, acc: 0.490234]  [A loss: 0.853799, acc: 0.222656]\n",
            "4630: [D loss: 0.695989, acc: 0.513672]  [A loss: 0.755966, acc: 0.425781]\n",
            "4631: [D loss: 0.728887, acc: 0.496094]  [A loss: 0.997221, acc: 0.062500]\n",
            "4632: [D loss: 0.699551, acc: 0.515625]  [A loss: 0.678322, acc: 0.562500]\n",
            "4633: [D loss: 0.714102, acc: 0.519531]  [A loss: 0.866397, acc: 0.210938]\n",
            "4634: [D loss: 0.713119, acc: 0.458984]  [A loss: 0.718398, acc: 0.445312]\n",
            "4635: [D loss: 0.710843, acc: 0.509766]  [A loss: 0.866709, acc: 0.203125]\n",
            "4636: [D loss: 0.703909, acc: 0.503906]  [A loss: 0.694429, acc: 0.515625]\n",
            "4637: [D loss: 0.720778, acc: 0.462891]  [A loss: 0.902275, acc: 0.128906]\n",
            "4638: [D loss: 0.708154, acc: 0.494141]  [A loss: 0.696840, acc: 0.484375]\n",
            "4639: [D loss: 0.696231, acc: 0.515625]  [A loss: 0.791817, acc: 0.355469]\n",
            "4640: [D loss: 0.706771, acc: 0.533203]  [A loss: 0.751010, acc: 0.363281]\n",
            "4641: [D loss: 0.706051, acc: 0.542969]  [A loss: 0.853718, acc: 0.179688]\n",
            "4642: [D loss: 0.694876, acc: 0.535156]  [A loss: 0.771173, acc: 0.335938]\n",
            "4643: [D loss: 0.706386, acc: 0.525391]  [A loss: 0.906886, acc: 0.089844]\n",
            "4644: [D loss: 0.684957, acc: 0.558594]  [A loss: 0.700464, acc: 0.488281]\n",
            "4645: [D loss: 0.715226, acc: 0.511719]  [A loss: 0.976817, acc: 0.078125]\n",
            "4646: [D loss: 0.704669, acc: 0.513672]  [A loss: 0.693790, acc: 0.492188]\n",
            "4647: [D loss: 0.719770, acc: 0.482422]  [A loss: 0.818276, acc: 0.269531]\n",
            "4648: [D loss: 0.703162, acc: 0.507812]  [A loss: 0.796933, acc: 0.300781]\n",
            "4649: [D loss: 0.702584, acc: 0.525391]  [A loss: 0.791509, acc: 0.289062]\n",
            "4650: [D loss: 0.694318, acc: 0.511719]  [A loss: 0.837500, acc: 0.250000]\n",
            "4651: [D loss: 0.684799, acc: 0.533203]  [A loss: 0.748854, acc: 0.402344]\n",
            "4652: [D loss: 0.715597, acc: 0.498047]  [A loss: 0.881384, acc: 0.156250]\n",
            "4653: [D loss: 0.691352, acc: 0.525391]  [A loss: 0.759461, acc: 0.371094]\n",
            "4654: [D loss: 0.704520, acc: 0.511719]  [A loss: 0.926476, acc: 0.125000]\n",
            "4655: [D loss: 0.695383, acc: 0.541016]  [A loss: 0.733048, acc: 0.406250]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4656: [D loss: 0.697930, acc: 0.529297]  [A loss: 0.819244, acc: 0.265625]\n",
            "4657: [D loss: 0.706146, acc: 0.494141]  [A loss: 0.871206, acc: 0.195312]\n",
            "4658: [D loss: 0.697779, acc: 0.533203]  [A loss: 0.766950, acc: 0.367188]\n",
            "4659: [D loss: 0.706599, acc: 0.525391]  [A loss: 0.831275, acc: 0.250000]\n",
            "4660: [D loss: 0.716623, acc: 0.464844]  [A loss: 0.849693, acc: 0.195312]\n",
            "4661: [D loss: 0.690514, acc: 0.560547]  [A loss: 0.752883, acc: 0.378906]\n",
            "4662: [D loss: 0.704300, acc: 0.515625]  [A loss: 0.988143, acc: 0.089844]\n",
            "4663: [D loss: 0.720462, acc: 0.462891]  [A loss: 0.711567, acc: 0.492188]\n",
            "4664: [D loss: 0.712938, acc: 0.498047]  [A loss: 0.921322, acc: 0.144531]\n",
            "4665: [D loss: 0.699461, acc: 0.541016]  [A loss: 0.674904, acc: 0.601562]\n",
            "4666: [D loss: 0.711076, acc: 0.509766]  [A loss: 0.868064, acc: 0.203125]\n",
            "4667: [D loss: 0.705516, acc: 0.486328]  [A loss: 0.706058, acc: 0.464844]\n",
            "4668: [D loss: 0.700994, acc: 0.544922]  [A loss: 0.835378, acc: 0.214844]\n",
            "4669: [D loss: 0.702294, acc: 0.507812]  [A loss: 0.770219, acc: 0.351562]\n",
            "4670: [D loss: 0.712975, acc: 0.494141]  [A loss: 0.775605, acc: 0.324219]\n",
            "4671: [D loss: 0.718339, acc: 0.472656]  [A loss: 0.780333, acc: 0.304688]\n",
            "4672: [D loss: 0.705705, acc: 0.509766]  [A loss: 0.815905, acc: 0.257812]\n",
            "4673: [D loss: 0.685385, acc: 0.523438]  [A loss: 0.764036, acc: 0.347656]\n",
            "4674: [D loss: 0.702035, acc: 0.537109]  [A loss: 0.860556, acc: 0.187500]\n",
            "4675: [D loss: 0.700167, acc: 0.533203]  [A loss: 0.790744, acc: 0.292969]\n",
            "4676: [D loss: 0.719429, acc: 0.451172]  [A loss: 0.772279, acc: 0.320312]\n",
            "4677: [D loss: 0.691576, acc: 0.541016]  [A loss: 0.816417, acc: 0.226562]\n",
            "4678: [D loss: 0.704506, acc: 0.513672]  [A loss: 0.839517, acc: 0.238281]\n",
            "4679: [D loss: 0.693568, acc: 0.541016]  [A loss: 0.758344, acc: 0.375000]\n",
            "4680: [D loss: 0.697389, acc: 0.517578]  [A loss: 0.860437, acc: 0.171875]\n",
            "4681: [D loss: 0.700033, acc: 0.509766]  [A loss: 0.768343, acc: 0.359375]\n",
            "4682: [D loss: 0.693422, acc: 0.511719]  [A loss: 0.861976, acc: 0.210938]\n",
            "4683: [D loss: 0.709717, acc: 0.505859]  [A loss: 0.783600, acc: 0.335938]\n",
            "4684: [D loss: 0.686109, acc: 0.556641]  [A loss: 0.870584, acc: 0.199219]\n",
            "4685: [D loss: 0.696568, acc: 0.529297]  [A loss: 0.809638, acc: 0.312500]\n",
            "4686: [D loss: 0.699652, acc: 0.490234]  [A loss: 0.849588, acc: 0.195312]\n",
            "4687: [D loss: 0.716516, acc: 0.496094]  [A loss: 0.798033, acc: 0.320312]\n",
            "4688: [D loss: 0.702887, acc: 0.535156]  [A loss: 0.915709, acc: 0.128906]\n",
            "4689: [D loss: 0.691668, acc: 0.537109]  [A loss: 0.720239, acc: 0.437500]\n",
            "4690: [D loss: 0.699950, acc: 0.539062]  [A loss: 0.943910, acc: 0.082031]\n",
            "4691: [D loss: 0.706333, acc: 0.523438]  [A loss: 0.735564, acc: 0.382812]\n",
            "4692: [D loss: 0.719520, acc: 0.470703]  [A loss: 0.901053, acc: 0.148438]\n",
            "4693: [D loss: 0.698695, acc: 0.500000]  [A loss: 0.738969, acc: 0.460938]\n",
            "4694: [D loss: 0.719357, acc: 0.503906]  [A loss: 0.867282, acc: 0.203125]\n",
            "4695: [D loss: 0.700077, acc: 0.509766]  [A loss: 0.786313, acc: 0.250000]\n",
            "4696: [D loss: 0.711354, acc: 0.500000]  [A loss: 0.866794, acc: 0.195312]\n",
            "4697: [D loss: 0.687457, acc: 0.554688]  [A loss: 0.759693, acc: 0.359375]\n",
            "4698: [D loss: 0.714033, acc: 0.509766]  [A loss: 0.950840, acc: 0.101562]\n",
            "4699: [D loss: 0.694474, acc: 0.525391]  [A loss: 0.698602, acc: 0.507812]\n",
            "4700: [D loss: 0.702235, acc: 0.494141]  [A loss: 0.815484, acc: 0.238281]\n",
            "4701: [D loss: 0.694626, acc: 0.558594]  [A loss: 0.801683, acc: 0.289062]\n",
            "4702: [D loss: 0.690674, acc: 0.539062]  [A loss: 0.856498, acc: 0.222656]\n",
            "4703: [D loss: 0.695492, acc: 0.523438]  [A loss: 0.736088, acc: 0.414062]\n",
            "4704: [D loss: 0.715563, acc: 0.515625]  [A loss: 0.948040, acc: 0.128906]\n",
            "4705: [D loss: 0.710324, acc: 0.466797]  [A loss: 0.713388, acc: 0.488281]\n",
            "4706: [D loss: 0.705975, acc: 0.523438]  [A loss: 0.874873, acc: 0.199219]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4707: [D loss: 0.700283, acc: 0.535156]  [A loss: 0.734883, acc: 0.441406]\n",
            "4708: [D loss: 0.725473, acc: 0.501953]  [A loss: 0.905258, acc: 0.109375]\n",
            "4709: [D loss: 0.692713, acc: 0.542969]  [A loss: 0.747374, acc: 0.394531]\n",
            "4710: [D loss: 0.706044, acc: 0.509766]  [A loss: 0.839119, acc: 0.242188]\n",
            "4711: [D loss: 0.692592, acc: 0.558594]  [A loss: 0.814707, acc: 0.238281]\n",
            "4712: [D loss: 0.705749, acc: 0.515625]  [A loss: 0.751075, acc: 0.402344]\n",
            "4713: [D loss: 0.707133, acc: 0.515625]  [A loss: 0.881357, acc: 0.148438]\n",
            "4714: [D loss: 0.705829, acc: 0.515625]  [A loss: 0.766528, acc: 0.328125]\n",
            "4715: [D loss: 0.712831, acc: 0.507812]  [A loss: 0.884946, acc: 0.148438]\n",
            "4716: [D loss: 0.696909, acc: 0.523438]  [A loss: 0.829915, acc: 0.222656]\n",
            "4717: [D loss: 0.709717, acc: 0.541016]  [A loss: 0.852023, acc: 0.234375]\n",
            "4718: [D loss: 0.724320, acc: 0.482422]  [A loss: 0.755359, acc: 0.363281]\n",
            "4719: [D loss: 0.701339, acc: 0.527344]  [A loss: 0.922492, acc: 0.132812]\n",
            "4720: [D loss: 0.694037, acc: 0.544922]  [A loss: 0.770922, acc: 0.386719]\n",
            "4721: [D loss: 0.713835, acc: 0.531250]  [A loss: 0.955982, acc: 0.078125]\n",
            "4722: [D loss: 0.686610, acc: 0.541016]  [A loss: 0.646002, acc: 0.625000]\n",
            "4723: [D loss: 0.743775, acc: 0.505859]  [A loss: 1.075653, acc: 0.046875]\n",
            "4724: [D loss: 0.706435, acc: 0.521484]  [A loss: 0.665506, acc: 0.617188]\n",
            "4725: [D loss: 0.732913, acc: 0.490234]  [A loss: 0.814057, acc: 0.273438]\n",
            "4726: [D loss: 0.691474, acc: 0.542969]  [A loss: 0.754499, acc: 0.359375]\n",
            "4727: [D loss: 0.721944, acc: 0.488281]  [A loss: 0.818089, acc: 0.269531]\n",
            "4728: [D loss: 0.692043, acc: 0.554688]  [A loss: 0.824156, acc: 0.265625]\n",
            "4729: [D loss: 0.691452, acc: 0.570312]  [A loss: 0.790733, acc: 0.320312]\n",
            "4730: [D loss: 0.709829, acc: 0.521484]  [A loss: 0.869036, acc: 0.164062]\n",
            "4731: [D loss: 0.712704, acc: 0.501953]  [A loss: 0.764692, acc: 0.320312]\n",
            "4732: [D loss: 0.701272, acc: 0.511719]  [A loss: 0.865155, acc: 0.179688]\n",
            "4733: [D loss: 0.710287, acc: 0.507812]  [A loss: 0.762801, acc: 0.351562]\n",
            "4734: [D loss: 0.707334, acc: 0.501953]  [A loss: 0.829774, acc: 0.238281]\n",
            "4735: [D loss: 0.699717, acc: 0.505859]  [A loss: 0.793434, acc: 0.308594]\n",
            "4736: [D loss: 0.700990, acc: 0.511719]  [A loss: 0.822122, acc: 0.285156]\n",
            "4737: [D loss: 0.687221, acc: 0.554688]  [A loss: 0.748882, acc: 0.382812]\n",
            "4738: [D loss: 0.707184, acc: 0.501953]  [A loss: 0.828076, acc: 0.261719]\n",
            "4739: [D loss: 0.709849, acc: 0.498047]  [A loss: 0.764481, acc: 0.300781]\n",
            "4740: [D loss: 0.707060, acc: 0.492188]  [A loss: 0.838754, acc: 0.191406]\n",
            "4741: [D loss: 0.705941, acc: 0.523438]  [A loss: 0.805879, acc: 0.261719]\n",
            "4742: [D loss: 0.699289, acc: 0.507812]  [A loss: 0.792623, acc: 0.312500]\n",
            "4743: [D loss: 0.685727, acc: 0.552734]  [A loss: 0.818720, acc: 0.230469]\n",
            "4744: [D loss: 0.698310, acc: 0.525391]  [A loss: 0.798513, acc: 0.296875]\n",
            "4745: [D loss: 0.693655, acc: 0.554688]  [A loss: 0.819868, acc: 0.222656]\n",
            "4746: [D loss: 0.695171, acc: 0.550781]  [A loss: 0.788417, acc: 0.277344]\n",
            "4747: [D loss: 0.708422, acc: 0.498047]  [A loss: 0.899082, acc: 0.160156]\n",
            "4748: [D loss: 0.702209, acc: 0.500000]  [A loss: 0.772769, acc: 0.343750]\n",
            "4749: [D loss: 0.721266, acc: 0.484375]  [A loss: 0.845280, acc: 0.230469]\n",
            "4750: [D loss: 0.693433, acc: 0.560547]  [A loss: 0.802671, acc: 0.269531]\n",
            "4751: [D loss: 0.698015, acc: 0.542969]  [A loss: 0.866736, acc: 0.183594]\n",
            "4752: [D loss: 0.698514, acc: 0.533203]  [A loss: 0.794520, acc: 0.308594]\n",
            "4753: [D loss: 0.684312, acc: 0.568359]  [A loss: 0.834297, acc: 0.226562]\n",
            "4754: [D loss: 0.710111, acc: 0.515625]  [A loss: 0.746960, acc: 0.421875]\n",
            "4755: [D loss: 0.723341, acc: 0.517578]  [A loss: 1.060745, acc: 0.054688]\n",
            "4756: [D loss: 0.706623, acc: 0.478516]  [A loss: 0.667797, acc: 0.574219]\n",
            "4757: [D loss: 0.734632, acc: 0.478516]  [A loss: 0.929142, acc: 0.105469]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4758: [D loss: 0.706109, acc: 0.482422]  [A loss: 0.685805, acc: 0.535156]\n",
            "4759: [D loss: 0.708471, acc: 0.515625]  [A loss: 0.941564, acc: 0.097656]\n",
            "4760: [D loss: 0.713384, acc: 0.500000]  [A loss: 0.707895, acc: 0.492188]\n",
            "4761: [D loss: 0.705825, acc: 0.521484]  [A loss: 0.896675, acc: 0.144531]\n",
            "4762: [D loss: 0.685555, acc: 0.531250]  [A loss: 0.738446, acc: 0.472656]\n",
            "4763: [D loss: 0.713187, acc: 0.492188]  [A loss: 0.848417, acc: 0.234375]\n",
            "4764: [D loss: 0.699495, acc: 0.539062]  [A loss: 0.748565, acc: 0.417969]\n",
            "4765: [D loss: 0.708035, acc: 0.511719]  [A loss: 0.885689, acc: 0.156250]\n",
            "4766: [D loss: 0.701537, acc: 0.505859]  [A loss: 0.733092, acc: 0.417969]\n",
            "4767: [D loss: 0.705271, acc: 0.517578]  [A loss: 0.859283, acc: 0.195312]\n",
            "4768: [D loss: 0.696566, acc: 0.519531]  [A loss: 0.771993, acc: 0.390625]\n",
            "4769: [D loss: 0.690237, acc: 0.537109]  [A loss: 0.853402, acc: 0.218750]\n",
            "4770: [D loss: 0.704461, acc: 0.511719]  [A loss: 0.824068, acc: 0.281250]\n",
            "4771: [D loss: 0.692722, acc: 0.552734]  [A loss: 0.834281, acc: 0.203125]\n",
            "4772: [D loss: 0.701664, acc: 0.500000]  [A loss: 0.820890, acc: 0.261719]\n",
            "4773: [D loss: 0.701254, acc: 0.515625]  [A loss: 0.774205, acc: 0.335938]\n",
            "4774: [D loss: 0.712864, acc: 0.513672]  [A loss: 0.852798, acc: 0.218750]\n",
            "4775: [D loss: 0.709522, acc: 0.500000]  [A loss: 0.780891, acc: 0.312500]\n",
            "4776: [D loss: 0.704081, acc: 0.531250]  [A loss: 0.806191, acc: 0.277344]\n",
            "4777: [D loss: 0.697921, acc: 0.531250]  [A loss: 0.830011, acc: 0.238281]\n",
            "4778: [D loss: 0.700367, acc: 0.525391]  [A loss: 0.948961, acc: 0.117188]\n",
            "4779: [D loss: 0.699620, acc: 0.531250]  [A loss: 0.759176, acc: 0.347656]\n",
            "4780: [D loss: 0.709814, acc: 0.535156]  [A loss: 0.901733, acc: 0.152344]\n",
            "4781: [D loss: 0.708763, acc: 0.515625]  [A loss: 0.673898, acc: 0.601562]\n",
            "4782: [D loss: 0.722933, acc: 0.496094]  [A loss: 0.919496, acc: 0.144531]\n",
            "4783: [D loss: 0.699583, acc: 0.521484]  [A loss: 0.737691, acc: 0.402344]\n",
            "4784: [D loss: 0.715488, acc: 0.496094]  [A loss: 0.876477, acc: 0.167969]\n",
            "4785: [D loss: 0.711842, acc: 0.486328]  [A loss: 0.742670, acc: 0.406250]\n",
            "4786: [D loss: 0.710914, acc: 0.529297]  [A loss: 0.837477, acc: 0.222656]\n",
            "4787: [D loss: 0.687902, acc: 0.537109]  [A loss: 0.752368, acc: 0.398438]\n",
            "4788: [D loss: 0.696624, acc: 0.544922]  [A loss: 0.839316, acc: 0.210938]\n",
            "4789: [D loss: 0.714793, acc: 0.515625]  [A loss: 0.715579, acc: 0.445312]\n",
            "4790: [D loss: 0.711776, acc: 0.500000]  [A loss: 0.945655, acc: 0.097656]\n",
            "4791: [D loss: 0.714761, acc: 0.490234]  [A loss: 0.720298, acc: 0.460938]\n",
            "4792: [D loss: 0.698731, acc: 0.523438]  [A loss: 0.846313, acc: 0.203125]\n",
            "4793: [D loss: 0.688429, acc: 0.558594]  [A loss: 0.745145, acc: 0.449219]\n",
            "4794: [D loss: 0.717383, acc: 0.468750]  [A loss: 0.821505, acc: 0.222656]\n",
            "4795: [D loss: 0.702217, acc: 0.515625]  [A loss: 0.785381, acc: 0.296875]\n",
            "4796: [D loss: 0.706127, acc: 0.529297]  [A loss: 0.847501, acc: 0.195312]\n",
            "4797: [D loss: 0.711282, acc: 0.488281]  [A loss: 0.830776, acc: 0.218750]\n",
            "4798: [D loss: 0.706422, acc: 0.503906]  [A loss: 0.787182, acc: 0.332031]\n",
            "4799: [D loss: 0.703777, acc: 0.509766]  [A loss: 0.839295, acc: 0.218750]\n",
            "4800: [D loss: 0.713370, acc: 0.505859]  [A loss: 0.765102, acc: 0.343750]\n",
            "4801: [D loss: 0.710553, acc: 0.501953]  [A loss: 0.797456, acc: 0.296875]\n",
            "4802: [D loss: 0.699677, acc: 0.525391]  [A loss: 0.805691, acc: 0.257812]\n",
            "4803: [D loss: 0.714830, acc: 0.478516]  [A loss: 0.817605, acc: 0.281250]\n",
            "4804: [D loss: 0.701022, acc: 0.544922]  [A loss: 0.785105, acc: 0.339844]\n",
            "4805: [D loss: 0.704099, acc: 0.484375]  [A loss: 0.867470, acc: 0.148438]\n",
            "4806: [D loss: 0.704130, acc: 0.509766]  [A loss: 0.703519, acc: 0.464844]\n",
            "4807: [D loss: 0.700902, acc: 0.523438]  [A loss: 0.924469, acc: 0.140625]\n",
            "4808: [D loss: 0.703043, acc: 0.523438]  [A loss: 0.738156, acc: 0.417969]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4809: [D loss: 0.713183, acc: 0.501953]  [A loss: 0.858742, acc: 0.164062]\n",
            "4810: [D loss: 0.714684, acc: 0.501953]  [A loss: 0.764810, acc: 0.339844]\n",
            "4811: [D loss: 0.714068, acc: 0.498047]  [A loss: 0.917939, acc: 0.113281]\n",
            "4812: [D loss: 0.698651, acc: 0.519531]  [A loss: 0.762769, acc: 0.359375]\n",
            "4813: [D loss: 0.701982, acc: 0.533203]  [A loss: 0.855107, acc: 0.187500]\n",
            "4814: [D loss: 0.701844, acc: 0.507812]  [A loss: 0.715497, acc: 0.468750]\n",
            "4815: [D loss: 0.722366, acc: 0.464844]  [A loss: 0.951026, acc: 0.093750]\n",
            "4816: [D loss: 0.700407, acc: 0.492188]  [A loss: 0.725456, acc: 0.441406]\n",
            "4817: [D loss: 0.704688, acc: 0.523438]  [A loss: 0.873042, acc: 0.164062]\n",
            "4818: [D loss: 0.716195, acc: 0.476562]  [A loss: 0.722563, acc: 0.406250]\n",
            "4819: [D loss: 0.710212, acc: 0.509766]  [A loss: 0.881396, acc: 0.136719]\n",
            "4820: [D loss: 0.680648, acc: 0.560547]  [A loss: 0.765679, acc: 0.386719]\n",
            "4821: [D loss: 0.711322, acc: 0.515625]  [A loss: 0.860656, acc: 0.203125]\n",
            "4822: [D loss: 0.697511, acc: 0.513672]  [A loss: 0.787275, acc: 0.359375]\n",
            "4823: [D loss: 0.707011, acc: 0.501953]  [A loss: 0.894939, acc: 0.105469]\n",
            "4824: [D loss: 0.705460, acc: 0.525391]  [A loss: 0.701477, acc: 0.523438]\n",
            "4825: [D loss: 0.714153, acc: 0.513672]  [A loss: 0.869962, acc: 0.171875]\n",
            "4826: [D loss: 0.695196, acc: 0.523438]  [A loss: 0.780788, acc: 0.316406]\n",
            "4827: [D loss: 0.713389, acc: 0.490234]  [A loss: 0.841484, acc: 0.218750]\n",
            "4828: [D loss: 0.709531, acc: 0.484375]  [A loss: 0.881305, acc: 0.136719]\n",
            "4829: [D loss: 0.683561, acc: 0.539062]  [A loss: 0.795807, acc: 0.359375]\n",
            "4830: [D loss: 0.690875, acc: 0.574219]  [A loss: 0.841033, acc: 0.167969]\n",
            "4831: [D loss: 0.701498, acc: 0.498047]  [A loss: 0.753565, acc: 0.367188]\n",
            "4832: [D loss: 0.705872, acc: 0.500000]  [A loss: 0.846070, acc: 0.203125]\n",
            "4833: [D loss: 0.699552, acc: 0.527344]  [A loss: 0.763994, acc: 0.339844]\n",
            "4834: [D loss: 0.707594, acc: 0.501953]  [A loss: 0.828995, acc: 0.226562]\n",
            "4835: [D loss: 0.697815, acc: 0.535156]  [A loss: 0.792895, acc: 0.300781]\n",
            "4836: [D loss: 0.683420, acc: 0.562500]  [A loss: 0.829384, acc: 0.253906]\n",
            "4837: [D loss: 0.702796, acc: 0.533203]  [A loss: 0.876828, acc: 0.195312]\n",
            "4838: [D loss: 0.707516, acc: 0.509766]  [A loss: 0.739730, acc: 0.410156]\n",
            "4839: [D loss: 0.689043, acc: 0.583984]  [A loss: 0.880692, acc: 0.199219]\n",
            "4840: [D loss: 0.701831, acc: 0.507812]  [A loss: 0.756885, acc: 0.343750]\n",
            "4841: [D loss: 0.697654, acc: 0.505859]  [A loss: 0.843000, acc: 0.238281]\n",
            "4842: [D loss: 0.699358, acc: 0.517578]  [A loss: 0.847911, acc: 0.175781]\n",
            "4843: [D loss: 0.695026, acc: 0.542969]  [A loss: 0.757210, acc: 0.382812]\n",
            "4844: [D loss: 0.718228, acc: 0.505859]  [A loss: 0.964858, acc: 0.062500]\n",
            "4845: [D loss: 0.692701, acc: 0.535156]  [A loss: 0.661036, acc: 0.593750]\n",
            "4846: [D loss: 0.712631, acc: 0.527344]  [A loss: 0.953107, acc: 0.117188]\n",
            "4847: [D loss: 0.717302, acc: 0.494141]  [A loss: 0.683570, acc: 0.546875]\n",
            "4848: [D loss: 0.714972, acc: 0.505859]  [A loss: 0.918661, acc: 0.132812]\n",
            "4849: [D loss: 0.703809, acc: 0.515625]  [A loss: 0.710329, acc: 0.488281]\n",
            "4850: [D loss: 0.712435, acc: 0.507812]  [A loss: 0.887853, acc: 0.203125]\n",
            "4851: [D loss: 0.709722, acc: 0.523438]  [A loss: 0.745182, acc: 0.425781]\n",
            "4852: [D loss: 0.712301, acc: 0.535156]  [A loss: 0.814395, acc: 0.265625]\n",
            "4853: [D loss: 0.698952, acc: 0.523438]  [A loss: 0.759424, acc: 0.398438]\n",
            "4854: [D loss: 0.701334, acc: 0.542969]  [A loss: 0.842377, acc: 0.207031]\n",
            "4855: [D loss: 0.708066, acc: 0.490234]  [A loss: 0.775458, acc: 0.335938]\n",
            "4856: [D loss: 0.716047, acc: 0.494141]  [A loss: 0.857390, acc: 0.191406]\n",
            "4857: [D loss: 0.706641, acc: 0.498047]  [A loss: 0.745449, acc: 0.378906]\n",
            "4858: [D loss: 0.701952, acc: 0.517578]  [A loss: 0.849283, acc: 0.175781]\n",
            "4859: [D loss: 0.698459, acc: 0.527344]  [A loss: 0.793286, acc: 0.335938]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4860: [D loss: 0.703032, acc: 0.517578]  [A loss: 0.865378, acc: 0.203125]\n",
            "4861: [D loss: 0.697623, acc: 0.531250]  [A loss: 0.731075, acc: 0.417969]\n",
            "4862: [D loss: 0.724611, acc: 0.490234]  [A loss: 0.975668, acc: 0.082031]\n",
            "4863: [D loss: 0.689345, acc: 0.564453]  [A loss: 0.711133, acc: 0.488281]\n",
            "4864: [D loss: 0.713279, acc: 0.513672]  [A loss: 0.830365, acc: 0.257812]\n",
            "4865: [D loss: 0.698441, acc: 0.537109]  [A loss: 0.752875, acc: 0.367188]\n",
            "4866: [D loss: 0.700759, acc: 0.521484]  [A loss: 0.820438, acc: 0.238281]\n",
            "4867: [D loss: 0.694940, acc: 0.541016]  [A loss: 0.756944, acc: 0.402344]\n",
            "4868: [D loss: 0.695745, acc: 0.533203]  [A loss: 0.804202, acc: 0.277344]\n",
            "4869: [D loss: 0.699009, acc: 0.525391]  [A loss: 0.820326, acc: 0.253906]\n",
            "4870: [D loss: 0.704512, acc: 0.507812]  [A loss: 0.797650, acc: 0.285156]\n",
            "4871: [D loss: 0.694174, acc: 0.521484]  [A loss: 0.795912, acc: 0.292969]\n",
            "4872: [D loss: 0.711269, acc: 0.517578]  [A loss: 0.895096, acc: 0.167969]\n",
            "4873: [D loss: 0.711695, acc: 0.486328]  [A loss: 0.694405, acc: 0.539062]\n",
            "4874: [D loss: 0.712230, acc: 0.492188]  [A loss: 0.870379, acc: 0.195312]\n",
            "4875: [D loss: 0.699084, acc: 0.505859]  [A loss: 0.777151, acc: 0.292969]\n",
            "4876: [D loss: 0.692807, acc: 0.550781]  [A loss: 0.872980, acc: 0.160156]\n",
            "4877: [D loss: 0.705012, acc: 0.529297]  [A loss: 0.767709, acc: 0.367188]\n",
            "4878: [D loss: 0.704155, acc: 0.488281]  [A loss: 0.812561, acc: 0.253906]\n",
            "4879: [D loss: 0.696878, acc: 0.542969]  [A loss: 0.818474, acc: 0.218750]\n",
            "4880: [D loss: 0.693603, acc: 0.537109]  [A loss: 0.858619, acc: 0.195312]\n",
            "4881: [D loss: 0.693411, acc: 0.537109]  [A loss: 0.752854, acc: 0.382812]\n",
            "4882: [D loss: 0.710145, acc: 0.529297]  [A loss: 1.004078, acc: 0.078125]\n",
            "4883: [D loss: 0.697648, acc: 0.531250]  [A loss: 0.699587, acc: 0.542969]\n",
            "4884: [D loss: 0.709041, acc: 0.501953]  [A loss: 0.869222, acc: 0.187500]\n",
            "4885: [D loss: 0.697123, acc: 0.529297]  [A loss: 0.716112, acc: 0.503906]\n",
            "4886: [D loss: 0.710036, acc: 0.500000]  [A loss: 0.921586, acc: 0.121094]\n",
            "4887: [D loss: 0.698534, acc: 0.503906]  [A loss: 0.710019, acc: 0.496094]\n",
            "4888: [D loss: 0.724820, acc: 0.476562]  [A loss: 0.908233, acc: 0.105469]\n",
            "4889: [D loss: 0.687257, acc: 0.517578]  [A loss: 0.722339, acc: 0.417969]\n",
            "4890: [D loss: 0.714501, acc: 0.496094]  [A loss: 0.829730, acc: 0.230469]\n",
            "4891: [D loss: 0.709108, acc: 0.517578]  [A loss: 0.832051, acc: 0.230469]\n",
            "4892: [D loss: 0.703965, acc: 0.500000]  [A loss: 0.783107, acc: 0.296875]\n",
            "4893: [D loss: 0.710986, acc: 0.496094]  [A loss: 0.854504, acc: 0.179688]\n",
            "4894: [D loss: 0.695502, acc: 0.533203]  [A loss: 0.776346, acc: 0.304688]\n",
            "4895: [D loss: 0.704224, acc: 0.519531]  [A loss: 0.932882, acc: 0.105469]\n",
            "4896: [D loss: 0.687146, acc: 0.544922]  [A loss: 0.690711, acc: 0.542969]\n",
            "4897: [D loss: 0.712845, acc: 0.501953]  [A loss: 0.901248, acc: 0.144531]\n",
            "4898: [D loss: 0.687564, acc: 0.544922]  [A loss: 0.717424, acc: 0.472656]\n",
            "4899: [D loss: 0.711499, acc: 0.507812]  [A loss: 0.898087, acc: 0.144531]\n",
            "4900: [D loss: 0.711601, acc: 0.451172]  [A loss: 0.745508, acc: 0.394531]\n",
            "4901: [D loss: 0.713175, acc: 0.513672]  [A loss: 0.876917, acc: 0.152344]\n",
            "4902: [D loss: 0.693382, acc: 0.537109]  [A loss: 0.725682, acc: 0.441406]\n",
            "4903: [D loss: 0.702079, acc: 0.537109]  [A loss: 0.833676, acc: 0.210938]\n",
            "4904: [D loss: 0.683989, acc: 0.564453]  [A loss: 0.772840, acc: 0.367188]\n",
            "4905: [D loss: 0.712848, acc: 0.480469]  [A loss: 0.826171, acc: 0.238281]\n",
            "4906: [D loss: 0.691375, acc: 0.548828]  [A loss: 0.778413, acc: 0.332031]\n",
            "4907: [D loss: 0.689856, acc: 0.537109]  [A loss: 0.834636, acc: 0.234375]\n",
            "4908: [D loss: 0.710311, acc: 0.492188]  [A loss: 0.739683, acc: 0.445312]\n",
            "4909: [D loss: 0.710303, acc: 0.519531]  [A loss: 0.940082, acc: 0.132812]\n",
            "4910: [D loss: 0.695846, acc: 0.537109]  [A loss: 0.692341, acc: 0.523438]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4911: [D loss: 0.711126, acc: 0.517578]  [A loss: 0.907010, acc: 0.187500]\n",
            "4912: [D loss: 0.705706, acc: 0.509766]  [A loss: 0.820857, acc: 0.238281]\n",
            "4913: [D loss: 0.680416, acc: 0.560547]  [A loss: 0.765322, acc: 0.359375]\n",
            "4914: [D loss: 0.694384, acc: 0.550781]  [A loss: 0.851387, acc: 0.195312]\n",
            "4915: [D loss: 0.700410, acc: 0.498047]  [A loss: 0.755289, acc: 0.390625]\n",
            "4916: [D loss: 0.699325, acc: 0.539062]  [A loss: 0.877205, acc: 0.183594]\n",
            "4917: [D loss: 0.686396, acc: 0.542969]  [A loss: 0.757994, acc: 0.378906]\n",
            "4918: [D loss: 0.693383, acc: 0.505859]  [A loss: 0.884512, acc: 0.175781]\n",
            "4919: [D loss: 0.703372, acc: 0.533203]  [A loss: 0.810453, acc: 0.281250]\n",
            "4920: [D loss: 0.703095, acc: 0.521484]  [A loss: 0.853122, acc: 0.238281]\n",
            "4921: [D loss: 0.705484, acc: 0.521484]  [A loss: 0.816823, acc: 0.304688]\n",
            "4922: [D loss: 0.703977, acc: 0.507812]  [A loss: 0.961869, acc: 0.066406]\n",
            "4923: [D loss: 0.697175, acc: 0.533203]  [A loss: 0.703223, acc: 0.503906]\n",
            "4924: [D loss: 0.720102, acc: 0.494141]  [A loss: 0.937434, acc: 0.128906]\n",
            "4925: [D loss: 0.693961, acc: 0.544922]  [A loss: 0.712718, acc: 0.488281]\n",
            "4926: [D loss: 0.718355, acc: 0.490234]  [A loss: 0.915622, acc: 0.105469]\n",
            "4927: [D loss: 0.709299, acc: 0.498047]  [A loss: 0.707379, acc: 0.523438]\n",
            "4928: [D loss: 0.703340, acc: 0.531250]  [A loss: 0.860120, acc: 0.203125]\n",
            "4929: [D loss: 0.703053, acc: 0.515625]  [A loss: 0.701777, acc: 0.496094]\n",
            "4930: [D loss: 0.724423, acc: 0.496094]  [A loss: 0.918224, acc: 0.128906]\n",
            "4931: [D loss: 0.703211, acc: 0.507812]  [A loss: 0.676353, acc: 0.539062]\n",
            "4932: [D loss: 0.704397, acc: 0.507812]  [A loss: 0.861265, acc: 0.171875]\n",
            "4933: [D loss: 0.701994, acc: 0.509766]  [A loss: 0.698203, acc: 0.515625]\n",
            "4934: [D loss: 0.702082, acc: 0.525391]  [A loss: 0.857037, acc: 0.164062]\n",
            "4935: [D loss: 0.712043, acc: 0.474609]  [A loss: 0.771367, acc: 0.316406]\n",
            "4936: [D loss: 0.718112, acc: 0.480469]  [A loss: 0.888209, acc: 0.160156]\n",
            "4937: [D loss: 0.706084, acc: 0.515625]  [A loss: 0.739701, acc: 0.414062]\n",
            "4938: [D loss: 0.714755, acc: 0.464844]  [A loss: 0.847585, acc: 0.167969]\n",
            "4939: [D loss: 0.693753, acc: 0.511719]  [A loss: 0.716040, acc: 0.460938]\n",
            "4940: [D loss: 0.701826, acc: 0.527344]  [A loss: 0.899813, acc: 0.144531]\n",
            "4941: [D loss: 0.684964, acc: 0.541016]  [A loss: 0.765346, acc: 0.320312]\n",
            "4942: [D loss: 0.714041, acc: 0.521484]  [A loss: 0.895790, acc: 0.156250]\n",
            "4943: [D loss: 0.690686, acc: 0.542969]  [A loss: 0.751408, acc: 0.382812]\n",
            "4944: [D loss: 0.711648, acc: 0.494141]  [A loss: 0.871599, acc: 0.144531]\n",
            "4945: [D loss: 0.696337, acc: 0.527344]  [A loss: 0.737805, acc: 0.402344]\n",
            "4946: [D loss: 0.711649, acc: 0.500000]  [A loss: 0.904454, acc: 0.136719]\n",
            "4947: [D loss: 0.698518, acc: 0.527344]  [A loss: 0.711686, acc: 0.453125]\n",
            "4948: [D loss: 0.704348, acc: 0.515625]  [A loss: 0.906369, acc: 0.113281]\n",
            "4949: [D loss: 0.711380, acc: 0.486328]  [A loss: 0.716249, acc: 0.421875]\n",
            "4950: [D loss: 0.708068, acc: 0.507812]  [A loss: 0.911835, acc: 0.070312]\n",
            "4951: [D loss: 0.691662, acc: 0.548828]  [A loss: 0.658510, acc: 0.628906]\n",
            "4952: [D loss: 0.725521, acc: 0.484375]  [A loss: 0.923886, acc: 0.101562]\n",
            "4953: [D loss: 0.700265, acc: 0.525391]  [A loss: 0.750409, acc: 0.378906]\n",
            "4954: [D loss: 0.689622, acc: 0.556641]  [A loss: 0.835539, acc: 0.203125]\n",
            "4955: [D loss: 0.687440, acc: 0.544922]  [A loss: 0.812987, acc: 0.246094]\n",
            "4956: [D loss: 0.699260, acc: 0.505859]  [A loss: 0.843691, acc: 0.222656]\n",
            "4957: [D loss: 0.696828, acc: 0.544922]  [A loss: 0.821844, acc: 0.261719]\n",
            "4958: [D loss: 0.700480, acc: 0.523438]  [A loss: 0.763186, acc: 0.371094]\n",
            "4959: [D loss: 0.694696, acc: 0.537109]  [A loss: 0.908841, acc: 0.101562]\n",
            "4960: [D loss: 0.703345, acc: 0.480469]  [A loss: 0.722152, acc: 0.476562]\n",
            "4961: [D loss: 0.712423, acc: 0.513672]  [A loss: 0.846050, acc: 0.191406]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4962: [D loss: 0.686439, acc: 0.550781]  [A loss: 0.739325, acc: 0.382812]\n",
            "4963: [D loss: 0.700717, acc: 0.523438]  [A loss: 0.950237, acc: 0.097656]\n",
            "4964: [D loss: 0.702355, acc: 0.525391]  [A loss: 0.730763, acc: 0.406250]\n",
            "4965: [D loss: 0.712210, acc: 0.517578]  [A loss: 0.939359, acc: 0.097656]\n",
            "4966: [D loss: 0.700649, acc: 0.519531]  [A loss: 0.709620, acc: 0.488281]\n",
            "4967: [D loss: 0.718804, acc: 0.513672]  [A loss: 0.872317, acc: 0.152344]\n",
            "4968: [D loss: 0.700065, acc: 0.529297]  [A loss: 0.729325, acc: 0.425781]\n",
            "4969: [D loss: 0.713492, acc: 0.517578]  [A loss: 0.883724, acc: 0.171875]\n",
            "4970: [D loss: 0.698933, acc: 0.523438]  [A loss: 0.720582, acc: 0.441406]\n",
            "4971: [D loss: 0.715085, acc: 0.539062]  [A loss: 0.867968, acc: 0.152344]\n",
            "4972: [D loss: 0.697996, acc: 0.521484]  [A loss: 0.712072, acc: 0.457031]\n",
            "4973: [D loss: 0.708225, acc: 0.515625]  [A loss: 0.866826, acc: 0.187500]\n",
            "4974: [D loss: 0.690603, acc: 0.539062]  [A loss: 0.719830, acc: 0.492188]\n",
            "4975: [D loss: 0.698619, acc: 0.515625]  [A loss: 0.865387, acc: 0.191406]\n",
            "4976: [D loss: 0.705724, acc: 0.507812]  [A loss: 0.835418, acc: 0.179688]\n",
            "4977: [D loss: 0.691893, acc: 0.531250]  [A loss: 0.739547, acc: 0.421875]\n",
            "4978: [D loss: 0.697348, acc: 0.517578]  [A loss: 0.868238, acc: 0.152344]\n",
            "4979: [D loss: 0.700121, acc: 0.511719]  [A loss: 0.750761, acc: 0.375000]\n",
            "4980: [D loss: 0.708638, acc: 0.515625]  [A loss: 0.852685, acc: 0.207031]\n",
            "4981: [D loss: 0.702625, acc: 0.492188]  [A loss: 0.823603, acc: 0.238281]\n",
            "4982: [D loss: 0.675870, acc: 0.570312]  [A loss: 0.810507, acc: 0.273438]\n",
            "4983: [D loss: 0.699207, acc: 0.511719]  [A loss: 0.871013, acc: 0.183594]\n",
            "4984: [D loss: 0.697706, acc: 0.527344]  [A loss: 0.763477, acc: 0.351562]\n",
            "4985: [D loss: 0.695350, acc: 0.535156]  [A loss: 0.894615, acc: 0.164062]\n",
            "4986: [D loss: 0.700048, acc: 0.494141]  [A loss: 0.686365, acc: 0.492188]\n",
            "4987: [D loss: 0.698235, acc: 0.521484]  [A loss: 0.988894, acc: 0.097656]\n",
            "4988: [D loss: 0.697877, acc: 0.513672]  [A loss: 0.665697, acc: 0.570312]\n",
            "4989: [D loss: 0.708986, acc: 0.509766]  [A loss: 0.919966, acc: 0.101562]\n",
            "4990: [D loss: 0.695549, acc: 0.521484]  [A loss: 0.671007, acc: 0.582031]\n",
            "4991: [D loss: 0.726941, acc: 0.505859]  [A loss: 0.879755, acc: 0.140625]\n",
            "4992: [D loss: 0.685635, acc: 0.568359]  [A loss: 0.739227, acc: 0.410156]\n",
            "4993: [D loss: 0.727306, acc: 0.484375]  [A loss: 0.816765, acc: 0.261719]\n",
            "4994: [D loss: 0.712014, acc: 0.488281]  [A loss: 0.759245, acc: 0.312500]\n",
            "4995: [D loss: 0.717814, acc: 0.501953]  [A loss: 0.938961, acc: 0.078125]\n",
            "4996: [D loss: 0.706027, acc: 0.505859]  [A loss: 0.721051, acc: 0.441406]\n",
            "4997: [D loss: 0.702602, acc: 0.542969]  [A loss: 0.880643, acc: 0.167969]\n",
            "4998: [D loss: 0.701103, acc: 0.535156]  [A loss: 0.758641, acc: 0.367188]\n",
            "4999: [D loss: 0.709598, acc: 0.523438]  [A loss: 0.922070, acc: 0.113281]\n",
            "5000: [D loss: 0.708900, acc: 0.523438]  [A loss: 0.699317, acc: 0.523438]\n",
            "5001: [D loss: 0.709101, acc: 0.494141]  [A loss: 0.862067, acc: 0.179688]\n",
            "5002: [D loss: 0.705157, acc: 0.494141]  [A loss: 0.728954, acc: 0.414062]\n",
            "5003: [D loss: 0.702361, acc: 0.523438]  [A loss: 0.937413, acc: 0.070312]\n",
            "5004: [D loss: 0.701171, acc: 0.521484]  [A loss: 0.793145, acc: 0.277344]\n",
            "5005: [D loss: 0.718102, acc: 0.509766]  [A loss: 0.882455, acc: 0.171875]\n",
            "5006: [D loss: 0.700590, acc: 0.511719]  [A loss: 0.706085, acc: 0.496094]\n",
            "5007: [D loss: 0.710308, acc: 0.533203]  [A loss: 0.832535, acc: 0.257812]\n",
            "5008: [D loss: 0.699882, acc: 0.515625]  [A loss: 0.763666, acc: 0.332031]\n",
            "5009: [D loss: 0.708231, acc: 0.525391]  [A loss: 0.837800, acc: 0.191406]\n",
            "5010: [D loss: 0.699426, acc: 0.529297]  [A loss: 0.813635, acc: 0.222656]\n",
            "5011: [D loss: 0.697006, acc: 0.533203]  [A loss: 0.812232, acc: 0.261719]\n",
            "5012: [D loss: 0.699201, acc: 0.535156]  [A loss: 0.845425, acc: 0.210938]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5013: [D loss: 0.710461, acc: 0.466797]  [A loss: 0.830361, acc: 0.167969]\n",
            "5014: [D loss: 0.691743, acc: 0.539062]  [A loss: 0.808038, acc: 0.253906]\n",
            "5015: [D loss: 0.701990, acc: 0.542969]  [A loss: 0.848101, acc: 0.207031]\n",
            "5016: [D loss: 0.703441, acc: 0.507812]  [A loss: 0.828022, acc: 0.242188]\n",
            "5017: [D loss: 0.696912, acc: 0.539062]  [A loss: 0.845159, acc: 0.203125]\n",
            "5018: [D loss: 0.695981, acc: 0.533203]  [A loss: 0.765650, acc: 0.343750]\n",
            "5019: [D loss: 0.717870, acc: 0.501953]  [A loss: 0.947760, acc: 0.117188]\n",
            "5020: [D loss: 0.711629, acc: 0.488281]  [A loss: 0.726927, acc: 0.441406]\n",
            "5021: [D loss: 0.706900, acc: 0.529297]  [A loss: 0.961645, acc: 0.078125]\n",
            "5022: [D loss: 0.696397, acc: 0.531250]  [A loss: 0.699007, acc: 0.511719]\n",
            "5023: [D loss: 0.721620, acc: 0.501953]  [A loss: 0.979892, acc: 0.082031]\n",
            "5024: [D loss: 0.714879, acc: 0.501953]  [A loss: 0.702505, acc: 0.531250]\n",
            "5025: [D loss: 0.716049, acc: 0.503906]  [A loss: 0.829568, acc: 0.242188]\n",
            "5026: [D loss: 0.695849, acc: 0.519531]  [A loss: 0.778016, acc: 0.312500]\n",
            "5027: [D loss: 0.696941, acc: 0.521484]  [A loss: 0.848808, acc: 0.203125]\n",
            "5028: [D loss: 0.701860, acc: 0.507812]  [A loss: 0.795889, acc: 0.304688]\n",
            "5029: [D loss: 0.691341, acc: 0.511719]  [A loss: 0.813654, acc: 0.273438]\n",
            "5030: [D loss: 0.705565, acc: 0.515625]  [A loss: 0.872953, acc: 0.214844]\n",
            "5031: [D loss: 0.699984, acc: 0.527344]  [A loss: 0.757662, acc: 0.382812]\n",
            "5032: [D loss: 0.699748, acc: 0.525391]  [A loss: 0.822772, acc: 0.203125]\n",
            "5033: [D loss: 0.696469, acc: 0.496094]  [A loss: 0.797041, acc: 0.300781]\n",
            "5034: [D loss: 0.706184, acc: 0.503906]  [A loss: 0.858198, acc: 0.179688]\n",
            "5035: [D loss: 0.699690, acc: 0.505859]  [A loss: 0.793589, acc: 0.292969]\n",
            "5036: [D loss: 0.687284, acc: 0.550781]  [A loss: 0.793535, acc: 0.292969]\n",
            "5037: [D loss: 0.714484, acc: 0.492188]  [A loss: 0.856432, acc: 0.203125]\n",
            "5038: [D loss: 0.698721, acc: 0.541016]  [A loss: 0.820272, acc: 0.250000]\n",
            "5039: [D loss: 0.701672, acc: 0.513672]  [A loss: 0.913285, acc: 0.125000]\n",
            "5040: [D loss: 0.704635, acc: 0.498047]  [A loss: 0.734689, acc: 0.410156]\n",
            "5041: [D loss: 0.730026, acc: 0.472656]  [A loss: 1.007723, acc: 0.074219]\n",
            "5042: [D loss: 0.686655, acc: 0.539062]  [A loss: 0.673846, acc: 0.578125]\n",
            "5043: [D loss: 0.722010, acc: 0.511719]  [A loss: 0.935302, acc: 0.097656]\n",
            "5044: [D loss: 0.712598, acc: 0.486328]  [A loss: 0.718419, acc: 0.476562]\n",
            "5045: [D loss: 0.713888, acc: 0.511719]  [A loss: 0.941393, acc: 0.085938]\n",
            "5046: [D loss: 0.703300, acc: 0.496094]  [A loss: 0.752519, acc: 0.386719]\n",
            "5047: [D loss: 0.700620, acc: 0.527344]  [A loss: 0.873814, acc: 0.167969]\n",
            "5048: [D loss: 0.707456, acc: 0.513672]  [A loss: 0.756885, acc: 0.343750]\n",
            "5049: [D loss: 0.709539, acc: 0.482422]  [A loss: 0.868275, acc: 0.179688]\n",
            "5050: [D loss: 0.702731, acc: 0.525391]  [A loss: 0.804385, acc: 0.312500]\n",
            "5051: [D loss: 0.698239, acc: 0.535156]  [A loss: 0.766077, acc: 0.320312]\n",
            "5052: [D loss: 0.717363, acc: 0.496094]  [A loss: 0.881625, acc: 0.171875]\n",
            "5053: [D loss: 0.694364, acc: 0.527344]  [A loss: 0.784181, acc: 0.308594]\n",
            "5054: [D loss: 0.709522, acc: 0.513672]  [A loss: 0.867861, acc: 0.171875]\n",
            "5055: [D loss: 0.708370, acc: 0.482422]  [A loss: 0.740789, acc: 0.433594]\n",
            "5056: [D loss: 0.716633, acc: 0.496094]  [A loss: 0.861163, acc: 0.156250]\n",
            "5057: [D loss: 0.688467, acc: 0.562500]  [A loss: 0.706566, acc: 0.492188]\n",
            "5058: [D loss: 0.713667, acc: 0.523438]  [A loss: 0.957630, acc: 0.089844]\n",
            "5059: [D loss: 0.688128, acc: 0.546875]  [A loss: 0.686073, acc: 0.535156]\n",
            "5060: [D loss: 0.704272, acc: 0.513672]  [A loss: 0.954253, acc: 0.078125]\n",
            "5061: [D loss: 0.705421, acc: 0.500000]  [A loss: 0.705319, acc: 0.500000]\n",
            "5062: [D loss: 0.704554, acc: 0.515625]  [A loss: 0.839183, acc: 0.210938]\n",
            "5063: [D loss: 0.692095, acc: 0.521484]  [A loss: 0.743552, acc: 0.441406]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5064: [D loss: 0.697459, acc: 0.537109]  [A loss: 0.873137, acc: 0.179688]\n",
            "5065: [D loss: 0.700868, acc: 0.529297]  [A loss: 0.786700, acc: 0.320312]\n",
            "5066: [D loss: 0.693413, acc: 0.550781]  [A loss: 0.838776, acc: 0.218750]\n",
            "5067: [D loss: 0.701616, acc: 0.531250]  [A loss: 0.913118, acc: 0.140625]\n",
            "5068: [D loss: 0.693710, acc: 0.544922]  [A loss: 0.805877, acc: 0.265625]\n",
            "5069: [D loss: 0.701036, acc: 0.535156]  [A loss: 0.877133, acc: 0.148438]\n",
            "5070: [D loss: 0.694614, acc: 0.544922]  [A loss: 0.749674, acc: 0.390625]\n",
            "5071: [D loss: 0.708521, acc: 0.509766]  [A loss: 0.882619, acc: 0.164062]\n",
            "5072: [D loss: 0.693633, acc: 0.556641]  [A loss: 0.740958, acc: 0.390625]\n",
            "5073: [D loss: 0.722667, acc: 0.492188]  [A loss: 0.852171, acc: 0.218750]\n",
            "5074: [D loss: 0.704703, acc: 0.509766]  [A loss: 0.757615, acc: 0.375000]\n",
            "5075: [D loss: 0.711164, acc: 0.501953]  [A loss: 0.869977, acc: 0.144531]\n",
            "5076: [D loss: 0.701116, acc: 0.509766]  [A loss: 0.792202, acc: 0.335938]\n",
            "5077: [D loss: 0.709269, acc: 0.507812]  [A loss: 0.873700, acc: 0.203125]\n",
            "5078: [D loss: 0.702503, acc: 0.515625]  [A loss: 0.739122, acc: 0.402344]\n",
            "5079: [D loss: 0.709373, acc: 0.511719]  [A loss: 0.841441, acc: 0.207031]\n",
            "5080: [D loss: 0.703799, acc: 0.500000]  [A loss: 0.751890, acc: 0.386719]\n",
            "5081: [D loss: 0.705417, acc: 0.525391]  [A loss: 0.862331, acc: 0.171875]\n",
            "5082: [D loss: 0.709896, acc: 0.492188]  [A loss: 0.757532, acc: 0.363281]\n",
            "5083: [D loss: 0.698340, acc: 0.539062]  [A loss: 0.950360, acc: 0.101562]\n",
            "5084: [D loss: 0.692973, acc: 0.529297]  [A loss: 0.691691, acc: 0.531250]\n",
            "5085: [D loss: 0.718852, acc: 0.542969]  [A loss: 0.948892, acc: 0.097656]\n",
            "5086: [D loss: 0.707480, acc: 0.474609]  [A loss: 0.678180, acc: 0.542969]\n",
            "5087: [D loss: 0.741256, acc: 0.501953]  [A loss: 0.933846, acc: 0.101562]\n",
            "5088: [D loss: 0.692814, acc: 0.529297]  [A loss: 0.772252, acc: 0.359375]\n",
            "5089: [D loss: 0.717393, acc: 0.480469]  [A loss: 0.868421, acc: 0.179688]\n",
            "5090: [D loss: 0.693275, acc: 0.525391]  [A loss: 0.738037, acc: 0.429688]\n",
            "5091: [D loss: 0.707789, acc: 0.496094]  [A loss: 0.846144, acc: 0.199219]\n",
            "5092: [D loss: 0.684129, acc: 0.554688]  [A loss: 0.801311, acc: 0.277344]\n",
            "5093: [D loss: 0.700799, acc: 0.527344]  [A loss: 0.871118, acc: 0.164062]\n",
            "5094: [D loss: 0.704917, acc: 0.466797]  [A loss: 0.779840, acc: 0.320312]\n",
            "5095: [D loss: 0.700678, acc: 0.486328]  [A loss: 0.842796, acc: 0.207031]\n",
            "5096: [D loss: 0.711069, acc: 0.501953]  [A loss: 0.858893, acc: 0.191406]\n",
            "5097: [D loss: 0.698181, acc: 0.521484]  [A loss: 0.783331, acc: 0.312500]\n",
            "5098: [D loss: 0.714143, acc: 0.494141]  [A loss: 0.871838, acc: 0.152344]\n",
            "5099: [D loss: 0.699691, acc: 0.509766]  [A loss: 0.803813, acc: 0.250000]\n",
            "5100: [D loss: 0.712980, acc: 0.505859]  [A loss: 0.859472, acc: 0.218750]\n",
            "5101: [D loss: 0.695993, acc: 0.529297]  [A loss: 0.845764, acc: 0.191406]\n",
            "5102: [D loss: 0.700438, acc: 0.527344]  [A loss: 0.778206, acc: 0.296875]\n",
            "5103: [D loss: 0.696819, acc: 0.531250]  [A loss: 0.885828, acc: 0.136719]\n",
            "5104: [D loss: 0.688726, acc: 0.544922]  [A loss: 0.732151, acc: 0.425781]\n",
            "5105: [D loss: 0.723065, acc: 0.490234]  [A loss: 0.977639, acc: 0.074219]\n",
            "5106: [D loss: 0.693790, acc: 0.550781]  [A loss: 0.680225, acc: 0.546875]\n",
            "5107: [D loss: 0.727814, acc: 0.523438]  [A loss: 1.011633, acc: 0.039062]\n",
            "5108: [D loss: 0.692196, acc: 0.541016]  [A loss: 0.643404, acc: 0.675781]\n",
            "5109: [D loss: 0.742926, acc: 0.488281]  [A loss: 0.899883, acc: 0.093750]\n",
            "5110: [D loss: 0.685648, acc: 0.519531]  [A loss: 0.759258, acc: 0.367188]\n",
            "5111: [D loss: 0.706639, acc: 0.488281]  [A loss: 0.852495, acc: 0.179688]\n",
            "5112: [D loss: 0.691992, acc: 0.529297]  [A loss: 0.789572, acc: 0.308594]\n",
            "5113: [D loss: 0.699680, acc: 0.527344]  [A loss: 0.784224, acc: 0.328125]\n",
            "5114: [D loss: 0.686046, acc: 0.556641]  [A loss: 0.818935, acc: 0.230469]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5115: [D loss: 0.699191, acc: 0.515625]  [A loss: 0.814504, acc: 0.304688]\n",
            "5116: [D loss: 0.697010, acc: 0.521484]  [A loss: 0.900845, acc: 0.140625]\n",
            "5117: [D loss: 0.702200, acc: 0.527344]  [A loss: 0.788933, acc: 0.312500]\n",
            "5118: [D loss: 0.685316, acc: 0.576172]  [A loss: 0.833843, acc: 0.195312]\n",
            "5119: [D loss: 0.701424, acc: 0.503906]  [A loss: 0.767766, acc: 0.339844]\n",
            "5120: [D loss: 0.695874, acc: 0.539062]  [A loss: 0.781559, acc: 0.332031]\n",
            "5121: [D loss: 0.703468, acc: 0.509766]  [A loss: 0.809365, acc: 0.250000]\n",
            "5122: [D loss: 0.700555, acc: 0.513672]  [A loss: 0.919975, acc: 0.121094]\n",
            "5123: [D loss: 0.692977, acc: 0.550781]  [A loss: 0.759322, acc: 0.351562]\n",
            "5124: [D loss: 0.697517, acc: 0.542969]  [A loss: 0.961033, acc: 0.066406]\n",
            "5125: [D loss: 0.702870, acc: 0.507812]  [A loss: 0.721607, acc: 0.468750]\n",
            "5126: [D loss: 0.713870, acc: 0.509766]  [A loss: 0.992454, acc: 0.062500]\n",
            "5127: [D loss: 0.703508, acc: 0.533203]  [A loss: 0.663481, acc: 0.601562]\n",
            "5128: [D loss: 0.721153, acc: 0.509766]  [A loss: 0.914326, acc: 0.109375]\n",
            "5129: [D loss: 0.700727, acc: 0.515625]  [A loss: 0.740237, acc: 0.402344]\n",
            "5130: [D loss: 0.705478, acc: 0.529297]  [A loss: 0.905900, acc: 0.125000]\n",
            "5131: [D loss: 0.701279, acc: 0.496094]  [A loss: 0.743390, acc: 0.390625]\n",
            "5132: [D loss: 0.723853, acc: 0.501953]  [A loss: 0.906920, acc: 0.109375]\n",
            "5133: [D loss: 0.697600, acc: 0.523438]  [A loss: 0.765068, acc: 0.367188]\n",
            "5134: [D loss: 0.692255, acc: 0.546875]  [A loss: 0.863732, acc: 0.175781]\n",
            "5135: [D loss: 0.685969, acc: 0.562500]  [A loss: 0.733544, acc: 0.410156]\n",
            "5136: [D loss: 0.702065, acc: 0.544922]  [A loss: 0.875983, acc: 0.187500]\n",
            "5137: [D loss: 0.701008, acc: 0.492188]  [A loss: 0.782713, acc: 0.289062]\n",
            "5138: [D loss: 0.705763, acc: 0.531250]  [A loss: 0.847655, acc: 0.218750]\n",
            "5139: [D loss: 0.710593, acc: 0.515625]  [A loss: 0.796467, acc: 0.261719]\n",
            "5140: [D loss: 0.699465, acc: 0.513672]  [A loss: 0.858688, acc: 0.160156]\n",
            "5141: [D loss: 0.704635, acc: 0.511719]  [A loss: 0.757706, acc: 0.355469]\n",
            "5142: [D loss: 0.710992, acc: 0.503906]  [A loss: 0.875920, acc: 0.195312]\n",
            "5143: [D loss: 0.706855, acc: 0.480469]  [A loss: 0.793305, acc: 0.296875]\n",
            "5144: [D loss: 0.696191, acc: 0.521484]  [A loss: 0.831514, acc: 0.246094]\n",
            "5145: [D loss: 0.703113, acc: 0.498047]  [A loss: 0.810031, acc: 0.265625]\n",
            "5146: [D loss: 0.722505, acc: 0.482422]  [A loss: 0.910666, acc: 0.109375]\n",
            "5147: [D loss: 0.703988, acc: 0.517578]  [A loss: 0.730792, acc: 0.445312]\n",
            "5148: [D loss: 0.702249, acc: 0.507812]  [A loss: 0.884738, acc: 0.140625]\n",
            "5149: [D loss: 0.707678, acc: 0.480469]  [A loss: 0.769921, acc: 0.343750]\n",
            "5150: [D loss: 0.700878, acc: 0.503906]  [A loss: 0.843637, acc: 0.203125]\n",
            "5151: [D loss: 0.703042, acc: 0.496094]  [A loss: 0.813112, acc: 0.269531]\n",
            "5152: [D loss: 0.717335, acc: 0.488281]  [A loss: 0.913966, acc: 0.125000]\n",
            "5153: [D loss: 0.716553, acc: 0.468750]  [A loss: 0.683602, acc: 0.546875]\n",
            "5154: [D loss: 0.714881, acc: 0.517578]  [A loss: 0.892169, acc: 0.187500]\n",
            "5155: [D loss: 0.695840, acc: 0.535156]  [A loss: 0.788712, acc: 0.304688]\n",
            "5156: [D loss: 0.717782, acc: 0.500000]  [A loss: 0.932830, acc: 0.062500]\n",
            "5157: [D loss: 0.693258, acc: 0.525391]  [A loss: 0.746134, acc: 0.417969]\n",
            "5158: [D loss: 0.730999, acc: 0.490234]  [A loss: 0.928160, acc: 0.132812]\n",
            "5159: [D loss: 0.693314, acc: 0.527344]  [A loss: 0.713548, acc: 0.468750]\n",
            "5160: [D loss: 0.714426, acc: 0.503906]  [A loss: 0.909705, acc: 0.148438]\n",
            "5161: [D loss: 0.697518, acc: 0.562500]  [A loss: 0.720209, acc: 0.425781]\n",
            "5162: [D loss: 0.715568, acc: 0.501953]  [A loss: 0.859741, acc: 0.160156]\n",
            "5163: [D loss: 0.709851, acc: 0.480469]  [A loss: 0.721745, acc: 0.429688]\n",
            "5164: [D loss: 0.698251, acc: 0.544922]  [A loss: 0.890837, acc: 0.140625]\n",
            "5165: [D loss: 0.697809, acc: 0.494141]  [A loss: 0.752651, acc: 0.437500]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5166: [D loss: 0.707907, acc: 0.517578]  [A loss: 0.867089, acc: 0.156250]\n",
            "5167: [D loss: 0.704387, acc: 0.513672]  [A loss: 0.745648, acc: 0.410156]\n",
            "5168: [D loss: 0.697975, acc: 0.517578]  [A loss: 0.944736, acc: 0.074219]\n",
            "5169: [D loss: 0.686264, acc: 0.550781]  [A loss: 0.681182, acc: 0.550781]\n",
            "5170: [D loss: 0.728134, acc: 0.488281]  [A loss: 0.973212, acc: 0.058594]\n",
            "5171: [D loss: 0.690010, acc: 0.541016]  [A loss: 0.702339, acc: 0.500000]\n",
            "5172: [D loss: 0.719487, acc: 0.492188]  [A loss: 0.936982, acc: 0.109375]\n",
            "5173: [D loss: 0.691654, acc: 0.511719]  [A loss: 0.724517, acc: 0.429688]\n",
            "5174: [D loss: 0.713787, acc: 0.511719]  [A loss: 0.898811, acc: 0.140625]\n",
            "5175: [D loss: 0.702806, acc: 0.484375]  [A loss: 0.731712, acc: 0.417969]\n",
            "5176: [D loss: 0.716579, acc: 0.496094]  [A loss: 0.905064, acc: 0.113281]\n",
            "5177: [D loss: 0.686825, acc: 0.541016]  [A loss: 0.714471, acc: 0.484375]\n",
            "5178: [D loss: 0.705349, acc: 0.539062]  [A loss: 0.818997, acc: 0.261719]\n",
            "5179: [D loss: 0.707104, acc: 0.509766]  [A loss: 0.798849, acc: 0.269531]\n",
            "5180: [D loss: 0.712941, acc: 0.498047]  [A loss: 0.781484, acc: 0.332031]\n",
            "5181: [D loss: 0.709520, acc: 0.498047]  [A loss: 0.790752, acc: 0.257812]\n",
            "5182: [D loss: 0.707429, acc: 0.505859]  [A loss: 0.836150, acc: 0.226562]\n",
            "5183: [D loss: 0.691759, acc: 0.525391]  [A loss: 0.749454, acc: 0.406250]\n",
            "5184: [D loss: 0.705000, acc: 0.490234]  [A loss: 0.835392, acc: 0.214844]\n",
            "5185: [D loss: 0.704638, acc: 0.519531]  [A loss: 0.755386, acc: 0.371094]\n",
            "5186: [D loss: 0.722463, acc: 0.519531]  [A loss: 0.881227, acc: 0.156250]\n",
            "5187: [D loss: 0.695818, acc: 0.527344]  [A loss: 0.740235, acc: 0.390625]\n",
            "5188: [D loss: 0.705513, acc: 0.509766]  [A loss: 0.909538, acc: 0.113281]\n",
            "5189: [D loss: 0.701569, acc: 0.505859]  [A loss: 0.716798, acc: 0.476562]\n",
            "5190: [D loss: 0.719542, acc: 0.500000]  [A loss: 0.920534, acc: 0.113281]\n",
            "5191: [D loss: 0.700395, acc: 0.542969]  [A loss: 0.728839, acc: 0.417969]\n",
            "5192: [D loss: 0.706398, acc: 0.537109]  [A loss: 0.906652, acc: 0.074219]\n",
            "5193: [D loss: 0.693241, acc: 0.535156]  [A loss: 0.696155, acc: 0.562500]\n",
            "5194: [D loss: 0.708447, acc: 0.509766]  [A loss: 0.891960, acc: 0.136719]\n",
            "5195: [D loss: 0.703767, acc: 0.537109]  [A loss: 0.738279, acc: 0.378906]\n",
            "5196: [D loss: 0.709377, acc: 0.500000]  [A loss: 0.900142, acc: 0.125000]\n",
            "5197: [D loss: 0.701272, acc: 0.511719]  [A loss: 0.747132, acc: 0.410156]\n",
            "5198: [D loss: 0.702002, acc: 0.546875]  [A loss: 0.929985, acc: 0.082031]\n",
            "5199: [D loss: 0.694260, acc: 0.523438]  [A loss: 0.746556, acc: 0.371094]\n",
            "5200: [D loss: 0.719478, acc: 0.503906]  [A loss: 0.829698, acc: 0.199219]\n",
            "5201: [D loss: 0.698138, acc: 0.521484]  [A loss: 0.793934, acc: 0.304688]\n",
            "5202: [D loss: 0.711655, acc: 0.517578]  [A loss: 0.835115, acc: 0.210938]\n",
            "5203: [D loss: 0.696907, acc: 0.505859]  [A loss: 0.761045, acc: 0.355469]\n",
            "5204: [D loss: 0.709675, acc: 0.503906]  [A loss: 0.922992, acc: 0.101562]\n",
            "5205: [D loss: 0.684187, acc: 0.560547]  [A loss: 0.744321, acc: 0.410156]\n",
            "5206: [D loss: 0.701049, acc: 0.531250]  [A loss: 0.900291, acc: 0.105469]\n",
            "5207: [D loss: 0.687241, acc: 0.533203]  [A loss: 0.712616, acc: 0.457031]\n",
            "5208: [D loss: 0.694762, acc: 0.546875]  [A loss: 0.866481, acc: 0.175781]\n",
            "5209: [D loss: 0.691412, acc: 0.539062]  [A loss: 0.728927, acc: 0.406250]\n",
            "5210: [D loss: 0.708194, acc: 0.513672]  [A loss: 0.901783, acc: 0.121094]\n",
            "5211: [D loss: 0.688717, acc: 0.535156]  [A loss: 0.775858, acc: 0.316406]\n",
            "5212: [D loss: 0.711858, acc: 0.523438]  [A loss: 0.806176, acc: 0.265625]\n",
            "5213: [D loss: 0.701221, acc: 0.509766]  [A loss: 0.777707, acc: 0.320312]\n",
            "5214: [D loss: 0.705188, acc: 0.535156]  [A loss: 0.798971, acc: 0.320312]\n",
            "5215: [D loss: 0.705902, acc: 0.492188]  [A loss: 0.825489, acc: 0.214844]\n",
            "5216: [D loss: 0.705834, acc: 0.498047]  [A loss: 0.910615, acc: 0.132812]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5217: [D loss: 0.693704, acc: 0.521484]  [A loss: 0.855061, acc: 0.175781]\n",
            "5218: [D loss: 0.711671, acc: 0.488281]  [A loss: 0.839071, acc: 0.214844]\n",
            "5219: [D loss: 0.699009, acc: 0.554688]  [A loss: 0.797974, acc: 0.296875]\n",
            "5220: [D loss: 0.703409, acc: 0.521484]  [A loss: 0.841121, acc: 0.207031]\n",
            "5221: [D loss: 0.699592, acc: 0.527344]  [A loss: 0.782444, acc: 0.308594]\n",
            "5222: [D loss: 0.697412, acc: 0.529297]  [A loss: 0.920295, acc: 0.140625]\n",
            "5223: [D loss: 0.692198, acc: 0.537109]  [A loss: 0.757870, acc: 0.351562]\n",
            "5224: [D loss: 0.704282, acc: 0.523438]  [A loss: 0.924483, acc: 0.101562]\n",
            "5225: [D loss: 0.703953, acc: 0.503906]  [A loss: 0.686056, acc: 0.523438]\n",
            "5226: [D loss: 0.713939, acc: 0.515625]  [A loss: 1.030816, acc: 0.058594]\n",
            "5227: [D loss: 0.707619, acc: 0.511719]  [A loss: 0.672766, acc: 0.597656]\n",
            "5228: [D loss: 0.706404, acc: 0.509766]  [A loss: 0.869721, acc: 0.156250]\n",
            "5229: [D loss: 0.696388, acc: 0.552734]  [A loss: 0.739234, acc: 0.425781]\n",
            "5230: [D loss: 0.716229, acc: 0.503906]  [A loss: 0.908669, acc: 0.148438]\n",
            "5231: [D loss: 0.691838, acc: 0.544922]  [A loss: 0.776478, acc: 0.312500]\n",
            "5232: [D loss: 0.700650, acc: 0.544922]  [A loss: 0.886809, acc: 0.164062]\n",
            "5233: [D loss: 0.682746, acc: 0.541016]  [A loss: 0.749597, acc: 0.394531]\n",
            "5234: [D loss: 0.704627, acc: 0.521484]  [A loss: 0.917017, acc: 0.113281]\n",
            "5235: [D loss: 0.697806, acc: 0.544922]  [A loss: 0.735465, acc: 0.421875]\n",
            "5236: [D loss: 0.716646, acc: 0.492188]  [A loss: 0.941809, acc: 0.085938]\n",
            "5237: [D loss: 0.697116, acc: 0.542969]  [A loss: 0.719480, acc: 0.457031]\n",
            "5238: [D loss: 0.715478, acc: 0.492188]  [A loss: 0.877204, acc: 0.160156]\n",
            "5239: [D loss: 0.692850, acc: 0.542969]  [A loss: 0.747619, acc: 0.382812]\n",
            "5240: [D loss: 0.704462, acc: 0.521484]  [A loss: 0.915908, acc: 0.128906]\n",
            "5241: [D loss: 0.689980, acc: 0.533203]  [A loss: 0.700388, acc: 0.511719]\n",
            "5242: [D loss: 0.716783, acc: 0.500000]  [A loss: 0.847547, acc: 0.207031]\n",
            "5243: [D loss: 0.692681, acc: 0.539062]  [A loss: 0.697890, acc: 0.523438]\n",
            "5244: [D loss: 0.720367, acc: 0.480469]  [A loss: 0.886894, acc: 0.136719]\n",
            "5245: [D loss: 0.697568, acc: 0.533203]  [A loss: 0.810437, acc: 0.257812]\n",
            "5246: [D loss: 0.688672, acc: 0.533203]  [A loss: 0.797353, acc: 0.312500]\n",
            "5247: [D loss: 0.703970, acc: 0.517578]  [A loss: 0.798199, acc: 0.269531]\n",
            "5248: [D loss: 0.696531, acc: 0.544922]  [A loss: 0.815274, acc: 0.253906]\n",
            "5249: [D loss: 0.690583, acc: 0.546875]  [A loss: 0.799693, acc: 0.273438]\n",
            "5250: [D loss: 0.695456, acc: 0.539062]  [A loss: 0.790156, acc: 0.316406]\n",
            "5251: [D loss: 0.711809, acc: 0.496094]  [A loss: 0.863487, acc: 0.203125]\n",
            "5252: [D loss: 0.698723, acc: 0.539062]  [A loss: 0.754091, acc: 0.375000]\n",
            "5253: [D loss: 0.718288, acc: 0.496094]  [A loss: 0.924054, acc: 0.109375]\n",
            "5254: [D loss: 0.703059, acc: 0.492188]  [A loss: 0.724827, acc: 0.457031]\n",
            "5255: [D loss: 0.701004, acc: 0.537109]  [A loss: 0.910078, acc: 0.156250]\n",
            "5256: [D loss: 0.694102, acc: 0.541016]  [A loss: 0.753761, acc: 0.421875]\n",
            "5257: [D loss: 0.705414, acc: 0.505859]  [A loss: 0.863895, acc: 0.195312]\n",
            "5258: [D loss: 0.696944, acc: 0.523438]  [A loss: 0.801573, acc: 0.285156]\n",
            "5259: [D loss: 0.722330, acc: 0.472656]  [A loss: 0.837083, acc: 0.207031]\n",
            "5260: [D loss: 0.701730, acc: 0.496094]  [A loss: 0.822728, acc: 0.195312]\n",
            "5261: [D loss: 0.695860, acc: 0.505859]  [A loss: 0.762926, acc: 0.343750]\n",
            "5262: [D loss: 0.713487, acc: 0.525391]  [A loss: 0.895603, acc: 0.171875]\n",
            "5263: [D loss: 0.700939, acc: 0.511719]  [A loss: 0.765489, acc: 0.378906]\n",
            "5264: [D loss: 0.713768, acc: 0.500000]  [A loss: 0.920749, acc: 0.121094]\n",
            "5265: [D loss: 0.698434, acc: 0.503906]  [A loss: 0.784230, acc: 0.324219]\n",
            "5266: [D loss: 0.702774, acc: 0.507812]  [A loss: 0.873348, acc: 0.128906]\n",
            "5267: [D loss: 0.690973, acc: 0.552734]  [A loss: 0.765069, acc: 0.367188]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5268: [D loss: 0.686220, acc: 0.550781]  [A loss: 0.830065, acc: 0.261719]\n",
            "5269: [D loss: 0.702812, acc: 0.507812]  [A loss: 0.824016, acc: 0.265625]\n",
            "5270: [D loss: 0.709684, acc: 0.501953]  [A loss: 0.849908, acc: 0.207031]\n",
            "5271: [D loss: 0.704518, acc: 0.503906]  [A loss: 0.778012, acc: 0.304688]\n",
            "5272: [D loss: 0.713504, acc: 0.500000]  [A loss: 0.873337, acc: 0.128906]\n",
            "5273: [D loss: 0.695142, acc: 0.529297]  [A loss: 0.869557, acc: 0.199219]\n",
            "5274: [D loss: 0.702652, acc: 0.523438]  [A loss: 0.777760, acc: 0.347656]\n",
            "5275: [D loss: 0.705522, acc: 0.515625]  [A loss: 1.010025, acc: 0.074219]\n",
            "5276: [D loss: 0.701083, acc: 0.544922]  [A loss: 0.677468, acc: 0.554688]\n",
            "5277: [D loss: 0.714177, acc: 0.525391]  [A loss: 0.976223, acc: 0.050781]\n",
            "5278: [D loss: 0.702845, acc: 0.503906]  [A loss: 0.625359, acc: 0.695312]\n",
            "5279: [D loss: 0.757764, acc: 0.490234]  [A loss: 0.934386, acc: 0.101562]\n",
            "5280: [D loss: 0.699729, acc: 0.523438]  [A loss: 0.726722, acc: 0.417969]\n",
            "5281: [D loss: 0.718811, acc: 0.494141]  [A loss: 0.919824, acc: 0.144531]\n",
            "5282: [D loss: 0.708829, acc: 0.494141]  [A loss: 0.751231, acc: 0.367188]\n",
            "5283: [D loss: 0.689543, acc: 0.544922]  [A loss: 0.812740, acc: 0.253906]\n",
            "5284: [D loss: 0.693655, acc: 0.552734]  [A loss: 0.811517, acc: 0.269531]\n",
            "5285: [D loss: 0.699855, acc: 0.527344]  [A loss: 0.834711, acc: 0.218750]\n",
            "5286: [D loss: 0.688606, acc: 0.546875]  [A loss: 0.819827, acc: 0.265625]\n",
            "5287: [D loss: 0.698409, acc: 0.521484]  [A loss: 0.843776, acc: 0.218750]\n",
            "5288: [D loss: 0.695208, acc: 0.533203]  [A loss: 0.790020, acc: 0.304688]\n",
            "5289: [D loss: 0.695275, acc: 0.546875]  [A loss: 0.843360, acc: 0.238281]\n",
            "5290: [D loss: 0.706834, acc: 0.496094]  [A loss: 0.823678, acc: 0.238281]\n",
            "5291: [D loss: 0.689155, acc: 0.544922]  [A loss: 0.857006, acc: 0.195312]\n",
            "5292: [D loss: 0.705192, acc: 0.519531]  [A loss: 0.780019, acc: 0.316406]\n",
            "5293: [D loss: 0.719426, acc: 0.492188]  [A loss: 1.026649, acc: 0.082031]\n",
            "5294: [D loss: 0.696116, acc: 0.525391]  [A loss: 0.667957, acc: 0.578125]\n",
            "5295: [D loss: 0.715121, acc: 0.509766]  [A loss: 0.926526, acc: 0.121094]\n",
            "5296: [D loss: 0.704423, acc: 0.521484]  [A loss: 0.671358, acc: 0.582031]\n",
            "5297: [D loss: 0.712011, acc: 0.511719]  [A loss: 0.861324, acc: 0.164062]\n",
            "5298: [D loss: 0.699673, acc: 0.513672]  [A loss: 0.727982, acc: 0.421875]\n",
            "5299: [D loss: 0.707493, acc: 0.507812]  [A loss: 0.829861, acc: 0.230469]\n",
            "5300: [D loss: 0.702468, acc: 0.511719]  [A loss: 0.765560, acc: 0.316406]\n",
            "5301: [D loss: 0.700940, acc: 0.525391]  [A loss: 0.821236, acc: 0.257812]\n",
            "5302: [D loss: 0.704197, acc: 0.505859]  [A loss: 0.850846, acc: 0.183594]\n",
            "5303: [D loss: 0.698108, acc: 0.507812]  [A loss: 0.817403, acc: 0.242188]\n",
            "5304: [D loss: 0.707855, acc: 0.513672]  [A loss: 0.863971, acc: 0.171875]\n",
            "5305: [D loss: 0.700967, acc: 0.537109]  [A loss: 0.777894, acc: 0.343750]\n",
            "5306: [D loss: 0.702087, acc: 0.521484]  [A loss: 0.946609, acc: 0.105469]\n",
            "5307: [D loss: 0.694497, acc: 0.535156]  [A loss: 0.768805, acc: 0.343750]\n",
            "5308: [D loss: 0.708059, acc: 0.533203]  [A loss: 0.845037, acc: 0.222656]\n",
            "5309: [D loss: 0.683276, acc: 0.556641]  [A loss: 0.802008, acc: 0.285156]\n",
            "5310: [D loss: 0.675718, acc: 0.566406]  [A loss: 0.807299, acc: 0.269531]\n",
            "5311: [D loss: 0.702816, acc: 0.511719]  [A loss: 0.915166, acc: 0.156250]\n",
            "5312: [D loss: 0.694059, acc: 0.527344]  [A loss: 0.784285, acc: 0.300781]\n",
            "5313: [D loss: 0.714582, acc: 0.517578]  [A loss: 1.016769, acc: 0.097656]\n",
            "5314: [D loss: 0.697469, acc: 0.531250]  [A loss: 0.749570, acc: 0.441406]\n",
            "5315: [D loss: 0.714702, acc: 0.509766]  [A loss: 0.921833, acc: 0.156250]\n",
            "5316: [D loss: 0.701076, acc: 0.492188]  [A loss: 0.738130, acc: 0.437500]\n",
            "5317: [D loss: 0.709427, acc: 0.496094]  [A loss: 0.871908, acc: 0.167969]\n",
            "5318: [D loss: 0.700629, acc: 0.500000]  [A loss: 0.793375, acc: 0.296875]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5319: [D loss: 0.688415, acc: 0.539062]  [A loss: 0.849885, acc: 0.171875]\n",
            "5320: [D loss: 0.699023, acc: 0.537109]  [A loss: 0.854079, acc: 0.203125]\n",
            "5321: [D loss: 0.698066, acc: 0.511719]  [A loss: 0.761113, acc: 0.398438]\n",
            "5322: [D loss: 0.722384, acc: 0.501953]  [A loss: 0.854915, acc: 0.222656]\n",
            "5323: [D loss: 0.692931, acc: 0.542969]  [A loss: 0.878509, acc: 0.136719]\n",
            "5324: [D loss: 0.688325, acc: 0.544922]  [A loss: 0.747063, acc: 0.378906]\n",
            "5325: [D loss: 0.700150, acc: 0.552734]  [A loss: 0.997985, acc: 0.078125]\n",
            "5326: [D loss: 0.706401, acc: 0.505859]  [A loss: 0.650221, acc: 0.625000]\n",
            "5327: [D loss: 0.724912, acc: 0.480469]  [A loss: 0.957704, acc: 0.105469]\n",
            "5328: [D loss: 0.699646, acc: 0.560547]  [A loss: 0.700394, acc: 0.476562]\n",
            "5329: [D loss: 0.703926, acc: 0.513672]  [A loss: 0.851853, acc: 0.195312]\n",
            "5330: [D loss: 0.702943, acc: 0.521484]  [A loss: 0.797217, acc: 0.277344]\n",
            "5331: [D loss: 0.709710, acc: 0.507812]  [A loss: 0.882678, acc: 0.164062]\n",
            "5332: [D loss: 0.681409, acc: 0.554688]  [A loss: 0.803695, acc: 0.281250]\n",
            "5333: [D loss: 0.712407, acc: 0.500000]  [A loss: 0.847578, acc: 0.210938]\n",
            "5334: [D loss: 0.693903, acc: 0.535156]  [A loss: 0.773263, acc: 0.332031]\n",
            "5335: [D loss: 0.716682, acc: 0.513672]  [A loss: 0.960948, acc: 0.097656]\n",
            "5336: [D loss: 0.702402, acc: 0.521484]  [A loss: 0.736963, acc: 0.382812]\n",
            "5337: [D loss: 0.714310, acc: 0.474609]  [A loss: 0.869015, acc: 0.214844]\n",
            "5338: [D loss: 0.699841, acc: 0.533203]  [A loss: 0.705810, acc: 0.480469]\n",
            "5339: [D loss: 0.719088, acc: 0.511719]  [A loss: 0.882074, acc: 0.148438]\n",
            "5340: [D loss: 0.700170, acc: 0.511719]  [A loss: 0.727820, acc: 0.433594]\n",
            "5341: [D loss: 0.715154, acc: 0.498047]  [A loss: 0.912723, acc: 0.109375]\n",
            "5342: [D loss: 0.695845, acc: 0.523438]  [A loss: 0.740741, acc: 0.402344]\n",
            "5343: [D loss: 0.714639, acc: 0.500000]  [A loss: 0.905619, acc: 0.117188]\n",
            "5344: [D loss: 0.694973, acc: 0.523438]  [A loss: 0.753611, acc: 0.363281]\n",
            "5345: [D loss: 0.703147, acc: 0.517578]  [A loss: 0.845131, acc: 0.226562]\n",
            "5346: [D loss: 0.685907, acc: 0.562500]  [A loss: 0.801037, acc: 0.289062]\n",
            "5347: [D loss: 0.702376, acc: 0.513672]  [A loss: 0.782556, acc: 0.320312]\n",
            "5348: [D loss: 0.701413, acc: 0.552734]  [A loss: 0.879134, acc: 0.160156]\n",
            "5349: [D loss: 0.704026, acc: 0.513672]  [A loss: 0.738858, acc: 0.425781]\n",
            "5350: [D loss: 0.707370, acc: 0.486328]  [A loss: 0.817035, acc: 0.289062]\n",
            "5351: [D loss: 0.695607, acc: 0.527344]  [A loss: 0.864162, acc: 0.187500]\n",
            "5352: [D loss: 0.696698, acc: 0.527344]  [A loss: 0.773003, acc: 0.296875]\n",
            "5353: [D loss: 0.697753, acc: 0.519531]  [A loss: 0.888308, acc: 0.140625]\n",
            "5354: [D loss: 0.701982, acc: 0.494141]  [A loss: 0.770761, acc: 0.339844]\n",
            "5355: [D loss: 0.696369, acc: 0.511719]  [A loss: 0.822650, acc: 0.253906]\n",
            "5356: [D loss: 0.715169, acc: 0.484375]  [A loss: 0.876679, acc: 0.218750]\n",
            "5357: [D loss: 0.704415, acc: 0.490234]  [A loss: 0.844747, acc: 0.191406]\n",
            "5358: [D loss: 0.691907, acc: 0.554688]  [A loss: 0.810908, acc: 0.312500]\n",
            "5359: [D loss: 0.702802, acc: 0.517578]  [A loss: 0.907299, acc: 0.128906]\n",
            "5360: [D loss: 0.697962, acc: 0.494141]  [A loss: 0.740474, acc: 0.386719]\n",
            "5361: [D loss: 0.710179, acc: 0.519531]  [A loss: 0.950618, acc: 0.074219]\n",
            "5362: [D loss: 0.697830, acc: 0.525391]  [A loss: 0.620079, acc: 0.699219]\n",
            "5363: [D loss: 0.723088, acc: 0.503906]  [A loss: 1.072150, acc: 0.019531]\n",
            "5364: [D loss: 0.717959, acc: 0.478516]  [A loss: 0.708175, acc: 0.484375]\n",
            "5365: [D loss: 0.718182, acc: 0.505859]  [A loss: 0.876416, acc: 0.191406]\n",
            "5366: [D loss: 0.690707, acc: 0.531250]  [A loss: 0.710623, acc: 0.500000]\n",
            "5367: [D loss: 0.719124, acc: 0.501953]  [A loss: 0.888735, acc: 0.191406]\n",
            "5368: [D loss: 0.705257, acc: 0.507812]  [A loss: 0.703528, acc: 0.527344]\n",
            "5369: [D loss: 0.714675, acc: 0.496094]  [A loss: 0.877741, acc: 0.144531]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5370: [D loss: 0.698200, acc: 0.527344]  [A loss: 0.705151, acc: 0.449219]\n",
            "5371: [D loss: 0.704878, acc: 0.527344]  [A loss: 0.875507, acc: 0.148438]\n",
            "5372: [D loss: 0.701847, acc: 0.500000]  [A loss: 0.705364, acc: 0.468750]\n",
            "5373: [D loss: 0.716883, acc: 0.503906]  [A loss: 0.890072, acc: 0.128906]\n",
            "5374: [D loss: 0.702508, acc: 0.503906]  [A loss: 0.745922, acc: 0.402344]\n",
            "5375: [D loss: 0.704748, acc: 0.496094]  [A loss: 0.824775, acc: 0.199219]\n",
            "5376: [D loss: 0.696279, acc: 0.515625]  [A loss: 0.839888, acc: 0.191406]\n",
            "5377: [D loss: 0.698954, acc: 0.535156]  [A loss: 0.802172, acc: 0.273438]\n",
            "5378: [D loss: 0.705939, acc: 0.507812]  [A loss: 0.846207, acc: 0.195312]\n",
            "5379: [D loss: 0.699739, acc: 0.507812]  [A loss: 0.806739, acc: 0.277344]\n",
            "5380: [D loss: 0.708250, acc: 0.527344]  [A loss: 0.892534, acc: 0.152344]\n",
            "5381: [D loss: 0.705761, acc: 0.529297]  [A loss: 0.751028, acc: 0.386719]\n",
            "5382: [D loss: 0.687244, acc: 0.523438]  [A loss: 0.918836, acc: 0.132812]\n",
            "5383: [D loss: 0.690759, acc: 0.527344]  [A loss: 0.728279, acc: 0.433594]\n",
            "5384: [D loss: 0.712778, acc: 0.521484]  [A loss: 0.951642, acc: 0.093750]\n",
            "5385: [D loss: 0.692273, acc: 0.562500]  [A loss: 0.663242, acc: 0.578125]\n",
            "5386: [D loss: 0.709621, acc: 0.511719]  [A loss: 0.889545, acc: 0.125000]\n",
            "5387: [D loss: 0.694719, acc: 0.519531]  [A loss: 0.699088, acc: 0.546875]\n",
            "5388: [D loss: 0.709569, acc: 0.507812]  [A loss: 0.878014, acc: 0.136719]\n",
            "5389: [D loss: 0.711249, acc: 0.478516]  [A loss: 0.763411, acc: 0.406250]\n",
            "5390: [D loss: 0.713107, acc: 0.501953]  [A loss: 0.852875, acc: 0.218750]\n",
            "5391: [D loss: 0.688069, acc: 0.560547]  [A loss: 0.793625, acc: 0.300781]\n",
            "5392: [D loss: 0.707978, acc: 0.503906]  [A loss: 0.880420, acc: 0.136719]\n",
            "5393: [D loss: 0.694332, acc: 0.542969]  [A loss: 0.792874, acc: 0.300781]\n",
            "5394: [D loss: 0.704985, acc: 0.503906]  [A loss: 0.826986, acc: 0.226562]\n",
            "5395: [D loss: 0.708078, acc: 0.488281]  [A loss: 0.863353, acc: 0.187500]\n",
            "5396: [D loss: 0.696722, acc: 0.523438]  [A loss: 0.728083, acc: 0.445312]\n",
            "5397: [D loss: 0.722876, acc: 0.513672]  [A loss: 0.912145, acc: 0.152344]\n",
            "5398: [D loss: 0.691070, acc: 0.544922]  [A loss: 0.706046, acc: 0.488281]\n",
            "5399: [D loss: 0.711112, acc: 0.513672]  [A loss: 0.912146, acc: 0.117188]\n",
            "5400: [D loss: 0.704216, acc: 0.517578]  [A loss: 0.716999, acc: 0.472656]\n",
            "5401: [D loss: 0.714174, acc: 0.531250]  [A loss: 0.914770, acc: 0.113281]\n",
            "5402: [D loss: 0.694758, acc: 0.527344]  [A loss: 0.710333, acc: 0.519531]\n",
            "5403: [D loss: 0.699685, acc: 0.552734]  [A loss: 0.826798, acc: 0.230469]\n",
            "5404: [D loss: 0.706293, acc: 0.496094]  [A loss: 0.776927, acc: 0.312500]\n",
            "5405: [D loss: 0.703350, acc: 0.507812]  [A loss: 0.795299, acc: 0.332031]\n",
            "5406: [D loss: 0.711688, acc: 0.490234]  [A loss: 0.866867, acc: 0.171875]\n",
            "5407: [D loss: 0.703064, acc: 0.513672]  [A loss: 0.775719, acc: 0.320312]\n",
            "5408: [D loss: 0.685760, acc: 0.558594]  [A loss: 0.853819, acc: 0.183594]\n",
            "5409: [D loss: 0.706850, acc: 0.505859]  [A loss: 0.758217, acc: 0.351562]\n",
            "5410: [D loss: 0.690042, acc: 0.535156]  [A loss: 0.934495, acc: 0.074219]\n",
            "5411: [D loss: 0.701287, acc: 0.509766]  [A loss: 0.740833, acc: 0.433594]\n",
            "5412: [D loss: 0.700017, acc: 0.537109]  [A loss: 0.883708, acc: 0.144531]\n",
            "5413: [D loss: 0.684255, acc: 0.560547]  [A loss: 0.787161, acc: 0.308594]\n",
            "5414: [D loss: 0.713259, acc: 0.517578]  [A loss: 0.912466, acc: 0.109375]\n",
            "5415: [D loss: 0.696546, acc: 0.513672]  [A loss: 0.763099, acc: 0.355469]\n",
            "5416: [D loss: 0.714568, acc: 0.480469]  [A loss: 0.962590, acc: 0.105469]\n",
            "5417: [D loss: 0.691307, acc: 0.544922]  [A loss: 0.789740, acc: 0.300781]\n",
            "5418: [D loss: 0.715434, acc: 0.527344]  [A loss: 0.890187, acc: 0.164062]\n",
            "5419: [D loss: 0.695134, acc: 0.539062]  [A loss: 0.762401, acc: 0.289062]\n",
            "5420: [D loss: 0.694095, acc: 0.560547]  [A loss: 0.814673, acc: 0.234375]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5421: [D loss: 0.707450, acc: 0.503906]  [A loss: 0.907852, acc: 0.105469]\n",
            "5422: [D loss: 0.697137, acc: 0.529297]  [A loss: 0.817386, acc: 0.250000]\n",
            "5423: [D loss: 0.695358, acc: 0.541016]  [A loss: 0.862475, acc: 0.210938]\n",
            "5424: [D loss: 0.697487, acc: 0.542969]  [A loss: 0.774224, acc: 0.347656]\n",
            "5425: [D loss: 0.695403, acc: 0.527344]  [A loss: 0.856661, acc: 0.207031]\n",
            "5426: [D loss: 0.690859, acc: 0.525391]  [A loss: 0.850844, acc: 0.218750]\n",
            "5427: [D loss: 0.702862, acc: 0.513672]  [A loss: 0.806443, acc: 0.304688]\n",
            "5428: [D loss: 0.706275, acc: 0.503906]  [A loss: 0.943352, acc: 0.121094]\n",
            "5429: [D loss: 0.699641, acc: 0.527344]  [A loss: 0.817777, acc: 0.285156]\n",
            "5430: [D loss: 0.703458, acc: 0.519531]  [A loss: 0.873229, acc: 0.156250]\n",
            "5431: [D loss: 0.704525, acc: 0.501953]  [A loss: 0.794592, acc: 0.296875]\n",
            "5432: [D loss: 0.714009, acc: 0.486328]  [A loss: 0.883343, acc: 0.175781]\n",
            "5433: [D loss: 0.695247, acc: 0.574219]  [A loss: 0.830331, acc: 0.230469]\n",
            "5434: [D loss: 0.697015, acc: 0.511719]  [A loss: 0.858590, acc: 0.222656]\n",
            "5435: [D loss: 0.710077, acc: 0.474609]  [A loss: 0.844066, acc: 0.222656]\n",
            "5436: [D loss: 0.699136, acc: 0.539062]  [A loss: 1.013893, acc: 0.074219]\n",
            "5437: [D loss: 0.712632, acc: 0.517578]  [A loss: 0.606861, acc: 0.707031]\n",
            "5438: [D loss: 0.737689, acc: 0.515625]  [A loss: 0.996766, acc: 0.082031]\n",
            "5439: [D loss: 0.706454, acc: 0.503906]  [A loss: 0.696972, acc: 0.546875]\n",
            "5440: [D loss: 0.716044, acc: 0.496094]  [A loss: 0.863240, acc: 0.164062]\n",
            "5441: [D loss: 0.690688, acc: 0.544922]  [A loss: 0.757525, acc: 0.351562]\n",
            "5442: [D loss: 0.701752, acc: 0.515625]  [A loss: 0.831320, acc: 0.230469]\n",
            "5443: [D loss: 0.700372, acc: 0.527344]  [A loss: 0.777857, acc: 0.332031]\n",
            "5444: [D loss: 0.700080, acc: 0.535156]  [A loss: 0.901187, acc: 0.183594]\n",
            "5445: [D loss: 0.685877, acc: 0.566406]  [A loss: 0.729721, acc: 0.433594]\n",
            "5446: [D loss: 0.694392, acc: 0.531250]  [A loss: 0.854434, acc: 0.234375]\n",
            "5447: [D loss: 0.697233, acc: 0.515625]  [A loss: 0.798860, acc: 0.320312]\n",
            "5448: [D loss: 0.710165, acc: 0.492188]  [A loss: 0.856144, acc: 0.171875]\n",
            "5449: [D loss: 0.701313, acc: 0.517578]  [A loss: 0.793160, acc: 0.289062]\n",
            "5450: [D loss: 0.706127, acc: 0.544922]  [A loss: 0.883847, acc: 0.187500]\n",
            "5451: [D loss: 0.693375, acc: 0.533203]  [A loss: 0.786446, acc: 0.328125]\n",
            "5452: [D loss: 0.693569, acc: 0.521484]  [A loss: 0.806967, acc: 0.238281]\n",
            "5453: [D loss: 0.700637, acc: 0.539062]  [A loss: 0.859385, acc: 0.187500]\n",
            "5454: [D loss: 0.699269, acc: 0.535156]  [A loss: 0.801870, acc: 0.289062]\n",
            "5455: [D loss: 0.715181, acc: 0.488281]  [A loss: 0.937967, acc: 0.121094]\n",
            "5456: [D loss: 0.695838, acc: 0.515625]  [A loss: 0.690303, acc: 0.527344]\n",
            "5457: [D loss: 0.718652, acc: 0.492188]  [A loss: 0.924574, acc: 0.101562]\n",
            "5458: [D loss: 0.702894, acc: 0.505859]  [A loss: 0.747366, acc: 0.445312]\n",
            "5459: [D loss: 0.709346, acc: 0.513672]  [A loss: 0.845999, acc: 0.226562]\n",
            "5460: [D loss: 0.691949, acc: 0.564453]  [A loss: 0.799848, acc: 0.300781]\n",
            "5461: [D loss: 0.694189, acc: 0.552734]  [A loss: 0.925023, acc: 0.128906]\n",
            "5462: [D loss: 0.700656, acc: 0.507812]  [A loss: 0.790050, acc: 0.300781]\n",
            "5463: [D loss: 0.703116, acc: 0.527344]  [A loss: 0.913524, acc: 0.140625]\n",
            "5464: [D loss: 0.719560, acc: 0.457031]  [A loss: 0.764938, acc: 0.339844]\n",
            "5465: [D loss: 0.710289, acc: 0.500000]  [A loss: 0.841193, acc: 0.230469]\n",
            "5466: [D loss: 0.696055, acc: 0.541016]  [A loss: 0.766367, acc: 0.359375]\n",
            "5467: [D loss: 0.710399, acc: 0.500000]  [A loss: 0.853286, acc: 0.222656]\n",
            "5468: [D loss: 0.704543, acc: 0.500000]  [A loss: 0.926437, acc: 0.144531]\n",
            "5469: [D loss: 0.699859, acc: 0.533203]  [A loss: 0.726509, acc: 0.437500]\n",
            "5470: [D loss: 0.710500, acc: 0.517578]  [A loss: 1.003441, acc: 0.093750]\n",
            "5471: [D loss: 0.707183, acc: 0.507812]  [A loss: 0.673422, acc: 0.601562]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5472: [D loss: 0.731696, acc: 0.513672]  [A loss: 0.948897, acc: 0.078125]\n",
            "5473: [D loss: 0.691085, acc: 0.548828]  [A loss: 0.677069, acc: 0.578125]\n",
            "5474: [D loss: 0.726337, acc: 0.492188]  [A loss: 0.946167, acc: 0.113281]\n",
            "5475: [D loss: 0.695925, acc: 0.546875]  [A loss: 0.793494, acc: 0.324219]\n",
            "5476: [D loss: 0.702902, acc: 0.507812]  [A loss: 0.965132, acc: 0.097656]\n",
            "5477: [D loss: 0.703789, acc: 0.494141]  [A loss: 0.692774, acc: 0.519531]\n",
            "5478: [D loss: 0.723757, acc: 0.500000]  [A loss: 0.899984, acc: 0.121094]\n",
            "5479: [D loss: 0.705104, acc: 0.476562]  [A loss: 0.742802, acc: 0.433594]\n",
            "5480: [D loss: 0.715238, acc: 0.521484]  [A loss: 0.938449, acc: 0.089844]\n",
            "5481: [D loss: 0.699839, acc: 0.517578]  [A loss: 0.706242, acc: 0.503906]\n",
            "5482: [D loss: 0.711350, acc: 0.517578]  [A loss: 0.989524, acc: 0.082031]\n",
            "5483: [D loss: 0.701423, acc: 0.505859]  [A loss: 0.688817, acc: 0.503906]\n",
            "5484: [D loss: 0.721956, acc: 0.498047]  [A loss: 0.867332, acc: 0.175781]\n",
            "5485: [D loss: 0.690019, acc: 0.525391]  [A loss: 0.738276, acc: 0.445312]\n",
            "5486: [D loss: 0.721058, acc: 0.507812]  [A loss: 0.850278, acc: 0.183594]\n",
            "5487: [D loss: 0.694175, acc: 0.519531]  [A loss: 0.772345, acc: 0.304688]\n",
            "5488: [D loss: 0.704735, acc: 0.527344]  [A loss: 0.859214, acc: 0.203125]\n",
            "5489: [D loss: 0.707582, acc: 0.511719]  [A loss: 0.788502, acc: 0.308594]\n",
            "5490: [D loss: 0.704583, acc: 0.509766]  [A loss: 0.867420, acc: 0.183594]\n",
            "5491: [D loss: 0.694223, acc: 0.539062]  [A loss: 0.806487, acc: 0.277344]\n",
            "5492: [D loss: 0.708994, acc: 0.503906]  [A loss: 0.855345, acc: 0.195312]\n",
            "5493: [D loss: 0.694536, acc: 0.519531]  [A loss: 0.817228, acc: 0.257812]\n",
            "5494: [D loss: 0.700414, acc: 0.544922]  [A loss: 0.936671, acc: 0.101562]\n",
            "5495: [D loss: 0.708173, acc: 0.509766]  [A loss: 0.764926, acc: 0.347656]\n",
            "5496: [D loss: 0.708886, acc: 0.517578]  [A loss: 0.882213, acc: 0.171875]\n",
            "5497: [D loss: 0.712796, acc: 0.488281]  [A loss: 0.766569, acc: 0.320312]\n",
            "5498: [D loss: 0.705099, acc: 0.505859]  [A loss: 0.948128, acc: 0.097656]\n",
            "5499: [D loss: 0.703526, acc: 0.541016]  [A loss: 0.784095, acc: 0.316406]\n",
            "5500: [D loss: 0.698163, acc: 0.527344]  [A loss: 0.886490, acc: 0.167969]\n",
            "5501: [D loss: 0.691592, acc: 0.562500]  [A loss: 0.700234, acc: 0.496094]\n",
            "5502: [D loss: 0.715888, acc: 0.490234]  [A loss: 0.946597, acc: 0.093750]\n",
            "5503: [D loss: 0.693363, acc: 0.535156]  [A loss: 0.688018, acc: 0.566406]\n",
            "5504: [D loss: 0.718450, acc: 0.525391]  [A loss: 0.937521, acc: 0.101562]\n",
            "5505: [D loss: 0.698526, acc: 0.515625]  [A loss: 0.729058, acc: 0.417969]\n",
            "5506: [D loss: 0.716510, acc: 0.480469]  [A loss: 0.820193, acc: 0.246094]\n",
            "5507: [D loss: 0.696066, acc: 0.517578]  [A loss: 0.745329, acc: 0.398438]\n",
            "5508: [D loss: 0.714276, acc: 0.527344]  [A loss: 0.863171, acc: 0.175781]\n",
            "5509: [D loss: 0.694393, acc: 0.523438]  [A loss: 0.813993, acc: 0.238281]\n",
            "5510: [D loss: 0.698189, acc: 0.537109]  [A loss: 0.823501, acc: 0.242188]\n",
            "5511: [D loss: 0.694510, acc: 0.535156]  [A loss: 0.803741, acc: 0.265625]\n",
            "5512: [D loss: 0.700267, acc: 0.523438]  [A loss: 0.871841, acc: 0.183594]\n",
            "5513: [D loss: 0.699735, acc: 0.548828]  [A loss: 0.749887, acc: 0.378906]\n",
            "5514: [D loss: 0.701638, acc: 0.500000]  [A loss: 0.865005, acc: 0.187500]\n",
            "5515: [D loss: 0.696092, acc: 0.523438]  [A loss: 0.819999, acc: 0.269531]\n",
            "5516: [D loss: 0.711186, acc: 0.509766]  [A loss: 0.890903, acc: 0.144531]\n",
            "5517: [D loss: 0.707874, acc: 0.531250]  [A loss: 0.810258, acc: 0.304688]\n",
            "5518: [D loss: 0.692389, acc: 0.535156]  [A loss: 0.783029, acc: 0.320312]\n",
            "5519: [D loss: 0.700782, acc: 0.529297]  [A loss: 0.839674, acc: 0.242188]\n",
            "5520: [D loss: 0.693207, acc: 0.548828]  [A loss: 0.835166, acc: 0.246094]\n",
            "5521: [D loss: 0.711655, acc: 0.492188]  [A loss: 0.811995, acc: 0.292969]\n",
            "5522: [D loss: 0.693644, acc: 0.533203]  [A loss: 0.843962, acc: 0.183594]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5523: [D loss: 0.698469, acc: 0.515625]  [A loss: 0.931246, acc: 0.121094]\n",
            "5524: [D loss: 0.697284, acc: 0.525391]  [A loss: 0.781117, acc: 0.347656]\n",
            "5525: [D loss: 0.708811, acc: 0.531250]  [A loss: 0.857172, acc: 0.191406]\n",
            "5526: [D loss: 0.690333, acc: 0.535156]  [A loss: 0.797387, acc: 0.277344]\n",
            "5527: [D loss: 0.705902, acc: 0.509766]  [A loss: 0.867933, acc: 0.191406]\n",
            "5528: [D loss: 0.705494, acc: 0.496094]  [A loss: 0.860228, acc: 0.179688]\n",
            "5529: [D loss: 0.694241, acc: 0.527344]  [A loss: 0.689091, acc: 0.527344]\n",
            "5530: [D loss: 0.729387, acc: 0.511719]  [A loss: 1.151419, acc: 0.015625]\n",
            "5531: [D loss: 0.727462, acc: 0.482422]  [A loss: 0.649109, acc: 0.632812]\n",
            "5532: [D loss: 0.730978, acc: 0.488281]  [A loss: 0.898265, acc: 0.187500]\n",
            "5533: [D loss: 0.691843, acc: 0.544922]  [A loss: 0.707309, acc: 0.503906]\n",
            "5534: [D loss: 0.716481, acc: 0.494141]  [A loss: 0.875063, acc: 0.171875]\n",
            "5535: [D loss: 0.701637, acc: 0.507812]  [A loss: 0.769392, acc: 0.355469]\n",
            "5536: [D loss: 0.708648, acc: 0.509766]  [A loss: 0.853000, acc: 0.183594]\n",
            "5537: [D loss: 0.695098, acc: 0.554688]  [A loss: 0.848218, acc: 0.195312]\n",
            "5538: [D loss: 0.716549, acc: 0.490234]  [A loss: 0.800993, acc: 0.328125]\n",
            "5539: [D loss: 0.701041, acc: 0.544922]  [A loss: 0.798151, acc: 0.308594]\n",
            "5540: [D loss: 0.695639, acc: 0.539062]  [A loss: 0.872518, acc: 0.160156]\n",
            "5541: [D loss: 0.703180, acc: 0.498047]  [A loss: 0.782646, acc: 0.328125]\n",
            "5542: [D loss: 0.712274, acc: 0.501953]  [A loss: 0.931585, acc: 0.113281]\n",
            "5543: [D loss: 0.688333, acc: 0.558594]  [A loss: 0.689668, acc: 0.500000]\n",
            "5544: [D loss: 0.730156, acc: 0.496094]  [A loss: 0.944591, acc: 0.097656]\n",
            "5545: [D loss: 0.699065, acc: 0.519531]  [A loss: 0.693532, acc: 0.507812]\n",
            "5546: [D loss: 0.724680, acc: 0.505859]  [A loss: 0.890395, acc: 0.171875]\n",
            "5547: [D loss: 0.692265, acc: 0.539062]  [A loss: 0.775049, acc: 0.355469]\n",
            "5548: [D loss: 0.703282, acc: 0.525391]  [A loss: 0.789439, acc: 0.292969]\n",
            "5549: [D loss: 0.717914, acc: 0.468750]  [A loss: 0.771306, acc: 0.324219]\n",
            "5550: [D loss: 0.691730, acc: 0.525391]  [A loss: 0.820521, acc: 0.281250]\n",
            "5551: [D loss: 0.706566, acc: 0.511719]  [A loss: 0.761178, acc: 0.316406]\n",
            "5552: [D loss: 0.700926, acc: 0.515625]  [A loss: 0.882515, acc: 0.171875]\n",
            "5553: [D loss: 0.705998, acc: 0.521484]  [A loss: 0.865613, acc: 0.164062]\n",
            "5554: [D loss: 0.693932, acc: 0.544922]  [A loss: 0.737773, acc: 0.414062]\n",
            "5555: [D loss: 0.717957, acc: 0.496094]  [A loss: 0.911995, acc: 0.117188]\n",
            "5556: [D loss: 0.701328, acc: 0.517578]  [A loss: 0.820975, acc: 0.261719]\n",
            "5557: [D loss: 0.696826, acc: 0.529297]  [A loss: 0.852961, acc: 0.195312]\n",
            "5558: [D loss: 0.709423, acc: 0.501953]  [A loss: 0.853539, acc: 0.214844]\n",
            "5559: [D loss: 0.708081, acc: 0.525391]  [A loss: 0.784627, acc: 0.332031]\n",
            "5560: [D loss: 0.699651, acc: 0.527344]  [A loss: 0.893718, acc: 0.132812]\n",
            "5561: [D loss: 0.700535, acc: 0.513672]  [A loss: 0.728592, acc: 0.421875]\n",
            "5562: [D loss: 0.695511, acc: 0.515625]  [A loss: 0.935791, acc: 0.093750]\n",
            "5563: [D loss: 0.705386, acc: 0.496094]  [A loss: 0.679778, acc: 0.523438]\n",
            "5564: [D loss: 0.721617, acc: 0.511719]  [A loss: 0.980340, acc: 0.074219]\n",
            "5565: [D loss: 0.702084, acc: 0.494141]  [A loss: 0.685918, acc: 0.527344]\n",
            "5566: [D loss: 0.716426, acc: 0.529297]  [A loss: 0.886009, acc: 0.128906]\n",
            "5567: [D loss: 0.694949, acc: 0.507812]  [A loss: 0.753137, acc: 0.367188]\n",
            "5568: [D loss: 0.710743, acc: 0.509766]  [A loss: 0.841550, acc: 0.238281]\n",
            "5569: [D loss: 0.694869, acc: 0.531250]  [A loss: 0.766925, acc: 0.339844]\n",
            "5570: [D loss: 0.704821, acc: 0.503906]  [A loss: 0.791306, acc: 0.269531]\n",
            "5571: [D loss: 0.695704, acc: 0.533203]  [A loss: 0.867645, acc: 0.144531]\n",
            "5572: [D loss: 0.697357, acc: 0.535156]  [A loss: 0.736821, acc: 0.421875]\n",
            "5573: [D loss: 0.708117, acc: 0.535156]  [A loss: 0.976614, acc: 0.074219]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5574: [D loss: 0.690005, acc: 0.535156]  [A loss: 0.688889, acc: 0.554688]\n",
            "5575: [D loss: 0.719807, acc: 0.523438]  [A loss: 0.985255, acc: 0.070312]\n",
            "5576: [D loss: 0.713650, acc: 0.513672]  [A loss: 0.712879, acc: 0.488281]\n",
            "5577: [D loss: 0.713682, acc: 0.503906]  [A loss: 0.814401, acc: 0.234375]\n",
            "5578: [D loss: 0.710974, acc: 0.476562]  [A loss: 0.809125, acc: 0.292969]\n",
            "5579: [D loss: 0.696081, acc: 0.527344]  [A loss: 0.816497, acc: 0.285156]\n",
            "5580: [D loss: 0.689407, acc: 0.542969]  [A loss: 0.869452, acc: 0.230469]\n",
            "5581: [D loss: 0.696397, acc: 0.509766]  [A loss: 0.762225, acc: 0.328125]\n",
            "5582: [D loss: 0.701323, acc: 0.517578]  [A loss: 0.850110, acc: 0.218750]\n",
            "5583: [D loss: 0.700710, acc: 0.515625]  [A loss: 0.754883, acc: 0.394531]\n",
            "5584: [D loss: 0.704529, acc: 0.535156]  [A loss: 0.870053, acc: 0.156250]\n",
            "5585: [D loss: 0.693880, acc: 0.498047]  [A loss: 0.800688, acc: 0.269531]\n",
            "5586: [D loss: 0.703338, acc: 0.500000]  [A loss: 0.848355, acc: 0.207031]\n",
            "5587: [D loss: 0.702629, acc: 0.519531]  [A loss: 0.731382, acc: 0.441406]\n",
            "5588: [D loss: 0.700065, acc: 0.511719]  [A loss: 0.919307, acc: 0.160156]\n",
            "5589: [D loss: 0.708793, acc: 0.515625]  [A loss: 0.780915, acc: 0.332031]\n",
            "5590: [D loss: 0.705512, acc: 0.517578]  [A loss: 0.832196, acc: 0.222656]\n",
            "5591: [D loss: 0.687901, acc: 0.542969]  [A loss: 0.785315, acc: 0.304688]\n",
            "5592: [D loss: 0.699108, acc: 0.525391]  [A loss: 0.835442, acc: 0.214844]\n",
            "5593: [D loss: 0.698698, acc: 0.501953]  [A loss: 0.829851, acc: 0.207031]\n",
            "5594: [D loss: 0.712171, acc: 0.500000]  [A loss: 0.777078, acc: 0.339844]\n",
            "5595: [D loss: 0.712179, acc: 0.500000]  [A loss: 0.946070, acc: 0.101562]\n",
            "5596: [D loss: 0.693164, acc: 0.533203]  [A loss: 0.767700, acc: 0.378906]\n",
            "5597: [D loss: 0.717521, acc: 0.529297]  [A loss: 0.941527, acc: 0.097656]\n",
            "5598: [D loss: 0.692723, acc: 0.556641]  [A loss: 0.812789, acc: 0.238281]\n",
            "5599: [D loss: 0.703483, acc: 0.529297]  [A loss: 0.885442, acc: 0.132812]\n",
            "5600: [D loss: 0.707521, acc: 0.505859]  [A loss: 0.754389, acc: 0.355469]\n",
            "5601: [D loss: 0.706315, acc: 0.537109]  [A loss: 0.895505, acc: 0.152344]\n",
            "5602: [D loss: 0.692462, acc: 0.521484]  [A loss: 0.801873, acc: 0.277344]\n",
            "5603: [D loss: 0.721068, acc: 0.501953]  [A loss: 0.917850, acc: 0.097656]\n",
            "5604: [D loss: 0.695454, acc: 0.529297]  [A loss: 0.783414, acc: 0.320312]\n",
            "5605: [D loss: 0.706295, acc: 0.496094]  [A loss: 0.896414, acc: 0.179688]\n",
            "5606: [D loss: 0.687241, acc: 0.519531]  [A loss: 0.729759, acc: 0.417969]\n",
            "5607: [D loss: 0.716629, acc: 0.509766]  [A loss: 0.961872, acc: 0.074219]\n",
            "5608: [D loss: 0.702867, acc: 0.525391]  [A loss: 0.662143, acc: 0.582031]\n",
            "5609: [D loss: 0.707500, acc: 0.546875]  [A loss: 0.927914, acc: 0.144531]\n",
            "5610: [D loss: 0.707260, acc: 0.531250]  [A loss: 0.757253, acc: 0.367188]\n",
            "5611: [D loss: 0.702655, acc: 0.515625]  [A loss: 0.857651, acc: 0.210938]\n",
            "5612: [D loss: 0.704824, acc: 0.517578]  [A loss: 0.755683, acc: 0.437500]\n",
            "5613: [D loss: 0.727722, acc: 0.492188]  [A loss: 0.935266, acc: 0.105469]\n",
            "5614: [D loss: 0.691687, acc: 0.556641]  [A loss: 0.684522, acc: 0.570312]\n",
            "5615: [D loss: 0.716878, acc: 0.537109]  [A loss: 0.954175, acc: 0.121094]\n",
            "5616: [D loss: 0.701529, acc: 0.552734]  [A loss: 0.727780, acc: 0.464844]\n",
            "5617: [D loss: 0.713097, acc: 0.515625]  [A loss: 0.867085, acc: 0.187500]\n",
            "5618: [D loss: 0.706510, acc: 0.505859]  [A loss: 0.792429, acc: 0.312500]\n",
            "5619: [D loss: 0.693540, acc: 0.550781]  [A loss: 0.797750, acc: 0.296875]\n",
            "5620: [D loss: 0.692335, acc: 0.535156]  [A loss: 0.821455, acc: 0.261719]\n",
            "5621: [D loss: 0.691788, acc: 0.507812]  [A loss: 0.766617, acc: 0.332031]\n",
            "5622: [D loss: 0.696461, acc: 0.529297]  [A loss: 0.842489, acc: 0.195312]\n",
            "5623: [D loss: 0.707448, acc: 0.511719]  [A loss: 0.889078, acc: 0.160156]\n",
            "5624: [D loss: 0.698705, acc: 0.533203]  [A loss: 0.790683, acc: 0.335938]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5625: [D loss: 0.703568, acc: 0.505859]  [A loss: 0.948173, acc: 0.082031]\n",
            "5626: [D loss: 0.703471, acc: 0.498047]  [A loss: 0.730650, acc: 0.417969]\n",
            "5627: [D loss: 0.719956, acc: 0.501953]  [A loss: 0.916437, acc: 0.195312]\n",
            "5628: [D loss: 0.711249, acc: 0.509766]  [A loss: 0.835468, acc: 0.207031]\n",
            "5629: [D loss: 0.700155, acc: 0.525391]  [A loss: 0.864085, acc: 0.183594]\n",
            "5630: [D loss: 0.691843, acc: 0.546875]  [A loss: 0.764837, acc: 0.339844]\n",
            "5631: [D loss: 0.710442, acc: 0.519531]  [A loss: 0.933664, acc: 0.105469]\n",
            "5632: [D loss: 0.688718, acc: 0.523438]  [A loss: 0.712606, acc: 0.468750]\n",
            "5633: [D loss: 0.709744, acc: 0.523438]  [A loss: 0.984203, acc: 0.085938]\n",
            "5634: [D loss: 0.703716, acc: 0.490234]  [A loss: 0.668848, acc: 0.554688]\n",
            "5635: [D loss: 0.731744, acc: 0.525391]  [A loss: 0.988630, acc: 0.058594]\n",
            "5636: [D loss: 0.714792, acc: 0.523438]  [A loss: 0.659424, acc: 0.605469]\n",
            "5637: [D loss: 0.729190, acc: 0.494141]  [A loss: 0.959905, acc: 0.054688]\n",
            "5638: [D loss: 0.695086, acc: 0.546875]  [A loss: 0.754690, acc: 0.378906]\n",
            "5639: [D loss: 0.702491, acc: 0.527344]  [A loss: 0.814304, acc: 0.214844]\n",
            "5640: [D loss: 0.700754, acc: 0.505859]  [A loss: 0.757859, acc: 0.398438]\n",
            "5641: [D loss: 0.697259, acc: 0.537109]  [A loss: 0.832697, acc: 0.195312]\n",
            "5642: [D loss: 0.695196, acc: 0.523438]  [A loss: 0.802759, acc: 0.335938]\n",
            "5643: [D loss: 0.694805, acc: 0.542969]  [A loss: 0.775787, acc: 0.316406]\n",
            "5644: [D loss: 0.701385, acc: 0.533203]  [A loss: 0.847430, acc: 0.242188]\n",
            "5645: [D loss: 0.698691, acc: 0.527344]  [A loss: 0.758082, acc: 0.390625]\n",
            "5646: [D loss: 0.708174, acc: 0.517578]  [A loss: 0.845869, acc: 0.222656]\n",
            "5647: [D loss: 0.694138, acc: 0.509766]  [A loss: 0.824847, acc: 0.281250]\n",
            "5648: [D loss: 0.695987, acc: 0.535156]  [A loss: 0.756903, acc: 0.359375]\n",
            "5649: [D loss: 0.704289, acc: 0.527344]  [A loss: 0.954529, acc: 0.082031]\n",
            "5650: [D loss: 0.692096, acc: 0.533203]  [A loss: 0.699926, acc: 0.484375]\n",
            "5651: [D loss: 0.702719, acc: 0.507812]  [A loss: 0.835442, acc: 0.246094]\n",
            "5652: [D loss: 0.706239, acc: 0.513672]  [A loss: 0.749786, acc: 0.406250]\n",
            "5653: [D loss: 0.707707, acc: 0.488281]  [A loss: 0.832447, acc: 0.214844]\n",
            "5654: [D loss: 0.701637, acc: 0.507812]  [A loss: 0.740695, acc: 0.445312]\n",
            "5655: [D loss: 0.708397, acc: 0.507812]  [A loss: 0.912256, acc: 0.167969]\n",
            "5656: [D loss: 0.699816, acc: 0.529297]  [A loss: 0.705750, acc: 0.539062]\n",
            "5657: [D loss: 0.730602, acc: 0.500000]  [A loss: 0.915995, acc: 0.113281]\n",
            "5658: [D loss: 0.696431, acc: 0.548828]  [A loss: 0.778804, acc: 0.312500]\n",
            "5659: [D loss: 0.713952, acc: 0.498047]  [A loss: 0.943221, acc: 0.101562]\n",
            "5660: [D loss: 0.711480, acc: 0.494141]  [A loss: 0.793921, acc: 0.312500]\n",
            "5661: [D loss: 0.688863, acc: 0.562500]  [A loss: 0.809627, acc: 0.296875]\n",
            "5662: [D loss: 0.707723, acc: 0.507812]  [A loss: 0.813960, acc: 0.257812]\n",
            "5663: [D loss: 0.693688, acc: 0.527344]  [A loss: 0.810340, acc: 0.253906]\n",
            "5664: [D loss: 0.701714, acc: 0.521484]  [A loss: 0.830930, acc: 0.238281]\n",
            "5665: [D loss: 0.700558, acc: 0.507812]  [A loss: 0.842844, acc: 0.187500]\n",
            "5666: [D loss: 0.699388, acc: 0.517578]  [A loss: 0.841573, acc: 0.195312]\n",
            "5667: [D loss: 0.685873, acc: 0.533203]  [A loss: 0.829525, acc: 0.234375]\n",
            "5668: [D loss: 0.710401, acc: 0.521484]  [A loss: 0.910924, acc: 0.109375]\n",
            "5669: [D loss: 0.694739, acc: 0.544922]  [A loss: 0.748299, acc: 0.425781]\n",
            "5670: [D loss: 0.702445, acc: 0.513672]  [A loss: 0.898653, acc: 0.191406]\n",
            "5671: [D loss: 0.704641, acc: 0.527344]  [A loss: 0.755664, acc: 0.351562]\n",
            "5672: [D loss: 0.710340, acc: 0.496094]  [A loss: 0.885649, acc: 0.191406]\n",
            "5673: [D loss: 0.706720, acc: 0.517578]  [A loss: 0.801469, acc: 0.339844]\n",
            "5674: [D loss: 0.719852, acc: 0.494141]  [A loss: 0.898824, acc: 0.160156]\n",
            "5675: [D loss: 0.696126, acc: 0.517578]  [A loss: 0.702179, acc: 0.492188]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5676: [D loss: 0.725694, acc: 0.500000]  [A loss: 0.979940, acc: 0.089844]\n",
            "5677: [D loss: 0.702824, acc: 0.523438]  [A loss: 0.702798, acc: 0.519531]\n",
            "5678: [D loss: 0.723887, acc: 0.521484]  [A loss: 0.838596, acc: 0.238281]\n",
            "5679: [D loss: 0.699618, acc: 0.525391]  [A loss: 0.702709, acc: 0.558594]\n",
            "5680: [D loss: 0.718429, acc: 0.505859]  [A loss: 0.990718, acc: 0.039062]\n",
            "5681: [D loss: 0.700362, acc: 0.527344]  [A loss: 0.668527, acc: 0.589844]\n",
            "5682: [D loss: 0.730002, acc: 0.498047]  [A loss: 0.927175, acc: 0.128906]\n",
            "5683: [D loss: 0.695156, acc: 0.542969]  [A loss: 0.719853, acc: 0.480469]\n",
            "5684: [D loss: 0.705821, acc: 0.533203]  [A loss: 0.865964, acc: 0.164062]\n",
            "5685: [D loss: 0.711176, acc: 0.484375]  [A loss: 0.772836, acc: 0.351562]\n",
            "5686: [D loss: 0.706391, acc: 0.515625]  [A loss: 0.832181, acc: 0.253906]\n",
            "5687: [D loss: 0.699965, acc: 0.519531]  [A loss: 0.764838, acc: 0.375000]\n",
            "5688: [D loss: 0.699204, acc: 0.500000]  [A loss: 0.836507, acc: 0.261719]\n",
            "5689: [D loss: 0.709432, acc: 0.498047]  [A loss: 0.859065, acc: 0.175781]\n",
            "5690: [D loss: 0.711169, acc: 0.500000]  [A loss: 0.842755, acc: 0.242188]\n",
            "5691: [D loss: 0.698669, acc: 0.533203]  [A loss: 0.839426, acc: 0.242188]\n",
            "5692: [D loss: 0.715094, acc: 0.490234]  [A loss: 0.877156, acc: 0.214844]\n",
            "5693: [D loss: 0.687110, acc: 0.507812]  [A loss: 0.810771, acc: 0.289062]\n",
            "5694: [D loss: 0.714521, acc: 0.501953]  [A loss: 0.892356, acc: 0.160156]\n",
            "5695: [D loss: 0.695713, acc: 0.531250]  [A loss: 0.795163, acc: 0.289062]\n",
            "5696: [D loss: 0.707329, acc: 0.521484]  [A loss: 0.875671, acc: 0.167969]\n",
            "5697: [D loss: 0.696208, acc: 0.531250]  [A loss: 0.841431, acc: 0.187500]\n",
            "5698: [D loss: 0.700082, acc: 0.527344]  [A loss: 0.829066, acc: 0.246094]\n",
            "5699: [D loss: 0.697354, acc: 0.517578]  [A loss: 0.788456, acc: 0.335938]\n",
            "5700: [D loss: 0.691926, acc: 0.554688]  [A loss: 0.839785, acc: 0.214844]\n",
            "5701: [D loss: 0.701039, acc: 0.527344]  [A loss: 0.852055, acc: 0.222656]\n",
            "5702: [D loss: 0.694754, acc: 0.554688]  [A loss: 0.841144, acc: 0.214844]\n",
            "5703: [D loss: 0.707519, acc: 0.500000]  [A loss: 0.859420, acc: 0.210938]\n",
            "5704: [D loss: 0.706846, acc: 0.505859]  [A loss: 0.802157, acc: 0.296875]\n",
            "5705: [D loss: 0.701253, acc: 0.523438]  [A loss: 0.925579, acc: 0.105469]\n",
            "5706: [D loss: 0.702444, acc: 0.509766]  [A loss: 0.676489, acc: 0.574219]\n",
            "5707: [D loss: 0.717280, acc: 0.531250]  [A loss: 1.038302, acc: 0.070312]\n",
            "5708: [D loss: 0.718564, acc: 0.476562]  [A loss: 0.616863, acc: 0.695312]\n",
            "5709: [D loss: 0.735946, acc: 0.513672]  [A loss: 0.974555, acc: 0.074219]\n",
            "5710: [D loss: 0.703078, acc: 0.523438]  [A loss: 0.670307, acc: 0.585938]\n",
            "5711: [D loss: 0.728424, acc: 0.498047]  [A loss: 0.964279, acc: 0.082031]\n",
            "5712: [D loss: 0.709764, acc: 0.498047]  [A loss: 0.704357, acc: 0.480469]\n",
            "5713: [D loss: 0.723612, acc: 0.496094]  [A loss: 0.886572, acc: 0.132812]\n",
            "5714: [D loss: 0.696863, acc: 0.535156]  [A loss: 0.736106, acc: 0.414062]\n",
            "5715: [D loss: 0.701345, acc: 0.542969]  [A loss: 0.857706, acc: 0.214844]\n",
            "5716: [D loss: 0.693459, acc: 0.529297]  [A loss: 0.775937, acc: 0.351562]\n",
            "5717: [D loss: 0.714187, acc: 0.521484]  [A loss: 0.871429, acc: 0.175781]\n",
            "5718: [D loss: 0.684535, acc: 0.566406]  [A loss: 0.754799, acc: 0.406250]\n",
            "5719: [D loss: 0.709801, acc: 0.515625]  [A loss: 0.859034, acc: 0.171875]\n",
            "5720: [D loss: 0.693817, acc: 0.529297]  [A loss: 0.828544, acc: 0.261719]\n",
            "5721: [D loss: 0.709230, acc: 0.511719]  [A loss: 0.817042, acc: 0.250000]\n",
            "5722: [D loss: 0.709004, acc: 0.480469]  [A loss: 0.854447, acc: 0.230469]\n",
            "5723: [D loss: 0.695268, acc: 0.558594]  [A loss: 0.792766, acc: 0.296875]\n",
            "5724: [D loss: 0.695128, acc: 0.533203]  [A loss: 0.901052, acc: 0.136719]\n",
            "5725: [D loss: 0.699185, acc: 0.507812]  [A loss: 0.733515, acc: 0.457031]\n",
            "5726: [D loss: 0.715127, acc: 0.496094]  [A loss: 1.069917, acc: 0.035156]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5727: [D loss: 0.699326, acc: 0.541016]  [A loss: 0.620284, acc: 0.679688]\n",
            "5728: [D loss: 0.733689, acc: 0.482422]  [A loss: 0.945275, acc: 0.082031]\n",
            "5729: [D loss: 0.694719, acc: 0.525391]  [A loss: 0.757834, acc: 0.382812]\n",
            "5730: [D loss: 0.712185, acc: 0.501953]  [A loss: 0.857001, acc: 0.195312]\n",
            "5731: [D loss: 0.704755, acc: 0.484375]  [A loss: 0.739845, acc: 0.425781]\n",
            "5732: [D loss: 0.712152, acc: 0.513672]  [A loss: 0.863389, acc: 0.187500]\n",
            "5733: [D loss: 0.695246, acc: 0.523438]  [A loss: 0.780170, acc: 0.308594]\n",
            "5734: [D loss: 0.697322, acc: 0.533203]  [A loss: 0.957457, acc: 0.109375]\n",
            "5735: [D loss: 0.705474, acc: 0.507812]  [A loss: 0.755292, acc: 0.363281]\n",
            "5736: [D loss: 0.699994, acc: 0.541016]  [A loss: 0.865251, acc: 0.199219]\n",
            "5737: [D loss: 0.705670, acc: 0.507812]  [A loss: 0.815306, acc: 0.222656]\n",
            "5738: [D loss: 0.706283, acc: 0.511719]  [A loss: 0.928579, acc: 0.136719]\n",
            "5739: [D loss: 0.693845, acc: 0.541016]  [A loss: 0.774642, acc: 0.359375]\n",
            "5740: [D loss: 0.705127, acc: 0.513672]  [A loss: 0.959013, acc: 0.109375]\n",
            "5741: [D loss: 0.711553, acc: 0.492188]  [A loss: 0.744476, acc: 0.394531]\n",
            "5742: [D loss: 0.710384, acc: 0.535156]  [A loss: 0.906751, acc: 0.128906]\n",
            "5743: [D loss: 0.700133, acc: 0.523438]  [A loss: 0.729015, acc: 0.414062]\n",
            "5744: [D loss: 0.713183, acc: 0.511719]  [A loss: 0.945673, acc: 0.109375]\n",
            "5745: [D loss: 0.693773, acc: 0.539062]  [A loss: 0.673579, acc: 0.601562]\n",
            "5746: [D loss: 0.713251, acc: 0.501953]  [A loss: 0.926344, acc: 0.113281]\n",
            "5747: [D loss: 0.705201, acc: 0.501953]  [A loss: 0.680314, acc: 0.558594]\n",
            "5748: [D loss: 0.727567, acc: 0.515625]  [A loss: 0.913849, acc: 0.152344]\n",
            "5749: [D loss: 0.706063, acc: 0.515625]  [A loss: 0.709293, acc: 0.468750]\n",
            "5750: [D loss: 0.729854, acc: 0.496094]  [A loss: 0.845133, acc: 0.230469]\n",
            "5751: [D loss: 0.716410, acc: 0.507812]  [A loss: 0.744639, acc: 0.402344]\n",
            "5752: [D loss: 0.709770, acc: 0.517578]  [A loss: 0.899088, acc: 0.132812]\n",
            "5753: [D loss: 0.689270, acc: 0.531250]  [A loss: 0.746353, acc: 0.406250]\n",
            "5754: [D loss: 0.714717, acc: 0.519531]  [A loss: 0.916226, acc: 0.121094]\n",
            "5755: [D loss: 0.706387, acc: 0.509766]  [A loss: 0.761797, acc: 0.394531]\n",
            "5756: [D loss: 0.710996, acc: 0.500000]  [A loss: 0.861740, acc: 0.179688]\n",
            "5757: [D loss: 0.695218, acc: 0.544922]  [A loss: 0.808753, acc: 0.265625]\n",
            "5758: [D loss: 0.695492, acc: 0.544922]  [A loss: 0.828158, acc: 0.265625]\n",
            "5759: [D loss: 0.699793, acc: 0.507812]  [A loss: 0.834330, acc: 0.250000]\n",
            "5760: [D loss: 0.707059, acc: 0.521484]  [A loss: 0.836142, acc: 0.234375]\n",
            "5761: [D loss: 0.692274, acc: 0.544922]  [A loss: 0.813649, acc: 0.300781]\n",
            "5762: [D loss: 0.697590, acc: 0.519531]  [A loss: 0.852042, acc: 0.191406]\n",
            "5763: [D loss: 0.695765, acc: 0.515625]  [A loss: 0.797273, acc: 0.257812]\n",
            "5764: [D loss: 0.707990, acc: 0.521484]  [A loss: 0.919622, acc: 0.128906]\n",
            "5765: [D loss: 0.704134, acc: 0.492188]  [A loss: 0.688708, acc: 0.496094]\n",
            "5766: [D loss: 0.708728, acc: 0.503906]  [A loss: 0.950983, acc: 0.152344]\n",
            "5767: [D loss: 0.705963, acc: 0.507812]  [A loss: 0.686553, acc: 0.554688]\n",
            "5768: [D loss: 0.729579, acc: 0.492188]  [A loss: 0.928870, acc: 0.144531]\n",
            "5769: [D loss: 0.698242, acc: 0.490234]  [A loss: 0.770622, acc: 0.324219]\n",
            "5770: [D loss: 0.725180, acc: 0.505859]  [A loss: 0.902805, acc: 0.105469]\n",
            "5771: [D loss: 0.703556, acc: 0.521484]  [A loss: 0.829529, acc: 0.214844]\n",
            "5772: [D loss: 0.705826, acc: 0.492188]  [A loss: 0.845008, acc: 0.191406]\n",
            "5773: [D loss: 0.715152, acc: 0.482422]  [A loss: 0.846697, acc: 0.195312]\n",
            "5774: [D loss: 0.691009, acc: 0.550781]  [A loss: 0.857581, acc: 0.183594]\n",
            "5775: [D loss: 0.697585, acc: 0.519531]  [A loss: 0.781401, acc: 0.339844]\n",
            "5776: [D loss: 0.718832, acc: 0.476562]  [A loss: 0.862609, acc: 0.183594]\n",
            "5777: [D loss: 0.701866, acc: 0.519531]  [A loss: 0.800513, acc: 0.269531]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5778: [D loss: 0.698358, acc: 0.542969]  [A loss: 0.882603, acc: 0.148438]\n",
            "5779: [D loss: 0.708774, acc: 0.458984]  [A loss: 0.756914, acc: 0.382812]\n",
            "5780: [D loss: 0.714438, acc: 0.498047]  [A loss: 0.933960, acc: 0.105469]\n",
            "5781: [D loss: 0.697553, acc: 0.542969]  [A loss: 0.680845, acc: 0.574219]\n",
            "5782: [D loss: 0.718562, acc: 0.517578]  [A loss: 1.023415, acc: 0.054688]\n",
            "5783: [D loss: 0.691881, acc: 0.529297]  [A loss: 0.633614, acc: 0.675781]\n",
            "5784: [D loss: 0.734096, acc: 0.501953]  [A loss: 0.979282, acc: 0.058594]\n",
            "5785: [D loss: 0.709435, acc: 0.509766]  [A loss: 0.712730, acc: 0.492188]\n",
            "5786: [D loss: 0.712214, acc: 0.515625]  [A loss: 0.892005, acc: 0.132812]\n",
            "5787: [D loss: 0.688302, acc: 0.531250]  [A loss: 0.765676, acc: 0.343750]\n",
            "5788: [D loss: 0.696374, acc: 0.537109]  [A loss: 0.829270, acc: 0.257812]\n",
            "5789: [D loss: 0.689359, acc: 0.576172]  [A loss: 0.797163, acc: 0.320312]\n",
            "5790: [D loss: 0.706475, acc: 0.515625]  [A loss: 0.864553, acc: 0.210938]\n",
            "5791: [D loss: 0.690170, acc: 0.546875]  [A loss: 0.782956, acc: 0.304688]\n",
            "5792: [D loss: 0.693929, acc: 0.548828]  [A loss: 0.868469, acc: 0.207031]\n",
            "5793: [D loss: 0.702985, acc: 0.494141]  [A loss: 0.814366, acc: 0.277344]\n",
            "5794: [D loss: 0.701749, acc: 0.527344]  [A loss: 0.807147, acc: 0.320312]\n",
            "5795: [D loss: 0.715038, acc: 0.496094]  [A loss: 0.830042, acc: 0.250000]\n",
            "5796: [D loss: 0.695212, acc: 0.535156]  [A loss: 0.876190, acc: 0.187500]\n",
            "5797: [D loss: 0.704697, acc: 0.496094]  [A loss: 0.813312, acc: 0.289062]\n",
            "5798: [D loss: 0.699814, acc: 0.533203]  [A loss: 0.922273, acc: 0.132812]\n",
            "5799: [D loss: 0.708962, acc: 0.486328]  [A loss: 0.769621, acc: 0.332031]\n",
            "5800: [D loss: 0.727716, acc: 0.488281]  [A loss: 0.985935, acc: 0.093750]\n",
            "5801: [D loss: 0.689094, acc: 0.531250]  [A loss: 0.662236, acc: 0.597656]\n",
            "5802: [D loss: 0.718839, acc: 0.517578]  [A loss: 0.961682, acc: 0.117188]\n",
            "5803: [D loss: 0.698954, acc: 0.527344]  [A loss: 0.656730, acc: 0.613281]\n",
            "5804: [D loss: 0.733224, acc: 0.507812]  [A loss: 0.933379, acc: 0.128906]\n",
            "5805: [D loss: 0.707179, acc: 0.490234]  [A loss: 0.780118, acc: 0.343750]\n",
            "5806: [D loss: 0.703930, acc: 0.554688]  [A loss: 0.895026, acc: 0.132812]\n",
            "5807: [D loss: 0.697300, acc: 0.542969]  [A loss: 0.771506, acc: 0.355469]\n",
            "5808: [D loss: 0.717078, acc: 0.519531]  [A loss: 0.866353, acc: 0.234375]\n",
            "5809: [D loss: 0.702822, acc: 0.509766]  [A loss: 0.746146, acc: 0.425781]\n",
            "5810: [D loss: 0.702307, acc: 0.544922]  [A loss: 0.859066, acc: 0.179688]\n",
            "5811: [D loss: 0.694441, acc: 0.548828]  [A loss: 0.741217, acc: 0.421875]\n",
            "5812: [D loss: 0.702215, acc: 0.503906]  [A loss: 0.880331, acc: 0.183594]\n",
            "5813: [D loss: 0.696348, acc: 0.505859]  [A loss: 0.687427, acc: 0.554688]\n",
            "5814: [D loss: 0.716738, acc: 0.544922]  [A loss: 0.953946, acc: 0.085938]\n",
            "5815: [D loss: 0.694631, acc: 0.517578]  [A loss: 0.725432, acc: 0.445312]\n",
            "5816: [D loss: 0.718981, acc: 0.498047]  [A loss: 0.922826, acc: 0.152344]\n",
            "5817: [D loss: 0.694990, acc: 0.531250]  [A loss: 0.710825, acc: 0.468750]\n",
            "5818: [D loss: 0.712307, acc: 0.498047]  [A loss: 0.928061, acc: 0.128906]\n",
            "5819: [D loss: 0.705013, acc: 0.494141]  [A loss: 0.742449, acc: 0.406250]\n",
            "5820: [D loss: 0.709503, acc: 0.505859]  [A loss: 0.864178, acc: 0.156250]\n",
            "5821: [D loss: 0.697805, acc: 0.515625]  [A loss: 0.755176, acc: 0.394531]\n",
            "5822: [D loss: 0.719041, acc: 0.496094]  [A loss: 0.916601, acc: 0.156250]\n",
            "5823: [D loss: 0.703063, acc: 0.503906]  [A loss: 0.711321, acc: 0.480469]\n",
            "5824: [D loss: 0.719949, acc: 0.511719]  [A loss: 0.949562, acc: 0.101562]\n",
            "5825: [D loss: 0.706975, acc: 0.496094]  [A loss: 0.679442, acc: 0.550781]\n",
            "5826: [D loss: 0.706000, acc: 0.517578]  [A loss: 0.907895, acc: 0.167969]\n",
            "5827: [D loss: 0.707685, acc: 0.521484]  [A loss: 0.734861, acc: 0.433594]\n",
            "5828: [D loss: 0.726181, acc: 0.474609]  [A loss: 0.935201, acc: 0.109375]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5829: [D loss: 0.692015, acc: 0.533203]  [A loss: 0.695883, acc: 0.515625]\n",
            "5830: [D loss: 0.712116, acc: 0.511719]  [A loss: 0.924991, acc: 0.121094]\n",
            "5831: [D loss: 0.705100, acc: 0.511719]  [A loss: 0.752003, acc: 0.382812]\n",
            "5832: [D loss: 0.717438, acc: 0.523438]  [A loss: 0.971044, acc: 0.082031]\n",
            "5833: [D loss: 0.702889, acc: 0.492188]  [A loss: 0.743769, acc: 0.433594]\n",
            "5834: [D loss: 0.721328, acc: 0.505859]  [A loss: 1.002456, acc: 0.070312]\n",
            "5835: [D loss: 0.711603, acc: 0.507812]  [A loss: 0.699764, acc: 0.539062]\n",
            "5836: [D loss: 0.708822, acc: 0.515625]  [A loss: 0.902734, acc: 0.160156]\n",
            "5837: [D loss: 0.706989, acc: 0.513672]  [A loss: 0.727200, acc: 0.464844]\n",
            "5838: [D loss: 0.711491, acc: 0.505859]  [A loss: 0.969897, acc: 0.097656]\n",
            "5839: [D loss: 0.698784, acc: 0.513672]  [A loss: 0.742608, acc: 0.398438]\n",
            "5840: [D loss: 0.721103, acc: 0.500000]  [A loss: 0.869913, acc: 0.187500]\n",
            "5841: [D loss: 0.703259, acc: 0.519531]  [A loss: 0.800976, acc: 0.304688]\n",
            "5842: [D loss: 0.718106, acc: 0.474609]  [A loss: 0.855189, acc: 0.195312]\n",
            "5843: [D loss: 0.715190, acc: 0.464844]  [A loss: 0.804913, acc: 0.246094]\n",
            "5844: [D loss: 0.702112, acc: 0.505859]  [A loss: 0.820035, acc: 0.281250]\n",
            "5845: [D loss: 0.704883, acc: 0.519531]  [A loss: 0.861428, acc: 0.171875]\n",
            "5846: [D loss: 0.706410, acc: 0.501953]  [A loss: 0.823256, acc: 0.265625]\n",
            "5847: [D loss: 0.698800, acc: 0.515625]  [A loss: 0.824773, acc: 0.246094]\n",
            "5848: [D loss: 0.690337, acc: 0.544922]  [A loss: 0.760514, acc: 0.371094]\n",
            "5849: [D loss: 0.703704, acc: 0.519531]  [A loss: 0.930726, acc: 0.097656]\n",
            "5850: [D loss: 0.693107, acc: 0.541016]  [A loss: 0.699503, acc: 0.511719]\n",
            "5851: [D loss: 0.735937, acc: 0.498047]  [A loss: 0.976158, acc: 0.101562]\n",
            "5852: [D loss: 0.703418, acc: 0.501953]  [A loss: 0.754269, acc: 0.386719]\n",
            "5853: [D loss: 0.705597, acc: 0.527344]  [A loss: 0.835643, acc: 0.234375]\n",
            "5854: [D loss: 0.697560, acc: 0.531250]  [A loss: 0.764575, acc: 0.382812]\n",
            "5855: [D loss: 0.692389, acc: 0.539062]  [A loss: 0.849011, acc: 0.207031]\n",
            "5856: [D loss: 0.707911, acc: 0.474609]  [A loss: 0.740121, acc: 0.421875]\n",
            "5857: [D loss: 0.710168, acc: 0.498047]  [A loss: 0.877804, acc: 0.136719]\n",
            "5858: [D loss: 0.704887, acc: 0.505859]  [A loss: 0.753023, acc: 0.390625]\n",
            "5859: [D loss: 0.707000, acc: 0.515625]  [A loss: 0.943793, acc: 0.074219]\n",
            "5860: [D loss: 0.683829, acc: 0.562500]  [A loss: 0.676718, acc: 0.601562]\n",
            "5861: [D loss: 0.736306, acc: 0.492188]  [A loss: 1.029087, acc: 0.054688]\n",
            "5862: [D loss: 0.717857, acc: 0.490234]  [A loss: 0.674221, acc: 0.621094]\n",
            "5863: [D loss: 0.739982, acc: 0.492188]  [A loss: 0.895679, acc: 0.136719]\n",
            "5864: [D loss: 0.692349, acc: 0.539062]  [A loss: 0.757106, acc: 0.347656]\n",
            "5865: [D loss: 0.719032, acc: 0.513672]  [A loss: 0.859865, acc: 0.203125]\n",
            "5866: [D loss: 0.702016, acc: 0.519531]  [A loss: 0.740205, acc: 0.386719]\n",
            "5867: [D loss: 0.714454, acc: 0.525391]  [A loss: 0.896709, acc: 0.160156]\n",
            "5868: [D loss: 0.690347, acc: 0.535156]  [A loss: 0.745945, acc: 0.398438]\n",
            "5869: [D loss: 0.714764, acc: 0.492188]  [A loss: 0.857029, acc: 0.203125]\n",
            "5870: [D loss: 0.703974, acc: 0.507812]  [A loss: 0.744254, acc: 0.394531]\n",
            "5871: [D loss: 0.700376, acc: 0.517578]  [A loss: 0.830130, acc: 0.210938]\n",
            "5872: [D loss: 0.703543, acc: 0.521484]  [A loss: 0.771063, acc: 0.351562]\n",
            "5873: [D loss: 0.695213, acc: 0.535156]  [A loss: 0.827601, acc: 0.257812]\n",
            "5874: [D loss: 0.697253, acc: 0.521484]  [A loss: 0.820359, acc: 0.285156]\n",
            "5875: [D loss: 0.708142, acc: 0.511719]  [A loss: 0.894300, acc: 0.140625]\n",
            "5876: [D loss: 0.697045, acc: 0.515625]  [A loss: 0.757922, acc: 0.363281]\n",
            "5877: [D loss: 0.698606, acc: 0.542969]  [A loss: 0.889310, acc: 0.144531]\n",
            "5878: [D loss: 0.699907, acc: 0.539062]  [A loss: 0.711521, acc: 0.464844]\n",
            "5879: [D loss: 0.710661, acc: 0.541016]  [A loss: 0.999134, acc: 0.035156]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5880: [D loss: 0.708555, acc: 0.488281]  [A loss: 0.720887, acc: 0.492188]\n",
            "5881: [D loss: 0.716908, acc: 0.496094]  [A loss: 0.977130, acc: 0.058594]\n",
            "5882: [D loss: 0.702733, acc: 0.523438]  [A loss: 0.684130, acc: 0.523438]\n",
            "5883: [D loss: 0.718730, acc: 0.500000]  [A loss: 0.971018, acc: 0.050781]\n",
            "5884: [D loss: 0.696988, acc: 0.523438]  [A loss: 0.669815, acc: 0.601562]\n",
            "5885: [D loss: 0.718258, acc: 0.505859]  [A loss: 0.971091, acc: 0.082031]\n",
            "5886: [D loss: 0.711170, acc: 0.464844]  [A loss: 0.667735, acc: 0.574219]\n",
            "5887: [D loss: 0.714053, acc: 0.527344]  [A loss: 0.929715, acc: 0.105469]\n",
            "5888: [D loss: 0.703308, acc: 0.509766]  [A loss: 0.735072, acc: 0.398438]\n",
            "5889: [D loss: 0.714882, acc: 0.498047]  [A loss: 0.885760, acc: 0.140625]\n",
            "5890: [D loss: 0.716074, acc: 0.460938]  [A loss: 0.782998, acc: 0.300781]\n",
            "5891: [D loss: 0.704827, acc: 0.519531]  [A loss: 0.847826, acc: 0.218750]\n",
            "5892: [D loss: 0.690260, acc: 0.558594]  [A loss: 0.758546, acc: 0.382812]\n",
            "5893: [D loss: 0.700480, acc: 0.509766]  [A loss: 0.854506, acc: 0.265625]\n",
            "5894: [D loss: 0.699751, acc: 0.542969]  [A loss: 0.805956, acc: 0.281250]\n",
            "5895: [D loss: 0.695972, acc: 0.525391]  [A loss: 0.833791, acc: 0.214844]\n",
            "5896: [D loss: 0.698218, acc: 0.509766]  [A loss: 0.772059, acc: 0.382812]\n",
            "5897: [D loss: 0.700681, acc: 0.517578]  [A loss: 0.870141, acc: 0.171875]\n",
            "5898: [D loss: 0.688183, acc: 0.535156]  [A loss: 0.755747, acc: 0.390625]\n",
            "5899: [D loss: 0.703346, acc: 0.515625]  [A loss: 0.838509, acc: 0.242188]\n",
            "5900: [D loss: 0.705667, acc: 0.511719]  [A loss: 0.755153, acc: 0.402344]\n",
            "5901: [D loss: 0.726872, acc: 0.476562]  [A loss: 0.896105, acc: 0.117188]\n",
            "5902: [D loss: 0.705304, acc: 0.486328]  [A loss: 0.719630, acc: 0.460938]\n",
            "5903: [D loss: 0.744531, acc: 0.486328]  [A loss: 1.103706, acc: 0.039062]\n",
            "5904: [D loss: 0.708613, acc: 0.503906]  [A loss: 0.657177, acc: 0.628906]\n",
            "5905: [D loss: 0.721898, acc: 0.509766]  [A loss: 0.912719, acc: 0.140625]\n",
            "5906: [D loss: 0.695498, acc: 0.503906]  [A loss: 0.745223, acc: 0.406250]\n",
            "5907: [D loss: 0.713907, acc: 0.511719]  [A loss: 0.862252, acc: 0.203125]\n",
            "5908: [D loss: 0.700437, acc: 0.519531]  [A loss: 0.830872, acc: 0.250000]\n",
            "5909: [D loss: 0.702817, acc: 0.519531]  [A loss: 0.804240, acc: 0.269531]\n",
            "5910: [D loss: 0.697561, acc: 0.544922]  [A loss: 0.787109, acc: 0.300781]\n",
            "5911: [D loss: 0.703648, acc: 0.523438]  [A loss: 0.877342, acc: 0.152344]\n",
            "5912: [D loss: 0.704787, acc: 0.494141]  [A loss: 0.780823, acc: 0.324219]\n",
            "5913: [D loss: 0.706850, acc: 0.511719]  [A loss: 0.901301, acc: 0.144531]\n",
            "5914: [D loss: 0.694790, acc: 0.521484]  [A loss: 0.758074, acc: 0.367188]\n",
            "5915: [D loss: 0.704780, acc: 0.535156]  [A loss: 0.866040, acc: 0.167969]\n",
            "5916: [D loss: 0.695170, acc: 0.525391]  [A loss: 0.688396, acc: 0.523438]\n",
            "5917: [D loss: 0.715836, acc: 0.521484]  [A loss: 1.013441, acc: 0.070312]\n",
            "5918: [D loss: 0.709207, acc: 0.496094]  [A loss: 0.653379, acc: 0.628906]\n",
            "5919: [D loss: 0.718789, acc: 0.505859]  [A loss: 1.009391, acc: 0.042969]\n",
            "5920: [D loss: 0.689126, acc: 0.546875]  [A loss: 0.682723, acc: 0.589844]\n",
            "5921: [D loss: 0.729190, acc: 0.500000]  [A loss: 0.925617, acc: 0.128906]\n",
            "5922: [D loss: 0.697404, acc: 0.525391]  [A loss: 0.754059, acc: 0.398438]\n",
            "5923: [D loss: 0.712698, acc: 0.496094]  [A loss: 0.896667, acc: 0.140625]\n",
            "5924: [D loss: 0.696768, acc: 0.501953]  [A loss: 0.748980, acc: 0.417969]\n",
            "5925: [D loss: 0.713511, acc: 0.503906]  [A loss: 0.851516, acc: 0.203125]\n",
            "5926: [D loss: 0.702447, acc: 0.517578]  [A loss: 0.754350, acc: 0.371094]\n",
            "5927: [D loss: 0.715858, acc: 0.486328]  [A loss: 0.889966, acc: 0.132812]\n",
            "5928: [D loss: 0.696955, acc: 0.523438]  [A loss: 0.736194, acc: 0.386719]\n",
            "5929: [D loss: 0.697134, acc: 0.531250]  [A loss: 0.860552, acc: 0.199219]\n",
            "5930: [D loss: 0.696231, acc: 0.525391]  [A loss: 0.769405, acc: 0.347656]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5931: [D loss: 0.686759, acc: 0.570312]  [A loss: 0.836660, acc: 0.199219]\n",
            "5932: [D loss: 0.707914, acc: 0.501953]  [A loss: 0.823875, acc: 0.250000]\n",
            "5933: [D loss: 0.689230, acc: 0.531250]  [A loss: 0.744198, acc: 0.414062]\n",
            "5934: [D loss: 0.714174, acc: 0.476562]  [A loss: 0.885459, acc: 0.156250]\n",
            "5935: [D loss: 0.687986, acc: 0.541016]  [A loss: 0.791051, acc: 0.332031]\n",
            "5936: [D loss: 0.706435, acc: 0.511719]  [A loss: 0.866562, acc: 0.203125]\n",
            "5937: [D loss: 0.701398, acc: 0.507812]  [A loss: 0.763521, acc: 0.347656]\n",
            "5938: [D loss: 0.700661, acc: 0.533203]  [A loss: 0.866354, acc: 0.238281]\n",
            "5939: [D loss: 0.694779, acc: 0.515625]  [A loss: 0.782710, acc: 0.343750]\n",
            "5940: [D loss: 0.699169, acc: 0.519531]  [A loss: 0.851342, acc: 0.222656]\n",
            "5941: [D loss: 0.704327, acc: 0.513672]  [A loss: 0.831640, acc: 0.242188]\n",
            "5942: [D loss: 0.709079, acc: 0.523438]  [A loss: 0.868942, acc: 0.183594]\n",
            "5943: [D loss: 0.712209, acc: 0.509766]  [A loss: 0.807446, acc: 0.328125]\n",
            "5944: [D loss: 0.709831, acc: 0.513672]  [A loss: 0.923040, acc: 0.097656]\n",
            "5945: [D loss: 0.703002, acc: 0.517578]  [A loss: 0.779300, acc: 0.292969]\n",
            "5946: [D loss: 0.709134, acc: 0.509766]  [A loss: 0.978756, acc: 0.078125]\n",
            "5947: [D loss: 0.706177, acc: 0.515625]  [A loss: 0.666339, acc: 0.593750]\n",
            "5948: [D loss: 0.734102, acc: 0.496094]  [A loss: 1.042752, acc: 0.046875]\n",
            "5949: [D loss: 0.696405, acc: 0.531250]  [A loss: 0.688870, acc: 0.558594]\n",
            "5950: [D loss: 0.705461, acc: 0.535156]  [A loss: 0.942396, acc: 0.121094]\n",
            "5951: [D loss: 0.705174, acc: 0.505859]  [A loss: 0.770414, acc: 0.347656]\n",
            "5952: [D loss: 0.711912, acc: 0.488281]  [A loss: 0.848772, acc: 0.195312]\n",
            "5953: [D loss: 0.697904, acc: 0.529297]  [A loss: 0.795041, acc: 0.296875]\n",
            "5954: [D loss: 0.710884, acc: 0.488281]  [A loss: 0.878606, acc: 0.183594]\n",
            "5955: [D loss: 0.711784, acc: 0.511719]  [A loss: 0.753772, acc: 0.382812]\n",
            "5956: [D loss: 0.715895, acc: 0.498047]  [A loss: 0.939114, acc: 0.109375]\n",
            "5957: [D loss: 0.697250, acc: 0.517578]  [A loss: 0.692336, acc: 0.531250]\n",
            "5958: [D loss: 0.725450, acc: 0.501953]  [A loss: 0.987282, acc: 0.082031]\n",
            "5959: [D loss: 0.697091, acc: 0.519531]  [A loss: 0.713118, acc: 0.468750]\n",
            "5960: [D loss: 0.719515, acc: 0.525391]  [A loss: 0.982309, acc: 0.058594]\n",
            "5961: [D loss: 0.700799, acc: 0.533203]  [A loss: 0.676834, acc: 0.578125]\n",
            "5962: [D loss: 0.707382, acc: 0.523438]  [A loss: 0.899149, acc: 0.144531]\n",
            "5963: [D loss: 0.694317, acc: 0.537109]  [A loss: 0.759378, acc: 0.371094]\n",
            "5964: [D loss: 0.708922, acc: 0.511719]  [A loss: 0.876559, acc: 0.195312]\n",
            "5965: [D loss: 0.710782, acc: 0.494141]  [A loss: 0.784345, acc: 0.320312]\n",
            "5966: [D loss: 0.714806, acc: 0.523438]  [A loss: 0.900200, acc: 0.121094]\n",
            "5967: [D loss: 0.695903, acc: 0.529297]  [A loss: 0.768507, acc: 0.347656]\n",
            "5968: [D loss: 0.712146, acc: 0.507812]  [A loss: 0.813258, acc: 0.253906]\n",
            "5969: [D loss: 0.708258, acc: 0.533203]  [A loss: 0.826088, acc: 0.218750]\n",
            "5970: [D loss: 0.696284, acc: 0.527344]  [A loss: 0.845068, acc: 0.226562]\n",
            "5971: [D loss: 0.706269, acc: 0.509766]  [A loss: 0.838994, acc: 0.218750]\n",
            "5972: [D loss: 0.688680, acc: 0.542969]  [A loss: 0.799104, acc: 0.238281]\n",
            "5973: [D loss: 0.698477, acc: 0.507812]  [A loss: 0.888442, acc: 0.148438]\n",
            "5974: [D loss: 0.695253, acc: 0.505859]  [A loss: 0.735917, acc: 0.457031]\n",
            "5975: [D loss: 0.719903, acc: 0.501953]  [A loss: 0.970254, acc: 0.089844]\n",
            "5976: [D loss: 0.693930, acc: 0.552734]  [A loss: 0.651254, acc: 0.644531]\n",
            "5977: [D loss: 0.713688, acc: 0.523438]  [A loss: 0.980736, acc: 0.078125]\n",
            "5978: [D loss: 0.708206, acc: 0.505859]  [A loss: 0.660276, acc: 0.578125]\n",
            "5979: [D loss: 0.706644, acc: 0.539062]  [A loss: 0.906255, acc: 0.128906]\n",
            "5980: [D loss: 0.691707, acc: 0.525391]  [A loss: 0.723142, acc: 0.441406]\n",
            "5981: [D loss: 0.725436, acc: 0.505859]  [A loss: 0.938813, acc: 0.132812]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5982: [D loss: 0.704873, acc: 0.523438]  [A loss: 0.760210, acc: 0.390625]\n",
            "5983: [D loss: 0.709745, acc: 0.500000]  [A loss: 0.862990, acc: 0.187500]\n",
            "5984: [D loss: 0.717994, acc: 0.478516]  [A loss: 0.799986, acc: 0.300781]\n",
            "5985: [D loss: 0.703290, acc: 0.515625]  [A loss: 0.830220, acc: 0.230469]\n",
            "5986: [D loss: 0.698014, acc: 0.515625]  [A loss: 0.794825, acc: 0.277344]\n",
            "5987: [D loss: 0.691744, acc: 0.539062]  [A loss: 0.861177, acc: 0.210938]\n",
            "5988: [D loss: 0.688616, acc: 0.554688]  [A loss: 0.772263, acc: 0.328125]\n",
            "5989: [D loss: 0.695760, acc: 0.521484]  [A loss: 0.894834, acc: 0.140625]\n",
            "5990: [D loss: 0.709602, acc: 0.511719]  [A loss: 0.718664, acc: 0.476562]\n",
            "5991: [D loss: 0.713415, acc: 0.507812]  [A loss: 0.991625, acc: 0.058594]\n",
            "5992: [D loss: 0.705476, acc: 0.537109]  [A loss: 0.726890, acc: 0.441406]\n",
            "5993: [D loss: 0.724833, acc: 0.478516]  [A loss: 0.963357, acc: 0.089844]\n",
            "5994: [D loss: 0.695528, acc: 0.517578]  [A loss: 0.675835, acc: 0.593750]\n",
            "5995: [D loss: 0.721391, acc: 0.498047]  [A loss: 0.984201, acc: 0.062500]\n",
            "5996: [D loss: 0.703930, acc: 0.490234]  [A loss: 0.712465, acc: 0.464844]\n",
            "5997: [D loss: 0.707646, acc: 0.521484]  [A loss: 0.901250, acc: 0.140625]\n",
            "5998: [D loss: 0.702468, acc: 0.527344]  [A loss: 0.702706, acc: 0.480469]\n",
            "5999: [D loss: 0.721495, acc: 0.517578]  [A loss: 0.909808, acc: 0.136719]\n",
            "6000: [D loss: 0.691986, acc: 0.519531]  [A loss: 0.763576, acc: 0.375000]\n",
            "6001: [D loss: 0.731391, acc: 0.462891]  [A loss: 0.831065, acc: 0.234375]\n",
            "6002: [D loss: 0.700446, acc: 0.503906]  [A loss: 0.802737, acc: 0.269531]\n",
            "6003: [D loss: 0.714593, acc: 0.511719]  [A loss: 0.868017, acc: 0.160156]\n",
            "6004: [D loss: 0.704725, acc: 0.515625]  [A loss: 0.770614, acc: 0.359375]\n",
            "6005: [D loss: 0.703525, acc: 0.507812]  [A loss: 0.887130, acc: 0.148438]\n",
            "6006: [D loss: 0.707267, acc: 0.486328]  [A loss: 0.786544, acc: 0.289062]\n",
            "6007: [D loss: 0.698445, acc: 0.546875]  [A loss: 0.890963, acc: 0.156250]\n",
            "6008: [D loss: 0.702704, acc: 0.515625]  [A loss: 0.809406, acc: 0.300781]\n",
            "6009: [D loss: 0.706658, acc: 0.501953]  [A loss: 0.879706, acc: 0.164062]\n",
            "6010: [D loss: 0.711807, acc: 0.494141]  [A loss: 0.714798, acc: 0.449219]\n",
            "6011: [D loss: 0.716258, acc: 0.525391]  [A loss: 0.938214, acc: 0.093750]\n",
            "6012: [D loss: 0.696741, acc: 0.519531]  [A loss: 0.709488, acc: 0.468750]\n",
            "6013: [D loss: 0.715016, acc: 0.556641]  [A loss: 1.052273, acc: 0.058594]\n",
            "6014: [D loss: 0.703839, acc: 0.521484]  [A loss: 0.665679, acc: 0.605469]\n",
            "6015: [D loss: 0.742065, acc: 0.500000]  [A loss: 0.938178, acc: 0.097656]\n",
            "6016: [D loss: 0.720594, acc: 0.482422]  [A loss: 0.685506, acc: 0.519531]\n",
            "6017: [D loss: 0.729458, acc: 0.496094]  [A loss: 0.879801, acc: 0.156250]\n",
            "6018: [D loss: 0.690291, acc: 0.527344]  [A loss: 0.736509, acc: 0.402344]\n",
            "6019: [D loss: 0.702260, acc: 0.517578]  [A loss: 0.822461, acc: 0.261719]\n",
            "6020: [D loss: 0.699212, acc: 0.511719]  [A loss: 0.813326, acc: 0.265625]\n",
            "6021: [D loss: 0.699551, acc: 0.535156]  [A loss: 0.739343, acc: 0.425781]\n",
            "6022: [D loss: 0.702537, acc: 0.521484]  [A loss: 0.817885, acc: 0.234375]\n",
            "6023: [D loss: 0.714520, acc: 0.527344]  [A loss: 0.781695, acc: 0.324219]\n",
            "6024: [D loss: 0.699698, acc: 0.537109]  [A loss: 0.813982, acc: 0.261719]\n",
            "6025: [D loss: 0.705405, acc: 0.515625]  [A loss: 0.796371, acc: 0.281250]\n",
            "6026: [D loss: 0.693216, acc: 0.542969]  [A loss: 0.770807, acc: 0.324219]\n",
            "6027: [D loss: 0.711877, acc: 0.488281]  [A loss: 0.845471, acc: 0.210938]\n",
            "6028: [D loss: 0.696210, acc: 0.509766]  [A loss: 0.818712, acc: 0.246094]\n",
            "6029: [D loss: 0.704110, acc: 0.521484]  [A loss: 0.831080, acc: 0.238281]\n",
            "6030: [D loss: 0.711964, acc: 0.490234]  [A loss: 0.810713, acc: 0.250000]\n",
            "6031: [D loss: 0.705174, acc: 0.490234]  [A loss: 0.807440, acc: 0.296875]\n",
            "6032: [D loss: 0.685661, acc: 0.527344]  [A loss: 0.837948, acc: 0.207031]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6033: [D loss: 0.691048, acc: 0.503906]  [A loss: 0.852930, acc: 0.203125]\n",
            "6034: [D loss: 0.692782, acc: 0.537109]  [A loss: 0.858766, acc: 0.203125]\n",
            "6035: [D loss: 0.701975, acc: 0.521484]  [A loss: 0.871911, acc: 0.171875]\n",
            "6036: [D loss: 0.702963, acc: 0.521484]  [A loss: 0.825944, acc: 0.246094]\n",
            "6037: [D loss: 0.695062, acc: 0.529297]  [A loss: 0.903369, acc: 0.152344]\n",
            "6038: [D loss: 0.705124, acc: 0.511719]  [A loss: 0.793024, acc: 0.316406]\n",
            "6039: [D loss: 0.716329, acc: 0.515625]  [A loss: 1.111302, acc: 0.031250]\n",
            "6040: [D loss: 0.703783, acc: 0.542969]  [A loss: 0.576680, acc: 0.761719]\n",
            "6041: [D loss: 0.766824, acc: 0.488281]  [A loss: 1.024163, acc: 0.027344]\n",
            "6042: [D loss: 0.703741, acc: 0.541016]  [A loss: 0.669105, acc: 0.562500]\n",
            "6043: [D loss: 0.723130, acc: 0.517578]  [A loss: 0.901869, acc: 0.171875]\n",
            "6044: [D loss: 0.685181, acc: 0.564453]  [A loss: 0.731933, acc: 0.425781]\n",
            "6045: [D loss: 0.707102, acc: 0.515625]  [A loss: 0.863601, acc: 0.203125]\n",
            "6046: [D loss: 0.709517, acc: 0.513672]  [A loss: 0.770992, acc: 0.347656]\n",
            "6047: [D loss: 0.701067, acc: 0.507812]  [A loss: 0.785703, acc: 0.312500]\n",
            "6048: [D loss: 0.711281, acc: 0.472656]  [A loss: 0.847110, acc: 0.230469]\n",
            "6049: [D loss: 0.711458, acc: 0.517578]  [A loss: 0.729923, acc: 0.460938]\n",
            "6050: [D loss: 0.716495, acc: 0.507812]  [A loss: 0.879257, acc: 0.164062]\n",
            "6051: [D loss: 0.707288, acc: 0.523438]  [A loss: 0.760546, acc: 0.371094]\n",
            "6052: [D loss: 0.718113, acc: 0.490234]  [A loss: 0.817280, acc: 0.257812]\n",
            "6053: [D loss: 0.702210, acc: 0.529297]  [A loss: 0.832642, acc: 0.210938]\n",
            "6054: [D loss: 0.707287, acc: 0.498047]  [A loss: 0.766701, acc: 0.382812]\n",
            "6055: [D loss: 0.712297, acc: 0.519531]  [A loss: 0.867853, acc: 0.210938]\n",
            "6056: [D loss: 0.694215, acc: 0.521484]  [A loss: 0.800015, acc: 0.300781]\n",
            "6057: [D loss: 0.701473, acc: 0.511719]  [A loss: 0.879319, acc: 0.152344]\n",
            "6058: [D loss: 0.697426, acc: 0.525391]  [A loss: 0.733591, acc: 0.453125]\n",
            "6059: [D loss: 0.716829, acc: 0.511719]  [A loss: 0.960082, acc: 0.078125]\n",
            "6060: [D loss: 0.683787, acc: 0.552734]  [A loss: 0.691184, acc: 0.542969]\n",
            "6061: [D loss: 0.728623, acc: 0.505859]  [A loss: 1.003349, acc: 0.058594]\n",
            "6062: [D loss: 0.696547, acc: 0.529297]  [A loss: 0.644180, acc: 0.632812]\n",
            "6063: [D loss: 0.734902, acc: 0.496094]  [A loss: 0.961257, acc: 0.058594]\n",
            "6064: [D loss: 0.700390, acc: 0.517578]  [A loss: 0.709183, acc: 0.488281]\n",
            "6065: [D loss: 0.720298, acc: 0.492188]  [A loss: 0.929260, acc: 0.097656]\n",
            "6066: [D loss: 0.689874, acc: 0.552734]  [A loss: 0.753297, acc: 0.359375]\n",
            "6067: [D loss: 0.703806, acc: 0.513672]  [A loss: 0.859875, acc: 0.238281]\n",
            "6068: [D loss: 0.698233, acc: 0.521484]  [A loss: 0.730704, acc: 0.429688]\n",
            "6069: [D loss: 0.695836, acc: 0.535156]  [A loss: 0.943359, acc: 0.109375]\n",
            "6070: [D loss: 0.711558, acc: 0.488281]  [A loss: 0.740707, acc: 0.394531]\n",
            "6071: [D loss: 0.720585, acc: 0.490234]  [A loss: 0.903809, acc: 0.167969]\n",
            "6072: [D loss: 0.709254, acc: 0.474609]  [A loss: 0.699435, acc: 0.523438]\n",
            "6073: [D loss: 0.722399, acc: 0.517578]  [A loss: 0.979070, acc: 0.082031]\n",
            "6074: [D loss: 0.704945, acc: 0.527344]  [A loss: 0.709829, acc: 0.496094]\n",
            "6075: [D loss: 0.712694, acc: 0.523438]  [A loss: 0.917282, acc: 0.085938]\n",
            "6076: [D loss: 0.702988, acc: 0.513672]  [A loss: 0.691555, acc: 0.511719]\n",
            "6077: [D loss: 0.701475, acc: 0.537109]  [A loss: 0.868710, acc: 0.195312]\n",
            "6078: [D loss: 0.689438, acc: 0.539062]  [A loss: 0.745478, acc: 0.398438]\n",
            "6079: [D loss: 0.729363, acc: 0.486328]  [A loss: 0.868209, acc: 0.171875]\n",
            "6080: [D loss: 0.697461, acc: 0.527344]  [A loss: 0.753880, acc: 0.410156]\n",
            "6081: [D loss: 0.698238, acc: 0.513672]  [A loss: 0.897759, acc: 0.191406]\n",
            "6082: [D loss: 0.698414, acc: 0.527344]  [A loss: 0.747481, acc: 0.398438]\n",
            "6083: [D loss: 0.699981, acc: 0.535156]  [A loss: 0.845207, acc: 0.203125]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6084: [D loss: 0.707670, acc: 0.525391]  [A loss: 0.782162, acc: 0.390625]\n",
            "6085: [D loss: 0.706214, acc: 0.527344]  [A loss: 0.792702, acc: 0.332031]\n",
            "6086: [D loss: 0.698749, acc: 0.525391]  [A loss: 0.819409, acc: 0.253906]\n",
            "6087: [D loss: 0.691849, acc: 0.537109]  [A loss: 0.792852, acc: 0.304688]\n",
            "6088: [D loss: 0.708440, acc: 0.525391]  [A loss: 0.806768, acc: 0.308594]\n",
            "6089: [D loss: 0.712312, acc: 0.535156]  [A loss: 0.862581, acc: 0.207031]\n",
            "6090: [D loss: 0.699442, acc: 0.511719]  [A loss: 0.811294, acc: 0.261719]\n",
            "6091: [D loss: 0.697427, acc: 0.513672]  [A loss: 0.843767, acc: 0.222656]\n",
            "6092: [D loss: 0.697092, acc: 0.517578]  [A loss: 0.747808, acc: 0.378906]\n",
            "6093: [D loss: 0.710737, acc: 0.498047]  [A loss: 0.954168, acc: 0.062500]\n",
            "6094: [D loss: 0.698803, acc: 0.507812]  [A loss: 0.679413, acc: 0.535156]\n",
            "6095: [D loss: 0.719581, acc: 0.519531]  [A loss: 1.077190, acc: 0.039062]\n",
            "6096: [D loss: 0.704928, acc: 0.521484]  [A loss: 0.697532, acc: 0.546875]\n",
            "6097: [D loss: 0.711747, acc: 0.513672]  [A loss: 0.959151, acc: 0.082031]\n",
            "6098: [D loss: 0.697497, acc: 0.521484]  [A loss: 0.687474, acc: 0.539062]\n",
            "6099: [D loss: 0.706820, acc: 0.521484]  [A loss: 0.914779, acc: 0.128906]\n",
            "6100: [D loss: 0.682478, acc: 0.552734]  [A loss: 0.765497, acc: 0.402344]\n",
            "6101: [D loss: 0.696808, acc: 0.531250]  [A loss: 0.808238, acc: 0.273438]\n",
            "6102: [D loss: 0.708494, acc: 0.498047]  [A loss: 0.857599, acc: 0.183594]\n",
            "6103: [D loss: 0.687182, acc: 0.533203]  [A loss: 0.758196, acc: 0.398438]\n",
            "6104: [D loss: 0.703472, acc: 0.498047]  [A loss: 0.887856, acc: 0.167969]\n",
            "6105: [D loss: 0.703603, acc: 0.515625]  [A loss: 0.806856, acc: 0.304688]\n",
            "6106: [D loss: 0.713822, acc: 0.480469]  [A loss: 0.951561, acc: 0.085938]\n",
            "6107: [D loss: 0.699358, acc: 0.527344]  [A loss: 0.697586, acc: 0.503906]\n",
            "6108: [D loss: 0.712318, acc: 0.509766]  [A loss: 0.921866, acc: 0.164062]\n",
            "6109: [D loss: 0.699593, acc: 0.548828]  [A loss: 0.721887, acc: 0.425781]\n",
            "6110: [D loss: 0.724748, acc: 0.490234]  [A loss: 0.922363, acc: 0.121094]\n",
            "6111: [D loss: 0.684643, acc: 0.550781]  [A loss: 0.685880, acc: 0.535156]\n",
            "6112: [D loss: 0.731899, acc: 0.492188]  [A loss: 0.926814, acc: 0.121094]\n",
            "6113: [D loss: 0.700129, acc: 0.527344]  [A loss: 0.712378, acc: 0.488281]\n",
            "6114: [D loss: 0.711468, acc: 0.505859]  [A loss: 0.877075, acc: 0.167969]\n",
            "6115: [D loss: 0.708494, acc: 0.470703]  [A loss: 0.744196, acc: 0.378906]\n",
            "6116: [D loss: 0.715270, acc: 0.509766]  [A loss: 0.887027, acc: 0.128906]\n",
            "6117: [D loss: 0.707492, acc: 0.509766]  [A loss: 0.789017, acc: 0.285156]\n",
            "6118: [D loss: 0.710633, acc: 0.527344]  [A loss: 0.803442, acc: 0.332031]\n",
            "6119: [D loss: 0.696240, acc: 0.544922]  [A loss: 0.960543, acc: 0.113281]\n",
            "6120: [D loss: 0.707117, acc: 0.529297]  [A loss: 0.701570, acc: 0.507812]\n",
            "6121: [D loss: 0.703851, acc: 0.535156]  [A loss: 0.944756, acc: 0.105469]\n",
            "6122: [D loss: 0.704900, acc: 0.533203]  [A loss: 0.671558, acc: 0.554688]\n",
            "6123: [D loss: 0.710403, acc: 0.519531]  [A loss: 0.929088, acc: 0.117188]\n",
            "6124: [D loss: 0.688090, acc: 0.529297]  [A loss: 0.717059, acc: 0.457031]\n",
            "6125: [D loss: 0.719726, acc: 0.500000]  [A loss: 0.882437, acc: 0.144531]\n",
            "6126: [D loss: 0.694888, acc: 0.544922]  [A loss: 0.716151, acc: 0.464844]\n",
            "6127: [D loss: 0.713773, acc: 0.490234]  [A loss: 0.959177, acc: 0.136719]\n",
            "6128: [D loss: 0.704262, acc: 0.476562]  [A loss: 0.765896, acc: 0.320312]\n",
            "6129: [D loss: 0.714722, acc: 0.492188]  [A loss: 0.875323, acc: 0.152344]\n",
            "6130: [D loss: 0.702969, acc: 0.529297]  [A loss: 0.780105, acc: 0.390625]\n",
            "6131: [D loss: 0.698695, acc: 0.521484]  [A loss: 0.817734, acc: 0.265625]\n",
            "6132: [D loss: 0.718179, acc: 0.500000]  [A loss: 0.758103, acc: 0.386719]\n",
            "6133: [D loss: 0.718951, acc: 0.478516]  [A loss: 0.863053, acc: 0.183594]\n",
            "6134: [D loss: 0.699197, acc: 0.521484]  [A loss: 0.777155, acc: 0.339844]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6135: [D loss: 0.710380, acc: 0.498047]  [A loss: 0.829407, acc: 0.222656]\n",
            "6136: [D loss: 0.696436, acc: 0.525391]  [A loss: 0.725404, acc: 0.464844]\n",
            "6137: [D loss: 0.712521, acc: 0.492188]  [A loss: 0.920358, acc: 0.105469]\n",
            "6138: [D loss: 0.693867, acc: 0.525391]  [A loss: 0.703517, acc: 0.472656]\n",
            "6139: [D loss: 0.725790, acc: 0.501953]  [A loss: 0.929680, acc: 0.121094]\n",
            "6140: [D loss: 0.704418, acc: 0.494141]  [A loss: 0.690617, acc: 0.535156]\n",
            "6141: [D loss: 0.711384, acc: 0.509766]  [A loss: 0.880203, acc: 0.167969]\n",
            "6142: [D loss: 0.710093, acc: 0.492188]  [A loss: 0.785600, acc: 0.332031]\n",
            "6143: [D loss: 0.710585, acc: 0.494141]  [A loss: 0.902720, acc: 0.125000]\n",
            "6144: [D loss: 0.691751, acc: 0.517578]  [A loss: 0.713827, acc: 0.464844]\n",
            "6145: [D loss: 0.714838, acc: 0.490234]  [A loss: 0.940400, acc: 0.117188]\n",
            "6146: [D loss: 0.707566, acc: 0.468750]  [A loss: 0.672680, acc: 0.597656]\n",
            "6147: [D loss: 0.713249, acc: 0.509766]  [A loss: 0.952635, acc: 0.082031]\n",
            "6148: [D loss: 0.692288, acc: 0.544922]  [A loss: 0.651138, acc: 0.644531]\n",
            "6149: [D loss: 0.730350, acc: 0.513672]  [A loss: 0.957034, acc: 0.089844]\n",
            "6150: [D loss: 0.695071, acc: 0.513672]  [A loss: 0.724972, acc: 0.417969]\n",
            "6151: [D loss: 0.714089, acc: 0.515625]  [A loss: 0.840519, acc: 0.207031]\n",
            "6152: [D loss: 0.692296, acc: 0.533203]  [A loss: 0.787005, acc: 0.304688]\n",
            "6153: [D loss: 0.704962, acc: 0.511719]  [A loss: 0.856775, acc: 0.175781]\n",
            "6154: [D loss: 0.696072, acc: 0.556641]  [A loss: 0.752352, acc: 0.367188]\n",
            "6155: [D loss: 0.717018, acc: 0.501953]  [A loss: 0.919786, acc: 0.156250]\n",
            "6156: [D loss: 0.695260, acc: 0.519531]  [A loss: 0.794059, acc: 0.269531]\n",
            "6157: [D loss: 0.706803, acc: 0.503906]  [A loss: 0.876702, acc: 0.148438]\n",
            "6158: [D loss: 0.699146, acc: 0.519531]  [A loss: 0.780296, acc: 0.320312]\n",
            "6159: [D loss: 0.693325, acc: 0.548828]  [A loss: 0.890717, acc: 0.128906]\n",
            "6160: [D loss: 0.684266, acc: 0.556641]  [A loss: 0.730314, acc: 0.421875]\n",
            "6161: [D loss: 0.724979, acc: 0.488281]  [A loss: 0.981171, acc: 0.042969]\n",
            "6162: [D loss: 0.700397, acc: 0.517578]  [A loss: 0.670523, acc: 0.578125]\n",
            "6163: [D loss: 0.719356, acc: 0.523438]  [A loss: 0.954967, acc: 0.070312]\n",
            "6164: [D loss: 0.694471, acc: 0.546875]  [A loss: 0.661711, acc: 0.625000]\n",
            "6165: [D loss: 0.729850, acc: 0.496094]  [A loss: 0.891080, acc: 0.136719]\n",
            "6166: [D loss: 0.703470, acc: 0.501953]  [A loss: 0.783355, acc: 0.312500]\n",
            "6167: [D loss: 0.713620, acc: 0.492188]  [A loss: 0.882353, acc: 0.160156]\n",
            "6168: [D loss: 0.686837, acc: 0.550781]  [A loss: 0.785097, acc: 0.335938]\n",
            "6169: [D loss: 0.714122, acc: 0.505859]  [A loss: 0.921919, acc: 0.109375]\n",
            "6170: [D loss: 0.708668, acc: 0.480469]  [A loss: 0.785005, acc: 0.308594]\n",
            "6171: [D loss: 0.712703, acc: 0.513672]  [A loss: 0.888178, acc: 0.144531]\n",
            "6172: [D loss: 0.696733, acc: 0.535156]  [A loss: 0.779305, acc: 0.285156]\n",
            "6173: [D loss: 0.704935, acc: 0.511719]  [A loss: 0.839761, acc: 0.195312]\n",
            "6174: [D loss: 0.699168, acc: 0.535156]  [A loss: 0.827029, acc: 0.234375]\n",
            "6175: [D loss: 0.691909, acc: 0.550781]  [A loss: 0.810269, acc: 0.226562]\n",
            "6176: [D loss: 0.712536, acc: 0.511719]  [A loss: 0.856428, acc: 0.175781]\n",
            "6177: [D loss: 0.695182, acc: 0.515625]  [A loss: 0.808265, acc: 0.265625]\n",
            "6178: [D loss: 0.701821, acc: 0.507812]  [A loss: 0.885226, acc: 0.136719]\n",
            "6179: [D loss: 0.695588, acc: 0.523438]  [A loss: 0.712039, acc: 0.503906]\n",
            "6180: [D loss: 0.713499, acc: 0.521484]  [A loss: 1.006160, acc: 0.042969]\n",
            "6181: [D loss: 0.697860, acc: 0.523438]  [A loss: 0.668142, acc: 0.582031]\n",
            "6182: [D loss: 0.712639, acc: 0.542969]  [A loss: 0.913266, acc: 0.113281]\n",
            "6183: [D loss: 0.710037, acc: 0.480469]  [A loss: 0.710552, acc: 0.500000]\n",
            "6184: [D loss: 0.709543, acc: 0.501953]  [A loss: 0.903262, acc: 0.136719]\n",
            "6185: [D loss: 0.696441, acc: 0.527344]  [A loss: 0.742218, acc: 0.441406]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6186: [D loss: 0.699810, acc: 0.519531]  [A loss: 0.884845, acc: 0.148438]\n",
            "6187: [D loss: 0.703794, acc: 0.517578]  [A loss: 0.744887, acc: 0.402344]\n",
            "6188: [D loss: 0.710822, acc: 0.503906]  [A loss: 0.871262, acc: 0.148438]\n",
            "6189: [D loss: 0.709217, acc: 0.492188]  [A loss: 0.793037, acc: 0.316406]\n",
            "6190: [D loss: 0.700519, acc: 0.523438]  [A loss: 0.843142, acc: 0.179688]\n",
            "6191: [D loss: 0.696992, acc: 0.500000]  [A loss: 0.772235, acc: 0.300781]\n",
            "6192: [D loss: 0.728236, acc: 0.498047]  [A loss: 0.926700, acc: 0.089844]\n",
            "6193: [D loss: 0.697401, acc: 0.503906]  [A loss: 0.722841, acc: 0.476562]\n",
            "6194: [D loss: 0.723203, acc: 0.507812]  [A loss: 0.986185, acc: 0.039062]\n",
            "6195: [D loss: 0.697133, acc: 0.511719]  [A loss: 0.722388, acc: 0.476562]\n",
            "6196: [D loss: 0.708507, acc: 0.515625]  [A loss: 0.943147, acc: 0.089844]\n",
            "6197: [D loss: 0.692831, acc: 0.507812]  [A loss: 0.680102, acc: 0.566406]\n",
            "6198: [D loss: 0.711638, acc: 0.503906]  [A loss: 0.972584, acc: 0.093750]\n",
            "6199: [D loss: 0.701078, acc: 0.494141]  [A loss: 0.691104, acc: 0.519531]\n",
            "6200: [D loss: 0.719505, acc: 0.505859]  [A loss: 0.917557, acc: 0.152344]\n",
            "6201: [D loss: 0.710207, acc: 0.500000]  [A loss: 0.735494, acc: 0.410156]\n",
            "6202: [D loss: 0.714782, acc: 0.507812]  [A loss: 0.890880, acc: 0.167969]\n",
            "6203: [D loss: 0.693607, acc: 0.558594]  [A loss: 0.790107, acc: 0.320312]\n",
            "6204: [D loss: 0.712738, acc: 0.486328]  [A loss: 0.842652, acc: 0.218750]\n",
            "6205: [D loss: 0.704306, acc: 0.515625]  [A loss: 0.756583, acc: 0.382812]\n",
            "6206: [D loss: 0.701784, acc: 0.539062]  [A loss: 0.908459, acc: 0.136719]\n",
            "6207: [D loss: 0.705545, acc: 0.500000]  [A loss: 0.750009, acc: 0.371094]\n",
            "6208: [D loss: 0.700675, acc: 0.511719]  [A loss: 0.950236, acc: 0.136719]\n",
            "6209: [D loss: 0.707114, acc: 0.509766]  [A loss: 0.693002, acc: 0.503906]\n",
            "6210: [D loss: 0.708057, acc: 0.533203]  [A loss: 0.945008, acc: 0.105469]\n",
            "6211: [D loss: 0.702759, acc: 0.517578]  [A loss: 0.748959, acc: 0.398438]\n",
            "6212: [D loss: 0.708526, acc: 0.515625]  [A loss: 0.954407, acc: 0.074219]\n",
            "6213: [D loss: 0.708161, acc: 0.472656]  [A loss: 0.732806, acc: 0.445312]\n",
            "6214: [D loss: 0.708162, acc: 0.492188]  [A loss: 0.857759, acc: 0.183594]\n",
            "6215: [D loss: 0.700207, acc: 0.488281]  [A loss: 0.762947, acc: 0.367188]\n",
            "6216: [D loss: 0.694021, acc: 0.539062]  [A loss: 0.854929, acc: 0.199219]\n",
            "6217: [D loss: 0.700378, acc: 0.525391]  [A loss: 0.815093, acc: 0.261719]\n",
            "6218: [D loss: 0.694775, acc: 0.511719]  [A loss: 0.890235, acc: 0.164062]\n",
            "6219: [D loss: 0.704543, acc: 0.501953]  [A loss: 0.770618, acc: 0.339844]\n",
            "6220: [D loss: 0.707282, acc: 0.544922]  [A loss: 0.891483, acc: 0.160156]\n",
            "6221: [D loss: 0.692796, acc: 0.533203]  [A loss: 0.781152, acc: 0.339844]\n",
            "6222: [D loss: 0.715343, acc: 0.486328]  [A loss: 0.914016, acc: 0.125000]\n",
            "6223: [D loss: 0.702913, acc: 0.496094]  [A loss: 0.756869, acc: 0.382812]\n",
            "6224: [D loss: 0.705567, acc: 0.505859]  [A loss: 0.958825, acc: 0.101562]\n",
            "6225: [D loss: 0.700423, acc: 0.513672]  [A loss: 0.689553, acc: 0.542969]\n",
            "6226: [D loss: 0.730702, acc: 0.490234]  [A loss: 1.019224, acc: 0.042969]\n",
            "6227: [D loss: 0.706222, acc: 0.523438]  [A loss: 0.641838, acc: 0.628906]\n",
            "6228: [D loss: 0.724681, acc: 0.507812]  [A loss: 0.961520, acc: 0.093750]\n",
            "6229: [D loss: 0.707634, acc: 0.521484]  [A loss: 0.678422, acc: 0.535156]\n",
            "6230: [D loss: 0.714649, acc: 0.498047]  [A loss: 0.843745, acc: 0.191406]\n",
            "6231: [D loss: 0.693792, acc: 0.527344]  [A loss: 0.766421, acc: 0.359375]\n",
            "6232: [D loss: 0.705564, acc: 0.507812]  [A loss: 0.798558, acc: 0.234375]\n",
            "6233: [D loss: 0.700964, acc: 0.517578]  [A loss: 0.730116, acc: 0.449219]\n",
            "6234: [D loss: 0.710556, acc: 0.525391]  [A loss: 0.877904, acc: 0.144531]\n",
            "6235: [D loss: 0.687696, acc: 0.560547]  [A loss: 0.671942, acc: 0.570312]\n",
            "6236: [D loss: 0.719325, acc: 0.496094]  [A loss: 0.932003, acc: 0.093750]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6237: [D loss: 0.707850, acc: 0.550781]  [A loss: 0.755273, acc: 0.382812]\n",
            "6238: [D loss: 0.695026, acc: 0.539062]  [A loss: 0.848679, acc: 0.195312]\n",
            "6239: [D loss: 0.694446, acc: 0.531250]  [A loss: 0.762699, acc: 0.332031]\n",
            "6240: [D loss: 0.703727, acc: 0.517578]  [A loss: 0.843066, acc: 0.199219]\n",
            "6241: [D loss: 0.694054, acc: 0.541016]  [A loss: 0.763636, acc: 0.382812]\n",
            "6242: [D loss: 0.714094, acc: 0.488281]  [A loss: 0.882551, acc: 0.136719]\n",
            "6243: [D loss: 0.693465, acc: 0.546875]  [A loss: 0.729564, acc: 0.445312]\n",
            "6244: [D loss: 0.715593, acc: 0.505859]  [A loss: 0.893156, acc: 0.128906]\n",
            "6245: [D loss: 0.702373, acc: 0.513672]  [A loss: 0.787703, acc: 0.343750]\n",
            "6246: [D loss: 0.703292, acc: 0.527344]  [A loss: 0.918418, acc: 0.125000]\n",
            "6247: [D loss: 0.701755, acc: 0.517578]  [A loss: 0.702644, acc: 0.484375]\n",
            "6248: [D loss: 0.716992, acc: 0.507812]  [A loss: 1.032794, acc: 0.039062]\n",
            "6249: [D loss: 0.695276, acc: 0.548828]  [A loss: 0.658243, acc: 0.593750]\n",
            "6250: [D loss: 0.726674, acc: 0.503906]  [A loss: 0.880241, acc: 0.152344]\n",
            "6251: [D loss: 0.685420, acc: 0.542969]  [A loss: 0.757812, acc: 0.386719]\n",
            "6252: [D loss: 0.713558, acc: 0.505859]  [A loss: 0.845665, acc: 0.175781]\n",
            "6253: [D loss: 0.705027, acc: 0.488281]  [A loss: 0.731724, acc: 0.433594]\n",
            "6254: [D loss: 0.708178, acc: 0.523438]  [A loss: 0.891475, acc: 0.117188]\n",
            "6255: [D loss: 0.702710, acc: 0.505859]  [A loss: 0.707872, acc: 0.457031]\n",
            "6256: [D loss: 0.705132, acc: 0.519531]  [A loss: 0.844237, acc: 0.226562]\n",
            "6257: [D loss: 0.703905, acc: 0.492188]  [A loss: 0.778656, acc: 0.332031]\n",
            "6258: [D loss: 0.703979, acc: 0.515625]  [A loss: 0.815052, acc: 0.214844]\n",
            "6259: [D loss: 0.694825, acc: 0.550781]  [A loss: 0.741671, acc: 0.398438]\n",
            "6260: [D loss: 0.715947, acc: 0.486328]  [A loss: 0.870222, acc: 0.171875]\n",
            "6261: [D loss: 0.679701, acc: 0.576172]  [A loss: 0.752750, acc: 0.359375]\n",
            "6262: [D loss: 0.722090, acc: 0.488281]  [A loss: 0.916268, acc: 0.078125]\n",
            "6263: [D loss: 0.697895, acc: 0.519531]  [A loss: 0.686123, acc: 0.542969]\n",
            "6264: [D loss: 0.716831, acc: 0.521484]  [A loss: 0.999715, acc: 0.042969]\n",
            "6265: [D loss: 0.700077, acc: 0.531250]  [A loss: 0.688230, acc: 0.511719]\n",
            "6266: [D loss: 0.709398, acc: 0.517578]  [A loss: 0.944886, acc: 0.085938]\n",
            "6267: [D loss: 0.693789, acc: 0.509766]  [A loss: 0.722116, acc: 0.460938]\n",
            "6268: [D loss: 0.712145, acc: 0.501953]  [A loss: 0.879400, acc: 0.136719]\n",
            "6269: [D loss: 0.701629, acc: 0.503906]  [A loss: 0.736608, acc: 0.421875]\n",
            "6270: [D loss: 0.696803, acc: 0.542969]  [A loss: 0.907827, acc: 0.125000]\n",
            "6271: [D loss: 0.681410, acc: 0.541016]  [A loss: 0.726411, acc: 0.453125]\n",
            "6272: [D loss: 0.715594, acc: 0.511719]  [A loss: 0.899207, acc: 0.125000]\n",
            "6273: [D loss: 0.692009, acc: 0.560547]  [A loss: 0.708868, acc: 0.527344]\n",
            "6274: [D loss: 0.713052, acc: 0.501953]  [A loss: 0.899034, acc: 0.152344]\n",
            "6275: [D loss: 0.702419, acc: 0.519531]  [A loss: 0.756856, acc: 0.402344]\n",
            "6276: [D loss: 0.726863, acc: 0.484375]  [A loss: 0.910246, acc: 0.121094]\n",
            "6277: [D loss: 0.695609, acc: 0.525391]  [A loss: 0.713153, acc: 0.468750]\n",
            "6278: [D loss: 0.699620, acc: 0.541016]  [A loss: 0.808318, acc: 0.265625]\n",
            "6279: [D loss: 0.693787, acc: 0.513672]  [A loss: 0.770359, acc: 0.378906]\n",
            "6280: [D loss: 0.719895, acc: 0.498047]  [A loss: 0.825915, acc: 0.214844]\n",
            "6281: [D loss: 0.710717, acc: 0.490234]  [A loss: 0.861460, acc: 0.179688]\n",
            "6282: [D loss: 0.706989, acc: 0.511719]  [A loss: 0.769251, acc: 0.332031]\n",
            "6283: [D loss: 0.710339, acc: 0.503906]  [A loss: 0.861886, acc: 0.171875]\n",
            "6284: [D loss: 0.690199, acc: 0.544922]  [A loss: 0.735057, acc: 0.410156]\n",
            "6285: [D loss: 0.705845, acc: 0.505859]  [A loss: 0.889872, acc: 0.117188]\n",
            "6286: [D loss: 0.705788, acc: 0.480469]  [A loss: 0.764085, acc: 0.363281]\n",
            "6287: [D loss: 0.707548, acc: 0.507812]  [A loss: 1.013209, acc: 0.046875]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6288: [D loss: 0.700159, acc: 0.527344]  [A loss: 0.663205, acc: 0.601562]\n",
            "6289: [D loss: 0.733274, acc: 0.480469]  [A loss: 0.891167, acc: 0.113281]\n",
            "6290: [D loss: 0.706193, acc: 0.501953]  [A loss: 0.721278, acc: 0.453125]\n",
            "6291: [D loss: 0.722681, acc: 0.484375]  [A loss: 0.844257, acc: 0.230469]\n",
            "6292: [D loss: 0.691297, acc: 0.537109]  [A loss: 0.761660, acc: 0.355469]\n",
            "6293: [D loss: 0.701726, acc: 0.519531]  [A loss: 0.803877, acc: 0.292969]\n",
            "6294: [D loss: 0.708350, acc: 0.492188]  [A loss: 0.801968, acc: 0.277344]\n",
            "6295: [D loss: 0.698531, acc: 0.525391]  [A loss: 0.839424, acc: 0.261719]\n",
            "6296: [D loss: 0.707981, acc: 0.525391]  [A loss: 0.770242, acc: 0.312500]\n",
            "6297: [D loss: 0.699664, acc: 0.519531]  [A loss: 0.812725, acc: 0.226562]\n",
            "6298: [D loss: 0.689937, acc: 0.544922]  [A loss: 0.823743, acc: 0.230469]\n",
            "6299: [D loss: 0.698474, acc: 0.503906]  [A loss: 0.806558, acc: 0.234375]\n",
            "6300: [D loss: 0.701625, acc: 0.523438]  [A loss: 0.873976, acc: 0.152344]\n",
            "6301: [D loss: 0.700398, acc: 0.513672]  [A loss: 0.764565, acc: 0.343750]\n",
            "6302: [D loss: 0.702901, acc: 0.535156]  [A loss: 0.931235, acc: 0.109375]\n",
            "6303: [D loss: 0.710433, acc: 0.498047]  [A loss: 0.662692, acc: 0.605469]\n",
            "6304: [D loss: 0.712346, acc: 0.517578]  [A loss: 0.908976, acc: 0.125000]\n",
            "6305: [D loss: 0.690984, acc: 0.556641]  [A loss: 0.743953, acc: 0.386719]\n",
            "6306: [D loss: 0.702657, acc: 0.494141]  [A loss: 0.860021, acc: 0.183594]\n",
            "6307: [D loss: 0.704230, acc: 0.542969]  [A loss: 0.720645, acc: 0.468750]\n",
            "6308: [D loss: 0.723217, acc: 0.519531]  [A loss: 0.902903, acc: 0.109375]\n",
            "6309: [D loss: 0.710327, acc: 0.511719]  [A loss: 0.733910, acc: 0.437500]\n",
            "6310: [D loss: 0.725951, acc: 0.474609]  [A loss: 0.850797, acc: 0.164062]\n",
            "6311: [D loss: 0.704411, acc: 0.519531]  [A loss: 0.770781, acc: 0.312500]\n",
            "6312: [D loss: 0.715790, acc: 0.494141]  [A loss: 0.817931, acc: 0.246094]\n",
            "6313: [D loss: 0.702288, acc: 0.503906]  [A loss: 0.793560, acc: 0.246094]\n",
            "6314: [D loss: 0.687642, acc: 0.539062]  [A loss: 0.853487, acc: 0.210938]\n",
            "6315: [D loss: 0.699354, acc: 0.519531]  [A loss: 0.752692, acc: 0.390625]\n",
            "6316: [D loss: 0.702631, acc: 0.511719]  [A loss: 0.880417, acc: 0.183594]\n",
            "6317: [D loss: 0.683357, acc: 0.548828]  [A loss: 0.685627, acc: 0.542969]\n",
            "6318: [D loss: 0.715279, acc: 0.503906]  [A loss: 0.871578, acc: 0.148438]\n",
            "6319: [D loss: 0.703339, acc: 0.492188]  [A loss: 0.776305, acc: 0.343750]\n",
            "6320: [D loss: 0.708849, acc: 0.486328]  [A loss: 0.860921, acc: 0.179688]\n",
            "6321: [D loss: 0.702932, acc: 0.513672]  [A loss: 0.779222, acc: 0.332031]\n",
            "6322: [D loss: 0.717125, acc: 0.482422]  [A loss: 0.857142, acc: 0.144531]\n",
            "6323: [D loss: 0.701346, acc: 0.529297]  [A loss: 0.812380, acc: 0.253906]\n",
            "6324: [D loss: 0.706280, acc: 0.546875]  [A loss: 0.955453, acc: 0.082031]\n",
            "6325: [D loss: 0.698103, acc: 0.529297]  [A loss: 0.712747, acc: 0.460938]\n",
            "6326: [D loss: 0.721121, acc: 0.505859]  [A loss: 1.012748, acc: 0.062500]\n",
            "6327: [D loss: 0.706626, acc: 0.519531]  [A loss: 0.648636, acc: 0.609375]\n",
            "6328: [D loss: 0.720791, acc: 0.507812]  [A loss: 0.957077, acc: 0.082031]\n",
            "6329: [D loss: 0.702678, acc: 0.482422]  [A loss: 0.734021, acc: 0.460938]\n",
            "6330: [D loss: 0.734727, acc: 0.484375]  [A loss: 0.918594, acc: 0.105469]\n",
            "6331: [D loss: 0.699953, acc: 0.503906]  [A loss: 0.729475, acc: 0.429688]\n",
            "6332: [D loss: 0.702318, acc: 0.552734]  [A loss: 0.912997, acc: 0.125000]\n",
            "6333: [D loss: 0.705737, acc: 0.503906]  [A loss: 0.706293, acc: 0.476562]\n",
            "6334: [D loss: 0.704010, acc: 0.511719]  [A loss: 0.836306, acc: 0.226562]\n",
            "6335: [D loss: 0.691877, acc: 0.544922]  [A loss: 0.713366, acc: 0.464844]\n",
            "6336: [D loss: 0.720174, acc: 0.486328]  [A loss: 0.867300, acc: 0.171875]\n",
            "6337: [D loss: 0.683006, acc: 0.558594]  [A loss: 0.711458, acc: 0.503906]\n",
            "6338: [D loss: 0.723174, acc: 0.521484]  [A loss: 0.947481, acc: 0.085938]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6339: [D loss: 0.706725, acc: 0.509766]  [A loss: 0.704789, acc: 0.507812]\n",
            "6340: [D loss: 0.719362, acc: 0.490234]  [A loss: 0.894254, acc: 0.121094]\n",
            "6341: [D loss: 0.681675, acc: 0.554688]  [A loss: 0.767124, acc: 0.347656]\n",
            "6342: [D loss: 0.697988, acc: 0.519531]  [A loss: 0.874755, acc: 0.167969]\n",
            "6343: [D loss: 0.705820, acc: 0.490234]  [A loss: 0.711490, acc: 0.457031]\n",
            "6344: [D loss: 0.712247, acc: 0.521484]  [A loss: 0.851700, acc: 0.214844]\n",
            "6345: [D loss: 0.691031, acc: 0.507812]  [A loss: 0.760817, acc: 0.367188]\n",
            "6346: [D loss: 0.708421, acc: 0.519531]  [A loss: 0.818214, acc: 0.261719]\n",
            "6347: [D loss: 0.690879, acc: 0.542969]  [A loss: 0.756412, acc: 0.375000]\n",
            "6348: [D loss: 0.712509, acc: 0.509766]  [A loss: 0.813632, acc: 0.230469]\n",
            "6349: [D loss: 0.697793, acc: 0.531250]  [A loss: 0.781349, acc: 0.296875]\n",
            "6350: [D loss: 0.695472, acc: 0.501953]  [A loss: 0.802941, acc: 0.300781]\n",
            "6351: [D loss: 0.699002, acc: 0.539062]  [A loss: 0.819595, acc: 0.265625]\n",
            "6352: [D loss: 0.689484, acc: 0.548828]  [A loss: 0.769982, acc: 0.304688]\n",
            "6353: [D loss: 0.707990, acc: 0.478516]  [A loss: 0.907682, acc: 0.136719]\n",
            "6354: [D loss: 0.697338, acc: 0.541016]  [A loss: 0.756717, acc: 0.386719]\n",
            "6355: [D loss: 0.718286, acc: 0.496094]  [A loss: 0.931073, acc: 0.128906]\n",
            "6356: [D loss: 0.707742, acc: 0.478516]  [A loss: 0.761622, acc: 0.335938]\n",
            "6357: [D loss: 0.707458, acc: 0.517578]  [A loss: 0.934098, acc: 0.101562]\n",
            "6358: [D loss: 0.709691, acc: 0.494141]  [A loss: 0.701852, acc: 0.496094]\n",
            "6359: [D loss: 0.727178, acc: 0.501953]  [A loss: 0.945155, acc: 0.082031]\n",
            "6360: [D loss: 0.703029, acc: 0.500000]  [A loss: 0.730544, acc: 0.425781]\n",
            "6361: [D loss: 0.729909, acc: 0.494141]  [A loss: 1.051955, acc: 0.027344]\n",
            "6362: [D loss: 0.703148, acc: 0.517578]  [A loss: 0.698726, acc: 0.496094]\n",
            "6363: [D loss: 0.714832, acc: 0.509766]  [A loss: 0.875470, acc: 0.183594]\n",
            "6364: [D loss: 0.701506, acc: 0.511719]  [A loss: 0.747602, acc: 0.433594]\n",
            "6365: [D loss: 0.711139, acc: 0.498047]  [A loss: 0.832534, acc: 0.242188]\n",
            "6366: [D loss: 0.718121, acc: 0.462891]  [A loss: 0.752011, acc: 0.367188]\n",
            "6367: [D loss: 0.703358, acc: 0.531250]  [A loss: 0.906050, acc: 0.121094]\n",
            "6368: [D loss: 0.697880, acc: 0.507812]  [A loss: 0.762698, acc: 0.339844]\n",
            "6369: [D loss: 0.698289, acc: 0.541016]  [A loss: 0.875385, acc: 0.148438]\n",
            "6370: [D loss: 0.705762, acc: 0.527344]  [A loss: 0.815536, acc: 0.261719]\n",
            "6371: [D loss: 0.712806, acc: 0.498047]  [A loss: 0.847933, acc: 0.175781]\n",
            "6372: [D loss: 0.697178, acc: 0.533203]  [A loss: 0.808100, acc: 0.277344]\n",
            "6373: [D loss: 0.704856, acc: 0.517578]  [A loss: 0.859590, acc: 0.171875]\n",
            "6374: [D loss: 0.700896, acc: 0.501953]  [A loss: 0.752848, acc: 0.371094]\n",
            "6375: [D loss: 0.711751, acc: 0.513672]  [A loss: 0.942283, acc: 0.113281]\n",
            "6376: [D loss: 0.698657, acc: 0.525391]  [A loss: 0.705039, acc: 0.484375]\n",
            "6377: [D loss: 0.711721, acc: 0.511719]  [A loss: 0.966509, acc: 0.074219]\n",
            "6378: [D loss: 0.700700, acc: 0.517578]  [A loss: 0.644807, acc: 0.656250]\n",
            "6379: [D loss: 0.709275, acc: 0.517578]  [A loss: 0.950364, acc: 0.082031]\n",
            "6380: [D loss: 0.691818, acc: 0.546875]  [A loss: 0.724295, acc: 0.433594]\n",
            "6381: [D loss: 0.714107, acc: 0.496094]  [A loss: 0.874257, acc: 0.156250]\n",
            "6382: [D loss: 0.704187, acc: 0.507812]  [A loss: 0.698094, acc: 0.531250]\n",
            "6383: [D loss: 0.718568, acc: 0.501953]  [A loss: 0.914047, acc: 0.121094]\n",
            "6384: [D loss: 0.693343, acc: 0.535156]  [A loss: 0.703330, acc: 0.480469]\n",
            "6385: [D loss: 0.709017, acc: 0.488281]  [A loss: 0.891056, acc: 0.121094]\n",
            "6386: [D loss: 0.700565, acc: 0.488281]  [A loss: 0.752456, acc: 0.394531]\n",
            "6387: [D loss: 0.719318, acc: 0.470703]  [A loss: 0.856884, acc: 0.171875]\n",
            "6388: [D loss: 0.689983, acc: 0.541016]  [A loss: 0.735232, acc: 0.429688]\n",
            "6389: [D loss: 0.696830, acc: 0.511719]  [A loss: 0.893849, acc: 0.136719]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6390: [D loss: 0.692190, acc: 0.550781]  [A loss: 0.720830, acc: 0.457031]\n",
            "6391: [D loss: 0.708075, acc: 0.496094]  [A loss: 0.913219, acc: 0.093750]\n",
            "6392: [D loss: 0.712900, acc: 0.484375]  [A loss: 0.738503, acc: 0.402344]\n",
            "6393: [D loss: 0.713046, acc: 0.498047]  [A loss: 0.926033, acc: 0.097656]\n",
            "6394: [D loss: 0.686752, acc: 0.550781]  [A loss: 0.716919, acc: 0.457031]\n",
            "6395: [D loss: 0.732355, acc: 0.476562]  [A loss: 0.909177, acc: 0.089844]\n",
            "6396: [D loss: 0.697047, acc: 0.537109]  [A loss: 0.757523, acc: 0.378906]\n",
            "6397: [D loss: 0.702306, acc: 0.527344]  [A loss: 0.948089, acc: 0.128906]\n",
            "6398: [D loss: 0.700155, acc: 0.527344]  [A loss: 0.689874, acc: 0.558594]\n",
            "6399: [D loss: 0.721715, acc: 0.505859]  [A loss: 0.889718, acc: 0.160156]\n",
            "6400: [D loss: 0.701487, acc: 0.507812]  [A loss: 0.728182, acc: 0.433594]\n",
            "6401: [D loss: 0.698450, acc: 0.515625]  [A loss: 0.918649, acc: 0.113281]\n",
            "6402: [D loss: 0.702705, acc: 0.503906]  [A loss: 0.699175, acc: 0.476562]\n",
            "6403: [D loss: 0.713990, acc: 0.513672]  [A loss: 0.891792, acc: 0.121094]\n",
            "6404: [D loss: 0.693146, acc: 0.511719]  [A loss: 0.688457, acc: 0.507812]\n",
            "6405: [D loss: 0.697059, acc: 0.544922]  [A loss: 0.941240, acc: 0.089844]\n",
            "6406: [D loss: 0.698421, acc: 0.513672]  [A loss: 0.680249, acc: 0.609375]\n",
            "6407: [D loss: 0.726339, acc: 0.484375]  [A loss: 0.910384, acc: 0.132812]\n",
            "6408: [D loss: 0.692908, acc: 0.521484]  [A loss: 0.691693, acc: 0.492188]\n",
            "6409: [D loss: 0.712457, acc: 0.488281]  [A loss: 0.880270, acc: 0.175781]\n",
            "6410: [D loss: 0.682146, acc: 0.570312]  [A loss: 0.700673, acc: 0.511719]\n",
            "6411: [D loss: 0.706622, acc: 0.527344]  [A loss: 0.873080, acc: 0.171875]\n",
            "6412: [D loss: 0.697561, acc: 0.529297]  [A loss: 0.776335, acc: 0.359375]\n",
            "6413: [D loss: 0.704154, acc: 0.519531]  [A loss: 0.823184, acc: 0.246094]\n",
            "6414: [D loss: 0.702733, acc: 0.527344]  [A loss: 0.767521, acc: 0.332031]\n",
            "6415: [D loss: 0.696555, acc: 0.515625]  [A loss: 0.829837, acc: 0.210938]\n",
            "6416: [D loss: 0.699586, acc: 0.507812]  [A loss: 0.813626, acc: 0.273438]\n",
            "6417: [D loss: 0.701336, acc: 0.554688]  [A loss: 0.830376, acc: 0.210938]\n",
            "6418: [D loss: 0.708003, acc: 0.472656]  [A loss: 0.791275, acc: 0.300781]\n",
            "6419: [D loss: 0.709283, acc: 0.500000]  [A loss: 0.907237, acc: 0.121094]\n",
            "6420: [D loss: 0.695245, acc: 0.537109]  [A loss: 0.720928, acc: 0.433594]\n",
            "6421: [D loss: 0.697913, acc: 0.531250]  [A loss: 0.891689, acc: 0.140625]\n",
            "6422: [D loss: 0.703392, acc: 0.501953]  [A loss: 0.731505, acc: 0.421875]\n",
            "6423: [D loss: 0.723250, acc: 0.488281]  [A loss: 0.944549, acc: 0.074219]\n",
            "6424: [D loss: 0.707305, acc: 0.500000]  [A loss: 0.695604, acc: 0.531250]\n",
            "6425: [D loss: 0.721236, acc: 0.503906]  [A loss: 0.921813, acc: 0.078125]\n",
            "6426: [D loss: 0.693187, acc: 0.521484]  [A loss: 0.754948, acc: 0.378906]\n",
            "6427: [D loss: 0.711931, acc: 0.509766]  [A loss: 0.851245, acc: 0.187500]\n",
            "6428: [D loss: 0.708912, acc: 0.480469]  [A loss: 0.821072, acc: 0.238281]\n",
            "6429: [D loss: 0.706502, acc: 0.484375]  [A loss: 0.794063, acc: 0.285156]\n",
            "6430: [D loss: 0.702214, acc: 0.501953]  [A loss: 0.881345, acc: 0.121094]\n",
            "6431: [D loss: 0.697163, acc: 0.517578]  [A loss: 0.734502, acc: 0.390625]\n",
            "6432: [D loss: 0.705447, acc: 0.537109]  [A loss: 0.931939, acc: 0.132812]\n",
            "6433: [D loss: 0.692393, acc: 0.539062]  [A loss: 0.714715, acc: 0.488281]\n",
            "6434: [D loss: 0.714584, acc: 0.482422]  [A loss: 0.885268, acc: 0.140625]\n",
            "6435: [D loss: 0.697440, acc: 0.501953]  [A loss: 0.702522, acc: 0.480469]\n",
            "6436: [D loss: 0.705707, acc: 0.513672]  [A loss: 0.948903, acc: 0.070312]\n",
            "6437: [D loss: 0.699853, acc: 0.539062]  [A loss: 0.708091, acc: 0.570312]\n",
            "6438: [D loss: 0.710328, acc: 0.519531]  [A loss: 0.932697, acc: 0.101562]\n",
            "6439: [D loss: 0.704578, acc: 0.484375]  [A loss: 0.744988, acc: 0.421875]\n",
            "6440: [D loss: 0.719954, acc: 0.490234]  [A loss: 0.890491, acc: 0.125000]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6441: [D loss: 0.696534, acc: 0.519531]  [A loss: 0.710100, acc: 0.492188]\n",
            "6442: [D loss: 0.727711, acc: 0.492188]  [A loss: 0.914684, acc: 0.089844]\n",
            "6443: [D loss: 0.690465, acc: 0.533203]  [A loss: 0.706291, acc: 0.519531]\n",
            "6444: [D loss: 0.709971, acc: 0.472656]  [A loss: 0.885944, acc: 0.140625]\n",
            "6445: [D loss: 0.701084, acc: 0.521484]  [A loss: 0.741824, acc: 0.414062]\n",
            "6446: [D loss: 0.703987, acc: 0.509766]  [A loss: 0.821606, acc: 0.214844]\n",
            "6447: [D loss: 0.701052, acc: 0.519531]  [A loss: 0.774380, acc: 0.363281]\n",
            "6448: [D loss: 0.707677, acc: 0.496094]  [A loss: 0.836960, acc: 0.195312]\n",
            "6449: [D loss: 0.697423, acc: 0.552734]  [A loss: 0.762846, acc: 0.308594]\n",
            "6450: [D loss: 0.696871, acc: 0.541016]  [A loss: 0.834866, acc: 0.160156]\n",
            "6451: [D loss: 0.679298, acc: 0.587891]  [A loss: 0.850704, acc: 0.183594]\n",
            "6452: [D loss: 0.700609, acc: 0.509766]  [A loss: 0.777849, acc: 0.328125]\n",
            "6453: [D loss: 0.701076, acc: 0.521484]  [A loss: 0.904894, acc: 0.128906]\n",
            "6454: [D loss: 0.700052, acc: 0.507812]  [A loss: 0.709440, acc: 0.476562]\n",
            "6455: [D loss: 0.713640, acc: 0.527344]  [A loss: 0.890176, acc: 0.128906]\n",
            "6456: [D loss: 0.700881, acc: 0.490234]  [A loss: 0.743644, acc: 0.394531]\n",
            "6457: [D loss: 0.701064, acc: 0.486328]  [A loss: 0.867011, acc: 0.148438]\n",
            "6458: [D loss: 0.700572, acc: 0.531250]  [A loss: 0.750538, acc: 0.378906]\n",
            "6459: [D loss: 0.709123, acc: 0.515625]  [A loss: 0.813765, acc: 0.218750]\n",
            "6460: [D loss: 0.707085, acc: 0.531250]  [A loss: 0.891769, acc: 0.164062]\n",
            "6461: [D loss: 0.706447, acc: 0.513672]  [A loss: 0.714245, acc: 0.480469]\n",
            "6462: [D loss: 0.715961, acc: 0.523438]  [A loss: 0.921652, acc: 0.082031]\n",
            "6463: [D loss: 0.703252, acc: 0.490234]  [A loss: 0.676399, acc: 0.609375]\n",
            "6464: [D loss: 0.735218, acc: 0.511719]  [A loss: 0.958174, acc: 0.031250]\n",
            "6465: [D loss: 0.696327, acc: 0.507812]  [A loss: 0.726442, acc: 0.472656]\n",
            "6466: [D loss: 0.720427, acc: 0.500000]  [A loss: 0.873363, acc: 0.113281]\n",
            "6467: [D loss: 0.702522, acc: 0.500000]  [A loss: 0.748895, acc: 0.406250]\n",
            "6468: [D loss: 0.711804, acc: 0.507812]  [A loss: 0.922790, acc: 0.082031]\n",
            "6469: [D loss: 0.696122, acc: 0.523438]  [A loss: 0.699021, acc: 0.523438]\n",
            "6470: [D loss: 0.718621, acc: 0.517578]  [A loss: 0.931087, acc: 0.121094]\n",
            "6471: [D loss: 0.705818, acc: 0.457031]  [A loss: 0.706771, acc: 0.523438]\n",
            "6472: [D loss: 0.722154, acc: 0.498047]  [A loss: 0.876777, acc: 0.140625]\n",
            "6473: [D loss: 0.701357, acc: 0.507812]  [A loss: 0.778474, acc: 0.281250]\n",
            "6474: [D loss: 0.703090, acc: 0.507812]  [A loss: 0.849312, acc: 0.179688]\n",
            "6475: [D loss: 0.701653, acc: 0.509766]  [A loss: 0.762099, acc: 0.351562]\n",
            "6476: [D loss: 0.702273, acc: 0.513672]  [A loss: 0.874288, acc: 0.125000]\n",
            "6477: [D loss: 0.699887, acc: 0.498047]  [A loss: 0.768266, acc: 0.320312]\n",
            "6478: [D loss: 0.700198, acc: 0.525391]  [A loss: 0.850861, acc: 0.195312]\n",
            "6479: [D loss: 0.700497, acc: 0.509766]  [A loss: 0.811079, acc: 0.230469]\n",
            "6480: [D loss: 0.695260, acc: 0.535156]  [A loss: 0.835593, acc: 0.187500]\n",
            "6481: [D loss: 0.704426, acc: 0.501953]  [A loss: 0.743460, acc: 0.402344]\n",
            "6482: [D loss: 0.710419, acc: 0.466797]  [A loss: 0.894904, acc: 0.105469]\n",
            "6483: [D loss: 0.700374, acc: 0.498047]  [A loss: 0.707642, acc: 0.500000]\n",
            "6484: [D loss: 0.705833, acc: 0.521484]  [A loss: 0.876531, acc: 0.125000]\n",
            "6485: [D loss: 0.691862, acc: 0.505859]  [A loss: 0.776621, acc: 0.300781]\n",
            "6486: [D loss: 0.704666, acc: 0.517578]  [A loss: 0.886421, acc: 0.121094]\n",
            "6487: [D loss: 0.700172, acc: 0.500000]  [A loss: 0.737873, acc: 0.386719]\n",
            "6488: [D loss: 0.714750, acc: 0.478516]  [A loss: 0.903564, acc: 0.125000]\n",
            "6489: [D loss: 0.697786, acc: 0.519531]  [A loss: 0.714946, acc: 0.464844]\n",
            "6490: [D loss: 0.719893, acc: 0.513672]  [A loss: 0.875793, acc: 0.113281]\n",
            "6491: [D loss: 0.682170, acc: 0.554688]  [A loss: 0.745988, acc: 0.410156]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6492: [D loss: 0.705109, acc: 0.521484]  [A loss: 0.812310, acc: 0.222656]\n",
            "6493: [D loss: 0.688123, acc: 0.544922]  [A loss: 0.780743, acc: 0.296875]\n",
            "6494: [D loss: 0.696519, acc: 0.531250]  [A loss: 0.813408, acc: 0.238281]\n",
            "6495: [D loss: 0.699767, acc: 0.507812]  [A loss: 0.772946, acc: 0.324219]\n",
            "6496: [D loss: 0.698716, acc: 0.507812]  [A loss: 0.920749, acc: 0.121094]\n",
            "6497: [D loss: 0.692043, acc: 0.552734]  [A loss: 0.733933, acc: 0.402344]\n",
            "6498: [D loss: 0.702389, acc: 0.546875]  [A loss: 0.956434, acc: 0.089844]\n",
            "6499: [D loss: 0.703875, acc: 0.494141]  [A loss: 0.689737, acc: 0.550781]\n",
            "6500: [D loss: 0.716488, acc: 0.519531]  [A loss: 0.919577, acc: 0.097656]\n",
            "6501: [D loss: 0.692907, acc: 0.515625]  [A loss: 0.711230, acc: 0.457031]\n",
            "6502: [D loss: 0.712623, acc: 0.513672]  [A loss: 0.878514, acc: 0.148438]\n",
            "6503: [D loss: 0.703373, acc: 0.515625]  [A loss: 0.841366, acc: 0.187500]\n",
            "6504: [D loss: 0.699371, acc: 0.517578]  [A loss: 0.758429, acc: 0.375000]\n",
            "6505: [D loss: 0.705236, acc: 0.496094]  [A loss: 0.806810, acc: 0.234375]\n",
            "6506: [D loss: 0.699717, acc: 0.525391]  [A loss: 0.826158, acc: 0.242188]\n",
            "6507: [D loss: 0.698861, acc: 0.521484]  [A loss: 0.773713, acc: 0.316406]\n",
            "6508: [D loss: 0.700053, acc: 0.519531]  [A loss: 0.819746, acc: 0.242188]\n",
            "6509: [D loss: 0.707132, acc: 0.496094]  [A loss: 0.823928, acc: 0.226562]\n",
            "6510: [D loss: 0.694642, acc: 0.541016]  [A loss: 0.839482, acc: 0.203125]\n",
            "6511: [D loss: 0.699968, acc: 0.533203]  [A loss: 0.818619, acc: 0.246094]\n",
            "6512: [D loss: 0.705741, acc: 0.529297]  [A loss: 0.807886, acc: 0.261719]\n",
            "6513: [D loss: 0.699344, acc: 0.505859]  [A loss: 0.853764, acc: 0.160156]\n",
            "6514: [D loss: 0.694046, acc: 0.523438]  [A loss: 0.775866, acc: 0.300781]\n",
            "6515: [D loss: 0.693597, acc: 0.531250]  [A loss: 0.823940, acc: 0.230469]\n",
            "6516: [D loss: 0.690393, acc: 0.552734]  [A loss: 0.731785, acc: 0.421875]\n",
            "6517: [D loss: 0.687592, acc: 0.548828]  [A loss: 0.895829, acc: 0.140625]\n",
            "6518: [D loss: 0.697420, acc: 0.521484]  [A loss: 0.678252, acc: 0.554688]\n",
            "6519: [D loss: 0.718191, acc: 0.511719]  [A loss: 0.947589, acc: 0.093750]\n",
            "6520: [D loss: 0.700420, acc: 0.525391]  [A loss: 0.684801, acc: 0.539062]\n",
            "6521: [D loss: 0.710503, acc: 0.513672]  [A loss: 0.921272, acc: 0.097656]\n",
            "6522: [D loss: 0.709431, acc: 0.484375]  [A loss: 0.766284, acc: 0.339844]\n",
            "6523: [D loss: 0.705247, acc: 0.500000]  [A loss: 0.825806, acc: 0.222656]\n",
            "6524: [D loss: 0.687079, acc: 0.529297]  [A loss: 0.812209, acc: 0.238281]\n",
            "6525: [D loss: 0.696068, acc: 0.535156]  [A loss: 0.730446, acc: 0.406250]\n",
            "6526: [D loss: 0.705680, acc: 0.515625]  [A loss: 0.932164, acc: 0.082031]\n",
            "6527: [D loss: 0.707057, acc: 0.509766]  [A loss: 0.677776, acc: 0.585938]\n",
            "6528: [D loss: 0.727557, acc: 0.484375]  [A loss: 0.956431, acc: 0.050781]\n",
            "6529: [D loss: 0.695551, acc: 0.541016]  [A loss: 0.736325, acc: 0.425781]\n",
            "6530: [D loss: 0.703685, acc: 0.531250]  [A loss: 0.974730, acc: 0.042969]\n",
            "6531: [D loss: 0.695698, acc: 0.525391]  [A loss: 0.650276, acc: 0.648438]\n",
            "6532: [D loss: 0.717312, acc: 0.503906]  [A loss: 0.916929, acc: 0.085938]\n",
            "6533: [D loss: 0.696970, acc: 0.531250]  [A loss: 0.729390, acc: 0.429688]\n",
            "6534: [D loss: 0.705412, acc: 0.523438]  [A loss: 0.847690, acc: 0.132812]\n",
            "6535: [D loss: 0.687742, acc: 0.517578]  [A loss: 0.720582, acc: 0.425781]\n",
            "6536: [D loss: 0.696878, acc: 0.519531]  [A loss: 0.853655, acc: 0.167969]\n",
            "6537: [D loss: 0.696270, acc: 0.517578]  [A loss: 0.811066, acc: 0.246094]\n",
            "6538: [D loss: 0.689497, acc: 0.533203]  [A loss: 0.789226, acc: 0.292969]\n",
            "6539: [D loss: 0.698112, acc: 0.529297]  [A loss: 0.769755, acc: 0.304688]\n",
            "6540: [D loss: 0.692298, acc: 0.548828]  [A loss: 0.809614, acc: 0.261719]\n",
            "6541: [D loss: 0.702539, acc: 0.498047]  [A loss: 0.795580, acc: 0.324219]\n",
            "6542: [D loss: 0.701000, acc: 0.529297]  [A loss: 0.822095, acc: 0.253906]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6543: [D loss: 0.692016, acc: 0.523438]  [A loss: 0.767610, acc: 0.355469]\n",
            "6544: [D loss: 0.701829, acc: 0.533203]  [A loss: 0.932694, acc: 0.085938]\n",
            "6545: [D loss: 0.700038, acc: 0.519531]  [A loss: 0.678857, acc: 0.589844]\n",
            "6546: [D loss: 0.713782, acc: 0.525391]  [A loss: 0.935527, acc: 0.078125]\n",
            "6547: [D loss: 0.700917, acc: 0.498047]  [A loss: 0.658088, acc: 0.617188]\n",
            "6548: [D loss: 0.720674, acc: 0.500000]  [A loss: 0.920695, acc: 0.121094]\n",
            "6549: [D loss: 0.702113, acc: 0.519531]  [A loss: 0.732711, acc: 0.429688]\n",
            "6550: [D loss: 0.703141, acc: 0.527344]  [A loss: 0.847354, acc: 0.148438]\n",
            "6551: [D loss: 0.693376, acc: 0.548828]  [A loss: 0.729119, acc: 0.433594]\n",
            "6552: [D loss: 0.718613, acc: 0.482422]  [A loss: 0.915764, acc: 0.132812]\n",
            "6553: [D loss: 0.696538, acc: 0.517578]  [A loss: 0.738910, acc: 0.410156]\n",
            "6554: [D loss: 0.701771, acc: 0.521484]  [A loss: 0.802688, acc: 0.269531]\n",
            "6555: [D loss: 0.697925, acc: 0.531250]  [A loss: 0.784134, acc: 0.308594]\n",
            "6556: [D loss: 0.713681, acc: 0.480469]  [A loss: 0.801727, acc: 0.261719]\n",
            "6557: [D loss: 0.703877, acc: 0.505859]  [A loss: 0.893410, acc: 0.113281]\n",
            "6558: [D loss: 0.703973, acc: 0.503906]  [A loss: 0.735250, acc: 0.414062]\n",
            "6559: [D loss: 0.706498, acc: 0.515625]  [A loss: 0.884917, acc: 0.125000]\n",
            "6560: [D loss: 0.699500, acc: 0.515625]  [A loss: 0.732568, acc: 0.417969]\n",
            "6561: [D loss: 0.708211, acc: 0.507812]  [A loss: 0.933345, acc: 0.093750]\n",
            "6562: [D loss: 0.693120, acc: 0.542969]  [A loss: 0.725594, acc: 0.402344]\n",
            "6563: [D loss: 0.708843, acc: 0.501953]  [A loss: 0.868907, acc: 0.152344]\n",
            "6564: [D loss: 0.698136, acc: 0.509766]  [A loss: 0.781746, acc: 0.289062]\n",
            "6565: [D loss: 0.699062, acc: 0.533203]  [A loss: 0.749602, acc: 0.382812]\n",
            "6566: [D loss: 0.705490, acc: 0.509766]  [A loss: 0.918995, acc: 0.109375]\n",
            "6567: [D loss: 0.702261, acc: 0.503906]  [A loss: 0.697712, acc: 0.511719]\n",
            "6568: [D loss: 0.710510, acc: 0.517578]  [A loss: 0.912520, acc: 0.109375]\n",
            "6569: [D loss: 0.696763, acc: 0.517578]  [A loss: 0.734275, acc: 0.468750]\n",
            "6570: [D loss: 0.707642, acc: 0.503906]  [A loss: 0.902695, acc: 0.089844]\n",
            "6571: [D loss: 0.698453, acc: 0.500000]  [A loss: 0.722795, acc: 0.449219]\n",
            "6572: [D loss: 0.716843, acc: 0.488281]  [A loss: 0.943258, acc: 0.078125]\n",
            "6573: [D loss: 0.693406, acc: 0.542969]  [A loss: 0.695229, acc: 0.503906]\n",
            "6574: [D loss: 0.710571, acc: 0.525391]  [A loss: 0.894095, acc: 0.109375]\n",
            "6575: [D loss: 0.705172, acc: 0.496094]  [A loss: 0.706011, acc: 0.500000]\n",
            "6576: [D loss: 0.714323, acc: 0.511719]  [A loss: 0.857245, acc: 0.136719]\n",
            "6577: [D loss: 0.704623, acc: 0.486328]  [A loss: 0.733718, acc: 0.433594]\n",
            "6578: [D loss: 0.710544, acc: 0.513672]  [A loss: 0.860821, acc: 0.152344]\n",
            "6579: [D loss: 0.701277, acc: 0.496094]  [A loss: 0.724804, acc: 0.429688]\n",
            "6580: [D loss: 0.707496, acc: 0.525391]  [A loss: 0.847638, acc: 0.207031]\n",
            "6581: [D loss: 0.703311, acc: 0.515625]  [A loss: 0.780813, acc: 0.308594]\n",
            "6582: [D loss: 0.701996, acc: 0.519531]  [A loss: 0.790259, acc: 0.281250]\n",
            "6583: [D loss: 0.699533, acc: 0.519531]  [A loss: 0.779933, acc: 0.324219]\n",
            "6584: [D loss: 0.704209, acc: 0.515625]  [A loss: 0.814593, acc: 0.230469]\n",
            "6585: [D loss: 0.697723, acc: 0.521484]  [A loss: 0.745421, acc: 0.398438]\n",
            "6586: [D loss: 0.707487, acc: 0.501953]  [A loss: 0.840729, acc: 0.179688]\n",
            "6587: [D loss: 0.705382, acc: 0.501953]  [A loss: 0.777267, acc: 0.320312]\n",
            "6588: [D loss: 0.698058, acc: 0.521484]  [A loss: 0.809209, acc: 0.253906]\n",
            "6589: [D loss: 0.685326, acc: 0.552734]  [A loss: 0.814539, acc: 0.230469]\n",
            "6590: [D loss: 0.696559, acc: 0.521484]  [A loss: 0.836061, acc: 0.187500]\n",
            "6591: [D loss: 0.700251, acc: 0.509766]  [A loss: 0.811587, acc: 0.203125]\n",
            "6592: [D loss: 0.707954, acc: 0.486328]  [A loss: 0.818854, acc: 0.167969]\n",
            "6593: [D loss: 0.680786, acc: 0.566406]  [A loss: 0.779925, acc: 0.296875]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6594: [D loss: 0.706092, acc: 0.501953]  [A loss: 0.806055, acc: 0.261719]\n",
            "6595: [D loss: 0.703458, acc: 0.527344]  [A loss: 0.861567, acc: 0.132812]\n",
            "6596: [D loss: 0.695026, acc: 0.521484]  [A loss: 0.700001, acc: 0.476562]\n",
            "6597: [D loss: 0.738635, acc: 0.484375]  [A loss: 0.916571, acc: 0.082031]\n",
            "6598: [D loss: 0.697034, acc: 0.535156]  [A loss: 0.840400, acc: 0.218750]\n",
            "6599: [D loss: 0.704310, acc: 0.503906]  [A loss: 0.872737, acc: 0.125000]\n",
            "6600: [D loss: 0.685494, acc: 0.552734]  [A loss: 0.686120, acc: 0.550781]\n",
            "6601: [D loss: 0.712334, acc: 0.527344]  [A loss: 0.932722, acc: 0.085938]\n",
            "6602: [D loss: 0.694842, acc: 0.558594]  [A loss: 0.670006, acc: 0.578125]\n",
            "6603: [D loss: 0.730381, acc: 0.478516]  [A loss: 0.951363, acc: 0.070312]\n",
            "6604: [D loss: 0.693412, acc: 0.546875]  [A loss: 0.716934, acc: 0.449219]\n",
            "6605: [D loss: 0.721976, acc: 0.496094]  [A loss: 0.929308, acc: 0.074219]\n",
            "6606: [D loss: 0.709783, acc: 0.500000]  [A loss: 0.756235, acc: 0.351562]\n",
            "6607: [D loss: 0.700922, acc: 0.517578]  [A loss: 0.832393, acc: 0.234375]\n",
            "6608: [D loss: 0.708188, acc: 0.513672]  [A loss: 0.742259, acc: 0.367188]\n",
            "6609: [D loss: 0.696919, acc: 0.509766]  [A loss: 0.829307, acc: 0.218750]\n",
            "6610: [D loss: 0.702925, acc: 0.539062]  [A loss: 0.787026, acc: 0.273438]\n",
            "6611: [D loss: 0.702539, acc: 0.537109]  [A loss: 0.818510, acc: 0.226562]\n",
            "6612: [D loss: 0.687046, acc: 0.564453]  [A loss: 0.766756, acc: 0.332031]\n",
            "6613: [D loss: 0.703148, acc: 0.542969]  [A loss: 0.839136, acc: 0.199219]\n",
            "6614: [D loss: 0.698012, acc: 0.535156]  [A loss: 0.780762, acc: 0.335938]\n",
            "6615: [D loss: 0.699627, acc: 0.529297]  [A loss: 0.881042, acc: 0.128906]\n",
            "6616: [D loss: 0.694116, acc: 0.560547]  [A loss: 0.751485, acc: 0.394531]\n",
            "6617: [D loss: 0.700310, acc: 0.544922]  [A loss: 0.922375, acc: 0.085938]\n",
            "6618: [D loss: 0.696781, acc: 0.541016]  [A loss: 0.711250, acc: 0.492188]\n",
            "6619: [D loss: 0.715182, acc: 0.498047]  [A loss: 0.934617, acc: 0.085938]\n",
            "6620: [D loss: 0.697112, acc: 0.513672]  [A loss: 0.688190, acc: 0.542969]\n",
            "6621: [D loss: 0.716134, acc: 0.511719]  [A loss: 0.908684, acc: 0.085938]\n",
            "6622: [D loss: 0.681703, acc: 0.544922]  [A loss: 0.760784, acc: 0.359375]\n",
            "6623: [D loss: 0.696001, acc: 0.500000]  [A loss: 0.876931, acc: 0.171875]\n",
            "6624: [D loss: 0.702062, acc: 0.511719]  [A loss: 0.732612, acc: 0.414062]\n",
            "6625: [D loss: 0.709313, acc: 0.519531]  [A loss: 0.875615, acc: 0.140625]\n",
            "6626: [D loss: 0.689557, acc: 0.521484]  [A loss: 0.760267, acc: 0.378906]\n",
            "6627: [D loss: 0.700871, acc: 0.533203]  [A loss: 0.769823, acc: 0.304688]\n",
            "6628: [D loss: 0.703118, acc: 0.492188]  [A loss: 0.783256, acc: 0.289062]\n",
            "6629: [D loss: 0.688937, acc: 0.550781]  [A loss: 0.814120, acc: 0.246094]\n",
            "6630: [D loss: 0.710098, acc: 0.503906]  [A loss: 0.811125, acc: 0.250000]\n",
            "6631: [D loss: 0.711243, acc: 0.509766]  [A loss: 0.782037, acc: 0.277344]\n",
            "6632: [D loss: 0.704388, acc: 0.490234]  [A loss: 0.795911, acc: 0.242188]\n",
            "6633: [D loss: 0.701350, acc: 0.517578]  [A loss: 0.871730, acc: 0.148438]\n",
            "6634: [D loss: 0.701258, acc: 0.513672]  [A loss: 0.755168, acc: 0.378906]\n",
            "6635: [D loss: 0.698199, acc: 0.535156]  [A loss: 0.871852, acc: 0.136719]\n",
            "6636: [D loss: 0.699015, acc: 0.531250]  [A loss: 0.757413, acc: 0.359375]\n",
            "6637: [D loss: 0.706973, acc: 0.519531]  [A loss: 0.866523, acc: 0.144531]\n",
            "6638: [D loss: 0.693726, acc: 0.529297]  [A loss: 0.755545, acc: 0.335938]\n",
            "6639: [D loss: 0.698291, acc: 0.542969]  [A loss: 0.815928, acc: 0.222656]\n",
            "6640: [D loss: 0.690860, acc: 0.548828]  [A loss: 0.794356, acc: 0.285156]\n",
            "6641: [D loss: 0.711280, acc: 0.486328]  [A loss: 0.844087, acc: 0.203125]\n",
            "6642: [D loss: 0.688277, acc: 0.568359]  [A loss: 0.798133, acc: 0.304688]\n",
            "6643: [D loss: 0.698993, acc: 0.541016]  [A loss: 0.850516, acc: 0.171875]\n",
            "6644: [D loss: 0.706609, acc: 0.478516]  [A loss: 0.824218, acc: 0.226562]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6645: [D loss: 0.717561, acc: 0.484375]  [A loss: 0.842901, acc: 0.171875]\n",
            "6646: [D loss: 0.692335, acc: 0.533203]  [A loss: 0.767860, acc: 0.324219]\n",
            "6647: [D loss: 0.710927, acc: 0.527344]  [A loss: 0.977357, acc: 0.054688]\n",
            "6648: [D loss: 0.699272, acc: 0.517578]  [A loss: 0.627501, acc: 0.695312]\n",
            "6649: [D loss: 0.719870, acc: 0.511719]  [A loss: 0.954888, acc: 0.085938]\n",
            "6650: [D loss: 0.714501, acc: 0.476562]  [A loss: 0.679954, acc: 0.546875]\n",
            "6651: [D loss: 0.702357, acc: 0.505859]  [A loss: 0.874807, acc: 0.156250]\n",
            "6652: [D loss: 0.709495, acc: 0.480469]  [A loss: 0.753399, acc: 0.351562]\n",
            "6653: [D loss: 0.712138, acc: 0.523438]  [A loss: 0.856194, acc: 0.160156]\n",
            "6654: [D loss: 0.704707, acc: 0.503906]  [A loss: 0.740314, acc: 0.343750]\n",
            "6655: [D loss: 0.718289, acc: 0.501953]  [A loss: 0.959786, acc: 0.058594]\n",
            "6656: [D loss: 0.688266, acc: 0.550781]  [A loss: 0.672028, acc: 0.605469]\n",
            "6657: [D loss: 0.714028, acc: 0.507812]  [A loss: 0.900083, acc: 0.097656]\n",
            "6658: [D loss: 0.706248, acc: 0.494141]  [A loss: 0.743261, acc: 0.382812]\n",
            "6659: [D loss: 0.700580, acc: 0.541016]  [A loss: 0.850889, acc: 0.187500]\n",
            "6660: [D loss: 0.689709, acc: 0.548828]  [A loss: 0.743457, acc: 0.359375]\n",
            "6661: [D loss: 0.703880, acc: 0.515625]  [A loss: 0.867134, acc: 0.144531]\n",
            "6662: [D loss: 0.692119, acc: 0.521484]  [A loss: 0.777341, acc: 0.335938]\n",
            "6663: [D loss: 0.691825, acc: 0.542969]  [A loss: 0.801600, acc: 0.261719]\n",
            "6664: [D loss: 0.698417, acc: 0.535156]  [A loss: 0.812013, acc: 0.218750]\n",
            "6665: [D loss: 0.692247, acc: 0.558594]  [A loss: 0.788411, acc: 0.347656]\n",
            "6666: [D loss: 0.703271, acc: 0.531250]  [A loss: 0.962649, acc: 0.082031]\n",
            "6667: [D loss: 0.701471, acc: 0.519531]  [A loss: 0.660823, acc: 0.621094]\n",
            "6668: [D loss: 0.718367, acc: 0.500000]  [A loss: 0.901680, acc: 0.117188]\n",
            "6669: [D loss: 0.699400, acc: 0.490234]  [A loss: 0.702898, acc: 0.480469]\n",
            "6670: [D loss: 0.727589, acc: 0.498047]  [A loss: 0.848247, acc: 0.195312]\n",
            "6671: [D loss: 0.690465, acc: 0.519531]  [A loss: 0.771523, acc: 0.332031]\n",
            "6672: [D loss: 0.699820, acc: 0.552734]  [A loss: 0.762697, acc: 0.300781]\n",
            "6673: [D loss: 0.713950, acc: 0.486328]  [A loss: 0.788939, acc: 0.300781]\n",
            "6674: [D loss: 0.699210, acc: 0.525391]  [A loss: 0.739405, acc: 0.398438]\n",
            "6675: [D loss: 0.710956, acc: 0.482422]  [A loss: 0.815860, acc: 0.250000]\n",
            "6676: [D loss: 0.705227, acc: 0.519531]  [A loss: 0.774474, acc: 0.335938]\n",
            "6677: [D loss: 0.701410, acc: 0.517578]  [A loss: 0.797555, acc: 0.265625]\n",
            "6678: [D loss: 0.697106, acc: 0.513672]  [A loss: 0.827220, acc: 0.183594]\n",
            "6679: [D loss: 0.694677, acc: 0.519531]  [A loss: 0.708599, acc: 0.460938]\n",
            "6680: [D loss: 0.690235, acc: 0.531250]  [A loss: 0.903128, acc: 0.113281]\n",
            "6681: [D loss: 0.704902, acc: 0.498047]  [A loss: 0.730879, acc: 0.425781]\n",
            "6682: [D loss: 0.718384, acc: 0.488281]  [A loss: 0.989181, acc: 0.035156]\n",
            "6683: [D loss: 0.702364, acc: 0.503906]  [A loss: 0.649584, acc: 0.621094]\n",
            "6684: [D loss: 0.718577, acc: 0.496094]  [A loss: 0.880190, acc: 0.105469]\n",
            "6685: [D loss: 0.694488, acc: 0.556641]  [A loss: 0.698763, acc: 0.519531]\n",
            "6686: [D loss: 0.699666, acc: 0.505859]  [A loss: 0.853575, acc: 0.167969]\n",
            "6687: [D loss: 0.699851, acc: 0.511719]  [A loss: 0.808762, acc: 0.246094]\n",
            "6688: [D loss: 0.694317, acc: 0.525391]  [A loss: 0.862836, acc: 0.148438]\n",
            "6689: [D loss: 0.683419, acc: 0.550781]  [A loss: 0.733888, acc: 0.378906]\n",
            "6690: [D loss: 0.707676, acc: 0.507812]  [A loss: 0.914161, acc: 0.109375]\n",
            "6691: [D loss: 0.705209, acc: 0.507812]  [A loss: 0.788386, acc: 0.296875]\n",
            "6692: [D loss: 0.704454, acc: 0.511719]  [A loss: 0.827405, acc: 0.191406]\n",
            "6693: [D loss: 0.694989, acc: 0.503906]  [A loss: 0.811879, acc: 0.250000]\n",
            "6694: [D loss: 0.704861, acc: 0.505859]  [A loss: 0.799503, acc: 0.246094]\n",
            "6695: [D loss: 0.701688, acc: 0.511719]  [A loss: 0.826900, acc: 0.222656]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6696: [D loss: 0.691504, acc: 0.521484]  [A loss: 0.703677, acc: 0.468750]\n",
            "6697: [D loss: 0.715250, acc: 0.513672]  [A loss: 0.863708, acc: 0.156250]\n",
            "6698: [D loss: 0.706186, acc: 0.496094]  [A loss: 0.756984, acc: 0.363281]\n",
            "6699: [D loss: 0.711449, acc: 0.517578]  [A loss: 0.842590, acc: 0.207031]\n",
            "6700: [D loss: 0.691136, acc: 0.554688]  [A loss: 0.761689, acc: 0.363281]\n",
            "6701: [D loss: 0.681821, acc: 0.578125]  [A loss: 0.791705, acc: 0.265625]\n",
            "6702: [D loss: 0.701021, acc: 0.511719]  [A loss: 0.776643, acc: 0.312500]\n",
            "6703: [D loss: 0.701752, acc: 0.523438]  [A loss: 0.859624, acc: 0.175781]\n",
            "6704: [D loss: 0.700911, acc: 0.525391]  [A loss: 0.735306, acc: 0.441406]\n",
            "6705: [D loss: 0.709255, acc: 0.501953]  [A loss: 0.871197, acc: 0.160156]\n",
            "6706: [D loss: 0.700356, acc: 0.523438]  [A loss: 0.795682, acc: 0.300781]\n",
            "6707: [D loss: 0.707894, acc: 0.501953]  [A loss: 0.811374, acc: 0.273438]\n",
            "6708: [D loss: 0.700484, acc: 0.500000]  [A loss: 0.805364, acc: 0.199219]\n",
            "6709: [D loss: 0.702732, acc: 0.515625]  [A loss: 0.813132, acc: 0.230469]\n",
            "6710: [D loss: 0.701539, acc: 0.525391]  [A loss: 0.827190, acc: 0.210938]\n",
            "6711: [D loss: 0.703451, acc: 0.511719]  [A loss: 0.823950, acc: 0.214844]\n",
            "6712: [D loss: 0.711134, acc: 0.480469]  [A loss: 0.789942, acc: 0.292969]\n",
            "6713: [D loss: 0.695876, acc: 0.521484]  [A loss: 0.871075, acc: 0.152344]\n",
            "6714: [D loss: 0.699505, acc: 0.509766]  [A loss: 0.728313, acc: 0.425781]\n",
            "6715: [D loss: 0.701509, acc: 0.490234]  [A loss: 0.892903, acc: 0.117188]\n",
            "6716: [D loss: 0.699999, acc: 0.531250]  [A loss: 0.812303, acc: 0.324219]\n",
            "6717: [D loss: 0.698594, acc: 0.513672]  [A loss: 0.848642, acc: 0.164062]\n",
            "6718: [D loss: 0.701335, acc: 0.505859]  [A loss: 0.721246, acc: 0.433594]\n",
            "6719: [D loss: 0.706039, acc: 0.529297]  [A loss: 0.917127, acc: 0.093750]\n",
            "6720: [D loss: 0.706201, acc: 0.515625]  [A loss: 0.703567, acc: 0.523438]\n",
            "6721: [D loss: 0.718195, acc: 0.513672]  [A loss: 0.932310, acc: 0.125000]\n",
            "6722: [D loss: 0.703031, acc: 0.476562]  [A loss: 0.736778, acc: 0.417969]\n",
            "6723: [D loss: 0.709763, acc: 0.513672]  [A loss: 0.836393, acc: 0.160156]\n",
            "6724: [D loss: 0.684721, acc: 0.560547]  [A loss: 0.793171, acc: 0.253906]\n",
            "6725: [D loss: 0.712233, acc: 0.486328]  [A loss: 0.810178, acc: 0.207031]\n",
            "6726: [D loss: 0.686197, acc: 0.544922]  [A loss: 0.772172, acc: 0.332031]\n",
            "6727: [D loss: 0.705697, acc: 0.527344]  [A loss: 0.866675, acc: 0.101562]\n",
            "6728: [D loss: 0.703255, acc: 0.527344]  [A loss: 0.710817, acc: 0.476562]\n",
            "6729: [D loss: 0.718329, acc: 0.509766]  [A loss: 0.923694, acc: 0.074219]\n",
            "6730: [D loss: 0.699587, acc: 0.511719]  [A loss: 0.662477, acc: 0.578125]\n",
            "6731: [D loss: 0.714071, acc: 0.521484]  [A loss: 0.931004, acc: 0.097656]\n",
            "6732: [D loss: 0.698103, acc: 0.517578]  [A loss: 0.690126, acc: 0.550781]\n",
            "6733: [D loss: 0.733417, acc: 0.472656]  [A loss: 0.885837, acc: 0.152344]\n",
            "6734: [D loss: 0.695850, acc: 0.531250]  [A loss: 0.753548, acc: 0.359375]\n",
            "6735: [D loss: 0.698293, acc: 0.531250]  [A loss: 0.851461, acc: 0.191406]\n",
            "6736: [D loss: 0.689629, acc: 0.521484]  [A loss: 0.766827, acc: 0.332031]\n",
            "6737: [D loss: 0.694480, acc: 0.529297]  [A loss: 0.820026, acc: 0.250000]\n",
            "6738: [D loss: 0.692222, acc: 0.513672]  [A loss: 0.770938, acc: 0.339844]\n",
            "6739: [D loss: 0.698541, acc: 0.505859]  [A loss: 0.767615, acc: 0.355469]\n",
            "6740: [D loss: 0.706276, acc: 0.507812]  [A loss: 0.799658, acc: 0.222656]\n",
            "6741: [D loss: 0.714993, acc: 0.457031]  [A loss: 0.799229, acc: 0.273438]\n",
            "6742: [D loss: 0.707717, acc: 0.476562]  [A loss: 0.841152, acc: 0.179688]\n",
            "6743: [D loss: 0.695369, acc: 0.533203]  [A loss: 0.806055, acc: 0.226562]\n",
            "6744: [D loss: 0.705745, acc: 0.523438]  [A loss: 0.865802, acc: 0.160156]\n",
            "6745: [D loss: 0.694425, acc: 0.498047]  [A loss: 0.725138, acc: 0.433594]\n",
            "6746: [D loss: 0.696154, acc: 0.535156]  [A loss: 0.843671, acc: 0.187500]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6747: [D loss: 0.693629, acc: 0.541016]  [A loss: 0.713283, acc: 0.464844]\n",
            "6748: [D loss: 0.718942, acc: 0.496094]  [A loss: 0.890426, acc: 0.160156]\n",
            "6749: [D loss: 0.700955, acc: 0.535156]  [A loss: 0.715151, acc: 0.488281]\n",
            "6750: [D loss: 0.715727, acc: 0.492188]  [A loss: 0.884900, acc: 0.144531]\n",
            "6751: [D loss: 0.704114, acc: 0.517578]  [A loss: 0.699644, acc: 0.496094]\n",
            "6752: [D loss: 0.719539, acc: 0.488281]  [A loss: 0.916506, acc: 0.082031]\n",
            "6753: [D loss: 0.696369, acc: 0.523438]  [A loss: 0.733638, acc: 0.398438]\n",
            "6754: [D loss: 0.705086, acc: 0.484375]  [A loss: 0.884035, acc: 0.148438]\n",
            "6755: [D loss: 0.687093, acc: 0.544922]  [A loss: 0.713275, acc: 0.468750]\n",
            "6756: [D loss: 0.702662, acc: 0.500000]  [A loss: 0.871816, acc: 0.136719]\n",
            "6757: [D loss: 0.697529, acc: 0.511719]  [A loss: 0.748112, acc: 0.375000]\n",
            "6758: [D loss: 0.699041, acc: 0.531250]  [A loss: 0.858104, acc: 0.175781]\n",
            "6759: [D loss: 0.693111, acc: 0.542969]  [A loss: 0.750887, acc: 0.347656]\n",
            "6760: [D loss: 0.700087, acc: 0.527344]  [A loss: 0.852985, acc: 0.156250]\n",
            "6761: [D loss: 0.692591, acc: 0.527344]  [A loss: 0.799415, acc: 0.292969]\n",
            "6762: [D loss: 0.714869, acc: 0.468750]  [A loss: 0.785890, acc: 0.265625]\n",
            "6763: [D loss: 0.703031, acc: 0.523438]  [A loss: 0.860134, acc: 0.175781]\n",
            "6764: [D loss: 0.697252, acc: 0.511719]  [A loss: 0.780382, acc: 0.324219]\n",
            "6765: [D loss: 0.700314, acc: 0.529297]  [A loss: 0.871697, acc: 0.160156]\n",
            "6766: [D loss: 0.697913, acc: 0.517578]  [A loss: 0.780148, acc: 0.328125]\n",
            "6767: [D loss: 0.696779, acc: 0.535156]  [A loss: 0.758452, acc: 0.359375]\n",
            "6768: [D loss: 0.711204, acc: 0.505859]  [A loss: 0.867275, acc: 0.175781]\n",
            "6769: [D loss: 0.696483, acc: 0.529297]  [A loss: 0.747176, acc: 0.382812]\n",
            "6770: [D loss: 0.693384, acc: 0.539062]  [A loss: 0.891124, acc: 0.125000]\n",
            "6771: [D loss: 0.698750, acc: 0.521484]  [A loss: 0.709731, acc: 0.496094]\n",
            "6772: [D loss: 0.709775, acc: 0.523438]  [A loss: 0.946362, acc: 0.082031]\n",
            "6773: [D loss: 0.703997, acc: 0.519531]  [A loss: 0.721166, acc: 0.445312]\n",
            "6774: [D loss: 0.717189, acc: 0.478516]  [A loss: 0.885358, acc: 0.132812]\n",
            "6775: [D loss: 0.690961, acc: 0.531250]  [A loss: 0.770546, acc: 0.351562]\n",
            "6776: [D loss: 0.703944, acc: 0.507812]  [A loss: 0.869838, acc: 0.148438]\n",
            "6777: [D loss: 0.703201, acc: 0.542969]  [A loss: 0.765600, acc: 0.324219]\n",
            "6778: [D loss: 0.710461, acc: 0.492188]  [A loss: 0.872131, acc: 0.140625]\n",
            "6779: [D loss: 0.696620, acc: 0.523438]  [A loss: 0.756615, acc: 0.355469]\n",
            "6780: [D loss: 0.706991, acc: 0.517578]  [A loss: 0.870994, acc: 0.175781]\n",
            "6781: [D loss: 0.700073, acc: 0.523438]  [A loss: 0.771955, acc: 0.335938]\n",
            "6782: [D loss: 0.700293, acc: 0.521484]  [A loss: 0.882967, acc: 0.199219]\n",
            "6783: [D loss: 0.695618, acc: 0.548828]  [A loss: 0.746623, acc: 0.363281]\n",
            "6784: [D loss: 0.700335, acc: 0.525391]  [A loss: 0.929540, acc: 0.171875]\n",
            "6785: [D loss: 0.688028, acc: 0.550781]  [A loss: 0.738601, acc: 0.425781]\n",
            "6786: [D loss: 0.704365, acc: 0.519531]  [A loss: 0.888500, acc: 0.121094]\n",
            "6787: [D loss: 0.687067, acc: 0.558594]  [A loss: 0.704563, acc: 0.527344]\n",
            "6788: [D loss: 0.705052, acc: 0.511719]  [A loss: 0.951463, acc: 0.074219]\n",
            "6789: [D loss: 0.694878, acc: 0.529297]  [A loss: 0.724074, acc: 0.460938]\n",
            "6790: [D loss: 0.703791, acc: 0.539062]  [A loss: 0.895344, acc: 0.132812]\n",
            "6791: [D loss: 0.694941, acc: 0.525391]  [A loss: 0.746341, acc: 0.386719]\n",
            "6792: [D loss: 0.701305, acc: 0.525391]  [A loss: 0.849086, acc: 0.179688]\n",
            "6793: [D loss: 0.691433, acc: 0.523438]  [A loss: 0.791089, acc: 0.265625]\n",
            "6794: [D loss: 0.696936, acc: 0.537109]  [A loss: 0.820697, acc: 0.238281]\n",
            "6795: [D loss: 0.702823, acc: 0.515625]  [A loss: 0.824593, acc: 0.230469]\n",
            "6796: [D loss: 0.688424, acc: 0.550781]  [A loss: 0.784566, acc: 0.320312]\n",
            "6797: [D loss: 0.716743, acc: 0.505859]  [A loss: 0.918731, acc: 0.113281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6798: [D loss: 0.715120, acc: 0.470703]  [A loss: 0.657431, acc: 0.617188]\n",
            "6799: [D loss: 0.713240, acc: 0.519531]  [A loss: 0.970192, acc: 0.039062]\n",
            "6800: [D loss: 0.703019, acc: 0.509766]  [A loss: 0.715239, acc: 0.433594]\n",
            "6801: [D loss: 0.706445, acc: 0.494141]  [A loss: 0.838301, acc: 0.226562]\n",
            "6802: [D loss: 0.709166, acc: 0.492188]  [A loss: 0.768221, acc: 0.328125]\n",
            "6803: [D loss: 0.699459, acc: 0.492188]  [A loss: 0.762378, acc: 0.332031]\n",
            "6804: [D loss: 0.714407, acc: 0.484375]  [A loss: 0.864940, acc: 0.125000]\n",
            "6805: [D loss: 0.703859, acc: 0.507812]  [A loss: 0.757575, acc: 0.398438]\n",
            "6806: [D loss: 0.703035, acc: 0.496094]  [A loss: 0.831001, acc: 0.199219]\n",
            "6807: [D loss: 0.708493, acc: 0.513672]  [A loss: 0.782728, acc: 0.316406]\n",
            "6808: [D loss: 0.699515, acc: 0.509766]  [A loss: 0.929810, acc: 0.199219]\n",
            "6809: [D loss: 0.689970, acc: 0.537109]  [A loss: 0.818638, acc: 0.273438]\n",
            "6810: [D loss: 0.702070, acc: 0.511719]  [A loss: 0.909445, acc: 0.125000]\n",
            "6811: [D loss: 0.692636, acc: 0.521484]  [A loss: 0.737034, acc: 0.394531]\n",
            "6812: [D loss: 0.719130, acc: 0.509766]  [A loss: 0.958583, acc: 0.097656]\n",
            "6813: [D loss: 0.693931, acc: 0.541016]  [A loss: 0.648539, acc: 0.632812]\n",
            "6814: [D loss: 0.706714, acc: 0.539062]  [A loss: 0.889533, acc: 0.160156]\n",
            "6815: [D loss: 0.718669, acc: 0.462891]  [A loss: 0.701878, acc: 0.464844]\n",
            "6816: [D loss: 0.721956, acc: 0.480469]  [A loss: 0.836398, acc: 0.191406]\n",
            "6817: [D loss: 0.694458, acc: 0.519531]  [A loss: 0.726397, acc: 0.437500]\n",
            "6818: [D loss: 0.709124, acc: 0.498047]  [A loss: 0.836026, acc: 0.210938]\n",
            "6819: [D loss: 0.690636, acc: 0.542969]  [A loss: 0.791869, acc: 0.289062]\n",
            "6820: [D loss: 0.703395, acc: 0.550781]  [A loss: 0.836352, acc: 0.230469]\n",
            "6821: [D loss: 0.704836, acc: 0.511719]  [A loss: 0.765523, acc: 0.355469]\n",
            "6822: [D loss: 0.720842, acc: 0.507812]  [A loss: 0.913921, acc: 0.074219]\n",
            "6823: [D loss: 0.713033, acc: 0.464844]  [A loss: 0.789099, acc: 0.269531]\n",
            "6824: [D loss: 0.700558, acc: 0.544922]  [A loss: 0.857523, acc: 0.195312]\n",
            "6825: [D loss: 0.697071, acc: 0.556641]  [A loss: 0.797206, acc: 0.320312]\n",
            "6826: [D loss: 0.714993, acc: 0.472656]  [A loss: 0.846982, acc: 0.164062]\n",
            "6827: [D loss: 0.691768, acc: 0.533203]  [A loss: 0.738814, acc: 0.386719]\n",
            "6828: [D loss: 0.707629, acc: 0.509766]  [A loss: 0.962134, acc: 0.054688]\n",
            "6829: [D loss: 0.703046, acc: 0.505859]  [A loss: 0.698084, acc: 0.527344]\n",
            "6830: [D loss: 0.710581, acc: 0.509766]  [A loss: 0.861509, acc: 0.187500]\n",
            "6831: [D loss: 0.709278, acc: 0.474609]  [A loss: 0.724090, acc: 0.410156]\n",
            "6832: [D loss: 0.708498, acc: 0.541016]  [A loss: 0.843963, acc: 0.148438]\n",
            "6833: [D loss: 0.701856, acc: 0.515625]  [A loss: 0.790356, acc: 0.277344]\n",
            "6834: [D loss: 0.695432, acc: 0.533203]  [A loss: 0.796952, acc: 0.273438]\n",
            "6835: [D loss: 0.721361, acc: 0.476562]  [A loss: 0.851570, acc: 0.167969]\n",
            "6836: [D loss: 0.693955, acc: 0.529297]  [A loss: 0.817589, acc: 0.230469]\n",
            "6837: [D loss: 0.699952, acc: 0.550781]  [A loss: 0.737711, acc: 0.414062]\n",
            "6838: [D loss: 0.709444, acc: 0.509766]  [A loss: 0.906368, acc: 0.105469]\n",
            "6839: [D loss: 0.694860, acc: 0.515625]  [A loss: 0.708769, acc: 0.492188]\n",
            "6840: [D loss: 0.724472, acc: 0.470703]  [A loss: 0.887033, acc: 0.156250]\n",
            "6841: [D loss: 0.695704, acc: 0.517578]  [A loss: 0.688043, acc: 0.531250]\n",
            "6842: [D loss: 0.712468, acc: 0.517578]  [A loss: 0.880942, acc: 0.136719]\n",
            "6843: [D loss: 0.693061, acc: 0.527344]  [A loss: 0.734336, acc: 0.410156]\n",
            "6844: [D loss: 0.715908, acc: 0.478516]  [A loss: 0.870585, acc: 0.128906]\n",
            "6845: [D loss: 0.688894, acc: 0.542969]  [A loss: 0.774082, acc: 0.308594]\n",
            "6846: [D loss: 0.700364, acc: 0.509766]  [A loss: 0.842503, acc: 0.199219]\n",
            "6847: [D loss: 0.691152, acc: 0.539062]  [A loss: 0.752769, acc: 0.363281]\n",
            "6848: [D loss: 0.694814, acc: 0.521484]  [A loss: 0.824362, acc: 0.269531]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6849: [D loss: 0.702999, acc: 0.541016]  [A loss: 0.818362, acc: 0.253906]\n",
            "6850: [D loss: 0.700145, acc: 0.517578]  [A loss: 0.762577, acc: 0.375000]\n",
            "6851: [D loss: 0.715564, acc: 0.515625]  [A loss: 0.941838, acc: 0.074219]\n",
            "6852: [D loss: 0.697574, acc: 0.519531]  [A loss: 0.708765, acc: 0.449219]\n",
            "6853: [D loss: 0.720219, acc: 0.533203]  [A loss: 0.880140, acc: 0.164062]\n",
            "6854: [D loss: 0.709715, acc: 0.488281]  [A loss: 0.785436, acc: 0.285156]\n",
            "6855: [D loss: 0.697876, acc: 0.533203]  [A loss: 0.871536, acc: 0.175781]\n",
            "6856: [D loss: 0.709406, acc: 0.501953]  [A loss: 0.726697, acc: 0.414062]\n",
            "6857: [D loss: 0.723264, acc: 0.484375]  [A loss: 0.904926, acc: 0.121094]\n",
            "6858: [D loss: 0.705042, acc: 0.501953]  [A loss: 0.757734, acc: 0.371094]\n",
            "6859: [D loss: 0.698404, acc: 0.539062]  [A loss: 0.893365, acc: 0.128906]\n",
            "6860: [D loss: 0.692524, acc: 0.527344]  [A loss: 0.770163, acc: 0.398438]\n",
            "6861: [D loss: 0.708146, acc: 0.513672]  [A loss: 0.967467, acc: 0.070312]\n",
            "6862: [D loss: 0.692207, acc: 0.535156]  [A loss: 0.648377, acc: 0.660156]\n",
            "6863: [D loss: 0.720953, acc: 0.511719]  [A loss: 0.827978, acc: 0.230469]\n",
            "6864: [D loss: 0.700425, acc: 0.498047]  [A loss: 0.760905, acc: 0.316406]\n",
            "6865: [D loss: 0.714143, acc: 0.521484]  [A loss: 0.826618, acc: 0.230469]\n",
            "6866: [D loss: 0.684826, acc: 0.550781]  [A loss: 0.735728, acc: 0.437500]\n",
            "6867: [D loss: 0.718211, acc: 0.480469]  [A loss: 0.892276, acc: 0.128906]\n",
            "6868: [D loss: 0.705385, acc: 0.492188]  [A loss: 0.710158, acc: 0.496094]\n",
            "6869: [D loss: 0.715183, acc: 0.509766]  [A loss: 0.835421, acc: 0.199219]\n",
            "6870: [D loss: 0.706081, acc: 0.523438]  [A loss: 0.835496, acc: 0.253906]\n",
            "6871: [D loss: 0.702769, acc: 0.482422]  [A loss: 0.816558, acc: 0.238281]\n",
            "6872: [D loss: 0.703187, acc: 0.486328]  [A loss: 0.755359, acc: 0.378906]\n",
            "6873: [D loss: 0.702812, acc: 0.513672]  [A loss: 0.822930, acc: 0.207031]\n",
            "6874: [D loss: 0.707992, acc: 0.509766]  [A loss: 0.753855, acc: 0.363281]\n",
            "6875: [D loss: 0.691525, acc: 0.503906]  [A loss: 0.833502, acc: 0.210938]\n",
            "6876: [D loss: 0.705607, acc: 0.501953]  [A loss: 0.807329, acc: 0.257812]\n",
            "6877: [D loss: 0.699925, acc: 0.531250]  [A loss: 0.927060, acc: 0.101562]\n",
            "6878: [D loss: 0.696987, acc: 0.527344]  [A loss: 0.689764, acc: 0.550781]\n",
            "6879: [D loss: 0.722298, acc: 0.496094]  [A loss: 0.886823, acc: 0.136719]\n",
            "6880: [D loss: 0.706871, acc: 0.484375]  [A loss: 0.756077, acc: 0.343750]\n",
            "6881: [D loss: 0.706420, acc: 0.498047]  [A loss: 0.837350, acc: 0.238281]\n",
            "6882: [D loss: 0.688547, acc: 0.560547]  [A loss: 0.797335, acc: 0.300781]\n",
            "6883: [D loss: 0.700700, acc: 0.523438]  [A loss: 0.837830, acc: 0.179688]\n",
            "6884: [D loss: 0.700440, acc: 0.511719]  [A loss: 0.778018, acc: 0.312500]\n",
            "6885: [D loss: 0.711184, acc: 0.509766]  [A loss: 0.833541, acc: 0.218750]\n",
            "6886: [D loss: 0.698431, acc: 0.535156]  [A loss: 0.795147, acc: 0.289062]\n",
            "6887: [D loss: 0.700952, acc: 0.484375]  [A loss: 0.821543, acc: 0.222656]\n",
            "6888: [D loss: 0.703502, acc: 0.501953]  [A loss: 0.775032, acc: 0.289062]\n",
            "6889: [D loss: 0.701355, acc: 0.521484]  [A loss: 0.909643, acc: 0.121094]\n",
            "6890: [D loss: 0.698430, acc: 0.517578]  [A loss: 0.760083, acc: 0.378906]\n",
            "6891: [D loss: 0.709351, acc: 0.521484]  [A loss: 0.887606, acc: 0.136719]\n",
            "6892: [D loss: 0.692519, acc: 0.513672]  [A loss: 0.778105, acc: 0.328125]\n",
            "6893: [D loss: 0.703644, acc: 0.513672]  [A loss: 0.886550, acc: 0.117188]\n",
            "6894: [D loss: 0.687848, acc: 0.554688]  [A loss: 0.707080, acc: 0.476562]\n",
            "6895: [D loss: 0.709888, acc: 0.525391]  [A loss: 0.952906, acc: 0.078125]\n",
            "6896: [D loss: 0.690360, acc: 0.541016]  [A loss: 0.687654, acc: 0.535156]\n",
            "6897: [D loss: 0.721344, acc: 0.503906]  [A loss: 0.897889, acc: 0.117188]\n",
            "6898: [D loss: 0.694290, acc: 0.541016]  [A loss: 0.736573, acc: 0.417969]\n",
            "6899: [D loss: 0.711839, acc: 0.511719]  [A loss: 0.920550, acc: 0.109375]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6900: [D loss: 0.677445, acc: 0.562500]  [A loss: 0.675173, acc: 0.574219]\n",
            "6901: [D loss: 0.720380, acc: 0.486328]  [A loss: 0.876771, acc: 0.136719]\n",
            "6902: [D loss: 0.725000, acc: 0.451172]  [A loss: 0.783053, acc: 0.363281]\n",
            "6903: [D loss: 0.720502, acc: 0.486328]  [A loss: 0.839745, acc: 0.203125]\n",
            "6904: [D loss: 0.693867, acc: 0.511719]  [A loss: 0.755747, acc: 0.378906]\n",
            "6905: [D loss: 0.705950, acc: 0.498047]  [A loss: 0.865838, acc: 0.164062]\n",
            "6906: [D loss: 0.698664, acc: 0.511719]  [A loss: 0.720923, acc: 0.464844]\n",
            "6907: [D loss: 0.700368, acc: 0.562500]  [A loss: 0.897370, acc: 0.148438]\n",
            "6908: [D loss: 0.709243, acc: 0.498047]  [A loss: 0.725615, acc: 0.402344]\n",
            "6909: [D loss: 0.717938, acc: 0.501953]  [A loss: 0.895715, acc: 0.140625]\n",
            "6910: [D loss: 0.691751, acc: 0.511719]  [A loss: 0.728558, acc: 0.433594]\n",
            "6911: [D loss: 0.706798, acc: 0.509766]  [A loss: 0.845036, acc: 0.195312]\n",
            "6912: [D loss: 0.701827, acc: 0.507812]  [A loss: 0.782222, acc: 0.292969]\n",
            "6913: [D loss: 0.707641, acc: 0.509766]  [A loss: 0.919799, acc: 0.132812]\n",
            "6914: [D loss: 0.692062, acc: 0.523438]  [A loss: 0.785922, acc: 0.316406]\n",
            "6915: [D loss: 0.700928, acc: 0.539062]  [A loss: 0.886659, acc: 0.136719]\n",
            "6916: [D loss: 0.700644, acc: 0.531250]  [A loss: 0.719820, acc: 0.472656]\n",
            "6917: [D loss: 0.717935, acc: 0.494141]  [A loss: 0.865471, acc: 0.179688]\n",
            "6918: [D loss: 0.705117, acc: 0.521484]  [A loss: 0.811120, acc: 0.261719]\n",
            "6919: [D loss: 0.699925, acc: 0.531250]  [A loss: 0.774243, acc: 0.296875]\n",
            "6920: [D loss: 0.708662, acc: 0.507812]  [A loss: 0.834008, acc: 0.230469]\n",
            "6921: [D loss: 0.702163, acc: 0.505859]  [A loss: 0.802047, acc: 0.253906]\n",
            "6922: [D loss: 0.709860, acc: 0.484375]  [A loss: 0.862757, acc: 0.203125]\n",
            "6923: [D loss: 0.709039, acc: 0.484375]  [A loss: 0.752528, acc: 0.371094]\n",
            "6924: [D loss: 0.707642, acc: 0.505859]  [A loss: 0.911767, acc: 0.128906]\n",
            "6925: [D loss: 0.694935, acc: 0.529297]  [A loss: 0.714202, acc: 0.476562]\n",
            "6926: [D loss: 0.715545, acc: 0.482422]  [A loss: 0.868282, acc: 0.164062]\n",
            "6927: [D loss: 0.690484, acc: 0.537109]  [A loss: 0.726471, acc: 0.441406]\n",
            "6928: [D loss: 0.710278, acc: 0.503906]  [A loss: 0.862789, acc: 0.175781]\n",
            "6929: [D loss: 0.708402, acc: 0.482422]  [A loss: 0.701272, acc: 0.500000]\n",
            "6930: [D loss: 0.708320, acc: 0.513672]  [A loss: 0.874387, acc: 0.144531]\n",
            "6931: [D loss: 0.697440, acc: 0.509766]  [A loss: 0.767233, acc: 0.355469]\n",
            "6932: [D loss: 0.707441, acc: 0.523438]  [A loss: 0.842581, acc: 0.191406]\n",
            "6933: [D loss: 0.705920, acc: 0.505859]  [A loss: 0.766825, acc: 0.390625]\n",
            "6934: [D loss: 0.703012, acc: 0.501953]  [A loss: 0.849776, acc: 0.187500]\n",
            "6935: [D loss: 0.682076, acc: 0.599609]  [A loss: 0.715145, acc: 0.449219]\n",
            "6936: [D loss: 0.702023, acc: 0.507812]  [A loss: 0.924230, acc: 0.101562]\n",
            "6937: [D loss: 0.694814, acc: 0.517578]  [A loss: 0.750510, acc: 0.386719]\n",
            "6938: [D loss: 0.707603, acc: 0.501953]  [A loss: 0.848642, acc: 0.203125]\n",
            "6939: [D loss: 0.691106, acc: 0.560547]  [A loss: 0.789545, acc: 0.316406]\n",
            "6940: [D loss: 0.699644, acc: 0.505859]  [A loss: 0.833908, acc: 0.234375]\n",
            "6941: [D loss: 0.703344, acc: 0.523438]  [A loss: 0.810009, acc: 0.265625]\n",
            "6942: [D loss: 0.701733, acc: 0.511719]  [A loss: 0.813009, acc: 0.222656]\n",
            "6943: [D loss: 0.697057, acc: 0.527344]  [A loss: 0.831043, acc: 0.253906]\n",
            "6944: [D loss: 0.699887, acc: 0.501953]  [A loss: 0.777776, acc: 0.296875]\n",
            "6945: [D loss: 0.710328, acc: 0.505859]  [A loss: 0.876516, acc: 0.136719]\n",
            "6946: [D loss: 0.699509, acc: 0.492188]  [A loss: 0.723400, acc: 0.441406]\n",
            "6947: [D loss: 0.711606, acc: 0.505859]  [A loss: 0.954583, acc: 0.101562]\n",
            "6948: [D loss: 0.709603, acc: 0.496094]  [A loss: 0.728054, acc: 0.457031]\n",
            "6949: [D loss: 0.711726, acc: 0.490234]  [A loss: 0.866046, acc: 0.183594]\n",
            "6950: [D loss: 0.693956, acc: 0.560547]  [A loss: 0.767072, acc: 0.375000]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "6951: [D loss: 0.699950, acc: 0.550781]  [A loss: 0.837642, acc: 0.246094]\n",
            "6952: [D loss: 0.702429, acc: 0.519531]  [A loss: 0.773558, acc: 0.343750]\n",
            "6953: [D loss: 0.708005, acc: 0.505859]  [A loss: 0.835338, acc: 0.238281]\n",
            "6954: [D loss: 0.697918, acc: 0.552734]  [A loss: 0.766146, acc: 0.347656]\n",
            "6955: [D loss: 0.695751, acc: 0.531250]  [A loss: 0.904446, acc: 0.164062]\n",
            "6956: [D loss: 0.704581, acc: 0.541016]  [A loss: 0.736586, acc: 0.390625]\n",
            "6957: [D loss: 0.712593, acc: 0.511719]  [A loss: 0.933855, acc: 0.109375]\n",
            "6958: [D loss: 0.704387, acc: 0.523438]  [A loss: 0.704265, acc: 0.488281]\n",
            "6959: [D loss: 0.710094, acc: 0.507812]  [A loss: 0.918205, acc: 0.113281]\n",
            "6960: [D loss: 0.698980, acc: 0.539062]  [A loss: 0.726575, acc: 0.441406]\n",
            "6961: [D loss: 0.707383, acc: 0.535156]  [A loss: 0.863086, acc: 0.191406]\n",
            "6962: [D loss: 0.703520, acc: 0.529297]  [A loss: 0.834326, acc: 0.226562]\n",
            "6963: [D loss: 0.700292, acc: 0.492188]  [A loss: 0.811221, acc: 0.226562]\n",
            "6964: [D loss: 0.704989, acc: 0.503906]  [A loss: 0.765896, acc: 0.339844]\n",
            "6965: [D loss: 0.709185, acc: 0.511719]  [A loss: 0.868472, acc: 0.160156]\n",
            "6966: [D loss: 0.712415, acc: 0.462891]  [A loss: 0.783382, acc: 0.285156]\n",
            "6967: [D loss: 0.707708, acc: 0.496094]  [A loss: 0.821501, acc: 0.222656]\n",
            "6968: [D loss: 0.700527, acc: 0.492188]  [A loss: 0.785140, acc: 0.378906]\n",
            "6969: [D loss: 0.709234, acc: 0.521484]  [A loss: 0.860234, acc: 0.148438]\n",
            "6970: [D loss: 0.710841, acc: 0.498047]  [A loss: 0.864851, acc: 0.187500]\n",
            "6971: [D loss: 0.706104, acc: 0.515625]  [A loss: 0.774225, acc: 0.335938]\n",
            "6972: [D loss: 0.706964, acc: 0.511719]  [A loss: 0.869414, acc: 0.156250]\n",
            "6973: [D loss: 0.693685, acc: 0.500000]  [A loss: 0.804161, acc: 0.289062]\n",
            "6974: [D loss: 0.688883, acc: 0.527344]  [A loss: 0.873669, acc: 0.183594]\n",
            "6975: [D loss: 0.707558, acc: 0.503906]  [A loss: 0.720446, acc: 0.441406]\n",
            "6976: [D loss: 0.704144, acc: 0.537109]  [A loss: 0.937981, acc: 0.109375]\n",
            "6977: [D loss: 0.703023, acc: 0.511719]  [A loss: 0.657384, acc: 0.601562]\n",
            "6978: [D loss: 0.725994, acc: 0.498047]  [A loss: 0.912516, acc: 0.144531]\n",
            "6979: [D loss: 0.714177, acc: 0.472656]  [A loss: 0.697138, acc: 0.527344]\n",
            "6980: [D loss: 0.705929, acc: 0.515625]  [A loss: 0.861291, acc: 0.167969]\n",
            "6981: [D loss: 0.707699, acc: 0.492188]  [A loss: 0.780782, acc: 0.339844]\n",
            "6982: [D loss: 0.702289, acc: 0.541016]  [A loss: 0.834789, acc: 0.187500]\n",
            "6983: [D loss: 0.705112, acc: 0.501953]  [A loss: 0.767382, acc: 0.316406]\n",
            "6984: [D loss: 0.700166, acc: 0.496094]  [A loss: 0.819877, acc: 0.203125]\n",
            "6985: [D loss: 0.695592, acc: 0.523438]  [A loss: 0.759216, acc: 0.332031]\n",
            "6986: [D loss: 0.701140, acc: 0.517578]  [A loss: 0.861287, acc: 0.175781]\n",
            "6987: [D loss: 0.704363, acc: 0.500000]  [A loss: 0.749063, acc: 0.371094]\n",
            "6988: [D loss: 0.703598, acc: 0.484375]  [A loss: 0.842963, acc: 0.175781]\n",
            "6989: [D loss: 0.689164, acc: 0.535156]  [A loss: 0.766717, acc: 0.316406]\n",
            "6990: [D loss: 0.702371, acc: 0.500000]  [A loss: 0.843844, acc: 0.195312]\n",
            "6991: [D loss: 0.700292, acc: 0.511719]  [A loss: 0.816425, acc: 0.261719]\n",
            "6992: [D loss: 0.696629, acc: 0.523438]  [A loss: 0.803297, acc: 0.246094]\n",
            "6993: [D loss: 0.707167, acc: 0.527344]  [A loss: 0.898419, acc: 0.144531]\n",
            "6994: [D loss: 0.688701, acc: 0.535156]  [A loss: 0.682721, acc: 0.535156]\n",
            "6995: [D loss: 0.703435, acc: 0.523438]  [A loss: 0.923643, acc: 0.101562]\n",
            "6996: [D loss: 0.695721, acc: 0.527344]  [A loss: 0.703591, acc: 0.480469]\n",
            "6997: [D loss: 0.717765, acc: 0.488281]  [A loss: 0.891063, acc: 0.097656]\n",
            "6998: [D loss: 0.699333, acc: 0.511719]  [A loss: 0.719609, acc: 0.449219]\n",
            "6999: [D loss: 0.708902, acc: 0.509766]  [A loss: 0.880294, acc: 0.167969]\n",
            "7000: [D loss: 0.700939, acc: 0.531250]  [A loss: 0.700436, acc: 0.476562]\n",
            "7001: [D loss: 0.722077, acc: 0.498047]  [A loss: 0.859377, acc: 0.140625]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7002: [D loss: 0.689968, acc: 0.542969]  [A loss: 0.725205, acc: 0.437500]\n",
            "7003: [D loss: 0.707009, acc: 0.507812]  [A loss: 1.013161, acc: 0.062500]\n",
            "7004: [D loss: 0.699590, acc: 0.531250]  [A loss: 0.759562, acc: 0.351562]\n",
            "7005: [D loss: 0.687484, acc: 0.544922]  [A loss: 0.835938, acc: 0.214844]\n",
            "7006: [D loss: 0.689157, acc: 0.554688]  [A loss: 0.767417, acc: 0.332031]\n",
            "7007: [D loss: 0.700668, acc: 0.523438]  [A loss: 0.829169, acc: 0.214844]\n",
            "7008: [D loss: 0.689526, acc: 0.556641]  [A loss: 0.721041, acc: 0.453125]\n",
            "7009: [D loss: 0.715723, acc: 0.519531]  [A loss: 0.880136, acc: 0.164062]\n",
            "7010: [D loss: 0.694749, acc: 0.519531]  [A loss: 0.770006, acc: 0.316406]\n",
            "7011: [D loss: 0.699767, acc: 0.513672]  [A loss: 0.818517, acc: 0.199219]\n",
            "7012: [D loss: 0.698907, acc: 0.515625]  [A loss: 0.787461, acc: 0.335938]\n",
            "7013: [D loss: 0.703540, acc: 0.511719]  [A loss: 0.841410, acc: 0.199219]\n",
            "7014: [D loss: 0.702296, acc: 0.496094]  [A loss: 0.781430, acc: 0.281250]\n",
            "7015: [D loss: 0.697179, acc: 0.535156]  [A loss: 0.885510, acc: 0.128906]\n",
            "7016: [D loss: 0.703860, acc: 0.505859]  [A loss: 0.708938, acc: 0.472656]\n",
            "7017: [D loss: 0.710442, acc: 0.505859]  [A loss: 0.913778, acc: 0.136719]\n",
            "7018: [D loss: 0.704219, acc: 0.519531]  [A loss: 0.782317, acc: 0.261719]\n",
            "7019: [D loss: 0.709475, acc: 0.474609]  [A loss: 0.839995, acc: 0.187500]\n",
            "7020: [D loss: 0.707821, acc: 0.494141]  [A loss: 0.767959, acc: 0.320312]\n",
            "7021: [D loss: 0.699692, acc: 0.527344]  [A loss: 0.790955, acc: 0.261719]\n",
            "7022: [D loss: 0.707526, acc: 0.511719]  [A loss: 0.825968, acc: 0.203125]\n",
            "7023: [D loss: 0.702000, acc: 0.511719]  [A loss: 0.829436, acc: 0.238281]\n",
            "7024: [D loss: 0.690979, acc: 0.529297]  [A loss: 0.698354, acc: 0.496094]\n",
            "7025: [D loss: 0.707331, acc: 0.494141]  [A loss: 0.882707, acc: 0.144531]\n",
            "7026: [D loss: 0.696463, acc: 0.529297]  [A loss: 0.770433, acc: 0.332031]\n",
            "7027: [D loss: 0.726126, acc: 0.468750]  [A loss: 0.856123, acc: 0.187500]\n",
            "7028: [D loss: 0.699898, acc: 0.515625]  [A loss: 0.748867, acc: 0.414062]\n",
            "7029: [D loss: 0.715720, acc: 0.498047]  [A loss: 0.911506, acc: 0.121094]\n",
            "7030: [D loss: 0.687177, acc: 0.552734]  [A loss: 0.704125, acc: 0.492188]\n",
            "7031: [D loss: 0.711095, acc: 0.513672]  [A loss: 0.878318, acc: 0.113281]\n",
            "7032: [D loss: 0.682153, acc: 0.529297]  [A loss: 0.753523, acc: 0.339844]\n",
            "7033: [D loss: 0.702161, acc: 0.531250]  [A loss: 0.833567, acc: 0.230469]\n",
            "7034: [D loss: 0.708819, acc: 0.490234]  [A loss: 0.724109, acc: 0.445312]\n",
            "7035: [D loss: 0.704898, acc: 0.498047]  [A loss: 0.883408, acc: 0.152344]\n",
            "7036: [D loss: 0.702291, acc: 0.533203]  [A loss: 0.727219, acc: 0.429688]\n",
            "7037: [D loss: 0.712783, acc: 0.523438]  [A loss: 0.932765, acc: 0.105469]\n",
            "7038: [D loss: 0.703766, acc: 0.507812]  [A loss: 0.683017, acc: 0.542969]\n",
            "7039: [D loss: 0.722156, acc: 0.488281]  [A loss: 0.864256, acc: 0.175781]\n",
            "7040: [D loss: 0.694723, acc: 0.519531]  [A loss: 0.688644, acc: 0.574219]\n",
            "7041: [D loss: 0.708945, acc: 0.521484]  [A loss: 0.988304, acc: 0.058594]\n",
            "7042: [D loss: 0.710109, acc: 0.515625]  [A loss: 0.676568, acc: 0.601562]\n",
            "7043: [D loss: 0.709701, acc: 0.527344]  [A loss: 0.771712, acc: 0.277344]\n",
            "7044: [D loss: 0.707686, acc: 0.505859]  [A loss: 0.745047, acc: 0.375000]\n",
            "7045: [D loss: 0.701681, acc: 0.523438]  [A loss: 0.802300, acc: 0.246094]\n",
            "7046: [D loss: 0.700087, acc: 0.478516]  [A loss: 0.817643, acc: 0.218750]\n",
            "7047: [D loss: 0.708499, acc: 0.505859]  [A loss: 0.830108, acc: 0.207031]\n",
            "7048: [D loss: 0.692771, acc: 0.521484]  [A loss: 0.847648, acc: 0.199219]\n",
            "7049: [D loss: 0.704215, acc: 0.501953]  [A loss: 0.794322, acc: 0.292969]\n",
            "7050: [D loss: 0.702905, acc: 0.525391]  [A loss: 0.797879, acc: 0.257812]\n",
            "7051: [D loss: 0.701567, acc: 0.490234]  [A loss: 0.778706, acc: 0.335938]\n",
            "7052: [D loss: 0.704508, acc: 0.519531]  [A loss: 0.877152, acc: 0.144531]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7053: [D loss: 0.704761, acc: 0.486328]  [A loss: 0.760798, acc: 0.351562]\n",
            "7054: [D loss: 0.696059, acc: 0.533203]  [A loss: 0.809011, acc: 0.289062]\n",
            "7055: [D loss: 0.692154, acc: 0.529297]  [A loss: 0.794803, acc: 0.292969]\n",
            "7056: [D loss: 0.698819, acc: 0.509766]  [A loss: 0.817565, acc: 0.261719]\n",
            "7057: [D loss: 0.709255, acc: 0.500000]  [A loss: 0.782650, acc: 0.316406]\n",
            "7058: [D loss: 0.697781, acc: 0.523438]  [A loss: 0.843051, acc: 0.199219]\n",
            "7059: [D loss: 0.689643, acc: 0.546875]  [A loss: 0.734522, acc: 0.398438]\n",
            "7060: [D loss: 0.703112, acc: 0.525391]  [A loss: 0.833438, acc: 0.207031]\n",
            "7061: [D loss: 0.689203, acc: 0.500000]  [A loss: 0.758354, acc: 0.339844]\n",
            "7062: [D loss: 0.701147, acc: 0.519531]  [A loss: 0.883284, acc: 0.160156]\n",
            "7063: [D loss: 0.694739, acc: 0.521484]  [A loss: 0.775706, acc: 0.437500]\n",
            "7064: [D loss: 0.709498, acc: 0.519531]  [A loss: 0.915459, acc: 0.113281]\n",
            "7065: [D loss: 0.694934, acc: 0.517578]  [A loss: 0.751548, acc: 0.355469]\n",
            "7066: [D loss: 0.710043, acc: 0.498047]  [A loss: 0.858741, acc: 0.164062]\n",
            "7067: [D loss: 0.712724, acc: 0.482422]  [A loss: 0.784334, acc: 0.300781]\n",
            "7068: [D loss: 0.692733, acc: 0.542969]  [A loss: 0.822011, acc: 0.250000]\n",
            "7069: [D loss: 0.691839, acc: 0.531250]  [A loss: 0.797775, acc: 0.273438]\n",
            "7070: [D loss: 0.706817, acc: 0.494141]  [A loss: 0.824841, acc: 0.203125]\n",
            "7071: [D loss: 0.695821, acc: 0.533203]  [A loss: 0.782857, acc: 0.328125]\n",
            "7072: [D loss: 0.684392, acc: 0.552734]  [A loss: 0.765319, acc: 0.308594]\n",
            "7073: [D loss: 0.705730, acc: 0.521484]  [A loss: 0.933702, acc: 0.097656]\n",
            "7074: [D loss: 0.697201, acc: 0.529297]  [A loss: 0.704277, acc: 0.476562]\n",
            "7075: [D loss: 0.696080, acc: 0.523438]  [A loss: 0.847117, acc: 0.199219]\n",
            "7076: [D loss: 0.697888, acc: 0.501953]  [A loss: 0.708388, acc: 0.492188]\n",
            "7077: [D loss: 0.704406, acc: 0.513672]  [A loss: 0.896062, acc: 0.132812]\n",
            "7078: [D loss: 0.700775, acc: 0.535156]  [A loss: 0.785887, acc: 0.312500]\n",
            "7079: [D loss: 0.701777, acc: 0.521484]  [A loss: 0.816998, acc: 0.238281]\n",
            "7080: [D loss: 0.699931, acc: 0.527344]  [A loss: 0.749305, acc: 0.375000]\n",
            "7081: [D loss: 0.716652, acc: 0.478516]  [A loss: 0.932174, acc: 0.105469]\n",
            "7082: [D loss: 0.697910, acc: 0.507812]  [A loss: 0.688916, acc: 0.558594]\n",
            "7083: [D loss: 0.711853, acc: 0.531250]  [A loss: 0.923749, acc: 0.125000]\n",
            "7084: [D loss: 0.690531, acc: 0.531250]  [A loss: 0.718038, acc: 0.488281]\n",
            "7085: [D loss: 0.702999, acc: 0.501953]  [A loss: 0.826171, acc: 0.238281]\n",
            "7086: [D loss: 0.687195, acc: 0.552734]  [A loss: 0.770826, acc: 0.343750]\n",
            "7087: [D loss: 0.702222, acc: 0.535156]  [A loss: 0.878630, acc: 0.156250]\n",
            "7088: [D loss: 0.705427, acc: 0.505859]  [A loss: 0.747419, acc: 0.371094]\n",
            "7089: [D loss: 0.709417, acc: 0.501953]  [A loss: 0.904662, acc: 0.132812]\n",
            "7090: [D loss: 0.702661, acc: 0.515625]  [A loss: 0.751217, acc: 0.414062]\n",
            "7091: [D loss: 0.692701, acc: 0.535156]  [A loss: 0.907501, acc: 0.191406]\n",
            "7092: [D loss: 0.692099, acc: 0.533203]  [A loss: 0.762890, acc: 0.339844]\n",
            "7093: [D loss: 0.704046, acc: 0.494141]  [A loss: 0.854022, acc: 0.222656]\n",
            "7094: [D loss: 0.701681, acc: 0.521484]  [A loss: 0.730358, acc: 0.417969]\n",
            "7095: [D loss: 0.707525, acc: 0.505859]  [A loss: 0.849060, acc: 0.164062]\n",
            "7096: [D loss: 0.690865, acc: 0.513672]  [A loss: 0.708630, acc: 0.484375]\n",
            "7097: [D loss: 0.720544, acc: 0.488281]  [A loss: 0.884446, acc: 0.132812]\n",
            "7098: [D loss: 0.687897, acc: 0.542969]  [A loss: 0.759260, acc: 0.390625]\n",
            "7099: [D loss: 0.698933, acc: 0.541016]  [A loss: 0.812450, acc: 0.222656]\n",
            "7100: [D loss: 0.702121, acc: 0.488281]  [A loss: 0.751958, acc: 0.367188]\n",
            "7101: [D loss: 0.700131, acc: 0.513672]  [A loss: 0.807808, acc: 0.285156]\n",
            "7102: [D loss: 0.706625, acc: 0.478516]  [A loss: 0.787336, acc: 0.304688]\n",
            "7103: [D loss: 0.700403, acc: 0.511719]  [A loss: 0.786955, acc: 0.292969]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7104: [D loss: 0.703303, acc: 0.541016]  [A loss: 0.809161, acc: 0.257812]\n",
            "7105: [D loss: 0.693304, acc: 0.550781]  [A loss: 0.784100, acc: 0.312500]\n",
            "7106: [D loss: 0.686121, acc: 0.583984]  [A loss: 0.820402, acc: 0.285156]\n",
            "7107: [D loss: 0.698443, acc: 0.527344]  [A loss: 0.827176, acc: 0.226562]\n",
            "7108: [D loss: 0.692952, acc: 0.531250]  [A loss: 0.836888, acc: 0.265625]\n",
            "7109: [D loss: 0.690311, acc: 0.544922]  [A loss: 0.916245, acc: 0.132812]\n",
            "7110: [D loss: 0.697451, acc: 0.519531]  [A loss: 0.729777, acc: 0.449219]\n",
            "7111: [D loss: 0.720578, acc: 0.515625]  [A loss: 1.030856, acc: 0.058594]\n",
            "7112: [D loss: 0.706312, acc: 0.511719]  [A loss: 0.636550, acc: 0.660156]\n",
            "7113: [D loss: 0.727192, acc: 0.503906]  [A loss: 0.895562, acc: 0.140625]\n",
            "7114: [D loss: 0.697240, acc: 0.498047]  [A loss: 0.725669, acc: 0.429688]\n",
            "7115: [D loss: 0.712215, acc: 0.498047]  [A loss: 0.785644, acc: 0.335938]\n",
            "7116: [D loss: 0.696669, acc: 0.517578]  [A loss: 0.762999, acc: 0.339844]\n",
            "7117: [D loss: 0.705885, acc: 0.496094]  [A loss: 0.784581, acc: 0.328125]\n",
            "7118: [D loss: 0.696944, acc: 0.529297]  [A loss: 0.792402, acc: 0.242188]\n",
            "7119: [D loss: 0.713719, acc: 0.470703]  [A loss: 0.761552, acc: 0.355469]\n",
            "7120: [D loss: 0.702027, acc: 0.529297]  [A loss: 0.785497, acc: 0.289062]\n",
            "7121: [D loss: 0.702616, acc: 0.529297]  [A loss: 0.785148, acc: 0.312500]\n",
            "7122: [D loss: 0.695942, acc: 0.521484]  [A loss: 0.816575, acc: 0.257812]\n",
            "7123: [D loss: 0.692404, acc: 0.533203]  [A loss: 0.838031, acc: 0.238281]\n",
            "7124: [D loss: 0.697921, acc: 0.525391]  [A loss: 0.728922, acc: 0.445312]\n",
            "7125: [D loss: 0.702942, acc: 0.539062]  [A loss: 0.838626, acc: 0.269531]\n",
            "7126: [D loss: 0.706938, acc: 0.511719]  [A loss: 0.896469, acc: 0.152344]\n",
            "7127: [D loss: 0.703400, acc: 0.509766]  [A loss: 0.768640, acc: 0.351562]\n",
            "7128: [D loss: 0.704199, acc: 0.523438]  [A loss: 0.885335, acc: 0.156250]\n",
            "7129: [D loss: 0.696647, acc: 0.542969]  [A loss: 0.745549, acc: 0.378906]\n",
            "7130: [D loss: 0.714661, acc: 0.507812]  [A loss: 0.975839, acc: 0.105469]\n",
            "7131: [D loss: 0.714431, acc: 0.498047]  [A loss: 0.669017, acc: 0.593750]\n",
            "7132: [D loss: 0.718657, acc: 0.496094]  [A loss: 0.894187, acc: 0.125000]\n",
            "7133: [D loss: 0.705593, acc: 0.492188]  [A loss: 0.747747, acc: 0.371094]\n",
            "7134: [D loss: 0.702909, acc: 0.521484]  [A loss: 0.880696, acc: 0.175781]\n",
            "7135: [D loss: 0.703892, acc: 0.474609]  [A loss: 0.745411, acc: 0.441406]\n",
            "7136: [D loss: 0.707391, acc: 0.525391]  [A loss: 0.846924, acc: 0.191406]\n",
            "7137: [D loss: 0.714503, acc: 0.490234]  [A loss: 0.734574, acc: 0.414062]\n",
            "7138: [D loss: 0.716181, acc: 0.517578]  [A loss: 0.827017, acc: 0.238281]\n",
            "7139: [D loss: 0.702412, acc: 0.496094]  [A loss: 0.748166, acc: 0.386719]\n",
            "7140: [D loss: 0.706719, acc: 0.527344]  [A loss: 0.826599, acc: 0.183594]\n",
            "7141: [D loss: 0.701901, acc: 0.515625]  [A loss: 0.730712, acc: 0.441406]\n",
            "7142: [D loss: 0.697599, acc: 0.515625]  [A loss: 0.835857, acc: 0.195312]\n",
            "7143: [D loss: 0.704454, acc: 0.498047]  [A loss: 0.803162, acc: 0.273438]\n",
            "7144: [D loss: 0.703521, acc: 0.529297]  [A loss: 0.807247, acc: 0.261719]\n",
            "7145: [D loss: 0.705684, acc: 0.511719]  [A loss: 0.786361, acc: 0.300781]\n",
            "7146: [D loss: 0.706917, acc: 0.527344]  [A loss: 0.851482, acc: 0.218750]\n",
            "7147: [D loss: 0.712338, acc: 0.478516]  [A loss: 0.743766, acc: 0.421875]\n",
            "7148: [D loss: 0.699622, acc: 0.517578]  [A loss: 0.875049, acc: 0.160156]\n",
            "7149: [D loss: 0.696959, acc: 0.527344]  [A loss: 0.793671, acc: 0.312500]\n",
            "7150: [D loss: 0.701055, acc: 0.535156]  [A loss: 0.758157, acc: 0.351562]\n",
            "7151: [D loss: 0.710403, acc: 0.511719]  [A loss: 0.937164, acc: 0.109375]\n",
            "7152: [D loss: 0.714176, acc: 0.501953]  [A loss: 0.672914, acc: 0.609375]\n",
            "7153: [D loss: 0.731284, acc: 0.500000]  [A loss: 0.920807, acc: 0.093750]\n",
            "7154: [D loss: 0.698682, acc: 0.519531]  [A loss: 0.678412, acc: 0.566406]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7155: [D loss: 0.711151, acc: 0.519531]  [A loss: 0.941850, acc: 0.058594]\n",
            "7156: [D loss: 0.704603, acc: 0.480469]  [A loss: 0.700540, acc: 0.476562]\n",
            "7157: [D loss: 0.705054, acc: 0.533203]  [A loss: 0.843547, acc: 0.175781]\n",
            "7158: [D loss: 0.692613, acc: 0.539062]  [A loss: 0.729083, acc: 0.468750]\n",
            "7159: [D loss: 0.698759, acc: 0.535156]  [A loss: 0.858920, acc: 0.179688]\n",
            "7160: [D loss: 0.700485, acc: 0.509766]  [A loss: 0.729373, acc: 0.441406]\n",
            "7161: [D loss: 0.702933, acc: 0.513672]  [A loss: 0.837056, acc: 0.199219]\n",
            "7162: [D loss: 0.700741, acc: 0.494141]  [A loss: 0.815719, acc: 0.218750]\n",
            "7163: [D loss: 0.713933, acc: 0.494141]  [A loss: 0.829274, acc: 0.238281]\n",
            "7164: [D loss: 0.692429, acc: 0.515625]  [A loss: 0.760553, acc: 0.382812]\n",
            "7165: [D loss: 0.707706, acc: 0.515625]  [A loss: 0.831298, acc: 0.207031]\n",
            "7166: [D loss: 0.706051, acc: 0.517578]  [A loss: 0.761086, acc: 0.343750]\n",
            "7167: [D loss: 0.692557, acc: 0.546875]  [A loss: 0.778535, acc: 0.304688]\n",
            "7168: [D loss: 0.697431, acc: 0.523438]  [A loss: 0.855446, acc: 0.167969]\n",
            "7169: [D loss: 0.702733, acc: 0.490234]  [A loss: 0.764509, acc: 0.328125]\n",
            "7170: [D loss: 0.709650, acc: 0.498047]  [A loss: 0.833301, acc: 0.199219]\n",
            "7171: [D loss: 0.697602, acc: 0.509766]  [A loss: 0.703882, acc: 0.503906]\n",
            "7172: [D loss: 0.696800, acc: 0.535156]  [A loss: 0.945193, acc: 0.093750]\n",
            "7173: [D loss: 0.707280, acc: 0.505859]  [A loss: 0.715469, acc: 0.488281]\n",
            "7174: [D loss: 0.700088, acc: 0.527344]  [A loss: 0.856520, acc: 0.203125]\n",
            "7175: [D loss: 0.702883, acc: 0.484375]  [A loss: 0.694152, acc: 0.500000]\n",
            "7176: [D loss: 0.729565, acc: 0.484375]  [A loss: 0.904684, acc: 0.113281]\n",
            "7177: [D loss: 0.696137, acc: 0.562500]  [A loss: 0.733229, acc: 0.421875]\n",
            "7178: [D loss: 0.707496, acc: 0.513672]  [A loss: 0.852152, acc: 0.199219]\n",
            "7179: [D loss: 0.701861, acc: 0.507812]  [A loss: 0.793445, acc: 0.261719]\n",
            "7180: [D loss: 0.716354, acc: 0.486328]  [A loss: 0.843480, acc: 0.207031]\n",
            "7181: [D loss: 0.702071, acc: 0.501953]  [A loss: 0.739351, acc: 0.382812]\n",
            "7182: [D loss: 0.692293, acc: 0.537109]  [A loss: 0.861877, acc: 0.175781]\n",
            "7183: [D loss: 0.691167, acc: 0.535156]  [A loss: 0.745637, acc: 0.394531]\n",
            "7184: [D loss: 0.725242, acc: 0.490234]  [A loss: 0.862821, acc: 0.136719]\n",
            "7185: [D loss: 0.695197, acc: 0.527344]  [A loss: 0.777275, acc: 0.308594]\n",
            "7186: [D loss: 0.702776, acc: 0.513672]  [A loss: 0.836241, acc: 0.195312]\n",
            "7187: [D loss: 0.693698, acc: 0.527344]  [A loss: 0.731872, acc: 0.453125]\n",
            "7188: [D loss: 0.703715, acc: 0.511719]  [A loss: 0.853634, acc: 0.214844]\n",
            "7189: [D loss: 0.705316, acc: 0.529297]  [A loss: 0.816321, acc: 0.222656]\n",
            "7190: [D loss: 0.694065, acc: 0.533203]  [A loss: 0.818829, acc: 0.273438]\n",
            "7191: [D loss: 0.716661, acc: 0.484375]  [A loss: 0.830914, acc: 0.222656]\n",
            "7192: [D loss: 0.703599, acc: 0.494141]  [A loss: 0.761218, acc: 0.324219]\n",
            "7193: [D loss: 0.708652, acc: 0.525391]  [A loss: 0.872287, acc: 0.148438]\n",
            "7194: [D loss: 0.708339, acc: 0.505859]  [A loss: 0.743715, acc: 0.394531]\n",
            "7195: [D loss: 0.703936, acc: 0.527344]  [A loss: 0.895251, acc: 0.160156]\n",
            "7196: [D loss: 0.714149, acc: 0.474609]  [A loss: 0.737768, acc: 0.398438]\n",
            "7197: [D loss: 0.710868, acc: 0.503906]  [A loss: 0.924006, acc: 0.101562]\n",
            "7198: [D loss: 0.707984, acc: 0.490234]  [A loss: 0.686156, acc: 0.515625]\n",
            "7199: [D loss: 0.704144, acc: 0.517578]  [A loss: 0.906168, acc: 0.136719]\n",
            "7200: [D loss: 0.710502, acc: 0.490234]  [A loss: 0.719642, acc: 0.457031]\n",
            "7201: [D loss: 0.715920, acc: 0.490234]  [A loss: 0.892156, acc: 0.171875]\n",
            "7202: [D loss: 0.704014, acc: 0.519531]  [A loss: 0.775617, acc: 0.339844]\n",
            "7203: [D loss: 0.705811, acc: 0.468750]  [A loss: 0.854500, acc: 0.183594]\n",
            "7204: [D loss: 0.717733, acc: 0.490234]  [A loss: 0.786111, acc: 0.316406]\n",
            "7205: [D loss: 0.705105, acc: 0.500000]  [A loss: 0.771126, acc: 0.339844]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7206: [D loss: 0.710855, acc: 0.498047]  [A loss: 0.876858, acc: 0.156250]\n",
            "7207: [D loss: 0.697056, acc: 0.531250]  [A loss: 0.796066, acc: 0.250000]\n",
            "7208: [D loss: 0.695698, acc: 0.552734]  [A loss: 0.801335, acc: 0.261719]\n",
            "7209: [D loss: 0.687535, acc: 0.544922]  [A loss: 0.813134, acc: 0.222656]\n",
            "7210: [D loss: 0.699553, acc: 0.488281]  [A loss: 0.738202, acc: 0.390625]\n",
            "7211: [D loss: 0.706447, acc: 0.509766]  [A loss: 0.893385, acc: 0.136719]\n",
            "7212: [D loss: 0.708838, acc: 0.509766]  [A loss: 0.713389, acc: 0.484375]\n",
            "7213: [D loss: 0.714492, acc: 0.515625]  [A loss: 0.873074, acc: 0.167969]\n",
            "7214: [D loss: 0.690485, acc: 0.554688]  [A loss: 0.736419, acc: 0.417969]\n",
            "7215: [D loss: 0.714144, acc: 0.496094]  [A loss: 0.865955, acc: 0.203125]\n",
            "7216: [D loss: 0.681900, acc: 0.525391]  [A loss: 0.724395, acc: 0.433594]\n",
            "7217: [D loss: 0.715701, acc: 0.488281]  [A loss: 0.883965, acc: 0.160156]\n",
            "7218: [D loss: 0.708352, acc: 0.468750]  [A loss: 0.769523, acc: 0.300781]\n",
            "7219: [D loss: 0.707894, acc: 0.511719]  [A loss: 0.816822, acc: 0.250000]\n",
            "7220: [D loss: 0.693007, acc: 0.529297]  [A loss: 0.776870, acc: 0.300781]\n",
            "7221: [D loss: 0.712162, acc: 0.486328]  [A loss: 0.856918, acc: 0.179688]\n",
            "7222: [D loss: 0.702190, acc: 0.472656]  [A loss: 0.704994, acc: 0.476562]\n",
            "7223: [D loss: 0.722255, acc: 0.509766]  [A loss: 0.965909, acc: 0.070312]\n",
            "7224: [D loss: 0.706806, acc: 0.507812]  [A loss: 0.702744, acc: 0.492188]\n",
            "7225: [D loss: 0.719333, acc: 0.511719]  [A loss: 0.913237, acc: 0.144531]\n",
            "7226: [D loss: 0.711293, acc: 0.476562]  [A loss: 0.695994, acc: 0.507812]\n",
            "7227: [D loss: 0.716156, acc: 0.490234]  [A loss: 0.817965, acc: 0.242188]\n",
            "7228: [D loss: 0.701790, acc: 0.503906]  [A loss: 0.776449, acc: 0.390625]\n",
            "7229: [D loss: 0.709404, acc: 0.500000]  [A loss: 0.909757, acc: 0.101562]\n",
            "7230: [D loss: 0.686673, acc: 0.507812]  [A loss: 0.721261, acc: 0.460938]\n",
            "7231: [D loss: 0.713933, acc: 0.513672]  [A loss: 0.843643, acc: 0.226562]\n",
            "7232: [D loss: 0.675002, acc: 0.566406]  [A loss: 0.736302, acc: 0.433594]\n",
            "7233: [D loss: 0.706085, acc: 0.517578]  [A loss: 0.921340, acc: 0.082031]\n",
            "7234: [D loss: 0.685702, acc: 0.564453]  [A loss: 0.720215, acc: 0.453125]\n",
            "7235: [D loss: 0.717602, acc: 0.505859]  [A loss: 0.853015, acc: 0.179688]\n",
            "7236: [D loss: 0.701636, acc: 0.509766]  [A loss: 0.748170, acc: 0.414062]\n",
            "7237: [D loss: 0.704466, acc: 0.523438]  [A loss: 0.865555, acc: 0.183594]\n",
            "7238: [D loss: 0.694316, acc: 0.507812]  [A loss: 0.698983, acc: 0.496094]\n",
            "7239: [D loss: 0.705564, acc: 0.521484]  [A loss: 0.882016, acc: 0.160156]\n",
            "7240: [D loss: 0.697316, acc: 0.537109]  [A loss: 0.704491, acc: 0.507812]\n",
            "7241: [D loss: 0.715025, acc: 0.523438]  [A loss: 0.881273, acc: 0.132812]\n",
            "7242: [D loss: 0.693693, acc: 0.521484]  [A loss: 0.738131, acc: 0.449219]\n",
            "7243: [D loss: 0.706367, acc: 0.515625]  [A loss: 0.809814, acc: 0.242188]\n",
            "7244: [D loss: 0.678171, acc: 0.560547]  [A loss: 0.767775, acc: 0.320312]\n",
            "7245: [D loss: 0.698309, acc: 0.527344]  [A loss: 0.803573, acc: 0.257812]\n",
            "7246: [D loss: 0.699874, acc: 0.500000]  [A loss: 0.777369, acc: 0.328125]\n",
            "7247: [D loss: 0.693756, acc: 0.550781]  [A loss: 0.792933, acc: 0.273438]\n",
            "7248: [D loss: 0.717025, acc: 0.472656]  [A loss: 0.840992, acc: 0.214844]\n",
            "7249: [D loss: 0.688083, acc: 0.531250]  [A loss: 0.765525, acc: 0.335938]\n",
            "7250: [D loss: 0.711332, acc: 0.500000]  [A loss: 0.832874, acc: 0.234375]\n",
            "7251: [D loss: 0.697231, acc: 0.527344]  [A loss: 0.751774, acc: 0.363281]\n",
            "7252: [D loss: 0.699266, acc: 0.521484]  [A loss: 0.806011, acc: 0.253906]\n",
            "7253: [D loss: 0.692785, acc: 0.550781]  [A loss: 0.780204, acc: 0.355469]\n",
            "7254: [D loss: 0.705825, acc: 0.503906]  [A loss: 0.807749, acc: 0.273438]\n",
            "7255: [D loss: 0.708575, acc: 0.519531]  [A loss: 0.787638, acc: 0.304688]\n",
            "7256: [D loss: 0.697269, acc: 0.521484]  [A loss: 0.821956, acc: 0.246094]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7257: [D loss: 0.688002, acc: 0.558594]  [A loss: 0.801531, acc: 0.277344]\n",
            "7258: [D loss: 0.681996, acc: 0.564453]  [A loss: 0.857964, acc: 0.167969]\n",
            "7259: [D loss: 0.698880, acc: 0.521484]  [A loss: 0.753079, acc: 0.363281]\n",
            "7260: [D loss: 0.708939, acc: 0.513672]  [A loss: 0.977960, acc: 0.078125]\n",
            "7261: [D loss: 0.700352, acc: 0.505859]  [A loss: 0.661488, acc: 0.585938]\n",
            "7262: [D loss: 0.737353, acc: 0.492188]  [A loss: 0.976243, acc: 0.039062]\n",
            "7263: [D loss: 0.699446, acc: 0.507812]  [A loss: 0.686464, acc: 0.523438]\n",
            "7264: [D loss: 0.723489, acc: 0.501953]  [A loss: 0.943455, acc: 0.121094]\n",
            "7265: [D loss: 0.702157, acc: 0.519531]  [A loss: 0.753707, acc: 0.378906]\n",
            "7266: [D loss: 0.696705, acc: 0.507812]  [A loss: 0.877130, acc: 0.121094]\n",
            "7267: [D loss: 0.685014, acc: 0.558594]  [A loss: 0.723520, acc: 0.437500]\n",
            "7268: [D loss: 0.700965, acc: 0.513672]  [A loss: 0.866800, acc: 0.171875]\n",
            "7269: [D loss: 0.692659, acc: 0.542969]  [A loss: 0.736826, acc: 0.425781]\n",
            "7270: [D loss: 0.701355, acc: 0.521484]  [A loss: 0.786097, acc: 0.308594]\n",
            "7271: [D loss: 0.695225, acc: 0.496094]  [A loss: 0.789067, acc: 0.300781]\n",
            "7272: [D loss: 0.705116, acc: 0.505859]  [A loss: 0.837064, acc: 0.230469]\n",
            "7273: [D loss: 0.700308, acc: 0.505859]  [A loss: 0.784527, acc: 0.281250]\n",
            "7274: [D loss: 0.707106, acc: 0.490234]  [A loss: 0.796610, acc: 0.269531]\n",
            "7275: [D loss: 0.700776, acc: 0.533203]  [A loss: 0.798612, acc: 0.257812]\n",
            "7276: [D loss: 0.708698, acc: 0.482422]  [A loss: 0.794827, acc: 0.261719]\n",
            "7277: [D loss: 0.692174, acc: 0.521484]  [A loss: 0.795622, acc: 0.265625]\n",
            "7278: [D loss: 0.704449, acc: 0.509766]  [A loss: 0.808688, acc: 0.238281]\n",
            "7279: [D loss: 0.708828, acc: 0.486328]  [A loss: 0.855963, acc: 0.179688]\n",
            "7280: [D loss: 0.704625, acc: 0.505859]  [A loss: 0.729414, acc: 0.433594]\n",
            "7281: [D loss: 0.708041, acc: 0.509766]  [A loss: 0.963936, acc: 0.093750]\n",
            "7282: [D loss: 0.713995, acc: 0.498047]  [A loss: 0.639341, acc: 0.636719]\n",
            "7283: [D loss: 0.722980, acc: 0.498047]  [A loss: 0.895323, acc: 0.199219]\n",
            "7284: [D loss: 0.688141, acc: 0.560547]  [A loss: 0.676132, acc: 0.574219]\n",
            "7285: [D loss: 0.728367, acc: 0.476562]  [A loss: 0.915807, acc: 0.125000]\n",
            "7286: [D loss: 0.705011, acc: 0.496094]  [A loss: 0.715459, acc: 0.484375]\n",
            "7287: [D loss: 0.716217, acc: 0.492188]  [A loss: 0.855423, acc: 0.175781]\n",
            "7288: [D loss: 0.694515, acc: 0.511719]  [A loss: 0.724732, acc: 0.433594]\n",
            "7289: [D loss: 0.706071, acc: 0.505859]  [A loss: 0.807655, acc: 0.250000]\n",
            "7290: [D loss: 0.696678, acc: 0.521484]  [A loss: 0.819907, acc: 0.218750]\n",
            "7291: [D loss: 0.699988, acc: 0.492188]  [A loss: 0.775786, acc: 0.328125]\n",
            "7292: [D loss: 0.712911, acc: 0.492188]  [A loss: 0.790336, acc: 0.289062]\n",
            "7293: [D loss: 0.708002, acc: 0.521484]  [A loss: 0.826114, acc: 0.218750]\n",
            "7294: [D loss: 0.690353, acc: 0.533203]  [A loss: 0.757959, acc: 0.378906]\n",
            "7295: [D loss: 0.704243, acc: 0.539062]  [A loss: 0.839503, acc: 0.218750]\n",
            "7296: [D loss: 0.697160, acc: 0.515625]  [A loss: 0.707809, acc: 0.468750]\n",
            "7297: [D loss: 0.711253, acc: 0.500000]  [A loss: 0.854115, acc: 0.171875]\n",
            "7298: [D loss: 0.695816, acc: 0.529297]  [A loss: 0.782198, acc: 0.335938]\n",
            "7299: [D loss: 0.705660, acc: 0.515625]  [A loss: 0.837868, acc: 0.203125]\n",
            "7300: [D loss: 0.692599, acc: 0.546875]  [A loss: 0.743889, acc: 0.402344]\n",
            "7301: [D loss: 0.713358, acc: 0.511719]  [A loss: 0.882828, acc: 0.167969]\n",
            "7302: [D loss: 0.712156, acc: 0.511719]  [A loss: 0.706109, acc: 0.539062]\n",
            "7303: [D loss: 0.703474, acc: 0.527344]  [A loss: 0.857067, acc: 0.195312]\n",
            "7304: [D loss: 0.708454, acc: 0.490234]  [A loss: 0.795357, acc: 0.257812]\n",
            "7305: [D loss: 0.699475, acc: 0.515625]  [A loss: 0.809450, acc: 0.285156]\n",
            "7306: [D loss: 0.715312, acc: 0.474609]  [A loss: 0.804564, acc: 0.253906]\n",
            "7307: [D loss: 0.703377, acc: 0.509766]  [A loss: 0.862237, acc: 0.175781]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7308: [D loss: 0.693252, acc: 0.533203]  [A loss: 0.782548, acc: 0.316406]\n",
            "7309: [D loss: 0.710779, acc: 0.519531]  [A loss: 0.902546, acc: 0.117188]\n",
            "7310: [D loss: 0.707919, acc: 0.496094]  [A loss: 0.708954, acc: 0.503906]\n",
            "7311: [D loss: 0.703968, acc: 0.509766]  [A loss: 0.894496, acc: 0.136719]\n",
            "7312: [D loss: 0.687664, acc: 0.544922]  [A loss: 0.670132, acc: 0.597656]\n",
            "7313: [D loss: 0.719993, acc: 0.517578]  [A loss: 0.915167, acc: 0.117188]\n",
            "7314: [D loss: 0.698625, acc: 0.529297]  [A loss: 0.704976, acc: 0.492188]\n",
            "7315: [D loss: 0.712114, acc: 0.511719]  [A loss: 0.845810, acc: 0.230469]\n",
            "7316: [D loss: 0.697547, acc: 0.517578]  [A loss: 0.683365, acc: 0.527344]\n",
            "7317: [D loss: 0.698355, acc: 0.519531]  [A loss: 0.867793, acc: 0.183594]\n",
            "7318: [D loss: 0.687727, acc: 0.544922]  [A loss: 0.724330, acc: 0.425781]\n",
            "7319: [D loss: 0.706625, acc: 0.488281]  [A loss: 0.870316, acc: 0.140625]\n",
            "7320: [D loss: 0.698227, acc: 0.531250]  [A loss: 0.730810, acc: 0.425781]\n",
            "7321: [D loss: 0.727073, acc: 0.468750]  [A loss: 0.878651, acc: 0.117188]\n",
            "7322: [D loss: 0.699127, acc: 0.517578]  [A loss: 0.695155, acc: 0.515625]\n",
            "7323: [D loss: 0.721979, acc: 0.488281]  [A loss: 0.940345, acc: 0.093750]\n",
            "7324: [D loss: 0.701431, acc: 0.500000]  [A loss: 0.707553, acc: 0.500000]\n",
            "7325: [D loss: 0.695081, acc: 0.537109]  [A loss: 0.865707, acc: 0.207031]\n",
            "7326: [D loss: 0.696840, acc: 0.529297]  [A loss: 0.704359, acc: 0.472656]\n",
            "7327: [D loss: 0.713739, acc: 0.507812]  [A loss: 0.902019, acc: 0.144531]\n",
            "7328: [D loss: 0.686787, acc: 0.566406]  [A loss: 0.763396, acc: 0.437500]\n",
            "7329: [D loss: 0.705296, acc: 0.509766]  [A loss: 0.863577, acc: 0.183594]\n",
            "7330: [D loss: 0.700420, acc: 0.509766]  [A loss: 0.694812, acc: 0.476562]\n",
            "7331: [D loss: 0.713552, acc: 0.517578]  [A loss: 0.867910, acc: 0.183594]\n",
            "7332: [D loss: 0.714944, acc: 0.470703]  [A loss: 0.705835, acc: 0.464844]\n",
            "7333: [D loss: 0.701385, acc: 0.525391]  [A loss: 0.799115, acc: 0.257812]\n",
            "7334: [D loss: 0.696500, acc: 0.509766]  [A loss: 0.824012, acc: 0.230469]\n",
            "7335: [D loss: 0.690561, acc: 0.541016]  [A loss: 0.771888, acc: 0.316406]\n",
            "7336: [D loss: 0.695022, acc: 0.521484]  [A loss: 0.789055, acc: 0.300781]\n",
            "7337: [D loss: 0.700983, acc: 0.490234]  [A loss: 0.816677, acc: 0.281250]\n",
            "7338: [D loss: 0.693706, acc: 0.529297]  [A loss: 0.735838, acc: 0.406250]\n",
            "7339: [D loss: 0.718355, acc: 0.496094]  [A loss: 0.819689, acc: 0.199219]\n",
            "7340: [D loss: 0.690522, acc: 0.537109]  [A loss: 0.853409, acc: 0.203125]\n",
            "7341: [D loss: 0.702726, acc: 0.533203]  [A loss: 0.769545, acc: 0.335938]\n",
            "7342: [D loss: 0.715996, acc: 0.501953]  [A loss: 0.961765, acc: 0.085938]\n",
            "7343: [D loss: 0.704649, acc: 0.515625]  [A loss: 0.764162, acc: 0.339844]\n",
            "7344: [D loss: 0.707198, acc: 0.498047]  [A loss: 0.865470, acc: 0.164062]\n",
            "7345: [D loss: 0.692069, acc: 0.531250]  [A loss: 0.748479, acc: 0.363281]\n",
            "7346: [D loss: 0.709532, acc: 0.500000]  [A loss: 0.860522, acc: 0.164062]\n",
            "7347: [D loss: 0.688076, acc: 0.562500]  [A loss: 0.712986, acc: 0.488281]\n",
            "7348: [D loss: 0.702765, acc: 0.525391]  [A loss: 0.920413, acc: 0.109375]\n",
            "7349: [D loss: 0.693510, acc: 0.509766]  [A loss: 0.702435, acc: 0.464844]\n",
            "7350: [D loss: 0.712289, acc: 0.517578]  [A loss: 0.889694, acc: 0.109375]\n",
            "7351: [D loss: 0.697242, acc: 0.505859]  [A loss: 0.712966, acc: 0.503906]\n",
            "7352: [D loss: 0.718227, acc: 0.494141]  [A loss: 0.876157, acc: 0.144531]\n",
            "7353: [D loss: 0.703690, acc: 0.478516]  [A loss: 0.677089, acc: 0.566406]\n",
            "7354: [D loss: 0.697711, acc: 0.548828]  [A loss: 0.877074, acc: 0.160156]\n",
            "7355: [D loss: 0.698509, acc: 0.505859]  [A loss: 0.698547, acc: 0.511719]\n",
            "7356: [D loss: 0.714216, acc: 0.529297]  [A loss: 0.889895, acc: 0.148438]\n",
            "7357: [D loss: 0.690865, acc: 0.531250]  [A loss: 0.698376, acc: 0.496094]\n",
            "7358: [D loss: 0.701420, acc: 0.511719]  [A loss: 0.843843, acc: 0.230469]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7359: [D loss: 0.698725, acc: 0.498047]  [A loss: 0.759707, acc: 0.390625]\n",
            "7360: [D loss: 0.706010, acc: 0.531250]  [A loss: 0.849043, acc: 0.238281]\n",
            "7361: [D loss: 0.703999, acc: 0.498047]  [A loss: 0.781366, acc: 0.285156]\n",
            "7362: [D loss: 0.699864, acc: 0.550781]  [A loss: 0.808981, acc: 0.265625]\n",
            "7363: [D loss: 0.700251, acc: 0.513672]  [A loss: 0.782496, acc: 0.332031]\n",
            "7364: [D loss: 0.711334, acc: 0.503906]  [A loss: 0.907729, acc: 0.132812]\n",
            "7365: [D loss: 0.693169, acc: 0.500000]  [A loss: 0.718738, acc: 0.464844]\n",
            "7366: [D loss: 0.722839, acc: 0.498047]  [A loss: 0.972210, acc: 0.050781]\n",
            "7367: [D loss: 0.699405, acc: 0.505859]  [A loss: 0.658711, acc: 0.601562]\n",
            "7368: [D loss: 0.734578, acc: 0.503906]  [A loss: 1.014560, acc: 0.054688]\n",
            "7369: [D loss: 0.714429, acc: 0.505859]  [A loss: 0.726157, acc: 0.460938]\n",
            "7370: [D loss: 0.719353, acc: 0.490234]  [A loss: 0.837061, acc: 0.195312]\n",
            "7371: [D loss: 0.691924, acc: 0.539062]  [A loss: 0.824527, acc: 0.265625]\n",
            "7372: [D loss: 0.697996, acc: 0.548828]  [A loss: 0.840997, acc: 0.171875]\n",
            "7373: [D loss: 0.704860, acc: 0.521484]  [A loss: 0.847473, acc: 0.191406]\n",
            "7374: [D loss: 0.691065, acc: 0.494141]  [A loss: 0.860916, acc: 0.175781]\n",
            "7375: [D loss: 0.677599, acc: 0.587891]  [A loss: 0.749823, acc: 0.382812]\n",
            "7376: [D loss: 0.722010, acc: 0.486328]  [A loss: 0.912622, acc: 0.109375]\n",
            "7377: [D loss: 0.698939, acc: 0.523438]  [A loss: 0.700891, acc: 0.519531]\n",
            "7378: [D loss: 0.732155, acc: 0.492188]  [A loss: 0.942973, acc: 0.078125]\n",
            "7379: [D loss: 0.704093, acc: 0.480469]  [A loss: 0.672515, acc: 0.570312]\n",
            "7380: [D loss: 0.710731, acc: 0.533203]  [A loss: 0.870316, acc: 0.175781]\n",
            "7381: [D loss: 0.692899, acc: 0.542969]  [A loss: 0.727096, acc: 0.441406]\n",
            "7382: [D loss: 0.723122, acc: 0.478516]  [A loss: 0.825652, acc: 0.222656]\n",
            "7383: [D loss: 0.702765, acc: 0.505859]  [A loss: 0.752113, acc: 0.386719]\n",
            "7384: [D loss: 0.723532, acc: 0.451172]  [A loss: 0.872696, acc: 0.160156]\n",
            "7385: [D loss: 0.697947, acc: 0.517578]  [A loss: 0.723336, acc: 0.472656]\n",
            "7386: [D loss: 0.711106, acc: 0.513672]  [A loss: 0.835287, acc: 0.214844]\n",
            "7387: [D loss: 0.695154, acc: 0.531250]  [A loss: 0.760740, acc: 0.343750]\n",
            "7388: [D loss: 0.710679, acc: 0.521484]  [A loss: 0.796728, acc: 0.281250]\n",
            "7389: [D loss: 0.698452, acc: 0.527344]  [A loss: 0.775161, acc: 0.339844]\n",
            "7390: [D loss: 0.698318, acc: 0.527344]  [A loss: 0.890501, acc: 0.140625]\n",
            "7391: [D loss: 0.688294, acc: 0.541016]  [A loss: 0.739798, acc: 0.421875]\n",
            "7392: [D loss: 0.700766, acc: 0.533203]  [A loss: 0.835774, acc: 0.230469]\n",
            "7393: [D loss: 0.698671, acc: 0.505859]  [A loss: 0.720763, acc: 0.433594]\n",
            "7394: [D loss: 0.709861, acc: 0.517578]  [A loss: 0.873930, acc: 0.167969]\n",
            "7395: [D loss: 0.704509, acc: 0.490234]  [A loss: 0.775775, acc: 0.371094]\n",
            "7396: [D loss: 0.706288, acc: 0.525391]  [A loss: 0.846690, acc: 0.214844]\n",
            "7397: [D loss: 0.701936, acc: 0.521484]  [A loss: 0.728265, acc: 0.437500]\n",
            "7398: [D loss: 0.708444, acc: 0.537109]  [A loss: 0.831850, acc: 0.218750]\n",
            "7399: [D loss: 0.687043, acc: 0.560547]  [A loss: 0.744113, acc: 0.375000]\n",
            "7400: [D loss: 0.708761, acc: 0.511719]  [A loss: 0.888418, acc: 0.136719]\n",
            "7401: [D loss: 0.678141, acc: 0.576172]  [A loss: 0.720276, acc: 0.453125]\n",
            "7402: [D loss: 0.712162, acc: 0.511719]  [A loss: 0.885282, acc: 0.167969]\n",
            "7403: [D loss: 0.691680, acc: 0.539062]  [A loss: 0.719687, acc: 0.460938]\n",
            "7404: [D loss: 0.728519, acc: 0.486328]  [A loss: 0.982954, acc: 0.074219]\n",
            "7405: [D loss: 0.714727, acc: 0.501953]  [A loss: 0.683462, acc: 0.570312]\n",
            "7406: [D loss: 0.717183, acc: 0.517578]  [A loss: 0.846857, acc: 0.191406]\n",
            "7407: [D loss: 0.695109, acc: 0.515625]  [A loss: 0.773526, acc: 0.320312]\n",
            "7408: [D loss: 0.707165, acc: 0.480469]  [A loss: 0.831913, acc: 0.218750]\n",
            "7409: [D loss: 0.711642, acc: 0.476562]  [A loss: 0.815825, acc: 0.238281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7410: [D loss: 0.706812, acc: 0.511719]  [A loss: 0.779571, acc: 0.304688]\n",
            "7411: [D loss: 0.699783, acc: 0.521484]  [A loss: 0.788600, acc: 0.257812]\n",
            "7412: [D loss: 0.712164, acc: 0.486328]  [A loss: 0.849893, acc: 0.222656]\n",
            "7413: [D loss: 0.692831, acc: 0.513672]  [A loss: 0.837746, acc: 0.179688]\n",
            "7414: [D loss: 0.701406, acc: 0.515625]  [A loss: 0.798926, acc: 0.296875]\n",
            "7415: [D loss: 0.719146, acc: 0.457031]  [A loss: 0.790070, acc: 0.320312]\n",
            "7416: [D loss: 0.686950, acc: 0.523438]  [A loss: 0.845227, acc: 0.199219]\n",
            "7417: [D loss: 0.706591, acc: 0.484375]  [A loss: 0.749234, acc: 0.402344]\n",
            "7418: [D loss: 0.709331, acc: 0.503906]  [A loss: 0.848908, acc: 0.199219]\n",
            "7419: [D loss: 0.689852, acc: 0.521484]  [A loss: 0.745840, acc: 0.402344]\n",
            "7420: [D loss: 0.704679, acc: 0.509766]  [A loss: 0.847867, acc: 0.199219]\n",
            "7421: [D loss: 0.714580, acc: 0.496094]  [A loss: 0.789548, acc: 0.289062]\n",
            "7422: [D loss: 0.701652, acc: 0.527344]  [A loss: 0.809166, acc: 0.292969]\n",
            "7423: [D loss: 0.701766, acc: 0.482422]  [A loss: 0.769770, acc: 0.324219]\n",
            "7424: [D loss: 0.711731, acc: 0.486328]  [A loss: 0.868074, acc: 0.199219]\n",
            "7425: [D loss: 0.692645, acc: 0.554688]  [A loss: 0.766485, acc: 0.367188]\n",
            "7426: [D loss: 0.708853, acc: 0.509766]  [A loss: 0.842471, acc: 0.160156]\n",
            "7427: [D loss: 0.697772, acc: 0.507812]  [A loss: 0.794398, acc: 0.300781]\n",
            "7428: [D loss: 0.704635, acc: 0.548828]  [A loss: 0.754465, acc: 0.386719]\n",
            "7429: [D loss: 0.704183, acc: 0.515625]  [A loss: 0.843060, acc: 0.218750]\n",
            "7430: [D loss: 0.707481, acc: 0.486328]  [A loss: 0.808145, acc: 0.292969]\n",
            "7431: [D loss: 0.709378, acc: 0.488281]  [A loss: 0.941741, acc: 0.128906]\n",
            "7432: [D loss: 0.705063, acc: 0.505859]  [A loss: 0.721224, acc: 0.464844]\n",
            "7433: [D loss: 0.703690, acc: 0.525391]  [A loss: 0.947112, acc: 0.070312]\n",
            "7434: [D loss: 0.698554, acc: 0.509766]  [A loss: 0.649104, acc: 0.636719]\n",
            "7435: [D loss: 0.716423, acc: 0.509766]  [A loss: 0.921526, acc: 0.097656]\n",
            "7436: [D loss: 0.710343, acc: 0.490234]  [A loss: 0.693263, acc: 0.511719]\n",
            "7437: [D loss: 0.715679, acc: 0.501953]  [A loss: 0.844416, acc: 0.183594]\n",
            "7438: [D loss: 0.707877, acc: 0.505859]  [A loss: 0.769344, acc: 0.312500]\n",
            "7439: [D loss: 0.703067, acc: 0.527344]  [A loss: 0.826301, acc: 0.199219]\n",
            "7440: [D loss: 0.692200, acc: 0.539062]  [A loss: 0.783748, acc: 0.320312]\n",
            "7441: [D loss: 0.698485, acc: 0.513672]  [A loss: 0.811327, acc: 0.300781]\n",
            "7442: [D loss: 0.696549, acc: 0.523438]  [A loss: 0.829523, acc: 0.234375]\n",
            "7443: [D loss: 0.701388, acc: 0.490234]  [A loss: 0.757150, acc: 0.328125]\n",
            "7444: [D loss: 0.710007, acc: 0.501953]  [A loss: 0.898897, acc: 0.179688]\n",
            "7445: [D loss: 0.700709, acc: 0.511719]  [A loss: 0.785077, acc: 0.304688]\n",
            "7446: [D loss: 0.696784, acc: 0.523438]  [A loss: 0.919509, acc: 0.171875]\n",
            "7447: [D loss: 0.712397, acc: 0.490234]  [A loss: 0.743350, acc: 0.386719]\n",
            "7448: [D loss: 0.721111, acc: 0.496094]  [A loss: 0.863130, acc: 0.187500]\n",
            "7449: [D loss: 0.697147, acc: 0.525391]  [A loss: 0.752756, acc: 0.367188]\n",
            "7450: [D loss: 0.709343, acc: 0.527344]  [A loss: 0.861566, acc: 0.140625]\n",
            "7451: [D loss: 0.715237, acc: 0.488281]  [A loss: 0.763728, acc: 0.363281]\n",
            "7452: [D loss: 0.716471, acc: 0.498047]  [A loss: 0.915375, acc: 0.101562]\n",
            "7453: [D loss: 0.710071, acc: 0.486328]  [A loss: 0.729408, acc: 0.425781]\n",
            "7454: [D loss: 0.720971, acc: 0.478516]  [A loss: 0.917610, acc: 0.113281]\n",
            "7455: [D loss: 0.707921, acc: 0.490234]  [A loss: 0.751458, acc: 0.359375]\n",
            "7456: [D loss: 0.716727, acc: 0.525391]  [A loss: 0.919216, acc: 0.097656]\n",
            "7457: [D loss: 0.701964, acc: 0.511719]  [A loss: 0.709593, acc: 0.484375]\n",
            "7458: [D loss: 0.720428, acc: 0.484375]  [A loss: 0.890862, acc: 0.148438]\n",
            "7459: [D loss: 0.689950, acc: 0.535156]  [A loss: 0.758883, acc: 0.343750]\n",
            "7460: [D loss: 0.703355, acc: 0.513672]  [A loss: 0.829097, acc: 0.242188]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7461: [D loss: 0.693501, acc: 0.517578]  [A loss: 0.762980, acc: 0.367188]\n",
            "7462: [D loss: 0.709799, acc: 0.503906]  [A loss: 0.849131, acc: 0.175781]\n",
            "7463: [D loss: 0.700380, acc: 0.537109]  [A loss: 0.739510, acc: 0.406250]\n",
            "7464: [D loss: 0.711104, acc: 0.498047]  [A loss: 0.802193, acc: 0.261719]\n",
            "7465: [D loss: 0.697022, acc: 0.519531]  [A loss: 0.794016, acc: 0.324219]\n",
            "7466: [D loss: 0.703888, acc: 0.500000]  [A loss: 0.867247, acc: 0.187500]\n",
            "7467: [D loss: 0.700843, acc: 0.509766]  [A loss: 0.712106, acc: 0.476562]\n",
            "7468: [D loss: 0.712627, acc: 0.501953]  [A loss: 0.881904, acc: 0.136719]\n",
            "7469: [D loss: 0.694411, acc: 0.535156]  [A loss: 0.731544, acc: 0.429688]\n",
            "7470: [D loss: 0.702129, acc: 0.513672]  [A loss: 0.891739, acc: 0.167969]\n",
            "7471: [D loss: 0.707200, acc: 0.509766]  [A loss: 0.693448, acc: 0.554688]\n",
            "7472: [D loss: 0.706837, acc: 0.515625]  [A loss: 0.918786, acc: 0.109375]\n",
            "7473: [D loss: 0.695382, acc: 0.529297]  [A loss: 0.715499, acc: 0.441406]\n",
            "7474: [D loss: 0.702791, acc: 0.519531]  [A loss: 0.891984, acc: 0.152344]\n",
            "7475: [D loss: 0.705404, acc: 0.494141]  [A loss: 0.701993, acc: 0.542969]\n",
            "7476: [D loss: 0.711781, acc: 0.501953]  [A loss: 0.923395, acc: 0.113281]\n",
            "7477: [D loss: 0.704640, acc: 0.496094]  [A loss: 0.733587, acc: 0.402344]\n",
            "7478: [D loss: 0.702690, acc: 0.550781]  [A loss: 0.819506, acc: 0.203125]\n",
            "7479: [D loss: 0.700747, acc: 0.521484]  [A loss: 0.820560, acc: 0.261719]\n",
            "7480: [D loss: 0.706858, acc: 0.505859]  [A loss: 0.804038, acc: 0.289062]\n",
            "7481: [D loss: 0.710357, acc: 0.505859]  [A loss: 0.839182, acc: 0.171875]\n",
            "7482: [D loss: 0.695710, acc: 0.544922]  [A loss: 0.787090, acc: 0.332031]\n",
            "7483: [D loss: 0.709871, acc: 0.476562]  [A loss: 0.811602, acc: 0.203125]\n",
            "7484: [D loss: 0.686052, acc: 0.546875]  [A loss: 0.733485, acc: 0.410156]\n",
            "7485: [D loss: 0.710397, acc: 0.515625]  [A loss: 0.924699, acc: 0.082031]\n",
            "7486: [D loss: 0.697556, acc: 0.519531]  [A loss: 0.673315, acc: 0.582031]\n",
            "7487: [D loss: 0.708026, acc: 0.523438]  [A loss: 0.985485, acc: 0.101562]\n",
            "7488: [D loss: 0.690347, acc: 0.544922]  [A loss: 0.671468, acc: 0.609375]\n",
            "7489: [D loss: 0.714543, acc: 0.492188]  [A loss: 0.869241, acc: 0.164062]\n",
            "7490: [D loss: 0.690209, acc: 0.552734]  [A loss: 0.704597, acc: 0.500000]\n",
            "7491: [D loss: 0.708395, acc: 0.505859]  [A loss: 0.845488, acc: 0.214844]\n",
            "7492: [D loss: 0.701266, acc: 0.513672]  [A loss: 0.754499, acc: 0.386719]\n",
            "7493: [D loss: 0.707004, acc: 0.542969]  [A loss: 0.836844, acc: 0.195312]\n",
            "7494: [D loss: 0.708552, acc: 0.505859]  [A loss: 0.757399, acc: 0.367188]\n",
            "7495: [D loss: 0.717635, acc: 0.480469]  [A loss: 0.821841, acc: 0.238281]\n",
            "7496: [D loss: 0.703049, acc: 0.521484]  [A loss: 0.874695, acc: 0.199219]\n",
            "7497: [D loss: 0.700472, acc: 0.517578]  [A loss: 0.779288, acc: 0.292969]\n",
            "7498: [D loss: 0.704860, acc: 0.509766]  [A loss: 0.857660, acc: 0.183594]\n",
            "7499: [D loss: 0.697333, acc: 0.515625]  [A loss: 0.774527, acc: 0.316406]\n",
            "7500: [D loss: 0.699306, acc: 0.529297]  [A loss: 0.868356, acc: 0.160156]\n",
            "7501: [D loss: 0.703408, acc: 0.513672]  [A loss: 0.721724, acc: 0.437500]\n",
            "7502: [D loss: 0.719428, acc: 0.513672]  [A loss: 0.992618, acc: 0.066406]\n",
            "7503: [D loss: 0.707846, acc: 0.509766]  [A loss: 0.658860, acc: 0.628906]\n",
            "7504: [D loss: 0.712421, acc: 0.500000]  [A loss: 0.909244, acc: 0.136719]\n",
            "7505: [D loss: 0.714790, acc: 0.458984]  [A loss: 0.760496, acc: 0.382812]\n",
            "7506: [D loss: 0.702652, acc: 0.527344]  [A loss: 0.863871, acc: 0.140625]\n",
            "7507: [D loss: 0.680965, acc: 0.558594]  [A loss: 0.724342, acc: 0.421875]\n",
            "7508: [D loss: 0.719471, acc: 0.488281]  [A loss: 0.812372, acc: 0.234375]\n",
            "7509: [D loss: 0.695009, acc: 0.515625]  [A loss: 0.758494, acc: 0.316406]\n",
            "7510: [D loss: 0.704754, acc: 0.511719]  [A loss: 0.861298, acc: 0.160156]\n",
            "7511: [D loss: 0.685871, acc: 0.523438]  [A loss: 0.750529, acc: 0.363281]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7512: [D loss: 0.700920, acc: 0.537109]  [A loss: 0.859751, acc: 0.187500]\n",
            "7513: [D loss: 0.686273, acc: 0.550781]  [A loss: 0.767153, acc: 0.343750]\n",
            "7514: [D loss: 0.704455, acc: 0.517578]  [A loss: 0.824112, acc: 0.199219]\n",
            "7515: [D loss: 0.698044, acc: 0.523438]  [A loss: 0.818263, acc: 0.210938]\n",
            "7516: [D loss: 0.697143, acc: 0.517578]  [A loss: 0.835223, acc: 0.199219]\n",
            "7517: [D loss: 0.687805, acc: 0.546875]  [A loss: 0.803564, acc: 0.230469]\n",
            "7518: [D loss: 0.702601, acc: 0.513672]  [A loss: 0.806123, acc: 0.242188]\n",
            "7519: [D loss: 0.700950, acc: 0.498047]  [A loss: 0.829657, acc: 0.214844]\n",
            "7520: [D loss: 0.706646, acc: 0.513672]  [A loss: 0.803335, acc: 0.250000]\n",
            "7521: [D loss: 0.710492, acc: 0.509766]  [A loss: 0.845525, acc: 0.191406]\n",
            "7522: [D loss: 0.691453, acc: 0.535156]  [A loss: 0.746867, acc: 0.421875]\n",
            "7523: [D loss: 0.711183, acc: 0.503906]  [A loss: 0.875106, acc: 0.148438]\n",
            "7524: [D loss: 0.690363, acc: 0.544922]  [A loss: 0.734484, acc: 0.421875]\n",
            "7525: [D loss: 0.698667, acc: 0.535156]  [A loss: 0.973788, acc: 0.035156]\n",
            "7526: [D loss: 0.708611, acc: 0.509766]  [A loss: 0.655674, acc: 0.671875]\n",
            "7527: [D loss: 0.741124, acc: 0.513672]  [A loss: 1.027232, acc: 0.066406]\n",
            "7528: [D loss: 0.705224, acc: 0.525391]  [A loss: 0.646223, acc: 0.644531]\n",
            "7529: [D loss: 0.737040, acc: 0.511719]  [A loss: 0.931636, acc: 0.078125]\n",
            "7530: [D loss: 0.688424, acc: 0.541016]  [A loss: 0.718275, acc: 0.468750]\n",
            "7531: [D loss: 0.705730, acc: 0.531250]  [A loss: 0.793137, acc: 0.273438]\n",
            "7532: [D loss: 0.707728, acc: 0.500000]  [A loss: 0.760489, acc: 0.335938]\n",
            "7533: [D loss: 0.692601, acc: 0.513672]  [A loss: 0.738821, acc: 0.410156]\n",
            "7534: [D loss: 0.709741, acc: 0.492188]  [A loss: 0.854592, acc: 0.242188]\n",
            "7535: [D loss: 0.695369, acc: 0.521484]  [A loss: 0.739403, acc: 0.429688]\n",
            "7536: [D loss: 0.708719, acc: 0.519531]  [A loss: 0.851235, acc: 0.175781]\n",
            "7537: [D loss: 0.706178, acc: 0.474609]  [A loss: 0.722179, acc: 0.449219]\n",
            "7538: [D loss: 0.707700, acc: 0.500000]  [A loss: 0.843966, acc: 0.199219]\n",
            "7539: [D loss: 0.687879, acc: 0.546875]  [A loss: 0.765748, acc: 0.343750]\n",
            "7540: [D loss: 0.699948, acc: 0.515625]  [A loss: 0.808046, acc: 0.285156]\n",
            "7541: [D loss: 0.701712, acc: 0.517578]  [A loss: 0.793835, acc: 0.296875]\n",
            "7542: [D loss: 0.717451, acc: 0.478516]  [A loss: 0.826622, acc: 0.242188]\n",
            "7543: [D loss: 0.704869, acc: 0.498047]  [A loss: 0.736948, acc: 0.433594]\n",
            "7544: [D loss: 0.705743, acc: 0.507812]  [A loss: 0.801618, acc: 0.257812]\n",
            "7545: [D loss: 0.707780, acc: 0.515625]  [A loss: 0.862148, acc: 0.179688]\n",
            "7546: [D loss: 0.710172, acc: 0.482422]  [A loss: 0.838983, acc: 0.226562]\n",
            "7547: [D loss: 0.704932, acc: 0.521484]  [A loss: 0.808341, acc: 0.269531]\n",
            "7548: [D loss: 0.705185, acc: 0.498047]  [A loss: 0.839291, acc: 0.218750]\n",
            "7549: [D loss: 0.704721, acc: 0.488281]  [A loss: 0.786990, acc: 0.347656]\n",
            "7550: [D loss: 0.703053, acc: 0.527344]  [A loss: 0.861642, acc: 0.167969]\n",
            "7551: [D loss: 0.701140, acc: 0.507812]  [A loss: 0.776611, acc: 0.328125]\n",
            "7552: [D loss: 0.709297, acc: 0.501953]  [A loss: 0.816761, acc: 0.257812]\n",
            "7553: [D loss: 0.712240, acc: 0.501953]  [A loss: 0.835870, acc: 0.195312]\n",
            "7554: [D loss: 0.702268, acc: 0.490234]  [A loss: 0.738015, acc: 0.429688]\n",
            "7555: [D loss: 0.707146, acc: 0.548828]  [A loss: 1.068486, acc: 0.035156]\n",
            "7556: [D loss: 0.718253, acc: 0.494141]  [A loss: 0.645045, acc: 0.632812]\n",
            "7557: [D loss: 0.720239, acc: 0.503906]  [A loss: 0.859231, acc: 0.148438]\n",
            "7558: [D loss: 0.708106, acc: 0.501953]  [A loss: 0.747686, acc: 0.414062]\n",
            "7559: [D loss: 0.715003, acc: 0.507812]  [A loss: 0.867493, acc: 0.125000]\n",
            "7560: [D loss: 0.701271, acc: 0.507812]  [A loss: 0.685053, acc: 0.519531]\n",
            "7561: [D loss: 0.716502, acc: 0.509766]  [A loss: 0.999544, acc: 0.078125]\n",
            "7562: [D loss: 0.702936, acc: 0.500000]  [A loss: 0.658750, acc: 0.597656]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7563: [D loss: 0.739739, acc: 0.492188]  [A loss: 0.927799, acc: 0.082031]\n",
            "7564: [D loss: 0.703783, acc: 0.513672]  [A loss: 0.716103, acc: 0.433594]\n",
            "7565: [D loss: 0.699738, acc: 0.544922]  [A loss: 0.795620, acc: 0.242188]\n",
            "7566: [D loss: 0.705016, acc: 0.517578]  [A loss: 0.735800, acc: 0.421875]\n",
            "7567: [D loss: 0.711319, acc: 0.501953]  [A loss: 0.812964, acc: 0.210938]\n",
            "7568: [D loss: 0.694132, acc: 0.519531]  [A loss: 0.760812, acc: 0.367188]\n",
            "7569: [D loss: 0.699685, acc: 0.523438]  [A loss: 0.812288, acc: 0.234375]\n",
            "7570: [D loss: 0.698542, acc: 0.492188]  [A loss: 0.741165, acc: 0.414062]\n",
            "7571: [D loss: 0.703130, acc: 0.521484]  [A loss: 0.862786, acc: 0.164062]\n",
            "7572: [D loss: 0.686432, acc: 0.535156]  [A loss: 0.745604, acc: 0.406250]\n",
            "7573: [D loss: 0.717292, acc: 0.498047]  [A loss: 0.849942, acc: 0.191406]\n",
            "7574: [D loss: 0.706247, acc: 0.511719]  [A loss: 0.694179, acc: 0.500000]\n",
            "7575: [D loss: 0.725051, acc: 0.501953]  [A loss: 0.906178, acc: 0.113281]\n",
            "7576: [D loss: 0.695697, acc: 0.515625]  [A loss: 0.732179, acc: 0.402344]\n",
            "7577: [D loss: 0.717871, acc: 0.486328]  [A loss: 0.903543, acc: 0.136719]\n",
            "7578: [D loss: 0.687104, acc: 0.525391]  [A loss: 0.760585, acc: 0.375000]\n",
            "7579: [D loss: 0.720687, acc: 0.476562]  [A loss: 0.791946, acc: 0.304688]\n",
            "7580: [D loss: 0.707981, acc: 0.503906]  [A loss: 0.791752, acc: 0.273438]\n",
            "7581: [D loss: 0.709700, acc: 0.503906]  [A loss: 0.833463, acc: 0.238281]\n",
            "7582: [D loss: 0.689352, acc: 0.537109]  [A loss: 0.714999, acc: 0.449219]\n",
            "7583: [D loss: 0.716961, acc: 0.511719]  [A loss: 0.959801, acc: 0.074219]\n",
            "7584: [D loss: 0.697954, acc: 0.501953]  [A loss: 0.692019, acc: 0.503906]\n",
            "7585: [D loss: 0.720725, acc: 0.482422]  [A loss: 0.905014, acc: 0.152344]\n",
            "7586: [D loss: 0.700543, acc: 0.519531]  [A loss: 0.693989, acc: 0.480469]\n",
            "7587: [D loss: 0.711434, acc: 0.515625]  [A loss: 0.840263, acc: 0.195312]\n",
            "7588: [D loss: 0.690745, acc: 0.519531]  [A loss: 0.775809, acc: 0.312500]\n",
            "7589: [D loss: 0.706611, acc: 0.511719]  [A loss: 0.816727, acc: 0.238281]\n",
            "7590: [D loss: 0.689964, acc: 0.525391]  [A loss: 0.781306, acc: 0.277344]\n",
            "7591: [D loss: 0.695560, acc: 0.513672]  [A loss: 0.803586, acc: 0.285156]\n",
            "7592: [D loss: 0.694176, acc: 0.507812]  [A loss: 0.770431, acc: 0.363281]\n",
            "7593: [D loss: 0.705698, acc: 0.501953]  [A loss: 0.820871, acc: 0.246094]\n",
            "7594: [D loss: 0.692301, acc: 0.537109]  [A loss: 0.818938, acc: 0.246094]\n",
            "7595: [D loss: 0.705447, acc: 0.513672]  [A loss: 0.799358, acc: 0.324219]\n",
            "7596: [D loss: 0.696988, acc: 0.500000]  [A loss: 0.793072, acc: 0.312500]\n",
            "7597: [D loss: 0.712788, acc: 0.488281]  [A loss: 0.899884, acc: 0.132812]\n",
            "7598: [D loss: 0.704402, acc: 0.484375]  [A loss: 0.727582, acc: 0.468750]\n",
            "7599: [D loss: 0.724012, acc: 0.500000]  [A loss: 0.835651, acc: 0.179688]\n",
            "7600: [D loss: 0.704733, acc: 0.503906]  [A loss: 0.817560, acc: 0.250000]\n",
            "7601: [D loss: 0.705575, acc: 0.533203]  [A loss: 0.829903, acc: 0.203125]\n",
            "7602: [D loss: 0.709434, acc: 0.484375]  [A loss: 0.772172, acc: 0.335938]\n",
            "7603: [D loss: 0.700517, acc: 0.519531]  [A loss: 0.956284, acc: 0.085938]\n",
            "7604: [D loss: 0.692229, acc: 0.546875]  [A loss: 0.665462, acc: 0.582031]\n",
            "7605: [D loss: 0.713048, acc: 0.519531]  [A loss: 0.955250, acc: 0.066406]\n",
            "7606: [D loss: 0.710876, acc: 0.492188]  [A loss: 0.692355, acc: 0.519531]\n",
            "7607: [D loss: 0.718389, acc: 0.484375]  [A loss: 0.858823, acc: 0.203125]\n",
            "7608: [D loss: 0.713873, acc: 0.472656]  [A loss: 0.777276, acc: 0.316406]\n",
            "7609: [D loss: 0.703171, acc: 0.535156]  [A loss: 0.845098, acc: 0.222656]\n",
            "7610: [D loss: 0.702519, acc: 0.498047]  [A loss: 0.752224, acc: 0.367188]\n",
            "7611: [D loss: 0.701557, acc: 0.519531]  [A loss: 0.771997, acc: 0.312500]\n",
            "7612: [D loss: 0.692359, acc: 0.517578]  [A loss: 0.757306, acc: 0.425781]\n",
            "7613: [D loss: 0.691741, acc: 0.550781]  [A loss: 0.846852, acc: 0.207031]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7614: [D loss: 0.722268, acc: 0.458984]  [A loss: 0.819767, acc: 0.238281]\n",
            "7615: [D loss: 0.702413, acc: 0.500000]  [A loss: 0.769449, acc: 0.320312]\n",
            "7616: [D loss: 0.709689, acc: 0.507812]  [A loss: 0.854807, acc: 0.203125]\n",
            "7617: [D loss: 0.711474, acc: 0.492188]  [A loss: 0.772304, acc: 0.281250]\n",
            "7618: [D loss: 0.709849, acc: 0.509766]  [A loss: 0.865971, acc: 0.175781]\n",
            "7619: [D loss: 0.697384, acc: 0.501953]  [A loss: 0.748335, acc: 0.394531]\n",
            "7620: [D loss: 0.711821, acc: 0.484375]  [A loss: 0.904540, acc: 0.089844]\n",
            "7621: [D loss: 0.703756, acc: 0.494141]  [A loss: 0.771893, acc: 0.335938]\n",
            "7622: [D loss: 0.713500, acc: 0.494141]  [A loss: 0.886199, acc: 0.144531]\n",
            "7623: [D loss: 0.698535, acc: 0.486328]  [A loss: 0.724973, acc: 0.425781]\n",
            "7624: [D loss: 0.708504, acc: 0.517578]  [A loss: 0.838437, acc: 0.214844]\n",
            "7625: [D loss: 0.708639, acc: 0.523438]  [A loss: 0.831668, acc: 0.203125]\n",
            "7626: [D loss: 0.696045, acc: 0.523438]  [A loss: 0.811422, acc: 0.285156]\n",
            "7627: [D loss: 0.695664, acc: 0.517578]  [A loss: 0.817009, acc: 0.261719]\n",
            "7628: [D loss: 0.700832, acc: 0.507812]  [A loss: 0.823362, acc: 0.214844]\n",
            "7629: [D loss: 0.702221, acc: 0.488281]  [A loss: 0.819201, acc: 0.261719]\n",
            "7630: [D loss: 0.704262, acc: 0.529297]  [A loss: 0.864866, acc: 0.203125]\n",
            "7631: [D loss: 0.708055, acc: 0.498047]  [A loss: 0.808429, acc: 0.304688]\n",
            "7632: [D loss: 0.707087, acc: 0.525391]  [A loss: 0.770933, acc: 0.304688]\n",
            "7633: [D loss: 0.698650, acc: 0.525391]  [A loss: 0.934687, acc: 0.078125]\n",
            "7634: [D loss: 0.698410, acc: 0.511719]  [A loss: 0.649221, acc: 0.632812]\n",
            "7635: [D loss: 0.742609, acc: 0.498047]  [A loss: 1.102559, acc: 0.031250]\n",
            "7636: [D loss: 0.706293, acc: 0.517578]  [A loss: 0.667108, acc: 0.574219]\n",
            "7637: [D loss: 0.751588, acc: 0.490234]  [A loss: 0.910083, acc: 0.125000]\n",
            "7638: [D loss: 0.703968, acc: 0.521484]  [A loss: 0.704764, acc: 0.531250]\n",
            "7639: [D loss: 0.727528, acc: 0.494141]  [A loss: 0.863801, acc: 0.156250]\n",
            "7640: [D loss: 0.692299, acc: 0.523438]  [A loss: 0.759820, acc: 0.355469]\n",
            "7641: [D loss: 0.709012, acc: 0.494141]  [A loss: 0.841510, acc: 0.207031]\n",
            "7642: [D loss: 0.695387, acc: 0.505859]  [A loss: 0.744970, acc: 0.378906]\n",
            "7643: [D loss: 0.699700, acc: 0.503906]  [A loss: 0.786266, acc: 0.304688]\n",
            "7644: [D loss: 0.702073, acc: 0.509766]  [A loss: 0.787533, acc: 0.277344]\n",
            "7645: [D loss: 0.701289, acc: 0.525391]  [A loss: 0.799829, acc: 0.308594]\n",
            "7646: [D loss: 0.688704, acc: 0.552734]  [A loss: 0.740386, acc: 0.410156]\n",
            "7647: [D loss: 0.715369, acc: 0.490234]  [A loss: 0.813689, acc: 0.281250]\n",
            "7648: [D loss: 0.699971, acc: 0.537109]  [A loss: 0.800034, acc: 0.257812]\n",
            "7649: [D loss: 0.702782, acc: 0.519531]  [A loss: 0.831585, acc: 0.207031]\n",
            "7650: [D loss: 0.691590, acc: 0.517578]  [A loss: 0.749715, acc: 0.394531]\n",
            "7651: [D loss: 0.711854, acc: 0.500000]  [A loss: 0.934677, acc: 0.093750]\n",
            "7652: [D loss: 0.705995, acc: 0.515625]  [A loss: 0.689590, acc: 0.542969]\n",
            "7653: [D loss: 0.719426, acc: 0.498047]  [A loss: 0.915887, acc: 0.101562]\n",
            "7654: [D loss: 0.688284, acc: 0.521484]  [A loss: 0.725454, acc: 0.429688]\n",
            "7655: [D loss: 0.715404, acc: 0.500000]  [A loss: 0.843734, acc: 0.238281]\n",
            "7656: [D loss: 0.695307, acc: 0.496094]  [A loss: 0.761570, acc: 0.343750]\n",
            "7657: [D loss: 0.713743, acc: 0.500000]  [A loss: 0.829918, acc: 0.214844]\n",
            "7658: [D loss: 0.717459, acc: 0.484375]  [A loss: 0.730734, acc: 0.429688]\n",
            "7659: [D loss: 0.713124, acc: 0.488281]  [A loss: 0.854802, acc: 0.183594]\n",
            "7660: [D loss: 0.703102, acc: 0.500000]  [A loss: 0.738939, acc: 0.417969]\n",
            "7661: [D loss: 0.705598, acc: 0.513672]  [A loss: 0.820136, acc: 0.296875]\n",
            "7662: [D loss: 0.695916, acc: 0.544922]  [A loss: 0.739617, acc: 0.429688]\n",
            "7663: [D loss: 0.709189, acc: 0.533203]  [A loss: 0.913991, acc: 0.109375]\n",
            "7664: [D loss: 0.705300, acc: 0.488281]  [A loss: 0.699170, acc: 0.523438]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7665: [D loss: 0.699593, acc: 0.505859]  [A loss: 0.855008, acc: 0.203125]\n",
            "7666: [D loss: 0.698821, acc: 0.513672]  [A loss: 0.736299, acc: 0.398438]\n",
            "7667: [D loss: 0.718305, acc: 0.486328]  [A loss: 0.883536, acc: 0.156250]\n",
            "7668: [D loss: 0.697342, acc: 0.523438]  [A loss: 0.739543, acc: 0.402344]\n",
            "7669: [D loss: 0.706514, acc: 0.492188]  [A loss: 0.810978, acc: 0.226562]\n",
            "7670: [D loss: 0.715449, acc: 0.468750]  [A loss: 0.809079, acc: 0.250000]\n",
            "7671: [D loss: 0.703156, acc: 0.521484]  [A loss: 0.817032, acc: 0.234375]\n",
            "7672: [D loss: 0.700521, acc: 0.525391]  [A loss: 0.800190, acc: 0.273438]\n",
            "7673: [D loss: 0.716028, acc: 0.476562]  [A loss: 0.781237, acc: 0.304688]\n",
            "7674: [D loss: 0.700194, acc: 0.525391]  [A loss: 0.958159, acc: 0.085938]\n",
            "7675: [D loss: 0.705644, acc: 0.492188]  [A loss: 0.706467, acc: 0.492188]\n",
            "7676: [D loss: 0.722297, acc: 0.498047]  [A loss: 1.028637, acc: 0.070312]\n",
            "7677: [D loss: 0.703927, acc: 0.505859]  [A loss: 0.698253, acc: 0.503906]\n",
            "7678: [D loss: 0.715781, acc: 0.496094]  [A loss: 0.896714, acc: 0.121094]\n",
            "7679: [D loss: 0.686055, acc: 0.521484]  [A loss: 0.729672, acc: 0.433594]\n",
            "7680: [D loss: 0.713366, acc: 0.498047]  [A loss: 0.874304, acc: 0.156250]\n",
            "7681: [D loss: 0.701389, acc: 0.492188]  [A loss: 0.735109, acc: 0.453125]\n",
            "7682: [D loss: 0.707286, acc: 0.531250]  [A loss: 0.912780, acc: 0.113281]\n",
            "7683: [D loss: 0.704356, acc: 0.490234]  [A loss: 0.729116, acc: 0.421875]\n",
            "7684: [D loss: 0.709204, acc: 0.515625]  [A loss: 0.888018, acc: 0.132812]\n",
            "7685: [D loss: 0.698927, acc: 0.509766]  [A loss: 0.734456, acc: 0.410156]\n",
            "7686: [D loss: 0.697261, acc: 0.537109]  [A loss: 0.858144, acc: 0.179688]\n",
            "7687: [D loss: 0.696374, acc: 0.554688]  [A loss: 0.712407, acc: 0.496094]\n",
            "7688: [D loss: 0.714717, acc: 0.488281]  [A loss: 0.871669, acc: 0.152344]\n",
            "7689: [D loss: 0.700909, acc: 0.507812]  [A loss: 0.740495, acc: 0.410156]\n",
            "7690: [D loss: 0.718984, acc: 0.505859]  [A loss: 0.835772, acc: 0.210938]\n",
            "7691: [D loss: 0.691305, acc: 0.541016]  [A loss: 0.752359, acc: 0.371094]\n",
            "7692: [D loss: 0.701548, acc: 0.537109]  [A loss: 0.825280, acc: 0.207031]\n",
            "7693: [D loss: 0.694844, acc: 0.515625]  [A loss: 0.770983, acc: 0.324219]\n",
            "7694: [D loss: 0.702326, acc: 0.525391]  [A loss: 0.821848, acc: 0.203125]\n",
            "7695: [D loss: 0.708646, acc: 0.507812]  [A loss: 0.750598, acc: 0.371094]\n",
            "7696: [D loss: 0.697277, acc: 0.527344]  [A loss: 0.830219, acc: 0.226562]\n",
            "7697: [D loss: 0.727952, acc: 0.445312]  [A loss: 0.791240, acc: 0.250000]\n",
            "7698: [D loss: 0.720520, acc: 0.480469]  [A loss: 0.903456, acc: 0.167969]\n",
            "7699: [D loss: 0.698535, acc: 0.519531]  [A loss: 0.762591, acc: 0.437500]\n",
            "7700: [D loss: 0.711758, acc: 0.521484]  [A loss: 0.850821, acc: 0.171875]\n",
            "7701: [D loss: 0.691159, acc: 0.521484]  [A loss: 0.755481, acc: 0.332031]\n",
            "7702: [D loss: 0.706401, acc: 0.537109]  [A loss: 0.849374, acc: 0.234375]\n",
            "7703: [D loss: 0.705368, acc: 0.498047]  [A loss: 0.724178, acc: 0.449219]\n",
            "7704: [D loss: 0.719930, acc: 0.480469]  [A loss: 0.893814, acc: 0.113281]\n",
            "7705: [D loss: 0.716355, acc: 0.458984]  [A loss: 0.702647, acc: 0.480469]\n",
            "7706: [D loss: 0.711620, acc: 0.501953]  [A loss: 0.850897, acc: 0.207031]\n",
            "7707: [D loss: 0.689505, acc: 0.535156]  [A loss: 0.711884, acc: 0.488281]\n",
            "7708: [D loss: 0.711403, acc: 0.505859]  [A loss: 0.876595, acc: 0.156250]\n",
            "7709: [D loss: 0.691949, acc: 0.548828]  [A loss: 0.691015, acc: 0.515625]\n",
            "7710: [D loss: 0.706092, acc: 0.519531]  [A loss: 0.893193, acc: 0.125000]\n",
            "7711: [D loss: 0.704962, acc: 0.490234]  [A loss: 0.720357, acc: 0.429688]\n",
            "7712: [D loss: 0.703950, acc: 0.548828]  [A loss: 0.845323, acc: 0.179688]\n",
            "7713: [D loss: 0.692077, acc: 0.531250]  [A loss: 0.730265, acc: 0.429688]\n",
            "7714: [D loss: 0.707543, acc: 0.542969]  [A loss: 0.805981, acc: 0.222656]\n",
            "7715: [D loss: 0.713394, acc: 0.498047]  [A loss: 0.878638, acc: 0.203125]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7716: [D loss: 0.687815, acc: 0.546875]  [A loss: 0.762323, acc: 0.394531]\n",
            "7717: [D loss: 0.698975, acc: 0.523438]  [A loss: 0.752406, acc: 0.351562]\n",
            "7718: [D loss: 0.705960, acc: 0.507812]  [A loss: 0.887950, acc: 0.148438]\n",
            "7719: [D loss: 0.706344, acc: 0.490234]  [A loss: 0.756304, acc: 0.371094]\n",
            "7720: [D loss: 0.706224, acc: 0.503906]  [A loss: 0.898998, acc: 0.128906]\n",
            "7721: [D loss: 0.698479, acc: 0.490234]  [A loss: 0.706825, acc: 0.515625]\n",
            "7722: [D loss: 0.716156, acc: 0.500000]  [A loss: 0.872132, acc: 0.109375]\n",
            "7723: [D loss: 0.701400, acc: 0.480469]  [A loss: 0.720027, acc: 0.445312]\n",
            "7724: [D loss: 0.707201, acc: 0.511719]  [A loss: 0.914227, acc: 0.105469]\n",
            "7725: [D loss: 0.700393, acc: 0.525391]  [A loss: 0.680418, acc: 0.535156]\n",
            "7726: [D loss: 0.720665, acc: 0.490234]  [A loss: 0.875493, acc: 0.152344]\n",
            "7727: [D loss: 0.692630, acc: 0.523438]  [A loss: 0.742507, acc: 0.382812]\n",
            "7728: [D loss: 0.722438, acc: 0.488281]  [A loss: 0.934264, acc: 0.082031]\n",
            "7729: [D loss: 0.694871, acc: 0.517578]  [A loss: 0.681469, acc: 0.578125]\n",
            "7730: [D loss: 0.715278, acc: 0.521484]  [A loss: 0.873354, acc: 0.148438]\n",
            "7731: [D loss: 0.689481, acc: 0.535156]  [A loss: 0.678102, acc: 0.554688]\n",
            "7732: [D loss: 0.708195, acc: 0.521484]  [A loss: 0.852218, acc: 0.160156]\n",
            "7733: [D loss: 0.680195, acc: 0.552734]  [A loss: 0.743319, acc: 0.375000]\n",
            "7734: [D loss: 0.696870, acc: 0.521484]  [A loss: 0.779688, acc: 0.312500]\n",
            "7735: [D loss: 0.700001, acc: 0.517578]  [A loss: 0.829981, acc: 0.234375]\n",
            "7736: [D loss: 0.702171, acc: 0.509766]  [A loss: 0.788984, acc: 0.316406]\n",
            "7737: [D loss: 0.702532, acc: 0.503906]  [A loss: 0.821822, acc: 0.210938]\n",
            "7738: [D loss: 0.705452, acc: 0.478516]  [A loss: 0.769619, acc: 0.359375]\n",
            "7739: [D loss: 0.705985, acc: 0.509766]  [A loss: 0.860505, acc: 0.167969]\n",
            "7740: [D loss: 0.700940, acc: 0.498047]  [A loss: 0.769358, acc: 0.351562]\n",
            "7741: [D loss: 0.695955, acc: 0.515625]  [A loss: 0.870432, acc: 0.175781]\n",
            "7742: [D loss: 0.695483, acc: 0.519531]  [A loss: 0.719733, acc: 0.433594]\n",
            "7743: [D loss: 0.713648, acc: 0.521484]  [A loss: 0.898516, acc: 0.121094]\n",
            "7744: [D loss: 0.692696, acc: 0.544922]  [A loss: 0.750124, acc: 0.394531]\n",
            "7745: [D loss: 0.708595, acc: 0.494141]  [A loss: 0.859698, acc: 0.183594]\n",
            "7746: [D loss: 0.698108, acc: 0.511719]  [A loss: 0.748701, acc: 0.421875]\n",
            "7747: [D loss: 0.706235, acc: 0.519531]  [A loss: 0.826690, acc: 0.242188]\n",
            "7748: [D loss: 0.694631, acc: 0.533203]  [A loss: 0.832300, acc: 0.187500]\n",
            "7749: [D loss: 0.700957, acc: 0.521484]  [A loss: 0.822862, acc: 0.187500]\n",
            "7750: [D loss: 0.689931, acc: 0.556641]  [A loss: 0.785623, acc: 0.324219]\n",
            "7751: [D loss: 0.707086, acc: 0.494141]  [A loss: 0.878777, acc: 0.132812]\n",
            "7752: [D loss: 0.693660, acc: 0.533203]  [A loss: 0.764932, acc: 0.312500]\n",
            "7753: [D loss: 0.709926, acc: 0.505859]  [A loss: 0.924591, acc: 0.121094]\n",
            "7754: [D loss: 0.698159, acc: 0.535156]  [A loss: 0.688109, acc: 0.558594]\n",
            "7755: [D loss: 0.719744, acc: 0.515625]  [A loss: 0.892016, acc: 0.113281]\n",
            "7756: [D loss: 0.700874, acc: 0.515625]  [A loss: 0.707011, acc: 0.457031]\n",
            "7757: [D loss: 0.722437, acc: 0.503906]  [A loss: 1.017056, acc: 0.039062]\n",
            "7758: [D loss: 0.699763, acc: 0.517578]  [A loss: 0.678043, acc: 0.566406]\n",
            "7759: [D loss: 0.708321, acc: 0.507812]  [A loss: 0.879782, acc: 0.148438]\n",
            "7760: [D loss: 0.703721, acc: 0.505859]  [A loss: 0.738037, acc: 0.437500]\n",
            "7761: [D loss: 0.716312, acc: 0.507812]  [A loss: 0.853271, acc: 0.171875]\n",
            "7762: [D loss: 0.708056, acc: 0.498047]  [A loss: 0.738723, acc: 0.386719]\n",
            "7763: [D loss: 0.696424, acc: 0.531250]  [A loss: 0.851839, acc: 0.195312]\n",
            "7764: [D loss: 0.703666, acc: 0.535156]  [A loss: 0.780255, acc: 0.285156]\n",
            "7765: [D loss: 0.716452, acc: 0.509766]  [A loss: 0.847207, acc: 0.167969]\n",
            "7766: [D loss: 0.710859, acc: 0.501953]  [A loss: 0.762924, acc: 0.355469]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7767: [D loss: 0.705705, acc: 0.511719]  [A loss: 0.877291, acc: 0.167969]\n",
            "7768: [D loss: 0.697472, acc: 0.537109]  [A loss: 0.711122, acc: 0.484375]\n",
            "7769: [D loss: 0.700942, acc: 0.515625]  [A loss: 0.815506, acc: 0.242188]\n",
            "7770: [D loss: 0.689003, acc: 0.535156]  [A loss: 0.733858, acc: 0.410156]\n",
            "7771: [D loss: 0.700444, acc: 0.554688]  [A loss: 0.835517, acc: 0.210938]\n",
            "7772: [D loss: 0.707380, acc: 0.464844]  [A loss: 0.787881, acc: 0.328125]\n",
            "7773: [D loss: 0.691930, acc: 0.531250]  [A loss: 0.822190, acc: 0.265625]\n",
            "7774: [D loss: 0.705089, acc: 0.515625]  [A loss: 0.832887, acc: 0.179688]\n",
            "7775: [D loss: 0.697187, acc: 0.550781]  [A loss: 0.882162, acc: 0.164062]\n",
            "7776: [D loss: 0.697824, acc: 0.542969]  [A loss: 0.765870, acc: 0.343750]\n",
            "7777: [D loss: 0.709334, acc: 0.496094]  [A loss: 0.992011, acc: 0.074219]\n",
            "7778: [D loss: 0.703314, acc: 0.498047]  [A loss: 0.680025, acc: 0.558594]\n",
            "7779: [D loss: 0.716830, acc: 0.513672]  [A loss: 0.907215, acc: 0.121094]\n",
            "7780: [D loss: 0.715407, acc: 0.482422]  [A loss: 0.704446, acc: 0.492188]\n",
            "7781: [D loss: 0.704576, acc: 0.519531]  [A loss: 0.873226, acc: 0.148438]\n",
            "7782: [D loss: 0.690003, acc: 0.523438]  [A loss: 0.696562, acc: 0.554688]\n",
            "7783: [D loss: 0.703261, acc: 0.529297]  [A loss: 0.890136, acc: 0.125000]\n",
            "7784: [D loss: 0.681615, acc: 0.556641]  [A loss: 0.738553, acc: 0.402344]\n",
            "7785: [D loss: 0.704628, acc: 0.517578]  [A loss: 0.902005, acc: 0.132812]\n",
            "7786: [D loss: 0.710525, acc: 0.476562]  [A loss: 0.693904, acc: 0.500000]\n",
            "7787: [D loss: 0.696100, acc: 0.513672]  [A loss: 0.828057, acc: 0.226562]\n",
            "7788: [D loss: 0.701766, acc: 0.496094]  [A loss: 0.796343, acc: 0.285156]\n",
            "7789: [D loss: 0.710876, acc: 0.509766]  [A loss: 0.836042, acc: 0.203125]\n",
            "7790: [D loss: 0.700717, acc: 0.513672]  [A loss: 0.713258, acc: 0.460938]\n",
            "7791: [D loss: 0.714336, acc: 0.484375]  [A loss: 0.879032, acc: 0.167969]\n",
            "7792: [D loss: 0.697006, acc: 0.511719]  [A loss: 0.768991, acc: 0.335938]\n",
            "7793: [D loss: 0.700272, acc: 0.525391]  [A loss: 0.845311, acc: 0.203125]\n",
            "7794: [D loss: 0.710009, acc: 0.505859]  [A loss: 0.799777, acc: 0.214844]\n",
            "7795: [D loss: 0.707952, acc: 0.501953]  [A loss: 0.834914, acc: 0.183594]\n",
            "7796: [D loss: 0.696643, acc: 0.511719]  [A loss: 0.751755, acc: 0.375000]\n",
            "7797: [D loss: 0.707742, acc: 0.505859]  [A loss: 0.815036, acc: 0.242188]\n",
            "7798: [D loss: 0.700486, acc: 0.501953]  [A loss: 0.756540, acc: 0.386719]\n",
            "7799: [D loss: 0.702940, acc: 0.501953]  [A loss: 0.891505, acc: 0.113281]\n",
            "7800: [D loss: 0.692975, acc: 0.517578]  [A loss: 0.734881, acc: 0.406250]\n",
            "7801: [D loss: 0.713027, acc: 0.513672]  [A loss: 0.912458, acc: 0.121094]\n",
            "7802: [D loss: 0.702265, acc: 0.503906]  [A loss: 0.695142, acc: 0.539062]\n",
            "7803: [D loss: 0.710596, acc: 0.515625]  [A loss: 0.870555, acc: 0.152344]\n",
            "7804: [D loss: 0.684487, acc: 0.546875]  [A loss: 0.730242, acc: 0.429688]\n",
            "7805: [D loss: 0.701681, acc: 0.529297]  [A loss: 0.823881, acc: 0.203125]\n",
            "7806: [D loss: 0.691056, acc: 0.535156]  [A loss: 0.804637, acc: 0.277344]\n",
            "7807: [D loss: 0.699979, acc: 0.511719]  [A loss: 0.800499, acc: 0.203125]\n",
            "7808: [D loss: 0.699393, acc: 0.503906]  [A loss: 0.808830, acc: 0.261719]\n",
            "7809: [D loss: 0.696584, acc: 0.529297]  [A loss: 0.784841, acc: 0.304688]\n",
            "7810: [D loss: 0.701614, acc: 0.496094]  [A loss: 0.857244, acc: 0.160156]\n",
            "7811: [D loss: 0.705150, acc: 0.480469]  [A loss: 0.800949, acc: 0.265625]\n",
            "7812: [D loss: 0.692399, acc: 0.511719]  [A loss: 0.754206, acc: 0.339844]\n",
            "7813: [D loss: 0.700763, acc: 0.498047]  [A loss: 0.886604, acc: 0.097656]\n",
            "7814: [D loss: 0.693238, acc: 0.542969]  [A loss: 0.757894, acc: 0.351562]\n",
            "7815: [D loss: 0.706090, acc: 0.505859]  [A loss: 0.842343, acc: 0.210938]\n",
            "7816: [D loss: 0.703205, acc: 0.503906]  [A loss: 0.740039, acc: 0.410156]\n",
            "7817: [D loss: 0.712730, acc: 0.513672]  [A loss: 0.957500, acc: 0.074219]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7818: [D loss: 0.714414, acc: 0.494141]  [A loss: 0.684072, acc: 0.554688]\n",
            "7819: [D loss: 0.708233, acc: 0.513672]  [A loss: 0.898532, acc: 0.136719]\n",
            "7820: [D loss: 0.694200, acc: 0.521484]  [A loss: 0.675638, acc: 0.546875]\n",
            "7821: [D loss: 0.701423, acc: 0.544922]  [A loss: 0.872564, acc: 0.175781]\n",
            "7822: [D loss: 0.700495, acc: 0.509766]  [A loss: 0.723111, acc: 0.484375]\n",
            "7823: [D loss: 0.707302, acc: 0.511719]  [A loss: 0.815325, acc: 0.230469]\n",
            "7824: [D loss: 0.699045, acc: 0.521484]  [A loss: 0.765106, acc: 0.382812]\n",
            "7825: [D loss: 0.702676, acc: 0.496094]  [A loss: 0.851199, acc: 0.195312]\n",
            "7826: [D loss: 0.704390, acc: 0.515625]  [A loss: 0.813732, acc: 0.250000]\n",
            "7827: [D loss: 0.698642, acc: 0.511719]  [A loss: 0.848125, acc: 0.210938]\n",
            "7828: [D loss: 0.699882, acc: 0.527344]  [A loss: 0.723584, acc: 0.429688]\n",
            "7829: [D loss: 0.702982, acc: 0.511719]  [A loss: 0.913232, acc: 0.128906]\n",
            "7830: [D loss: 0.690153, acc: 0.542969]  [A loss: 0.687195, acc: 0.550781]\n",
            "7831: [D loss: 0.709586, acc: 0.523438]  [A loss: 0.834485, acc: 0.203125]\n",
            "7832: [D loss: 0.695632, acc: 0.521484]  [A loss: 0.712850, acc: 0.457031]\n",
            "7833: [D loss: 0.720522, acc: 0.478516]  [A loss: 0.866818, acc: 0.175781]\n",
            "7834: [D loss: 0.700274, acc: 0.523438]  [A loss: 0.699924, acc: 0.503906]\n",
            "7835: [D loss: 0.711752, acc: 0.488281]  [A loss: 0.908200, acc: 0.113281]\n",
            "7836: [D loss: 0.695884, acc: 0.515625]  [A loss: 0.703877, acc: 0.492188]\n",
            "7837: [D loss: 0.711087, acc: 0.509766]  [A loss: 0.945247, acc: 0.085938]\n",
            "7838: [D loss: 0.695101, acc: 0.521484]  [A loss: 0.710222, acc: 0.464844]\n",
            "7839: [D loss: 0.725025, acc: 0.515625]  [A loss: 0.917330, acc: 0.121094]\n",
            "7840: [D loss: 0.702407, acc: 0.515625]  [A loss: 0.717650, acc: 0.464844]\n",
            "7841: [D loss: 0.704997, acc: 0.533203]  [A loss: 0.829526, acc: 0.207031]\n",
            "7842: [D loss: 0.703899, acc: 0.519531]  [A loss: 0.738434, acc: 0.406250]\n",
            "7843: [D loss: 0.707983, acc: 0.505859]  [A loss: 0.761561, acc: 0.351562]\n",
            "7844: [D loss: 0.703847, acc: 0.535156]  [A loss: 0.858749, acc: 0.187500]\n",
            "7845: [D loss: 0.692547, acc: 0.523438]  [A loss: 0.718059, acc: 0.468750]\n",
            "7846: [D loss: 0.709635, acc: 0.494141]  [A loss: 0.928357, acc: 0.089844]\n",
            "7847: [D loss: 0.707399, acc: 0.484375]  [A loss: 0.689179, acc: 0.542969]\n",
            "7848: [D loss: 0.709441, acc: 0.527344]  [A loss: 0.812340, acc: 0.269531]\n",
            "7849: [D loss: 0.718563, acc: 0.482422]  [A loss: 0.781794, acc: 0.312500]\n",
            "7850: [D loss: 0.709509, acc: 0.494141]  [A loss: 0.787688, acc: 0.289062]\n",
            "7851: [D loss: 0.696984, acc: 0.515625]  [A loss: 0.766798, acc: 0.335938]\n",
            "7852: [D loss: 0.700230, acc: 0.509766]  [A loss: 0.865315, acc: 0.191406]\n",
            "7853: [D loss: 0.703901, acc: 0.482422]  [A loss: 0.732624, acc: 0.421875]\n",
            "7854: [D loss: 0.715148, acc: 0.513672]  [A loss: 0.865625, acc: 0.136719]\n",
            "7855: [D loss: 0.709150, acc: 0.482422]  [A loss: 0.719388, acc: 0.433594]\n",
            "7856: [D loss: 0.716054, acc: 0.517578]  [A loss: 0.902917, acc: 0.093750]\n",
            "7857: [D loss: 0.698560, acc: 0.515625]  [A loss: 0.745857, acc: 0.378906]\n",
            "7858: [D loss: 0.714463, acc: 0.480469]  [A loss: 0.768681, acc: 0.367188]\n",
            "7859: [D loss: 0.700502, acc: 0.517578]  [A loss: 0.854740, acc: 0.207031]\n",
            "7860: [D loss: 0.698501, acc: 0.521484]  [A loss: 0.755609, acc: 0.378906]\n",
            "7861: [D loss: 0.725504, acc: 0.460938]  [A loss: 0.852530, acc: 0.171875]\n",
            "7862: [D loss: 0.697527, acc: 0.509766]  [A loss: 0.706378, acc: 0.492188]\n",
            "7863: [D loss: 0.711638, acc: 0.527344]  [A loss: 0.867572, acc: 0.144531]\n",
            "7864: [D loss: 0.695863, acc: 0.513672]  [A loss: 0.755152, acc: 0.382812]\n",
            "7865: [D loss: 0.714422, acc: 0.492188]  [A loss: 0.809498, acc: 0.253906]\n",
            "7866: [D loss: 0.694899, acc: 0.507812]  [A loss: 0.787358, acc: 0.308594]\n",
            "7867: [D loss: 0.707664, acc: 0.507812]  [A loss: 0.859162, acc: 0.203125]\n",
            "7868: [D loss: 0.696855, acc: 0.507812]  [A loss: 0.730409, acc: 0.429688]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7869: [D loss: 0.703184, acc: 0.525391]  [A loss: 0.852906, acc: 0.175781]\n",
            "7870: [D loss: 0.701634, acc: 0.507812]  [A loss: 0.794218, acc: 0.289062]\n",
            "7871: [D loss: 0.698222, acc: 0.505859]  [A loss: 0.780765, acc: 0.320312]\n",
            "7872: [D loss: 0.720012, acc: 0.462891]  [A loss: 0.813007, acc: 0.265625]\n",
            "7873: [D loss: 0.707434, acc: 0.482422]  [A loss: 0.820678, acc: 0.273438]\n",
            "7874: [D loss: 0.710320, acc: 0.490234]  [A loss: 0.794882, acc: 0.242188]\n",
            "7875: [D loss: 0.704530, acc: 0.531250]  [A loss: 0.910364, acc: 0.125000]\n",
            "7876: [D loss: 0.711443, acc: 0.496094]  [A loss: 0.725759, acc: 0.445312]\n",
            "7877: [D loss: 0.708258, acc: 0.496094]  [A loss: 0.925009, acc: 0.117188]\n",
            "7878: [D loss: 0.700423, acc: 0.529297]  [A loss: 0.727899, acc: 0.417969]\n",
            "7879: [D loss: 0.702057, acc: 0.529297]  [A loss: 0.835884, acc: 0.238281]\n",
            "7880: [D loss: 0.695776, acc: 0.519531]  [A loss: 0.784435, acc: 0.265625]\n",
            "7881: [D loss: 0.700643, acc: 0.531250]  [A loss: 0.870869, acc: 0.167969]\n",
            "7882: [D loss: 0.693317, acc: 0.537109]  [A loss: 0.770301, acc: 0.378906]\n",
            "7883: [D loss: 0.698693, acc: 0.521484]  [A loss: 0.885012, acc: 0.171875]\n",
            "7884: [D loss: 0.704901, acc: 0.494141]  [A loss: 0.701590, acc: 0.488281]\n",
            "7885: [D loss: 0.719471, acc: 0.484375]  [A loss: 0.895659, acc: 0.113281]\n",
            "7886: [D loss: 0.710874, acc: 0.472656]  [A loss: 0.672351, acc: 0.589844]\n",
            "7887: [D loss: 0.719376, acc: 0.498047]  [A loss: 0.859706, acc: 0.183594]\n",
            "7888: [D loss: 0.707102, acc: 0.517578]  [A loss: 0.707029, acc: 0.464844]\n",
            "7889: [D loss: 0.707469, acc: 0.498047]  [A loss: 0.844902, acc: 0.183594]\n",
            "7890: [D loss: 0.702886, acc: 0.511719]  [A loss: 0.742436, acc: 0.367188]\n",
            "7891: [D loss: 0.711539, acc: 0.476562]  [A loss: 0.811530, acc: 0.207031]\n",
            "7892: [D loss: 0.701102, acc: 0.498047]  [A loss: 0.815310, acc: 0.210938]\n",
            "7893: [D loss: 0.703970, acc: 0.511719]  [A loss: 0.754108, acc: 0.347656]\n",
            "7894: [D loss: 0.705090, acc: 0.531250]  [A loss: 0.897679, acc: 0.128906]\n",
            "7895: [D loss: 0.697142, acc: 0.513672]  [A loss: 0.734347, acc: 0.390625]\n",
            "7896: [D loss: 0.714917, acc: 0.496094]  [A loss: 0.853507, acc: 0.191406]\n",
            "7897: [D loss: 0.701154, acc: 0.511719]  [A loss: 0.769385, acc: 0.312500]\n",
            "7898: [D loss: 0.718189, acc: 0.476562]  [A loss: 0.828430, acc: 0.230469]\n",
            "7899: [D loss: 0.696267, acc: 0.503906]  [A loss: 0.782868, acc: 0.273438]\n",
            "7900: [D loss: 0.697840, acc: 0.513672]  [A loss: 0.830348, acc: 0.246094]\n",
            "7901: [D loss: 0.692343, acc: 0.533203]  [A loss: 0.767412, acc: 0.355469]\n",
            "7902: [D loss: 0.714825, acc: 0.484375]  [A loss: 0.840578, acc: 0.234375]\n",
            "7903: [D loss: 0.698679, acc: 0.507812]  [A loss: 0.802949, acc: 0.277344]\n",
            "7904: [D loss: 0.712302, acc: 0.496094]  [A loss: 0.799281, acc: 0.257812]\n",
            "7905: [D loss: 0.687784, acc: 0.562500]  [A loss: 0.825144, acc: 0.238281]\n",
            "7906: [D loss: 0.709795, acc: 0.500000]  [A loss: 0.894267, acc: 0.125000]\n",
            "7907: [D loss: 0.710620, acc: 0.476562]  [A loss: 0.688170, acc: 0.507812]\n",
            "7908: [D loss: 0.723426, acc: 0.501953]  [A loss: 0.958285, acc: 0.070312]\n",
            "7909: [D loss: 0.697096, acc: 0.511719]  [A loss: 0.692556, acc: 0.519531]\n",
            "7910: [D loss: 0.708603, acc: 0.515625]  [A loss: 0.830111, acc: 0.230469]\n",
            "7911: [D loss: 0.709362, acc: 0.460938]  [A loss: 0.712744, acc: 0.511719]\n",
            "7912: [D loss: 0.715113, acc: 0.501953]  [A loss: 0.827990, acc: 0.253906]\n",
            "7913: [D loss: 0.707340, acc: 0.505859]  [A loss: 0.761498, acc: 0.343750]\n",
            "7914: [D loss: 0.700192, acc: 0.535156]  [A loss: 0.767150, acc: 0.320312]\n",
            "7915: [D loss: 0.704579, acc: 0.535156]  [A loss: 0.921427, acc: 0.105469]\n",
            "7916: [D loss: 0.698144, acc: 0.513672]  [A loss: 0.745464, acc: 0.417969]\n",
            "7917: [D loss: 0.712996, acc: 0.521484]  [A loss: 0.844533, acc: 0.179688]\n",
            "7918: [D loss: 0.699006, acc: 0.494141]  [A loss: 0.753373, acc: 0.359375]\n",
            "7919: [D loss: 0.702598, acc: 0.496094]  [A loss: 0.811327, acc: 0.246094]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7920: [D loss: 0.696724, acc: 0.511719]  [A loss: 0.733805, acc: 0.414062]\n",
            "7921: [D loss: 0.705478, acc: 0.500000]  [A loss: 0.848536, acc: 0.175781]\n",
            "7922: [D loss: 0.694886, acc: 0.513672]  [A loss: 0.741868, acc: 0.410156]\n",
            "7923: [D loss: 0.710593, acc: 0.503906]  [A loss: 0.842986, acc: 0.207031]\n",
            "7924: [D loss: 0.705430, acc: 0.492188]  [A loss: 0.713724, acc: 0.476562]\n",
            "7925: [D loss: 0.710274, acc: 0.478516]  [A loss: 0.893072, acc: 0.121094]\n",
            "7926: [D loss: 0.702326, acc: 0.505859]  [A loss: 0.737452, acc: 0.433594]\n",
            "7927: [D loss: 0.699788, acc: 0.513672]  [A loss: 0.887977, acc: 0.140625]\n",
            "7928: [D loss: 0.698259, acc: 0.500000]  [A loss: 0.713904, acc: 0.496094]\n",
            "7929: [D loss: 0.720767, acc: 0.503906]  [A loss: 0.863226, acc: 0.136719]\n",
            "7930: [D loss: 0.692982, acc: 0.515625]  [A loss: 0.752906, acc: 0.371094]\n",
            "7931: [D loss: 0.704059, acc: 0.525391]  [A loss: 0.860688, acc: 0.148438]\n",
            "7932: [D loss: 0.708809, acc: 0.515625]  [A loss: 0.751002, acc: 0.375000]\n",
            "7933: [D loss: 0.712736, acc: 0.509766]  [A loss: 0.887907, acc: 0.175781]\n",
            "7934: [D loss: 0.692848, acc: 0.537109]  [A loss: 0.729565, acc: 0.417969]\n",
            "7935: [D loss: 0.707109, acc: 0.507812]  [A loss: 0.842155, acc: 0.187500]\n",
            "7936: [D loss: 0.705227, acc: 0.517578]  [A loss: 0.710930, acc: 0.464844]\n",
            "7937: [D loss: 0.708530, acc: 0.537109]  [A loss: 0.946114, acc: 0.105469]\n",
            "7938: [D loss: 0.700118, acc: 0.533203]  [A loss: 0.706014, acc: 0.507812]\n",
            "7939: [D loss: 0.703076, acc: 0.531250]  [A loss: 0.791064, acc: 0.289062]\n",
            "7940: [D loss: 0.701206, acc: 0.515625]  [A loss: 0.780621, acc: 0.339844]\n",
            "7941: [D loss: 0.705994, acc: 0.517578]  [A loss: 0.815392, acc: 0.285156]\n",
            "7942: [D loss: 0.698582, acc: 0.535156]  [A loss: 0.790557, acc: 0.292969]\n",
            "7943: [D loss: 0.706260, acc: 0.500000]  [A loss: 0.759049, acc: 0.339844]\n",
            "7944: [D loss: 0.693364, acc: 0.523438]  [A loss: 0.846240, acc: 0.187500]\n",
            "7945: [D loss: 0.716871, acc: 0.445312]  [A loss: 0.752362, acc: 0.402344]\n",
            "7946: [D loss: 0.707445, acc: 0.511719]  [A loss: 0.825495, acc: 0.195312]\n",
            "7947: [D loss: 0.716653, acc: 0.470703]  [A loss: 0.759757, acc: 0.371094]\n",
            "7948: [D loss: 0.705413, acc: 0.480469]  [A loss: 0.858005, acc: 0.140625]\n",
            "7949: [D loss: 0.707359, acc: 0.498047]  [A loss: 0.819812, acc: 0.277344]\n",
            "7950: [D loss: 0.703196, acc: 0.527344]  [A loss: 0.806786, acc: 0.257812]\n",
            "7951: [D loss: 0.689047, acc: 0.550781]  [A loss: 0.800263, acc: 0.257812]\n",
            "7952: [D loss: 0.700779, acc: 0.515625]  [A loss: 0.791049, acc: 0.261719]\n",
            "7953: [D loss: 0.704314, acc: 0.494141]  [A loss: 0.775430, acc: 0.335938]\n",
            "7954: [D loss: 0.703570, acc: 0.503906]  [A loss: 0.871644, acc: 0.164062]\n",
            "7955: [D loss: 0.689306, acc: 0.542969]  [A loss: 0.723722, acc: 0.445312]\n",
            "7956: [D loss: 0.716710, acc: 0.496094]  [A loss: 0.940405, acc: 0.113281]\n",
            "7957: [D loss: 0.702534, acc: 0.494141]  [A loss: 0.648698, acc: 0.613281]\n",
            "7958: [D loss: 0.721373, acc: 0.513672]  [A loss: 0.953834, acc: 0.054688]\n",
            "7959: [D loss: 0.706481, acc: 0.515625]  [A loss: 0.710635, acc: 0.472656]\n",
            "7960: [D loss: 0.708157, acc: 0.500000]  [A loss: 0.822052, acc: 0.214844]\n",
            "7961: [D loss: 0.699208, acc: 0.531250]  [A loss: 0.756763, acc: 0.386719]\n",
            "7962: [D loss: 0.701963, acc: 0.517578]  [A loss: 0.778713, acc: 0.285156]\n",
            "7963: [D loss: 0.700929, acc: 0.523438]  [A loss: 0.768654, acc: 0.339844]\n",
            "7964: [D loss: 0.707527, acc: 0.474609]  [A loss: 0.835383, acc: 0.226562]\n",
            "7965: [D loss: 0.697431, acc: 0.542969]  [A loss: 0.753895, acc: 0.355469]\n",
            "7966: [D loss: 0.712386, acc: 0.535156]  [A loss: 0.821691, acc: 0.191406]\n",
            "7967: [D loss: 0.712995, acc: 0.488281]  [A loss: 0.873699, acc: 0.167969]\n",
            "7968: [D loss: 0.711616, acc: 0.498047]  [A loss: 0.759544, acc: 0.367188]\n",
            "7969: [D loss: 0.689027, acc: 0.564453]  [A loss: 0.861010, acc: 0.148438]\n",
            "7970: [D loss: 0.689151, acc: 0.544922]  [A loss: 0.700139, acc: 0.523438]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7971: [D loss: 0.717082, acc: 0.513672]  [A loss: 0.927903, acc: 0.117188]\n",
            "7972: [D loss: 0.684290, acc: 0.564453]  [A loss: 0.716902, acc: 0.468750]\n",
            "7973: [D loss: 0.731240, acc: 0.476562]  [A loss: 0.868473, acc: 0.148438]\n",
            "7974: [D loss: 0.698582, acc: 0.513672]  [A loss: 0.753387, acc: 0.390625]\n",
            "7975: [D loss: 0.712997, acc: 0.503906]  [A loss: 0.871681, acc: 0.125000]\n",
            "7976: [D loss: 0.695074, acc: 0.525391]  [A loss: 0.849680, acc: 0.222656]\n",
            "7977: [D loss: 0.707644, acc: 0.494141]  [A loss: 0.842054, acc: 0.179688]\n",
            "7978: [D loss: 0.696306, acc: 0.494141]  [A loss: 0.753080, acc: 0.375000]\n",
            "7979: [D loss: 0.694349, acc: 0.529297]  [A loss: 0.857205, acc: 0.199219]\n",
            "7980: [D loss: 0.690039, acc: 0.556641]  [A loss: 0.745675, acc: 0.386719]\n",
            "7981: [D loss: 0.707622, acc: 0.529297]  [A loss: 0.917123, acc: 0.144531]\n",
            "7982: [D loss: 0.688139, acc: 0.546875]  [A loss: 0.707254, acc: 0.503906]\n",
            "7983: [D loss: 0.715791, acc: 0.511719]  [A loss: 0.848367, acc: 0.179688]\n",
            "7984: [D loss: 0.699440, acc: 0.533203]  [A loss: 0.739360, acc: 0.398438]\n",
            "7985: [D loss: 0.709881, acc: 0.500000]  [A loss: 0.879566, acc: 0.136719]\n",
            "7986: [D loss: 0.695425, acc: 0.531250]  [A loss: 0.687595, acc: 0.562500]\n",
            "7987: [D loss: 0.712886, acc: 0.511719]  [A loss: 0.885550, acc: 0.167969]\n",
            "7988: [D loss: 0.704472, acc: 0.498047]  [A loss: 0.757817, acc: 0.359375]\n",
            "7989: [D loss: 0.700197, acc: 0.515625]  [A loss: 0.867399, acc: 0.140625]\n",
            "7990: [D loss: 0.705660, acc: 0.488281]  [A loss: 0.765595, acc: 0.378906]\n",
            "7991: [D loss: 0.714464, acc: 0.500000]  [A loss: 0.837233, acc: 0.218750]\n",
            "7992: [D loss: 0.687008, acc: 0.537109]  [A loss: 0.897282, acc: 0.128906]\n",
            "7993: [D loss: 0.708254, acc: 0.482422]  [A loss: 0.750002, acc: 0.398438]\n",
            "7994: [D loss: 0.703688, acc: 0.507812]  [A loss: 0.876442, acc: 0.179688]\n",
            "7995: [D loss: 0.700252, acc: 0.523438]  [A loss: 0.764713, acc: 0.347656]\n",
            "7996: [D loss: 0.698884, acc: 0.511719]  [A loss: 0.879187, acc: 0.152344]\n",
            "7997: [D loss: 0.697771, acc: 0.531250]  [A loss: 0.756629, acc: 0.390625]\n",
            "7998: [D loss: 0.703137, acc: 0.507812]  [A loss: 0.920677, acc: 0.089844]\n",
            "7999: [D loss: 0.687531, acc: 0.566406]  [A loss: 0.689108, acc: 0.562500]\n",
            "8000: [D loss: 0.706658, acc: 0.541016]  [A loss: 0.941846, acc: 0.074219]\n",
            "8001: [D loss: 0.694913, acc: 0.527344]  [A loss: 0.743002, acc: 0.414062]\n",
            "8002: [D loss: 0.708112, acc: 0.496094]  [A loss: 0.873077, acc: 0.148438]\n",
            "8003: [D loss: 0.698562, acc: 0.509766]  [A loss: 0.779456, acc: 0.320312]\n",
            "8004: [D loss: 0.709347, acc: 0.503906]  [A loss: 0.882111, acc: 0.152344]\n",
            "8005: [D loss: 0.688957, acc: 0.531250]  [A loss: 0.721206, acc: 0.464844]\n",
            "8006: [D loss: 0.693937, acc: 0.531250]  [A loss: 0.827315, acc: 0.238281]\n",
            "8007: [D loss: 0.694706, acc: 0.556641]  [A loss: 0.711813, acc: 0.449219]\n",
            "8008: [D loss: 0.710531, acc: 0.500000]  [A loss: 0.832144, acc: 0.183594]\n",
            "8009: [D loss: 0.699826, acc: 0.515625]  [A loss: 0.732466, acc: 0.425781]\n",
            "8010: [D loss: 0.697922, acc: 0.519531]  [A loss: 0.865126, acc: 0.179688]\n",
            "8011: [D loss: 0.695771, acc: 0.525391]  [A loss: 0.744179, acc: 0.433594]\n",
            "8012: [D loss: 0.694095, acc: 0.552734]  [A loss: 0.876323, acc: 0.148438]\n",
            "8013: [D loss: 0.693027, acc: 0.560547]  [A loss: 0.727353, acc: 0.441406]\n",
            "8014: [D loss: 0.721279, acc: 0.513672]  [A loss: 0.896885, acc: 0.109375]\n",
            "8015: [D loss: 0.703874, acc: 0.496094]  [A loss: 0.685795, acc: 0.566406]\n",
            "8016: [D loss: 0.705321, acc: 0.517578]  [A loss: 0.925394, acc: 0.097656]\n",
            "8017: [D loss: 0.703914, acc: 0.498047]  [A loss: 0.684589, acc: 0.585938]\n",
            "8018: [D loss: 0.719421, acc: 0.480469]  [A loss: 0.876441, acc: 0.144531]\n",
            "8019: [D loss: 0.713317, acc: 0.468750]  [A loss: 0.738475, acc: 0.386719]\n",
            "8020: [D loss: 0.715929, acc: 0.472656]  [A loss: 0.839574, acc: 0.222656]\n",
            "8021: [D loss: 0.708838, acc: 0.503906]  [A loss: 0.808931, acc: 0.253906]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8022: [D loss: 0.701464, acc: 0.523438]  [A loss: 0.795855, acc: 0.273438]\n",
            "8023: [D loss: 0.700301, acc: 0.515625]  [A loss: 0.762006, acc: 0.351562]\n",
            "8024: [D loss: 0.712081, acc: 0.492188]  [A loss: 0.785699, acc: 0.289062]\n",
            "8025: [D loss: 0.711495, acc: 0.472656]  [A loss: 0.831150, acc: 0.230469]\n",
            "8026: [D loss: 0.696245, acc: 0.537109]  [A loss: 0.816194, acc: 0.230469]\n",
            "8027: [D loss: 0.705506, acc: 0.507812]  [A loss: 0.822648, acc: 0.257812]\n",
            "8028: [D loss: 0.693159, acc: 0.519531]  [A loss: 0.761908, acc: 0.355469]\n",
            "8029: [D loss: 0.695343, acc: 0.542969]  [A loss: 0.883039, acc: 0.144531]\n",
            "8030: [D loss: 0.707120, acc: 0.476562]  [A loss: 0.737948, acc: 0.429688]\n",
            "8031: [D loss: 0.716286, acc: 0.501953]  [A loss: 0.890146, acc: 0.136719]\n",
            "8032: [D loss: 0.696702, acc: 0.523438]  [A loss: 0.741278, acc: 0.414062]\n",
            "8033: [D loss: 0.709895, acc: 0.523438]  [A loss: 0.901577, acc: 0.152344]\n",
            "8034: [D loss: 0.695097, acc: 0.513672]  [A loss: 0.739376, acc: 0.378906]\n",
            "8035: [D loss: 0.714827, acc: 0.492188]  [A loss: 0.964733, acc: 0.074219]\n",
            "8036: [D loss: 0.705858, acc: 0.482422]  [A loss: 0.700545, acc: 0.488281]\n",
            "8037: [D loss: 0.717428, acc: 0.480469]  [A loss: 0.911721, acc: 0.101562]\n",
            "8038: [D loss: 0.684201, acc: 0.521484]  [A loss: 0.705104, acc: 0.500000]\n",
            "8039: [D loss: 0.720537, acc: 0.486328]  [A loss: 0.913852, acc: 0.093750]\n",
            "8040: [D loss: 0.702313, acc: 0.503906]  [A loss: 0.688315, acc: 0.531250]\n",
            "8041: [D loss: 0.721776, acc: 0.496094]  [A loss: 0.904164, acc: 0.050781]\n",
            "8042: [D loss: 0.686649, acc: 0.539062]  [A loss: 0.737843, acc: 0.390625]\n",
            "8043: [D loss: 0.706738, acc: 0.529297]  [A loss: 0.872962, acc: 0.156250]\n",
            "8044: [D loss: 0.696808, acc: 0.521484]  [A loss: 0.725398, acc: 0.449219]\n",
            "8045: [D loss: 0.694562, acc: 0.554688]  [A loss: 0.809651, acc: 0.289062]\n",
            "8046: [D loss: 0.684745, acc: 0.537109]  [A loss: 0.783083, acc: 0.265625]\n",
            "8047: [D loss: 0.700702, acc: 0.531250]  [A loss: 0.799983, acc: 0.285156]\n",
            "8048: [D loss: 0.706973, acc: 0.505859]  [A loss: 0.814477, acc: 0.265625]\n",
            "8049: [D loss: 0.693780, acc: 0.531250]  [A loss: 0.840539, acc: 0.234375]\n",
            "8050: [D loss: 0.695750, acc: 0.544922]  [A loss: 0.807985, acc: 0.250000]\n",
            "8051: [D loss: 0.705159, acc: 0.500000]  [A loss: 0.868446, acc: 0.207031]\n",
            "8052: [D loss: 0.701342, acc: 0.509766]  [A loss: 0.734680, acc: 0.421875]\n",
            "8053: [D loss: 0.711791, acc: 0.511719]  [A loss: 0.811792, acc: 0.214844]\n",
            "8054: [D loss: 0.692085, acc: 0.521484]  [A loss: 0.772567, acc: 0.343750]\n",
            "8055: [D loss: 0.700905, acc: 0.511719]  [A loss: 0.830071, acc: 0.214844]\n",
            "8056: [D loss: 0.708580, acc: 0.476562]  [A loss: 0.708970, acc: 0.480469]\n",
            "8057: [D loss: 0.710802, acc: 0.517578]  [A loss: 0.833828, acc: 0.199219]\n",
            "8058: [D loss: 0.701869, acc: 0.507812]  [A loss: 0.776010, acc: 0.343750]\n",
            "8059: [D loss: 0.706476, acc: 0.505859]  [A loss: 0.865975, acc: 0.144531]\n",
            "8060: [D loss: 0.690549, acc: 0.517578]  [A loss: 0.703843, acc: 0.492188]\n",
            "8061: [D loss: 0.714966, acc: 0.486328]  [A loss: 0.928543, acc: 0.089844]\n",
            "8062: [D loss: 0.697619, acc: 0.531250]  [A loss: 0.798769, acc: 0.269531]\n",
            "8063: [D loss: 0.691681, acc: 0.542969]  [A loss: 0.915064, acc: 0.132812]\n",
            "8064: [D loss: 0.687483, acc: 0.546875]  [A loss: 0.743286, acc: 0.417969]\n",
            "8065: [D loss: 0.699198, acc: 0.535156]  [A loss: 0.893996, acc: 0.121094]\n",
            "8066: [D loss: 0.700958, acc: 0.523438]  [A loss: 0.756370, acc: 0.398438]\n",
            "8067: [D loss: 0.711012, acc: 0.509766]  [A loss: 0.862273, acc: 0.175781]\n",
            "8068: [D loss: 0.697682, acc: 0.513672]  [A loss: 0.756773, acc: 0.371094]\n",
            "8069: [D loss: 0.701932, acc: 0.529297]  [A loss: 0.887348, acc: 0.140625]\n",
            "8070: [D loss: 0.695566, acc: 0.541016]  [A loss: 0.737768, acc: 0.406250]\n",
            "8071: [D loss: 0.713728, acc: 0.500000]  [A loss: 0.901525, acc: 0.097656]\n",
            "8072: [D loss: 0.691740, acc: 0.544922]  [A loss: 0.776469, acc: 0.390625]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8073: [D loss: 0.712340, acc: 0.488281]  [A loss: 0.845424, acc: 0.218750]\n",
            "8074: [D loss: 0.708495, acc: 0.519531]  [A loss: 0.763989, acc: 0.375000]\n",
            "8075: [D loss: 0.705149, acc: 0.521484]  [A loss: 0.904674, acc: 0.125000]\n",
            "8076: [D loss: 0.683422, acc: 0.582031]  [A loss: 0.730179, acc: 0.433594]\n",
            "8077: [D loss: 0.716195, acc: 0.517578]  [A loss: 0.924463, acc: 0.113281]\n",
            "8078: [D loss: 0.709395, acc: 0.492188]  [A loss: 0.747745, acc: 0.351562]\n",
            "8079: [D loss: 0.698855, acc: 0.488281]  [A loss: 0.914125, acc: 0.152344]\n",
            "8080: [D loss: 0.695496, acc: 0.539062]  [A loss: 0.742522, acc: 0.375000]\n",
            "8081: [D loss: 0.706828, acc: 0.503906]  [A loss: 0.839636, acc: 0.187500]\n",
            "8082: [D loss: 0.698441, acc: 0.523438]  [A loss: 0.737845, acc: 0.421875]\n",
            "8083: [D loss: 0.710459, acc: 0.513672]  [A loss: 0.877506, acc: 0.152344]\n",
            "8084: [D loss: 0.699672, acc: 0.527344]  [A loss: 0.674304, acc: 0.585938]\n",
            "8085: [D loss: 0.686233, acc: 0.556641]  [A loss: 0.830079, acc: 0.222656]\n",
            "8086: [D loss: 0.698184, acc: 0.533203]  [A loss: 0.746954, acc: 0.398438]\n",
            "8087: [D loss: 0.690860, acc: 0.537109]  [A loss: 0.779584, acc: 0.332031]\n",
            "8088: [D loss: 0.700410, acc: 0.531250]  [A loss: 0.843614, acc: 0.164062]\n",
            "8089: [D loss: 0.690683, acc: 0.548828]  [A loss: 0.723259, acc: 0.468750]\n",
            "8090: [D loss: 0.703414, acc: 0.513672]  [A loss: 0.805673, acc: 0.250000]\n",
            "8091: [D loss: 0.703613, acc: 0.525391]  [A loss: 0.833166, acc: 0.183594]\n",
            "8092: [D loss: 0.716645, acc: 0.447266]  [A loss: 0.774423, acc: 0.308594]\n",
            "8093: [D loss: 0.715060, acc: 0.478516]  [A loss: 0.883510, acc: 0.152344]\n",
            "8094: [D loss: 0.692009, acc: 0.542969]  [A loss: 0.721420, acc: 0.445312]\n",
            "8095: [D loss: 0.722778, acc: 0.492188]  [A loss: 0.939095, acc: 0.085938]\n",
            "8096: [D loss: 0.693149, acc: 0.535156]  [A loss: 0.716515, acc: 0.484375]\n",
            "8097: [D loss: 0.722200, acc: 0.533203]  [A loss: 0.870140, acc: 0.183594]\n",
            "8098: [D loss: 0.694659, acc: 0.515625]  [A loss: 0.766158, acc: 0.363281]\n",
            "8099: [D loss: 0.707934, acc: 0.509766]  [A loss: 0.822799, acc: 0.222656]\n",
            "8100: [D loss: 0.694850, acc: 0.521484]  [A loss: 0.729218, acc: 0.410156]\n",
            "8101: [D loss: 0.718733, acc: 0.498047]  [A loss: 0.857158, acc: 0.183594]\n",
            "8102: [D loss: 0.699655, acc: 0.515625]  [A loss: 0.725931, acc: 0.445312]\n",
            "8103: [D loss: 0.707037, acc: 0.519531]  [A loss: 0.836265, acc: 0.195312]\n",
            "8104: [D loss: 0.706235, acc: 0.501953]  [A loss: 0.828411, acc: 0.289062]\n",
            "8105: [D loss: 0.706863, acc: 0.476562]  [A loss: 0.778138, acc: 0.316406]\n",
            "8106: [D loss: 0.712674, acc: 0.496094]  [A loss: 0.800262, acc: 0.265625]\n",
            "8107: [D loss: 0.713459, acc: 0.496094]  [A loss: 0.789023, acc: 0.296875]\n",
            "8108: [D loss: 0.712542, acc: 0.494141]  [A loss: 0.843566, acc: 0.218750]\n",
            "8109: [D loss: 0.698810, acc: 0.496094]  [A loss: 0.755830, acc: 0.402344]\n",
            "8110: [D loss: 0.713996, acc: 0.501953]  [A loss: 0.855959, acc: 0.195312]\n",
            "8111: [D loss: 0.695202, acc: 0.521484]  [A loss: 0.783899, acc: 0.320312]\n",
            "8112: [D loss: 0.695204, acc: 0.531250]  [A loss: 0.846204, acc: 0.218750]\n",
            "8113: [D loss: 0.707227, acc: 0.464844]  [A loss: 0.756458, acc: 0.343750]\n",
            "8114: [D loss: 0.703386, acc: 0.535156]  [A loss: 0.808984, acc: 0.289062]\n",
            "8115: [D loss: 0.703744, acc: 0.490234]  [A loss: 0.767021, acc: 0.328125]\n",
            "8116: [D loss: 0.699247, acc: 0.523438]  [A loss: 0.829774, acc: 0.222656]\n",
            "8117: [D loss: 0.705981, acc: 0.505859]  [A loss: 0.783806, acc: 0.304688]\n",
            "8118: [D loss: 0.698111, acc: 0.505859]  [A loss: 0.834180, acc: 0.203125]\n",
            "8119: [D loss: 0.695451, acc: 0.531250]  [A loss: 0.742964, acc: 0.429688]\n",
            "8120: [D loss: 0.706753, acc: 0.507812]  [A loss: 0.908262, acc: 0.121094]\n",
            "8121: [D loss: 0.687609, acc: 0.550781]  [A loss: 0.699969, acc: 0.503906]\n",
            "8122: [D loss: 0.707395, acc: 0.511719]  [A loss: 0.923448, acc: 0.085938]\n",
            "8123: [D loss: 0.701141, acc: 0.521484]  [A loss: 0.723097, acc: 0.429688]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8124: [D loss: 0.709268, acc: 0.523438]  [A loss: 0.880501, acc: 0.160156]\n",
            "8125: [D loss: 0.683656, acc: 0.560547]  [A loss: 0.733939, acc: 0.425781]\n",
            "8126: [D loss: 0.703231, acc: 0.533203]  [A loss: 0.848549, acc: 0.175781]\n",
            "8127: [D loss: 0.694688, acc: 0.556641]  [A loss: 0.753274, acc: 0.378906]\n",
            "8128: [D loss: 0.704933, acc: 0.517578]  [A loss: 0.853730, acc: 0.207031]\n",
            "8129: [D loss: 0.707874, acc: 0.517578]  [A loss: 0.797990, acc: 0.300781]\n",
            "8130: [D loss: 0.702514, acc: 0.537109]  [A loss: 0.863957, acc: 0.132812]\n",
            "8131: [D loss: 0.691246, acc: 0.539062]  [A loss: 0.807779, acc: 0.332031]\n",
            "8132: [D loss: 0.698682, acc: 0.529297]  [A loss: 0.870686, acc: 0.160156]\n",
            "8133: [D loss: 0.701135, acc: 0.546875]  [A loss: 0.751524, acc: 0.390625]\n",
            "8134: [D loss: 0.704915, acc: 0.519531]  [A loss: 0.887661, acc: 0.136719]\n",
            "8135: [D loss: 0.702085, acc: 0.519531]  [A loss: 0.717311, acc: 0.441406]\n",
            "8136: [D loss: 0.713480, acc: 0.511719]  [A loss: 0.882330, acc: 0.171875]\n",
            "8137: [D loss: 0.694691, acc: 0.505859]  [A loss: 0.751948, acc: 0.371094]\n",
            "8138: [D loss: 0.705688, acc: 0.480469]  [A loss: 0.852663, acc: 0.183594]\n",
            "8139: [D loss: 0.705963, acc: 0.482422]  [A loss: 0.761065, acc: 0.363281]\n",
            "8140: [D loss: 0.691136, acc: 0.535156]  [A loss: 0.831060, acc: 0.210938]\n",
            "8141: [D loss: 0.707379, acc: 0.509766]  [A loss: 0.790383, acc: 0.261719]\n",
            "8142: [D loss: 0.690920, acc: 0.544922]  [A loss: 0.752742, acc: 0.347656]\n",
            "8143: [D loss: 0.701484, acc: 0.515625]  [A loss: 0.873147, acc: 0.195312]\n",
            "8144: [D loss: 0.686061, acc: 0.550781]  [A loss: 0.728908, acc: 0.414062]\n",
            "8145: [D loss: 0.703623, acc: 0.523438]  [A loss: 0.840577, acc: 0.160156]\n",
            "8146: [D loss: 0.691931, acc: 0.533203]  [A loss: 0.784389, acc: 0.316406]\n",
            "8147: [D loss: 0.705497, acc: 0.503906]  [A loss: 0.795992, acc: 0.292969]\n",
            "8148: [D loss: 0.705824, acc: 0.482422]  [A loss: 0.771339, acc: 0.312500]\n",
            "8149: [D loss: 0.697627, acc: 0.529297]  [A loss: 0.925942, acc: 0.089844]\n",
            "8150: [D loss: 0.696726, acc: 0.505859]  [A loss: 0.738136, acc: 0.398438]\n",
            "8151: [D loss: 0.704746, acc: 0.505859]  [A loss: 0.895210, acc: 0.125000]\n",
            "8152: [D loss: 0.699260, acc: 0.507812]  [A loss: 0.703366, acc: 0.527344]\n",
            "8153: [D loss: 0.701060, acc: 0.511719]  [A loss: 0.907307, acc: 0.109375]\n",
            "8154: [D loss: 0.703923, acc: 0.500000]  [A loss: 0.669929, acc: 0.589844]\n",
            "8155: [D loss: 0.720931, acc: 0.482422]  [A loss: 0.939061, acc: 0.089844]\n",
            "8156: [D loss: 0.713593, acc: 0.476562]  [A loss: 0.785374, acc: 0.332031]\n",
            "8157: [D loss: 0.712420, acc: 0.509766]  [A loss: 0.857309, acc: 0.156250]\n",
            "8158: [D loss: 0.701590, acc: 0.500000]  [A loss: 0.735952, acc: 0.394531]\n",
            "8159: [D loss: 0.697147, acc: 0.496094]  [A loss: 0.862282, acc: 0.167969]\n",
            "8160: [D loss: 0.693554, acc: 0.523438]  [A loss: 0.768116, acc: 0.328125]\n",
            "8161: [D loss: 0.718550, acc: 0.470703]  [A loss: 0.839523, acc: 0.175781]\n",
            "8162: [D loss: 0.697911, acc: 0.525391]  [A loss: 0.769157, acc: 0.296875]\n",
            "8163: [D loss: 0.705939, acc: 0.529297]  [A loss: 0.834517, acc: 0.242188]\n",
            "8164: [D loss: 0.708359, acc: 0.482422]  [A loss: 0.799477, acc: 0.230469]\n",
            "8165: [D loss: 0.704057, acc: 0.527344]  [A loss: 0.825530, acc: 0.183594]\n",
            "8166: [D loss: 0.694723, acc: 0.513672]  [A loss: 0.760224, acc: 0.359375]\n",
            "8167: [D loss: 0.697780, acc: 0.511719]  [A loss: 0.837139, acc: 0.210938]\n",
            "8168: [D loss: 0.713316, acc: 0.470703]  [A loss: 0.784222, acc: 0.296875]\n",
            "8169: [D loss: 0.706849, acc: 0.501953]  [A loss: 0.851739, acc: 0.160156]\n",
            "8170: [D loss: 0.697433, acc: 0.535156]  [A loss: 0.713811, acc: 0.468750]\n",
            "8171: [D loss: 0.693781, acc: 0.542969]  [A loss: 0.884509, acc: 0.125000]\n",
            "8172: [D loss: 0.691694, acc: 0.541016]  [A loss: 0.849514, acc: 0.292969]\n",
            "8173: [D loss: 0.697610, acc: 0.525391]  [A loss: 0.832037, acc: 0.230469]\n",
            "8174: [D loss: 0.705614, acc: 0.515625]  [A loss: 0.738091, acc: 0.453125]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8175: [D loss: 0.701117, acc: 0.521484]  [A loss: 0.848065, acc: 0.199219]\n",
            "8176: [D loss: 0.689986, acc: 0.527344]  [A loss: 0.720461, acc: 0.445312]\n",
            "8177: [D loss: 0.725513, acc: 0.492188]  [A loss: 1.006641, acc: 0.074219]\n",
            "8178: [D loss: 0.726372, acc: 0.474609]  [A loss: 0.643372, acc: 0.660156]\n",
            "8179: [D loss: 0.730976, acc: 0.517578]  [A loss: 0.901730, acc: 0.101562]\n",
            "8180: [D loss: 0.699612, acc: 0.523438]  [A loss: 0.690160, acc: 0.500000]\n",
            "8181: [D loss: 0.716625, acc: 0.513672]  [A loss: 0.871567, acc: 0.164062]\n",
            "8182: [D loss: 0.700906, acc: 0.531250]  [A loss: 0.707022, acc: 0.464844]\n",
            "8183: [D loss: 0.709969, acc: 0.523438]  [A loss: 0.863114, acc: 0.132812]\n",
            "8184: [D loss: 0.703909, acc: 0.503906]  [A loss: 0.744190, acc: 0.363281]\n",
            "8185: [D loss: 0.700644, acc: 0.505859]  [A loss: 0.865058, acc: 0.171875]\n",
            "8186: [D loss: 0.705723, acc: 0.478516]  [A loss: 0.733304, acc: 0.414062]\n",
            "8187: [D loss: 0.713727, acc: 0.490234]  [A loss: 0.847612, acc: 0.187500]\n",
            "8188: [D loss: 0.705102, acc: 0.521484]  [A loss: 0.796296, acc: 0.250000]\n",
            "8189: [D loss: 0.697809, acc: 0.515625]  [A loss: 0.827622, acc: 0.257812]\n",
            "8190: [D loss: 0.694294, acc: 0.511719]  [A loss: 0.776834, acc: 0.343750]\n",
            "8191: [D loss: 0.718421, acc: 0.509766]  [A loss: 0.869982, acc: 0.160156]\n",
            "8192: [D loss: 0.693811, acc: 0.517578]  [A loss: 0.736155, acc: 0.359375]\n",
            "8193: [D loss: 0.719875, acc: 0.494141]  [A loss: 0.858871, acc: 0.214844]\n",
            "8194: [D loss: 0.687035, acc: 0.527344]  [A loss: 0.787751, acc: 0.312500]\n",
            "8195: [D loss: 0.705743, acc: 0.503906]  [A loss: 0.801245, acc: 0.234375]\n",
            "8196: [D loss: 0.699045, acc: 0.541016]  [A loss: 0.766263, acc: 0.351562]\n",
            "8197: [D loss: 0.699893, acc: 0.531250]  [A loss: 0.805876, acc: 0.289062]\n",
            "8198: [D loss: 0.704543, acc: 0.519531]  [A loss: 0.873521, acc: 0.128906]\n",
            "8199: [D loss: 0.689162, acc: 0.529297]  [A loss: 0.767665, acc: 0.343750]\n",
            "8200: [D loss: 0.703986, acc: 0.529297]  [A loss: 0.874783, acc: 0.191406]\n",
            "8201: [D loss: 0.703209, acc: 0.509766]  [A loss: 0.717293, acc: 0.437500]\n",
            "8202: [D loss: 0.706668, acc: 0.539062]  [A loss: 0.893309, acc: 0.156250]\n",
            "8203: [D loss: 0.697935, acc: 0.542969]  [A loss: 0.710520, acc: 0.476562]\n",
            "8204: [D loss: 0.727696, acc: 0.472656]  [A loss: 0.872689, acc: 0.101562]\n",
            "8205: [D loss: 0.702949, acc: 0.527344]  [A loss: 0.725840, acc: 0.457031]\n",
            "8206: [D loss: 0.693394, acc: 0.541016]  [A loss: 0.861520, acc: 0.140625]\n",
            "8207: [D loss: 0.710258, acc: 0.513672]  [A loss: 0.764138, acc: 0.351562]\n",
            "8208: [D loss: 0.704218, acc: 0.511719]  [A loss: 0.866260, acc: 0.148438]\n",
            "8209: [D loss: 0.700623, acc: 0.492188]  [A loss: 0.721572, acc: 0.468750]\n",
            "8210: [D loss: 0.717308, acc: 0.490234]  [A loss: 0.952915, acc: 0.062500]\n",
            "8211: [D loss: 0.701851, acc: 0.507812]  [A loss: 0.704661, acc: 0.492188]\n",
            "8212: [D loss: 0.722960, acc: 0.500000]  [A loss: 0.996708, acc: 0.070312]\n",
            "8213: [D loss: 0.711699, acc: 0.488281]  [A loss: 0.661192, acc: 0.625000]\n",
            "8214: [D loss: 0.726449, acc: 0.501953]  [A loss: 0.897147, acc: 0.113281]\n",
            "8215: [D loss: 0.696769, acc: 0.533203]  [A loss: 0.729154, acc: 0.460938]\n",
            "8216: [D loss: 0.699063, acc: 0.519531]  [A loss: 0.853909, acc: 0.152344]\n",
            "8217: [D loss: 0.693103, acc: 0.513672]  [A loss: 0.714533, acc: 0.515625]\n",
            "8218: [D loss: 0.707267, acc: 0.515625]  [A loss: 0.852736, acc: 0.160156]\n",
            "8219: [D loss: 0.693609, acc: 0.560547]  [A loss: 0.760458, acc: 0.375000]\n",
            "8220: [D loss: 0.697521, acc: 0.507812]  [A loss: 0.822397, acc: 0.222656]\n",
            "8221: [D loss: 0.711840, acc: 0.472656]  [A loss: 0.713822, acc: 0.468750]\n",
            "8222: [D loss: 0.699586, acc: 0.535156]  [A loss: 0.814291, acc: 0.250000]\n",
            "8223: [D loss: 0.691916, acc: 0.537109]  [A loss: 0.757811, acc: 0.386719]\n",
            "8224: [D loss: 0.711842, acc: 0.501953]  [A loss: 0.830027, acc: 0.191406]\n",
            "8225: [D loss: 0.685803, acc: 0.554688]  [A loss: 0.802985, acc: 0.265625]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8226: [D loss: 0.706597, acc: 0.488281]  [A loss: 0.811753, acc: 0.242188]\n",
            "8227: [D loss: 0.701619, acc: 0.507812]  [A loss: 0.765694, acc: 0.316406]\n",
            "8228: [D loss: 0.700000, acc: 0.519531]  [A loss: 0.818677, acc: 0.230469]\n",
            "8229: [D loss: 0.694219, acc: 0.556641]  [A loss: 0.772655, acc: 0.296875]\n",
            "8230: [D loss: 0.705817, acc: 0.505859]  [A loss: 0.848186, acc: 0.203125]\n",
            "8231: [D loss: 0.703826, acc: 0.498047]  [A loss: 0.764725, acc: 0.332031]\n",
            "8232: [D loss: 0.708097, acc: 0.492188]  [A loss: 0.909792, acc: 0.144531]\n",
            "8233: [D loss: 0.708805, acc: 0.494141]  [A loss: 0.715813, acc: 0.468750]\n",
            "8234: [D loss: 0.703128, acc: 0.521484]  [A loss: 0.908324, acc: 0.117188]\n",
            "8235: [D loss: 0.700238, acc: 0.500000]  [A loss: 0.759196, acc: 0.437500]\n",
            "8236: [D loss: 0.707046, acc: 0.515625]  [A loss: 0.968893, acc: 0.085938]\n",
            "8237: [D loss: 0.697618, acc: 0.513672]  [A loss: 0.696725, acc: 0.507812]\n",
            "8238: [D loss: 0.689239, acc: 0.531250]  [A loss: 0.854585, acc: 0.179688]\n",
            "8239: [D loss: 0.692332, acc: 0.542969]  [A loss: 0.747170, acc: 0.382812]\n",
            "8240: [D loss: 0.695679, acc: 0.533203]  [A loss: 0.866983, acc: 0.175781]\n",
            "8241: [D loss: 0.686043, acc: 0.544922]  [A loss: 0.774587, acc: 0.355469]\n",
            "8242: [D loss: 0.716296, acc: 0.501953]  [A loss: 0.808491, acc: 0.261719]\n",
            "8243: [D loss: 0.708134, acc: 0.511719]  [A loss: 0.771838, acc: 0.394531]\n",
            "8244: [D loss: 0.711263, acc: 0.513672]  [A loss: 0.922213, acc: 0.085938]\n",
            "8245: [D loss: 0.682511, acc: 0.544922]  [A loss: 0.673043, acc: 0.585938]\n",
            "8246: [D loss: 0.719566, acc: 0.523438]  [A loss: 0.901193, acc: 0.152344]\n",
            "8247: [D loss: 0.704213, acc: 0.517578]  [A loss: 0.677814, acc: 0.570312]\n",
            "8248: [D loss: 0.703015, acc: 0.527344]  [A loss: 0.867107, acc: 0.195312]\n",
            "8249: [D loss: 0.704606, acc: 0.492188]  [A loss: 0.768505, acc: 0.328125]\n",
            "8250: [D loss: 0.706566, acc: 0.507812]  [A loss: 0.837039, acc: 0.156250]\n",
            "8251: [D loss: 0.700558, acc: 0.488281]  [A loss: 0.809156, acc: 0.246094]\n",
            "8252: [D loss: 0.703992, acc: 0.503906]  [A loss: 0.766302, acc: 0.367188]\n",
            "8253: [D loss: 0.700215, acc: 0.517578]  [A loss: 0.873146, acc: 0.156250]\n",
            "8254: [D loss: 0.709181, acc: 0.492188]  [A loss: 0.721888, acc: 0.476562]\n",
            "8255: [D loss: 0.723657, acc: 0.498047]  [A loss: 0.955242, acc: 0.066406]\n",
            "8256: [D loss: 0.703988, acc: 0.513672]  [A loss: 0.676662, acc: 0.589844]\n",
            "8257: [D loss: 0.727865, acc: 0.490234]  [A loss: 0.910337, acc: 0.121094]\n",
            "8258: [D loss: 0.701655, acc: 0.515625]  [A loss: 0.729993, acc: 0.417969]\n",
            "8259: [D loss: 0.710794, acc: 0.517578]  [A loss: 0.841850, acc: 0.218750]\n",
            "8260: [D loss: 0.706957, acc: 0.490234]  [A loss: 0.781497, acc: 0.308594]\n",
            "8261: [D loss: 0.705997, acc: 0.511719]  [A loss: 0.767887, acc: 0.328125]\n",
            "8262: [D loss: 0.700292, acc: 0.503906]  [A loss: 0.792328, acc: 0.312500]\n",
            "8263: [D loss: 0.693875, acc: 0.517578]  [A loss: 0.868279, acc: 0.128906]\n",
            "8264: [D loss: 0.698330, acc: 0.541016]  [A loss: 0.779889, acc: 0.273438]\n",
            "8265: [D loss: 0.706629, acc: 0.494141]  [A loss: 0.816813, acc: 0.230469]\n",
            "8266: [D loss: 0.705773, acc: 0.496094]  [A loss: 0.786607, acc: 0.304688]\n",
            "8267: [D loss: 0.704936, acc: 0.503906]  [A loss: 0.786817, acc: 0.320312]\n",
            "8268: [D loss: 0.702469, acc: 0.511719]  [A loss: 0.783923, acc: 0.285156]\n",
            "8269: [D loss: 0.710541, acc: 0.503906]  [A loss: 0.801541, acc: 0.203125]\n",
            "8270: [D loss: 0.706135, acc: 0.505859]  [A loss: 0.762558, acc: 0.332031]\n",
            "8271: [D loss: 0.703452, acc: 0.523438]  [A loss: 0.839679, acc: 0.167969]\n",
            "8272: [D loss: 0.686139, acc: 0.537109]  [A loss: 0.746323, acc: 0.375000]\n",
            "8273: [D loss: 0.701770, acc: 0.529297]  [A loss: 0.907984, acc: 0.105469]\n",
            "8274: [D loss: 0.693353, acc: 0.542969]  [A loss: 0.724878, acc: 0.468750]\n",
            "8275: [D loss: 0.715636, acc: 0.494141]  [A loss: 0.965118, acc: 0.054688]\n",
            "8276: [D loss: 0.701818, acc: 0.490234]  [A loss: 0.695261, acc: 0.507812]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8277: [D loss: 0.709970, acc: 0.492188]  [A loss: 0.879282, acc: 0.117188]\n",
            "8278: [D loss: 0.698864, acc: 0.507812]  [A loss: 0.717618, acc: 0.460938]\n",
            "8279: [D loss: 0.707548, acc: 0.537109]  [A loss: 0.864931, acc: 0.144531]\n",
            "8280: [D loss: 0.702000, acc: 0.511719]  [A loss: 0.699003, acc: 0.496094]\n",
            "8281: [D loss: 0.698273, acc: 0.527344]  [A loss: 0.839596, acc: 0.222656]\n",
            "8282: [D loss: 0.702121, acc: 0.505859]  [A loss: 0.726388, acc: 0.433594]\n",
            "8283: [D loss: 0.709052, acc: 0.482422]  [A loss: 0.854486, acc: 0.191406]\n",
            "8284: [D loss: 0.705988, acc: 0.472656]  [A loss: 0.740893, acc: 0.390625]\n",
            "8285: [D loss: 0.716640, acc: 0.484375]  [A loss: 0.909803, acc: 0.125000]\n",
            "8286: [D loss: 0.691503, acc: 0.564453]  [A loss: 0.687996, acc: 0.539062]\n",
            "8287: [D loss: 0.719723, acc: 0.537109]  [A loss: 0.968827, acc: 0.054688]\n",
            "8288: [D loss: 0.704473, acc: 0.498047]  [A loss: 0.697067, acc: 0.527344]\n",
            "8289: [D loss: 0.699446, acc: 0.529297]  [A loss: 0.826854, acc: 0.250000]\n",
            "8290: [D loss: 0.704214, acc: 0.503906]  [A loss: 0.815399, acc: 0.253906]\n",
            "8291: [D loss: 0.697110, acc: 0.542969]  [A loss: 0.773413, acc: 0.347656]\n",
            "8292: [D loss: 0.702441, acc: 0.539062]  [A loss: 0.873969, acc: 0.179688]\n",
            "8293: [D loss: 0.696455, acc: 0.523438]  [A loss: 0.698929, acc: 0.488281]\n",
            "8294: [D loss: 0.702574, acc: 0.539062]  [A loss: 0.853759, acc: 0.179688]\n",
            "8295: [D loss: 0.692922, acc: 0.533203]  [A loss: 0.733671, acc: 0.445312]\n",
            "8296: [D loss: 0.722593, acc: 0.501953]  [A loss: 0.991107, acc: 0.058594]\n",
            "8297: [D loss: 0.706679, acc: 0.507812]  [A loss: 0.682723, acc: 0.566406]\n",
            "8298: [D loss: 0.706820, acc: 0.537109]  [A loss: 0.784848, acc: 0.273438]\n",
            "8299: [D loss: 0.704348, acc: 0.494141]  [A loss: 0.801205, acc: 0.250000]\n",
            "8300: [D loss: 0.720650, acc: 0.445312]  [A loss: 0.786596, acc: 0.273438]\n",
            "8301: [D loss: 0.696882, acc: 0.500000]  [A loss: 0.828669, acc: 0.242188]\n",
            "8302: [D loss: 0.695614, acc: 0.539062]  [A loss: 0.774594, acc: 0.304688]\n",
            "8303: [D loss: 0.690479, acc: 0.531250]  [A loss: 0.875744, acc: 0.164062]\n",
            "8304: [D loss: 0.693033, acc: 0.521484]  [A loss: 0.770150, acc: 0.332031]\n",
            "8305: [D loss: 0.695215, acc: 0.562500]  [A loss: 0.855290, acc: 0.179688]\n",
            "8306: [D loss: 0.700932, acc: 0.498047]  [A loss: 0.755568, acc: 0.390625]\n",
            "8307: [D loss: 0.689379, acc: 0.535156]  [A loss: 0.863664, acc: 0.167969]\n",
            "8308: [D loss: 0.689574, acc: 0.537109]  [A loss: 0.757121, acc: 0.343750]\n",
            "8309: [D loss: 0.709215, acc: 0.498047]  [A loss: 0.894028, acc: 0.128906]\n",
            "8310: [D loss: 0.710116, acc: 0.515625]  [A loss: 0.737220, acc: 0.414062]\n",
            "8311: [D loss: 0.711560, acc: 0.494141]  [A loss: 0.867985, acc: 0.136719]\n",
            "8312: [D loss: 0.704619, acc: 0.500000]  [A loss: 0.770133, acc: 0.351562]\n",
            "8313: [D loss: 0.712525, acc: 0.498047]  [A loss: 0.841161, acc: 0.183594]\n",
            "8314: [D loss: 0.706032, acc: 0.505859]  [A loss: 0.786393, acc: 0.324219]\n",
            "8315: [D loss: 0.715366, acc: 0.474609]  [A loss: 0.767100, acc: 0.335938]\n",
            "8316: [D loss: 0.713541, acc: 0.498047]  [A loss: 0.848624, acc: 0.167969]\n",
            "8317: [D loss: 0.700309, acc: 0.535156]  [A loss: 0.770339, acc: 0.335938]\n",
            "8318: [D loss: 0.708729, acc: 0.521484]  [A loss: 0.956117, acc: 0.085938]\n",
            "8319: [D loss: 0.701690, acc: 0.527344]  [A loss: 0.677430, acc: 0.527344]\n",
            "8320: [D loss: 0.733907, acc: 0.496094]  [A loss: 0.919809, acc: 0.105469]\n",
            "8321: [D loss: 0.694354, acc: 0.507812]  [A loss: 0.685992, acc: 0.523438]\n",
            "8322: [D loss: 0.723077, acc: 0.501953]  [A loss: 0.951874, acc: 0.074219]\n",
            "8323: [D loss: 0.705956, acc: 0.515625]  [A loss: 0.671745, acc: 0.617188]\n",
            "8324: [D loss: 0.722928, acc: 0.500000]  [A loss: 0.865438, acc: 0.128906]\n",
            "8325: [D loss: 0.697048, acc: 0.527344]  [A loss: 0.737455, acc: 0.371094]\n",
            "8326: [D loss: 0.707796, acc: 0.505859]  [A loss: 0.824856, acc: 0.250000]\n",
            "8327: [D loss: 0.690208, acc: 0.509766]  [A loss: 0.765714, acc: 0.328125]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8328: [D loss: 0.722532, acc: 0.466797]  [A loss: 0.822034, acc: 0.187500]\n",
            "8329: [D loss: 0.703917, acc: 0.480469]  [A loss: 0.837227, acc: 0.210938]\n",
            "8330: [D loss: 0.696974, acc: 0.517578]  [A loss: 0.739102, acc: 0.425781]\n",
            "8331: [D loss: 0.715872, acc: 0.515625]  [A loss: 0.821810, acc: 0.214844]\n",
            "8332: [D loss: 0.687590, acc: 0.560547]  [A loss: 0.729231, acc: 0.425781]\n",
            "8333: [D loss: 0.712335, acc: 0.490234]  [A loss: 0.861743, acc: 0.132812]\n",
            "8334: [D loss: 0.707024, acc: 0.515625]  [A loss: 0.770688, acc: 0.332031]\n",
            "8335: [D loss: 0.698389, acc: 0.529297]  [A loss: 0.998437, acc: 0.140625]\n",
            "8336: [D loss: 0.696606, acc: 0.521484]  [A loss: 0.734907, acc: 0.410156]\n",
            "8337: [D loss: 0.709401, acc: 0.509766]  [A loss: 0.981320, acc: 0.050781]\n",
            "8338: [D loss: 0.698682, acc: 0.507812]  [A loss: 0.684811, acc: 0.527344]\n",
            "8339: [D loss: 0.721233, acc: 0.500000]  [A loss: 0.908814, acc: 0.101562]\n",
            "8340: [D loss: 0.708742, acc: 0.521484]  [A loss: 0.747851, acc: 0.382812]\n",
            "8341: [D loss: 0.721634, acc: 0.472656]  [A loss: 0.845459, acc: 0.152344]\n",
            "8342: [D loss: 0.704892, acc: 0.511719]  [A loss: 0.752925, acc: 0.386719]\n",
            "8343: [D loss: 0.704432, acc: 0.513672]  [A loss: 0.827932, acc: 0.242188]\n",
            "8344: [D loss: 0.702699, acc: 0.501953]  [A loss: 0.754662, acc: 0.371094]\n",
            "8345: [D loss: 0.714703, acc: 0.496094]  [A loss: 0.842254, acc: 0.187500]\n",
            "8346: [D loss: 0.704890, acc: 0.519531]  [A loss: 0.806755, acc: 0.289062]\n",
            "8347: [D loss: 0.696925, acc: 0.525391]  [A loss: 0.837575, acc: 0.187500]\n",
            "8348: [D loss: 0.704424, acc: 0.486328]  [A loss: 0.768375, acc: 0.367188]\n",
            "8349: [D loss: 0.684204, acc: 0.562500]  [A loss: 0.813156, acc: 0.226562]\n",
            "8350: [D loss: 0.697281, acc: 0.517578]  [A loss: 0.801619, acc: 0.273438]\n",
            "8351: [D loss: 0.702350, acc: 0.519531]  [A loss: 0.824540, acc: 0.230469]\n",
            "8352: [D loss: 0.699628, acc: 0.498047]  [A loss: 0.752446, acc: 0.378906]\n",
            "8353: [D loss: 0.691666, acc: 0.541016]  [A loss: 0.865531, acc: 0.121094]\n",
            "8354: [D loss: 0.691209, acc: 0.513672]  [A loss: 0.754718, acc: 0.355469]\n",
            "8355: [D loss: 0.695897, acc: 0.525391]  [A loss: 0.934071, acc: 0.097656]\n",
            "8356: [D loss: 0.698566, acc: 0.501953]  [A loss: 0.699958, acc: 0.503906]\n",
            "8357: [D loss: 0.707446, acc: 0.517578]  [A loss: 0.924711, acc: 0.109375]\n",
            "8358: [D loss: 0.698291, acc: 0.533203]  [A loss: 0.661109, acc: 0.613281]\n",
            "8359: [D loss: 0.716186, acc: 0.480469]  [A loss: 0.831826, acc: 0.230469]\n",
            "8360: [D loss: 0.701762, acc: 0.517578]  [A loss: 0.784534, acc: 0.328125]\n",
            "8361: [D loss: 0.705030, acc: 0.496094]  [A loss: 0.922201, acc: 0.097656]\n",
            "8362: [D loss: 0.704102, acc: 0.496094]  [A loss: 0.681377, acc: 0.562500]\n",
            "8363: [D loss: 0.717945, acc: 0.507812]  [A loss: 0.929625, acc: 0.097656]\n",
            "8364: [D loss: 0.694755, acc: 0.513672]  [A loss: 0.698318, acc: 0.511719]\n",
            "8365: [D loss: 0.705137, acc: 0.527344]  [A loss: 0.855607, acc: 0.144531]\n",
            "8366: [D loss: 0.697138, acc: 0.515625]  [A loss: 0.764553, acc: 0.363281]\n",
            "8367: [D loss: 0.696932, acc: 0.517578]  [A loss: 0.811155, acc: 0.246094]\n",
            "8368: [D loss: 0.695892, acc: 0.554688]  [A loss: 0.799791, acc: 0.292969]\n",
            "8369: [D loss: 0.699114, acc: 0.505859]  [A loss: 0.808915, acc: 0.253906]\n",
            "8370: [D loss: 0.691659, acc: 0.529297]  [A loss: 0.784660, acc: 0.339844]\n",
            "8371: [D loss: 0.709943, acc: 0.517578]  [A loss: 0.934059, acc: 0.101562]\n",
            "8372: [D loss: 0.701314, acc: 0.529297]  [A loss: 0.703805, acc: 0.457031]\n",
            "8373: [D loss: 0.711911, acc: 0.500000]  [A loss: 0.964738, acc: 0.128906]\n",
            "8374: [D loss: 0.691056, acc: 0.515625]  [A loss: 0.676799, acc: 0.554688]\n",
            "8375: [D loss: 0.723952, acc: 0.501953]  [A loss: 0.877460, acc: 0.144531]\n",
            "8376: [D loss: 0.696286, acc: 0.492188]  [A loss: 0.745585, acc: 0.386719]\n",
            "8377: [D loss: 0.697472, acc: 0.533203]  [A loss: 0.836541, acc: 0.148438]\n",
            "8378: [D loss: 0.698974, acc: 0.523438]  [A loss: 0.846611, acc: 0.164062]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8379: [D loss: 0.702118, acc: 0.533203]  [A loss: 0.752649, acc: 0.328125]\n",
            "8380: [D loss: 0.693035, acc: 0.554688]  [A loss: 0.825566, acc: 0.218750]\n",
            "8381: [D loss: 0.700118, acc: 0.531250]  [A loss: 0.810708, acc: 0.234375]\n",
            "8382: [D loss: 0.684212, acc: 0.548828]  [A loss: 0.827186, acc: 0.226562]\n",
            "8383: [D loss: 0.693263, acc: 0.539062]  [A loss: 0.770158, acc: 0.371094]\n",
            "8384: [D loss: 0.698260, acc: 0.531250]  [A loss: 0.866708, acc: 0.167969]\n",
            "8385: [D loss: 0.701107, acc: 0.501953]  [A loss: 0.831958, acc: 0.226562]\n",
            "8386: [D loss: 0.700438, acc: 0.511719]  [A loss: 0.800417, acc: 0.257812]\n",
            "8387: [D loss: 0.706427, acc: 0.490234]  [A loss: 0.824729, acc: 0.222656]\n",
            "8388: [D loss: 0.713034, acc: 0.496094]  [A loss: 0.743181, acc: 0.410156]\n",
            "8389: [D loss: 0.714032, acc: 0.480469]  [A loss: 0.918901, acc: 0.109375]\n",
            "8390: [D loss: 0.698560, acc: 0.521484]  [A loss: 0.671500, acc: 0.589844]\n",
            "8391: [D loss: 0.707134, acc: 0.498047]  [A loss: 0.824666, acc: 0.179688]\n",
            "8392: [D loss: 0.707012, acc: 0.494141]  [A loss: 0.834102, acc: 0.203125]\n",
            "8393: [D loss: 0.694105, acc: 0.544922]  [A loss: 0.892738, acc: 0.125000]\n",
            "8394: [D loss: 0.705510, acc: 0.517578]  [A loss: 0.714753, acc: 0.492188]\n",
            "8395: [D loss: 0.705762, acc: 0.533203]  [A loss: 0.890826, acc: 0.117188]\n",
            "8396: [D loss: 0.703861, acc: 0.509766]  [A loss: 0.738186, acc: 0.425781]\n",
            "8397: [D loss: 0.706662, acc: 0.500000]  [A loss: 0.875223, acc: 0.175781]\n",
            "8398: [D loss: 0.696864, acc: 0.517578]  [A loss: 0.739784, acc: 0.417969]\n",
            "8399: [D loss: 0.712961, acc: 0.484375]  [A loss: 0.871175, acc: 0.195312]\n",
            "8400: [D loss: 0.689255, acc: 0.527344]  [A loss: 0.731586, acc: 0.449219]\n",
            "8401: [D loss: 0.708859, acc: 0.503906]  [A loss: 0.860023, acc: 0.203125]\n",
            "8402: [D loss: 0.695330, acc: 0.517578]  [A loss: 0.787911, acc: 0.324219]\n",
            "8403: [D loss: 0.706097, acc: 0.501953]  [A loss: 0.880811, acc: 0.179688]\n",
            "8404: [D loss: 0.693182, acc: 0.537109]  [A loss: 0.809301, acc: 0.234375]\n",
            "8405: [D loss: 0.691252, acc: 0.535156]  [A loss: 0.833591, acc: 0.183594]\n",
            "8406: [D loss: 0.700423, acc: 0.498047]  [A loss: 0.779872, acc: 0.332031]\n",
            "8407: [D loss: 0.695295, acc: 0.519531]  [A loss: 0.878306, acc: 0.144531]\n",
            "8408: [D loss: 0.701245, acc: 0.509766]  [A loss: 0.731571, acc: 0.417969]\n",
            "8409: [D loss: 0.713866, acc: 0.509766]  [A loss: 0.961079, acc: 0.093750]\n",
            "8410: [D loss: 0.707492, acc: 0.505859]  [A loss: 0.695879, acc: 0.542969]\n",
            "8411: [D loss: 0.696616, acc: 0.539062]  [A loss: 0.890756, acc: 0.210938]\n",
            "8412: [D loss: 0.697446, acc: 0.517578]  [A loss: 0.795617, acc: 0.273438]\n",
            "8413: [D loss: 0.701041, acc: 0.527344]  [A loss: 0.869519, acc: 0.187500]\n",
            "8414: [D loss: 0.699712, acc: 0.505859]  [A loss: 0.728944, acc: 0.437500]\n",
            "8415: [D loss: 0.705587, acc: 0.523438]  [A loss: 0.946220, acc: 0.082031]\n",
            "8416: [D loss: 0.707304, acc: 0.494141]  [A loss: 0.693731, acc: 0.507812]\n",
            "8417: [D loss: 0.709601, acc: 0.521484]  [A loss: 0.881782, acc: 0.144531]\n",
            "8418: [D loss: 0.693615, acc: 0.509766]  [A loss: 0.764979, acc: 0.375000]\n",
            "8419: [D loss: 0.709791, acc: 0.523438]  [A loss: 0.853922, acc: 0.250000]\n",
            "8420: [D loss: 0.703005, acc: 0.492188]  [A loss: 0.800191, acc: 0.261719]\n",
            "8421: [D loss: 0.694914, acc: 0.537109]  [A loss: 0.835452, acc: 0.199219]\n",
            "8422: [D loss: 0.712590, acc: 0.501953]  [A loss: 0.725369, acc: 0.421875]\n",
            "8423: [D loss: 0.703124, acc: 0.519531]  [A loss: 0.907645, acc: 0.132812]\n",
            "8424: [D loss: 0.703785, acc: 0.498047]  [A loss: 0.726162, acc: 0.484375]\n",
            "8425: [D loss: 0.712874, acc: 0.527344]  [A loss: 0.907423, acc: 0.093750]\n",
            "8426: [D loss: 0.706274, acc: 0.482422]  [A loss: 0.684125, acc: 0.542969]\n",
            "8427: [D loss: 0.704129, acc: 0.535156]  [A loss: 0.881079, acc: 0.160156]\n",
            "8428: [D loss: 0.684301, acc: 0.576172]  [A loss: 0.711316, acc: 0.472656]\n",
            "8429: [D loss: 0.718470, acc: 0.494141]  [A loss: 0.889497, acc: 0.144531]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8430: [D loss: 0.706064, acc: 0.509766]  [A loss: 0.737562, acc: 0.390625]\n",
            "8431: [D loss: 0.714874, acc: 0.486328]  [A loss: 0.844602, acc: 0.210938]\n",
            "8432: [D loss: 0.712012, acc: 0.466797]  [A loss: 0.741908, acc: 0.421875]\n",
            "8433: [D loss: 0.698237, acc: 0.527344]  [A loss: 0.856914, acc: 0.160156]\n",
            "8434: [D loss: 0.699312, acc: 0.488281]  [A loss: 0.732903, acc: 0.394531]\n",
            "8435: [D loss: 0.697560, acc: 0.527344]  [A loss: 0.861511, acc: 0.136719]\n",
            "8436: [D loss: 0.697790, acc: 0.517578]  [A loss: 0.768948, acc: 0.269531]\n",
            "8437: [D loss: 0.698283, acc: 0.521484]  [A loss: 0.893219, acc: 0.136719]\n",
            "8438: [D loss: 0.706394, acc: 0.492188]  [A loss: 0.719266, acc: 0.425781]\n",
            "8439: [D loss: 0.716383, acc: 0.515625]  [A loss: 0.849279, acc: 0.183594]\n",
            "8440: [D loss: 0.687947, acc: 0.535156]  [A loss: 0.736793, acc: 0.398438]\n",
            "8441: [D loss: 0.704797, acc: 0.523438]  [A loss: 0.943874, acc: 0.082031]\n",
            "8442: [D loss: 0.700751, acc: 0.531250]  [A loss: 0.737601, acc: 0.414062]\n",
            "8443: [D loss: 0.715026, acc: 0.480469]  [A loss: 0.884378, acc: 0.152344]\n",
            "8444: [D loss: 0.703132, acc: 0.490234]  [A loss: 0.749530, acc: 0.359375]\n",
            "8445: [D loss: 0.702132, acc: 0.488281]  [A loss: 0.893223, acc: 0.144531]\n",
            "8446: [D loss: 0.693929, acc: 0.509766]  [A loss: 0.787995, acc: 0.320312]\n",
            "8447: [D loss: 0.715254, acc: 0.498047]  [A loss: 0.924278, acc: 0.125000]\n",
            "8448: [D loss: 0.691960, acc: 0.541016]  [A loss: 0.724714, acc: 0.441406]\n",
            "8449: [D loss: 0.702263, acc: 0.515625]  [A loss: 0.968259, acc: 0.070312]\n",
            "8450: [D loss: 0.709282, acc: 0.509766]  [A loss: 0.667163, acc: 0.566406]\n",
            "8451: [D loss: 0.728010, acc: 0.501953]  [A loss: 0.960152, acc: 0.054688]\n",
            "8452: [D loss: 0.700978, acc: 0.505859]  [A loss: 0.680726, acc: 0.542969]\n",
            "8453: [D loss: 0.711715, acc: 0.517578]  [A loss: 0.886633, acc: 0.140625]\n",
            "8454: [D loss: 0.700795, acc: 0.542969]  [A loss: 0.775263, acc: 0.328125]\n",
            "8455: [D loss: 0.701743, acc: 0.531250]  [A loss: 0.795237, acc: 0.242188]\n",
            "8456: [D loss: 0.705579, acc: 0.501953]  [A loss: 0.787519, acc: 0.277344]\n",
            "8457: [D loss: 0.702002, acc: 0.507812]  [A loss: 0.834146, acc: 0.218750]\n",
            "8458: [D loss: 0.705901, acc: 0.494141]  [A loss: 0.751023, acc: 0.332031]\n",
            "8459: [D loss: 0.706309, acc: 0.529297]  [A loss: 0.875055, acc: 0.140625]\n",
            "8460: [D loss: 0.691257, acc: 0.542969]  [A loss: 0.702893, acc: 0.507812]\n",
            "8461: [D loss: 0.712981, acc: 0.521484]  [A loss: 0.909456, acc: 0.109375]\n",
            "8462: [D loss: 0.682315, acc: 0.589844]  [A loss: 0.712995, acc: 0.476562]\n",
            "8463: [D loss: 0.705764, acc: 0.492188]  [A loss: 0.951339, acc: 0.066406]\n",
            "8464: [D loss: 0.692874, acc: 0.523438]  [A loss: 0.713358, acc: 0.449219]\n",
            "8465: [D loss: 0.716863, acc: 0.509766]  [A loss: 0.847261, acc: 0.195312]\n",
            "8466: [D loss: 0.704058, acc: 0.490234]  [A loss: 0.756426, acc: 0.355469]\n",
            "8467: [D loss: 0.701509, acc: 0.544922]  [A loss: 0.848279, acc: 0.171875]\n",
            "8468: [D loss: 0.697423, acc: 0.525391]  [A loss: 0.747482, acc: 0.351562]\n",
            "8469: [D loss: 0.707083, acc: 0.488281]  [A loss: 0.760664, acc: 0.351562]\n",
            "8470: [D loss: 0.695834, acc: 0.501953]  [A loss: 0.819623, acc: 0.207031]\n",
            "8471: [D loss: 0.701813, acc: 0.525391]  [A loss: 0.782236, acc: 0.300781]\n",
            "8472: [D loss: 0.700387, acc: 0.531250]  [A loss: 0.851984, acc: 0.226562]\n",
            "8473: [D loss: 0.696744, acc: 0.500000]  [A loss: 0.768271, acc: 0.324219]\n",
            "8474: [D loss: 0.713342, acc: 0.513672]  [A loss: 0.872852, acc: 0.164062]\n",
            "8475: [D loss: 0.704025, acc: 0.513672]  [A loss: 0.709973, acc: 0.480469]\n",
            "8476: [D loss: 0.704463, acc: 0.507812]  [A loss: 0.851100, acc: 0.195312]\n",
            "8477: [D loss: 0.713571, acc: 0.490234]  [A loss: 0.757819, acc: 0.355469]\n",
            "8478: [D loss: 0.703464, acc: 0.523438]  [A loss: 0.856633, acc: 0.175781]\n",
            "8479: [D loss: 0.701394, acc: 0.533203]  [A loss: 0.773645, acc: 0.300781]\n",
            "8480: [D loss: 0.687627, acc: 0.554688]  [A loss: 0.801883, acc: 0.285156]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8481: [D loss: 0.694425, acc: 0.539062]  [A loss: 0.792814, acc: 0.269531]\n",
            "8482: [D loss: 0.698834, acc: 0.511719]  [A loss: 0.863519, acc: 0.222656]\n",
            "8483: [D loss: 0.699196, acc: 0.523438]  [A loss: 0.726257, acc: 0.433594]\n",
            "8484: [D loss: 0.702366, acc: 0.517578]  [A loss: 0.916168, acc: 0.109375]\n",
            "8485: [D loss: 0.704819, acc: 0.490234]  [A loss: 0.773273, acc: 0.343750]\n",
            "8486: [D loss: 0.698976, acc: 0.529297]  [A loss: 0.829640, acc: 0.207031]\n",
            "8487: [D loss: 0.692969, acc: 0.527344]  [A loss: 0.810635, acc: 0.257812]\n",
            "8488: [D loss: 0.707211, acc: 0.505859]  [A loss: 0.841294, acc: 0.175781]\n",
            "8489: [D loss: 0.705004, acc: 0.505859]  [A loss: 0.733137, acc: 0.386719]\n",
            "8490: [D loss: 0.709465, acc: 0.509766]  [A loss: 0.947507, acc: 0.066406]\n",
            "8491: [D loss: 0.696896, acc: 0.521484]  [A loss: 0.630359, acc: 0.664062]\n",
            "8492: [D loss: 0.726331, acc: 0.494141]  [A loss: 0.954713, acc: 0.082031]\n",
            "8493: [D loss: 0.710599, acc: 0.486328]  [A loss: 0.681122, acc: 0.558594]\n",
            "8494: [D loss: 0.709572, acc: 0.513672]  [A loss: 0.833153, acc: 0.175781]\n",
            "8495: [D loss: 0.692047, acc: 0.523438]  [A loss: 0.737486, acc: 0.402344]\n",
            "8496: [D loss: 0.714667, acc: 0.496094]  [A loss: 0.867752, acc: 0.125000]\n",
            "8497: [D loss: 0.704918, acc: 0.468750]  [A loss: 0.704205, acc: 0.457031]\n",
            "8498: [D loss: 0.710203, acc: 0.486328]  [A loss: 0.889174, acc: 0.171875]\n",
            "8499: [D loss: 0.692424, acc: 0.513672]  [A loss: 0.708359, acc: 0.468750]\n",
            "8500: [D loss: 0.700859, acc: 0.531250]  [A loss: 0.834110, acc: 0.199219]\n",
            "8501: [D loss: 0.699733, acc: 0.505859]  [A loss: 0.825536, acc: 0.222656]\n",
            "8502: [D loss: 0.699249, acc: 0.525391]  [A loss: 0.832473, acc: 0.234375]\n",
            "8503: [D loss: 0.697904, acc: 0.539062]  [A loss: 0.763392, acc: 0.351562]\n",
            "8504: [D loss: 0.701653, acc: 0.507812]  [A loss: 0.822595, acc: 0.226562]\n",
            "8505: [D loss: 0.699531, acc: 0.507812]  [A loss: 0.788433, acc: 0.273438]\n",
            "8506: [D loss: 0.718139, acc: 0.484375]  [A loss: 0.823816, acc: 0.214844]\n",
            "8507: [D loss: 0.686542, acc: 0.554688]  [A loss: 0.759605, acc: 0.375000]\n",
            "8508: [D loss: 0.708953, acc: 0.484375]  [A loss: 0.810076, acc: 0.250000]\n",
            "8509: [D loss: 0.694135, acc: 0.537109]  [A loss: 0.829576, acc: 0.242188]\n",
            "8510: [D loss: 0.679419, acc: 0.578125]  [A loss: 0.750413, acc: 0.398438]\n",
            "8511: [D loss: 0.706720, acc: 0.529297]  [A loss: 0.853857, acc: 0.167969]\n",
            "8512: [D loss: 0.700280, acc: 0.507812]  [A loss: 0.759454, acc: 0.339844]\n",
            "8513: [D loss: 0.705083, acc: 0.503906]  [A loss: 0.843856, acc: 0.210938]\n",
            "8514: [D loss: 0.701770, acc: 0.488281]  [A loss: 0.885733, acc: 0.214844]\n",
            "8515: [D loss: 0.711947, acc: 0.464844]  [A loss: 0.828091, acc: 0.199219]\n",
            "8516: [D loss: 0.698507, acc: 0.521484]  [A loss: 0.838209, acc: 0.207031]\n",
            "8517: [D loss: 0.713050, acc: 0.507812]  [A loss: 0.749768, acc: 0.359375]\n",
            "8518: [D loss: 0.704434, acc: 0.535156]  [A loss: 0.915072, acc: 0.125000]\n",
            "8519: [D loss: 0.699058, acc: 0.513672]  [A loss: 0.749799, acc: 0.386719]\n",
            "8520: [D loss: 0.718127, acc: 0.488281]  [A loss: 0.986094, acc: 0.058594]\n",
            "8521: [D loss: 0.705119, acc: 0.517578]  [A loss: 0.634913, acc: 0.703125]\n",
            "8522: [D loss: 0.736446, acc: 0.482422]  [A loss: 0.955018, acc: 0.042969]\n",
            "8523: [D loss: 0.709038, acc: 0.466797]  [A loss: 0.690726, acc: 0.550781]\n",
            "8524: [D loss: 0.711443, acc: 0.517578]  [A loss: 0.840666, acc: 0.183594]\n",
            "8525: [D loss: 0.696983, acc: 0.519531]  [A loss: 0.757024, acc: 0.367188]\n",
            "8526: [D loss: 0.708140, acc: 0.525391]  [A loss: 0.841318, acc: 0.300781]\n",
            "8527: [D loss: 0.705889, acc: 0.531250]  [A loss: 0.894574, acc: 0.140625]\n",
            "8528: [D loss: 0.700849, acc: 0.490234]  [A loss: 0.755017, acc: 0.363281]\n",
            "8529: [D loss: 0.711776, acc: 0.476562]  [A loss: 0.892518, acc: 0.132812]\n",
            "8530: [D loss: 0.716565, acc: 0.451172]  [A loss: 0.717554, acc: 0.453125]\n",
            "8531: [D loss: 0.716675, acc: 0.505859]  [A loss: 0.914340, acc: 0.089844]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8532: [D loss: 0.705017, acc: 0.509766]  [A loss: 0.760548, acc: 0.328125]\n",
            "8533: [D loss: 0.717128, acc: 0.484375]  [A loss: 0.866583, acc: 0.148438]\n",
            "8534: [D loss: 0.696160, acc: 0.542969]  [A loss: 0.703031, acc: 0.535156]\n",
            "8535: [D loss: 0.711165, acc: 0.501953]  [A loss: 0.870567, acc: 0.156250]\n",
            "8536: [D loss: 0.712392, acc: 0.470703]  [A loss: 0.705159, acc: 0.507812]\n",
            "8537: [D loss: 0.699568, acc: 0.546875]  [A loss: 0.820876, acc: 0.238281]\n",
            "8538: [D loss: 0.687514, acc: 0.542969]  [A loss: 0.771656, acc: 0.316406]\n",
            "8539: [D loss: 0.698672, acc: 0.507812]  [A loss: 0.836716, acc: 0.207031]\n",
            "8540: [D loss: 0.687199, acc: 0.554688]  [A loss: 0.828098, acc: 0.226562]\n",
            "8541: [D loss: 0.703345, acc: 0.507812]  [A loss: 0.800474, acc: 0.312500]\n",
            "8542: [D loss: 0.696179, acc: 0.539062]  [A loss: 0.841874, acc: 0.218750]\n",
            "8543: [D loss: 0.701085, acc: 0.509766]  [A loss: 0.767708, acc: 0.304688]\n",
            "8544: [D loss: 0.707563, acc: 0.501953]  [A loss: 0.857924, acc: 0.203125]\n",
            "8545: [D loss: 0.698696, acc: 0.541016]  [A loss: 0.732029, acc: 0.433594]\n",
            "8546: [D loss: 0.713759, acc: 0.501953]  [A loss: 0.891145, acc: 0.140625]\n",
            "8547: [D loss: 0.691680, acc: 0.539062]  [A loss: 0.706957, acc: 0.535156]\n",
            "8548: [D loss: 0.707353, acc: 0.531250]  [A loss: 0.871160, acc: 0.160156]\n",
            "8549: [D loss: 0.695791, acc: 0.523438]  [A loss: 0.735278, acc: 0.390625]\n",
            "8550: [D loss: 0.699007, acc: 0.527344]  [A loss: 0.836228, acc: 0.214844]\n",
            "8551: [D loss: 0.701633, acc: 0.515625]  [A loss: 0.716260, acc: 0.468750]\n",
            "8552: [D loss: 0.692358, acc: 0.542969]  [A loss: 0.859924, acc: 0.160156]\n",
            "8553: [D loss: 0.704659, acc: 0.533203]  [A loss: 0.753383, acc: 0.386719]\n",
            "8554: [D loss: 0.699039, acc: 0.496094]  [A loss: 0.840737, acc: 0.195312]\n",
            "8555: [D loss: 0.703687, acc: 0.503906]  [A loss: 0.719926, acc: 0.468750]\n",
            "8556: [D loss: 0.712162, acc: 0.480469]  [A loss: 0.860312, acc: 0.152344]\n",
            "8557: [D loss: 0.711468, acc: 0.482422]  [A loss: 0.839768, acc: 0.222656]\n",
            "8558: [D loss: 0.711617, acc: 0.484375]  [A loss: 0.844628, acc: 0.214844]\n",
            "8559: [D loss: 0.696662, acc: 0.529297]  [A loss: 0.792965, acc: 0.257812]\n",
            "8560: [D loss: 0.703388, acc: 0.544922]  [A loss: 0.807714, acc: 0.218750]\n",
            "8561: [D loss: 0.704986, acc: 0.527344]  [A loss: 0.780697, acc: 0.304688]\n",
            "8562: [D loss: 0.711746, acc: 0.486328]  [A loss: 0.864040, acc: 0.167969]\n",
            "8563: [D loss: 0.705251, acc: 0.482422]  [A loss: 0.732137, acc: 0.445312]\n",
            "8564: [D loss: 0.714140, acc: 0.511719]  [A loss: 0.919975, acc: 0.082031]\n",
            "8565: [D loss: 0.689444, acc: 0.523438]  [A loss: 0.709621, acc: 0.480469]\n",
            "8566: [D loss: 0.710927, acc: 0.509766]  [A loss: 1.005411, acc: 0.070312]\n",
            "8567: [D loss: 0.705853, acc: 0.519531]  [A loss: 0.657928, acc: 0.593750]\n",
            "8568: [D loss: 0.723540, acc: 0.500000]  [A loss: 0.913596, acc: 0.113281]\n",
            "8569: [D loss: 0.700844, acc: 0.529297]  [A loss: 0.770187, acc: 0.363281]\n",
            "8570: [D loss: 0.704639, acc: 0.505859]  [A loss: 0.867203, acc: 0.148438]\n",
            "8571: [D loss: 0.699988, acc: 0.501953]  [A loss: 0.751657, acc: 0.375000]\n",
            "8572: [D loss: 0.716062, acc: 0.490234]  [A loss: 0.898448, acc: 0.097656]\n",
            "8573: [D loss: 0.698773, acc: 0.525391]  [A loss: 0.746941, acc: 0.382812]\n",
            "8574: [D loss: 0.724292, acc: 0.455078]  [A loss: 0.846326, acc: 0.218750]\n",
            "8575: [D loss: 0.697897, acc: 0.529297]  [A loss: 0.780090, acc: 0.324219]\n",
            "8576: [D loss: 0.713361, acc: 0.509766]  [A loss: 0.877095, acc: 0.152344]\n",
            "8577: [D loss: 0.701506, acc: 0.494141]  [A loss: 0.742420, acc: 0.355469]\n",
            "8578: [D loss: 0.695160, acc: 0.525391]  [A loss: 0.877541, acc: 0.183594]\n",
            "8579: [D loss: 0.708977, acc: 0.492188]  [A loss: 0.755157, acc: 0.375000]\n",
            "8580: [D loss: 0.708099, acc: 0.503906]  [A loss: 0.850300, acc: 0.226562]\n",
            "8581: [D loss: 0.709894, acc: 0.496094]  [A loss: 0.779538, acc: 0.312500]\n",
            "8582: [D loss: 0.705345, acc: 0.507812]  [A loss: 0.829163, acc: 0.203125]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8583: [D loss: 0.705292, acc: 0.505859]  [A loss: 0.765796, acc: 0.332031]\n",
            "8584: [D loss: 0.702797, acc: 0.490234]  [A loss: 0.857419, acc: 0.152344]\n",
            "8585: [D loss: 0.699397, acc: 0.501953]  [A loss: 0.700137, acc: 0.519531]\n",
            "8586: [D loss: 0.711882, acc: 0.515625]  [A loss: 0.916519, acc: 0.113281]\n",
            "8587: [D loss: 0.692728, acc: 0.546875]  [A loss: 0.706701, acc: 0.503906]\n",
            "8588: [D loss: 0.719653, acc: 0.492188]  [A loss: 0.963077, acc: 0.050781]\n",
            "8589: [D loss: 0.706638, acc: 0.527344]  [A loss: 0.686907, acc: 0.531250]\n",
            "8590: [D loss: 0.689927, acc: 0.503906]  [A loss: 0.862554, acc: 0.175781]\n",
            "8591: [D loss: 0.707283, acc: 0.505859]  [A loss: 0.757647, acc: 0.343750]\n",
            "8592: [D loss: 0.708682, acc: 0.503906]  [A loss: 0.845422, acc: 0.175781]\n",
            "8593: [D loss: 0.698320, acc: 0.498047]  [A loss: 0.778685, acc: 0.316406]\n",
            "8594: [D loss: 0.698717, acc: 0.523438]  [A loss: 0.828640, acc: 0.226562]\n",
            "8595: [D loss: 0.690539, acc: 0.517578]  [A loss: 0.766269, acc: 0.390625]\n",
            "8596: [D loss: 0.697675, acc: 0.507812]  [A loss: 0.878519, acc: 0.187500]\n",
            "8597: [D loss: 0.707652, acc: 0.490234]  [A loss: 0.800996, acc: 0.281250]\n",
            "8598: [D loss: 0.694048, acc: 0.519531]  [A loss: 0.833668, acc: 0.218750]\n",
            "8599: [D loss: 0.707730, acc: 0.517578]  [A loss: 0.849661, acc: 0.160156]\n",
            "8600: [D loss: 0.716818, acc: 0.474609]  [A loss: 0.784633, acc: 0.281250]\n",
            "8601: [D loss: 0.705151, acc: 0.503906]  [A loss: 0.852398, acc: 0.203125]\n",
            "8602: [D loss: 0.680762, acc: 0.546875]  [A loss: 0.749433, acc: 0.347656]\n",
            "8603: [D loss: 0.715744, acc: 0.492188]  [A loss: 0.896908, acc: 0.128906]\n",
            "8604: [D loss: 0.701270, acc: 0.521484]  [A loss: 0.677994, acc: 0.558594]\n",
            "8605: [D loss: 0.722967, acc: 0.503906]  [A loss: 0.984657, acc: 0.085938]\n",
            "8606: [D loss: 0.702322, acc: 0.505859]  [A loss: 0.692789, acc: 0.531250]\n",
            "8607: [D loss: 0.725360, acc: 0.484375]  [A loss: 0.902291, acc: 0.171875]\n",
            "8608: [D loss: 0.694558, acc: 0.541016]  [A loss: 0.767808, acc: 0.363281]\n",
            "8609: [D loss: 0.701536, acc: 0.525391]  [A loss: 0.829340, acc: 0.234375]\n",
            "8610: [D loss: 0.691469, acc: 0.539062]  [A loss: 0.713486, acc: 0.472656]\n",
            "8611: [D loss: 0.706283, acc: 0.525391]  [A loss: 0.872145, acc: 0.136719]\n",
            "8612: [D loss: 0.700884, acc: 0.521484]  [A loss: 0.767202, acc: 0.355469]\n",
            "8613: [D loss: 0.706581, acc: 0.484375]  [A loss: 0.901817, acc: 0.121094]\n",
            "8614: [D loss: 0.686777, acc: 0.548828]  [A loss: 0.672908, acc: 0.574219]\n",
            "8615: [D loss: 0.726398, acc: 0.505859]  [A loss: 0.959085, acc: 0.074219]\n",
            "8616: [D loss: 0.698312, acc: 0.501953]  [A loss: 0.758161, acc: 0.382812]\n",
            "8617: [D loss: 0.699688, acc: 0.515625]  [A loss: 0.791903, acc: 0.285156]\n",
            "8618: [D loss: 0.688878, acc: 0.564453]  [A loss: 0.755615, acc: 0.367188]\n",
            "8619: [D loss: 0.710655, acc: 0.515625]  [A loss: 0.773144, acc: 0.343750]\n",
            "8620: [D loss: 0.708886, acc: 0.494141]  [A loss: 0.748024, acc: 0.394531]\n",
            "8621: [D loss: 0.704902, acc: 0.505859]  [A loss: 0.791443, acc: 0.296875]\n",
            "8622: [D loss: 0.694304, acc: 0.527344]  [A loss: 0.826604, acc: 0.214844]\n",
            "8623: [D loss: 0.708915, acc: 0.529297]  [A loss: 0.796664, acc: 0.265625]\n",
            "8624: [D loss: 0.702962, acc: 0.494141]  [A loss: 0.806343, acc: 0.277344]\n",
            "8625: [D loss: 0.700567, acc: 0.533203]  [A loss: 0.770740, acc: 0.402344]\n",
            "8626: [D loss: 0.716388, acc: 0.494141]  [A loss: 0.906112, acc: 0.109375]\n",
            "8627: [D loss: 0.678039, acc: 0.580078]  [A loss: 0.722944, acc: 0.445312]\n",
            "8628: [D loss: 0.721967, acc: 0.458984]  [A loss: 0.874551, acc: 0.148438]\n",
            "8629: [D loss: 0.692488, acc: 0.533203]  [A loss: 0.768426, acc: 0.308594]\n",
            "8630: [D loss: 0.694359, acc: 0.527344]  [A loss: 0.830569, acc: 0.214844]\n",
            "8631: [D loss: 0.716192, acc: 0.501953]  [A loss: 0.788738, acc: 0.285156]\n",
            "8632: [D loss: 0.693991, acc: 0.503906]  [A loss: 0.781151, acc: 0.281250]\n",
            "8633: [D loss: 0.701916, acc: 0.521484]  [A loss: 0.855300, acc: 0.160156]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8634: [D loss: 0.716550, acc: 0.476562]  [A loss: 0.794149, acc: 0.269531]\n",
            "8635: [D loss: 0.703646, acc: 0.535156]  [A loss: 0.836148, acc: 0.238281]\n",
            "8636: [D loss: 0.699147, acc: 0.511719]  [A loss: 0.810416, acc: 0.257812]\n",
            "8637: [D loss: 0.706565, acc: 0.494141]  [A loss: 0.768888, acc: 0.347656]\n",
            "8638: [D loss: 0.711923, acc: 0.484375]  [A loss: 0.883607, acc: 0.132812]\n",
            "8639: [D loss: 0.699079, acc: 0.515625]  [A loss: 0.775853, acc: 0.367188]\n",
            "8640: [D loss: 0.708317, acc: 0.517578]  [A loss: 0.950917, acc: 0.136719]\n",
            "8641: [D loss: 0.698569, acc: 0.537109]  [A loss: 0.710193, acc: 0.457031]\n",
            "8642: [D loss: 0.721485, acc: 0.517578]  [A loss: 0.910888, acc: 0.082031]\n",
            "8643: [D loss: 0.704132, acc: 0.505859]  [A loss: 0.777090, acc: 0.324219]\n",
            "8644: [D loss: 0.709262, acc: 0.492188]  [A loss: 0.938845, acc: 0.097656]\n",
            "8645: [D loss: 0.717011, acc: 0.466797]  [A loss: 0.670854, acc: 0.562500]\n",
            "8646: [D loss: 0.716887, acc: 0.515625]  [A loss: 0.956598, acc: 0.082031]\n",
            "8647: [D loss: 0.718892, acc: 0.480469]  [A loss: 0.655121, acc: 0.593750]\n",
            "8648: [D loss: 0.713160, acc: 0.517578]  [A loss: 0.834430, acc: 0.199219]\n",
            "8649: [D loss: 0.702254, acc: 0.501953]  [A loss: 0.732919, acc: 0.414062]\n",
            "8650: [D loss: 0.699742, acc: 0.507812]  [A loss: 0.829203, acc: 0.195312]\n",
            "8651: [D loss: 0.704133, acc: 0.498047]  [A loss: 0.774154, acc: 0.351562]\n",
            "8652: [D loss: 0.696629, acc: 0.533203]  [A loss: 0.849265, acc: 0.214844]\n",
            "8653: [D loss: 0.704475, acc: 0.515625]  [A loss: 0.790692, acc: 0.324219]\n",
            "8654: [D loss: 0.705878, acc: 0.498047]  [A loss: 0.830690, acc: 0.210938]\n",
            "8655: [D loss: 0.703150, acc: 0.515625]  [A loss: 0.824239, acc: 0.238281]\n",
            "8656: [D loss: 0.696348, acc: 0.513672]  [A loss: 0.787781, acc: 0.285156]\n",
            "8657: [D loss: 0.698455, acc: 0.513672]  [A loss: 0.755171, acc: 0.421875]\n",
            "8658: [D loss: 0.704215, acc: 0.505859]  [A loss: 0.870274, acc: 0.167969]\n",
            "8659: [D loss: 0.694542, acc: 0.533203]  [A loss: 0.728909, acc: 0.460938]\n",
            "8660: [D loss: 0.703186, acc: 0.498047]  [A loss: 0.861898, acc: 0.187500]\n",
            "8661: [D loss: 0.692464, acc: 0.535156]  [A loss: 0.754944, acc: 0.371094]\n",
            "8662: [D loss: 0.712620, acc: 0.501953]  [A loss: 0.924904, acc: 0.054688]\n",
            "8663: [D loss: 0.693723, acc: 0.505859]  [A loss: 0.721959, acc: 0.472656]\n",
            "8664: [D loss: 0.712553, acc: 0.505859]  [A loss: 0.876471, acc: 0.140625]\n",
            "8665: [D loss: 0.706231, acc: 0.492188]  [A loss: 0.696665, acc: 0.527344]\n",
            "8666: [D loss: 0.726063, acc: 0.498047]  [A loss: 0.907525, acc: 0.097656]\n",
            "8667: [D loss: 0.697151, acc: 0.507812]  [A loss: 0.705701, acc: 0.460938]\n",
            "8668: [D loss: 0.718659, acc: 0.492188]  [A loss: 0.879155, acc: 0.121094]\n",
            "8669: [D loss: 0.702241, acc: 0.513672]  [A loss: 0.712481, acc: 0.476562]\n",
            "8670: [D loss: 0.705543, acc: 0.500000]  [A loss: 0.848932, acc: 0.175781]\n",
            "8671: [D loss: 0.689047, acc: 0.568359]  [A loss: 0.719178, acc: 0.441406]\n",
            "8672: [D loss: 0.704047, acc: 0.513672]  [A loss: 0.872054, acc: 0.187500]\n",
            "8673: [D loss: 0.699741, acc: 0.517578]  [A loss: 0.754143, acc: 0.386719]\n",
            "8674: [D loss: 0.703555, acc: 0.517578]  [A loss: 0.767812, acc: 0.343750]\n",
            "8675: [D loss: 0.698499, acc: 0.541016]  [A loss: 0.836825, acc: 0.187500]\n",
            "8676: [D loss: 0.698869, acc: 0.531250]  [A loss: 0.858772, acc: 0.167969]\n",
            "8677: [D loss: 0.688968, acc: 0.546875]  [A loss: 0.749711, acc: 0.347656]\n",
            "8678: [D loss: 0.696063, acc: 0.550781]  [A loss: 0.891325, acc: 0.109375]\n",
            "8679: [D loss: 0.699416, acc: 0.509766]  [A loss: 0.753821, acc: 0.375000]\n",
            "8680: [D loss: 0.719850, acc: 0.501953]  [A loss: 0.845667, acc: 0.203125]\n",
            "8681: [D loss: 0.710417, acc: 0.482422]  [A loss: 0.826855, acc: 0.253906]\n",
            "8682: [D loss: 0.698369, acc: 0.535156]  [A loss: 0.808864, acc: 0.222656]\n",
            "8683: [D loss: 0.695521, acc: 0.546875]  [A loss: 0.786446, acc: 0.292969]\n",
            "8684: [D loss: 0.689852, acc: 0.558594]  [A loss: 0.822859, acc: 0.218750]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8685: [D loss: 0.700342, acc: 0.494141]  [A loss: 0.867296, acc: 0.214844]\n",
            "8686: [D loss: 0.712086, acc: 0.468750]  [A loss: 0.731293, acc: 0.414062]\n",
            "8687: [D loss: 0.708120, acc: 0.507812]  [A loss: 0.881953, acc: 0.089844]\n",
            "8688: [D loss: 0.693443, acc: 0.537109]  [A loss: 0.716561, acc: 0.468750]\n",
            "8689: [D loss: 0.701576, acc: 0.525391]  [A loss: 0.846412, acc: 0.210938]\n",
            "8690: [D loss: 0.707692, acc: 0.480469]  [A loss: 0.766752, acc: 0.351562]\n",
            "8691: [D loss: 0.694363, acc: 0.539062]  [A loss: 0.845856, acc: 0.195312]\n",
            "8692: [D loss: 0.700366, acc: 0.503906]  [A loss: 0.771509, acc: 0.324219]\n",
            "8693: [D loss: 0.704660, acc: 0.492188]  [A loss: 0.873056, acc: 0.144531]\n",
            "8694: [D loss: 0.701469, acc: 0.527344]  [A loss: 0.746060, acc: 0.386719]\n",
            "8695: [D loss: 0.709005, acc: 0.509766]  [A loss: 0.925098, acc: 0.089844]\n",
            "8696: [D loss: 0.695612, acc: 0.523438]  [A loss: 0.710331, acc: 0.484375]\n",
            "8697: [D loss: 0.708315, acc: 0.513672]  [A loss: 0.928886, acc: 0.093750]\n",
            "8698: [D loss: 0.686517, acc: 0.539062]  [A loss: 0.796748, acc: 0.292969]\n",
            "8699: [D loss: 0.700070, acc: 0.529297]  [A loss: 0.808316, acc: 0.261719]\n",
            "8700: [D loss: 0.690464, acc: 0.550781]  [A loss: 0.761643, acc: 0.339844]\n",
            "8701: [D loss: 0.706917, acc: 0.503906]  [A loss: 0.829792, acc: 0.164062]\n",
            "8702: [D loss: 0.690183, acc: 0.546875]  [A loss: 0.778758, acc: 0.339844]\n",
            "8703: [D loss: 0.705665, acc: 0.517578]  [A loss: 0.874944, acc: 0.218750]\n",
            "8704: [D loss: 0.692497, acc: 0.537109]  [A loss: 0.773844, acc: 0.316406]\n",
            "8705: [D loss: 0.690981, acc: 0.539062]  [A loss: 0.842852, acc: 0.207031]\n",
            "8706: [D loss: 0.687646, acc: 0.550781]  [A loss: 0.694107, acc: 0.546875]\n",
            "8707: [D loss: 0.701184, acc: 0.523438]  [A loss: 0.982284, acc: 0.078125]\n",
            "8708: [D loss: 0.694509, acc: 0.521484]  [A loss: 0.657769, acc: 0.613281]\n",
            "8709: [D loss: 0.726404, acc: 0.501953]  [A loss: 0.939335, acc: 0.082031]\n",
            "8710: [D loss: 0.701942, acc: 0.523438]  [A loss: 0.701023, acc: 0.476562]\n",
            "8711: [D loss: 0.729113, acc: 0.505859]  [A loss: 0.834251, acc: 0.214844]\n",
            "8712: [D loss: 0.699459, acc: 0.507812]  [A loss: 0.755199, acc: 0.347656]\n",
            "8713: [D loss: 0.723512, acc: 0.492188]  [A loss: 0.839194, acc: 0.191406]\n",
            "8714: [D loss: 0.695666, acc: 0.550781]  [A loss: 0.717054, acc: 0.492188]\n",
            "8715: [D loss: 0.721878, acc: 0.503906]  [A loss: 0.866707, acc: 0.132812]\n",
            "8716: [D loss: 0.701594, acc: 0.509766]  [A loss: 0.822773, acc: 0.218750]\n",
            "8717: [D loss: 0.698707, acc: 0.525391]  [A loss: 0.779462, acc: 0.324219]\n",
            "8718: [D loss: 0.703170, acc: 0.521484]  [A loss: 0.844953, acc: 0.242188]\n",
            "8719: [D loss: 0.683209, acc: 0.570312]  [A loss: 0.725571, acc: 0.402344]\n",
            "8720: [D loss: 0.708875, acc: 0.521484]  [A loss: 0.846848, acc: 0.191406]\n",
            "8721: [D loss: 0.697436, acc: 0.513672]  [A loss: 0.767893, acc: 0.335938]\n",
            "8722: [D loss: 0.710948, acc: 0.486328]  [A loss: 0.892003, acc: 0.132812]\n",
            "8723: [D loss: 0.691566, acc: 0.562500]  [A loss: 0.718019, acc: 0.433594]\n",
            "8724: [D loss: 0.706857, acc: 0.521484]  [A loss: 0.923898, acc: 0.121094]\n",
            "8725: [D loss: 0.700533, acc: 0.537109]  [A loss: 0.735635, acc: 0.382812]\n",
            "8726: [D loss: 0.713778, acc: 0.494141]  [A loss: 0.926993, acc: 0.089844]\n",
            "8727: [D loss: 0.709579, acc: 0.488281]  [A loss: 0.705299, acc: 0.472656]\n",
            "8728: [D loss: 0.716535, acc: 0.513672]  [A loss: 0.771022, acc: 0.324219]\n",
            "8729: [D loss: 0.702263, acc: 0.511719]  [A loss: 0.786780, acc: 0.261719]\n",
            "8730: [D loss: 0.704824, acc: 0.519531]  [A loss: 0.855990, acc: 0.179688]\n",
            "8731: [D loss: 0.693742, acc: 0.537109]  [A loss: 0.778705, acc: 0.332031]\n",
            "8732: [D loss: 0.691032, acc: 0.529297]  [A loss: 0.831369, acc: 0.234375]\n",
            "8733: [D loss: 0.725561, acc: 0.474609]  [A loss: 0.743521, acc: 0.402344]\n",
            "8734: [D loss: 0.704836, acc: 0.517578]  [A loss: 0.781671, acc: 0.300781]\n",
            "8735: [D loss: 0.704822, acc: 0.490234]  [A loss: 0.784972, acc: 0.308594]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8736: [D loss: 0.712629, acc: 0.488281]  [A loss: 0.798763, acc: 0.265625]\n",
            "8737: [D loss: 0.694473, acc: 0.515625]  [A loss: 0.771749, acc: 0.296875]\n",
            "8738: [D loss: 0.685403, acc: 0.535156]  [A loss: 0.766099, acc: 0.363281]\n",
            "8739: [D loss: 0.695772, acc: 0.507812]  [A loss: 0.916794, acc: 0.128906]\n",
            "8740: [D loss: 0.705512, acc: 0.507812]  [A loss: 0.732597, acc: 0.417969]\n",
            "8741: [D loss: 0.715685, acc: 0.501953]  [A loss: 0.897497, acc: 0.121094]\n",
            "8742: [D loss: 0.702681, acc: 0.523438]  [A loss: 0.720501, acc: 0.468750]\n",
            "8743: [D loss: 0.713312, acc: 0.531250]  [A loss: 0.921426, acc: 0.054688]\n",
            "8744: [D loss: 0.691210, acc: 0.523438]  [A loss: 0.720858, acc: 0.453125]\n",
            "8745: [D loss: 0.730628, acc: 0.492188]  [A loss: 0.961950, acc: 0.101562]\n",
            "8746: [D loss: 0.691815, acc: 0.531250]  [A loss: 0.739394, acc: 0.453125]\n",
            "8747: [D loss: 0.714654, acc: 0.490234]  [A loss: 0.966117, acc: 0.085938]\n",
            "8748: [D loss: 0.696222, acc: 0.535156]  [A loss: 0.726611, acc: 0.417969]\n",
            "8749: [D loss: 0.715955, acc: 0.488281]  [A loss: 0.896140, acc: 0.179688]\n",
            "8750: [D loss: 0.692854, acc: 0.552734]  [A loss: 0.717931, acc: 0.496094]\n",
            "8751: [D loss: 0.703283, acc: 0.517578]  [A loss: 0.823342, acc: 0.238281]\n",
            "8752: [D loss: 0.705483, acc: 0.500000]  [A loss: 0.766569, acc: 0.343750]\n",
            "8753: [D loss: 0.703813, acc: 0.529297]  [A loss: 0.877160, acc: 0.167969]\n",
            "8754: [D loss: 0.692428, acc: 0.509766]  [A loss: 0.758555, acc: 0.320312]\n",
            "8755: [D loss: 0.716337, acc: 0.482422]  [A loss: 0.855215, acc: 0.121094]\n",
            "8756: [D loss: 0.701451, acc: 0.511719]  [A loss: 0.736077, acc: 0.402344]\n",
            "8757: [D loss: 0.693992, acc: 0.550781]  [A loss: 0.850283, acc: 0.183594]\n",
            "8758: [D loss: 0.704331, acc: 0.501953]  [A loss: 0.747110, acc: 0.339844]\n",
            "8759: [D loss: 0.713906, acc: 0.498047]  [A loss: 0.812373, acc: 0.210938]\n",
            "8760: [D loss: 0.702961, acc: 0.523438]  [A loss: 0.745573, acc: 0.375000]\n",
            "8761: [D loss: 0.700058, acc: 0.529297]  [A loss: 0.884636, acc: 0.164062]\n",
            "8762: [D loss: 0.696159, acc: 0.529297]  [A loss: 0.745830, acc: 0.390625]\n",
            "8763: [D loss: 0.702714, acc: 0.521484]  [A loss: 0.825281, acc: 0.242188]\n",
            "8764: [D loss: 0.698794, acc: 0.494141]  [A loss: 0.781393, acc: 0.250000]\n",
            "8765: [D loss: 0.713772, acc: 0.470703]  [A loss: 0.842720, acc: 0.203125]\n",
            "8766: [D loss: 0.698694, acc: 0.527344]  [A loss: 0.745844, acc: 0.386719]\n",
            "8767: [D loss: 0.704678, acc: 0.533203]  [A loss: 0.871247, acc: 0.132812]\n",
            "8768: [D loss: 0.690284, acc: 0.527344]  [A loss: 0.749929, acc: 0.406250]\n",
            "8769: [D loss: 0.710443, acc: 0.494141]  [A loss: 0.827017, acc: 0.234375]\n",
            "8770: [D loss: 0.699593, acc: 0.507812]  [A loss: 0.810982, acc: 0.250000]\n",
            "8771: [D loss: 0.711923, acc: 0.488281]  [A loss: 0.787957, acc: 0.308594]\n",
            "8772: [D loss: 0.711120, acc: 0.505859]  [A loss: 0.779869, acc: 0.347656]\n",
            "8773: [D loss: 0.711793, acc: 0.517578]  [A loss: 0.868530, acc: 0.136719]\n",
            "8774: [D loss: 0.691244, acc: 0.521484]  [A loss: 0.698380, acc: 0.507812]\n",
            "8775: [D loss: 0.720908, acc: 0.488281]  [A loss: 0.902641, acc: 0.128906]\n",
            "8776: [D loss: 0.689586, acc: 0.548828]  [A loss: 0.684579, acc: 0.550781]\n",
            "8777: [D loss: 0.725278, acc: 0.515625]  [A loss: 0.897195, acc: 0.125000]\n",
            "8778: [D loss: 0.698332, acc: 0.531250]  [A loss: 0.709964, acc: 0.488281]\n",
            "8779: [D loss: 0.713516, acc: 0.482422]  [A loss: 0.934050, acc: 0.062500]\n",
            "8780: [D loss: 0.701849, acc: 0.517578]  [A loss: 0.688093, acc: 0.546875]\n",
            "8781: [D loss: 0.722168, acc: 0.505859]  [A loss: 0.847902, acc: 0.195312]\n",
            "8782: [D loss: 0.695413, acc: 0.531250]  [A loss: 0.751086, acc: 0.355469]\n",
            "8783: [D loss: 0.709602, acc: 0.525391]  [A loss: 0.777698, acc: 0.296875]\n",
            "8784: [D loss: 0.704220, acc: 0.511719]  [A loss: 0.807313, acc: 0.210938]\n",
            "8785: [D loss: 0.700150, acc: 0.494141]  [A loss: 0.793540, acc: 0.312500]\n",
            "8786: [D loss: 0.702083, acc: 0.523438]  [A loss: 0.883159, acc: 0.136719]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8787: [D loss: 0.698388, acc: 0.548828]  [A loss: 0.796225, acc: 0.316406]\n",
            "8788: [D loss: 0.697007, acc: 0.513672]  [A loss: 0.813521, acc: 0.242188]\n",
            "8789: [D loss: 0.702535, acc: 0.523438]  [A loss: 0.827801, acc: 0.191406]\n",
            "8790: [D loss: 0.685194, acc: 0.537109]  [A loss: 0.762705, acc: 0.343750]\n",
            "8791: [D loss: 0.713195, acc: 0.492188]  [A loss: 0.902332, acc: 0.109375]\n",
            "8792: [D loss: 0.700617, acc: 0.503906]  [A loss: 0.690923, acc: 0.527344]\n",
            "8793: [D loss: 0.718742, acc: 0.509766]  [A loss: 0.856017, acc: 0.187500]\n",
            "8794: [D loss: 0.702673, acc: 0.513672]  [A loss: 0.798860, acc: 0.277344]\n",
            "8795: [D loss: 0.713133, acc: 0.501953]  [A loss: 0.947714, acc: 0.058594]\n",
            "8796: [D loss: 0.704749, acc: 0.474609]  [A loss: 0.736818, acc: 0.398438]\n",
            "8797: [D loss: 0.716538, acc: 0.519531]  [A loss: 0.954103, acc: 0.085938]\n",
            "8798: [D loss: 0.710661, acc: 0.490234]  [A loss: 0.689269, acc: 0.539062]\n",
            "8799: [D loss: 0.724095, acc: 0.490234]  [A loss: 0.856446, acc: 0.152344]\n",
            "8800: [D loss: 0.701160, acc: 0.484375]  [A loss: 0.722294, acc: 0.437500]\n",
            "8801: [D loss: 0.712661, acc: 0.494141]  [A loss: 0.859866, acc: 0.203125]\n",
            "8802: [D loss: 0.712807, acc: 0.482422]  [A loss: 0.710056, acc: 0.492188]\n",
            "8803: [D loss: 0.719390, acc: 0.492188]  [A loss: 0.847286, acc: 0.148438]\n",
            "8804: [D loss: 0.698882, acc: 0.515625]  [A loss: 0.716108, acc: 0.472656]\n",
            "8805: [D loss: 0.705006, acc: 0.507812]  [A loss: 0.885574, acc: 0.097656]\n",
            "8806: [D loss: 0.697565, acc: 0.507812]  [A loss: 0.728525, acc: 0.417969]\n",
            "8807: [D loss: 0.710694, acc: 0.482422]  [A loss: 0.924098, acc: 0.070312]\n",
            "8808: [D loss: 0.685686, acc: 0.554688]  [A loss: 0.650294, acc: 0.644531]\n",
            "8809: [D loss: 0.711255, acc: 0.511719]  [A loss: 0.900393, acc: 0.109375]\n",
            "8810: [D loss: 0.690377, acc: 0.531250]  [A loss: 0.739266, acc: 0.390625]\n",
            "8811: [D loss: 0.703822, acc: 0.521484]  [A loss: 0.786654, acc: 0.296875]\n",
            "8812: [D loss: 0.700988, acc: 0.478516]  [A loss: 0.806622, acc: 0.234375]\n",
            "8813: [D loss: 0.706917, acc: 0.472656]  [A loss: 0.812547, acc: 0.277344]\n",
            "8814: [D loss: 0.701240, acc: 0.525391]  [A loss: 0.758024, acc: 0.351562]\n",
            "8815: [D loss: 0.698574, acc: 0.523438]  [A loss: 0.794915, acc: 0.246094]\n",
            "8816: [D loss: 0.696332, acc: 0.515625]  [A loss: 0.729770, acc: 0.417969]\n",
            "8817: [D loss: 0.701378, acc: 0.525391]  [A loss: 0.876741, acc: 0.128906]\n",
            "8818: [D loss: 0.688823, acc: 0.525391]  [A loss: 0.746490, acc: 0.414062]\n",
            "8819: [D loss: 0.690293, acc: 0.560547]  [A loss: 0.830423, acc: 0.230469]\n",
            "8820: [D loss: 0.691446, acc: 0.523438]  [A loss: 0.777203, acc: 0.308594]\n",
            "8821: [D loss: 0.705930, acc: 0.521484]  [A loss: 0.862867, acc: 0.136719]\n",
            "8822: [D loss: 0.701288, acc: 0.525391]  [A loss: 0.800689, acc: 0.234375]\n",
            "8823: [D loss: 0.699682, acc: 0.492188]  [A loss: 0.792760, acc: 0.250000]\n",
            "8824: [D loss: 0.690871, acc: 0.542969]  [A loss: 0.762501, acc: 0.347656]\n",
            "8825: [D loss: 0.705622, acc: 0.500000]  [A loss: 0.912019, acc: 0.109375]\n",
            "8826: [D loss: 0.688337, acc: 0.539062]  [A loss: 0.799556, acc: 0.250000]\n",
            "8827: [D loss: 0.707750, acc: 0.482422]  [A loss: 0.885545, acc: 0.105469]\n",
            "8828: [D loss: 0.701604, acc: 0.501953]  [A loss: 0.705642, acc: 0.480469]\n",
            "8829: [D loss: 0.705288, acc: 0.527344]  [A loss: 0.951417, acc: 0.089844]\n",
            "8830: [D loss: 0.687056, acc: 0.568359]  [A loss: 0.698244, acc: 0.503906]\n",
            "8831: [D loss: 0.717863, acc: 0.498047]  [A loss: 0.895759, acc: 0.125000]\n",
            "8832: [D loss: 0.693407, acc: 0.519531]  [A loss: 0.710582, acc: 0.484375]\n",
            "8833: [D loss: 0.700700, acc: 0.513672]  [A loss: 0.886807, acc: 0.144531]\n",
            "8834: [D loss: 0.694766, acc: 0.500000]  [A loss: 0.676126, acc: 0.582031]\n",
            "8835: [D loss: 0.727943, acc: 0.515625]  [A loss: 0.900652, acc: 0.078125]\n",
            "8836: [D loss: 0.691460, acc: 0.537109]  [A loss: 0.765052, acc: 0.324219]\n",
            "8837: [D loss: 0.729617, acc: 0.470703]  [A loss: 0.930188, acc: 0.121094]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8838: [D loss: 0.703689, acc: 0.509766]  [A loss: 0.743932, acc: 0.398438]\n",
            "8839: [D loss: 0.711662, acc: 0.484375]  [A loss: 0.815663, acc: 0.214844]\n",
            "8840: [D loss: 0.693596, acc: 0.523438]  [A loss: 0.734452, acc: 0.425781]\n",
            "8841: [D loss: 0.707386, acc: 0.523438]  [A loss: 0.902068, acc: 0.128906]\n",
            "8842: [D loss: 0.694780, acc: 0.517578]  [A loss: 0.766309, acc: 0.320312]\n",
            "8843: [D loss: 0.702356, acc: 0.523438]  [A loss: 0.988129, acc: 0.082031]\n",
            "8844: [D loss: 0.701002, acc: 0.515625]  [A loss: 0.750541, acc: 0.394531]\n",
            "8845: [D loss: 0.701904, acc: 0.513672]  [A loss: 0.811286, acc: 0.250000]\n",
            "8846: [D loss: 0.697666, acc: 0.517578]  [A loss: 0.812230, acc: 0.222656]\n",
            "8847: [D loss: 0.693250, acc: 0.525391]  [A loss: 0.813651, acc: 0.199219]\n",
            "8848: [D loss: 0.697598, acc: 0.511719]  [A loss: 0.756365, acc: 0.324219]\n",
            "8849: [D loss: 0.699782, acc: 0.482422]  [A loss: 0.813022, acc: 0.234375]\n",
            "8850: [D loss: 0.707804, acc: 0.488281]  [A loss: 0.802569, acc: 0.253906]\n",
            "8851: [D loss: 0.701447, acc: 0.507812]  [A loss: 0.795403, acc: 0.257812]\n",
            "8852: [D loss: 0.700543, acc: 0.515625]  [A loss: 0.829764, acc: 0.203125]\n",
            "8853: [D loss: 0.698957, acc: 0.525391]  [A loss: 0.835255, acc: 0.195312]\n",
            "8854: [D loss: 0.711840, acc: 0.470703]  [A loss: 0.842361, acc: 0.167969]\n",
            "8855: [D loss: 0.698154, acc: 0.517578]  [A loss: 0.778296, acc: 0.328125]\n",
            "8856: [D loss: 0.713179, acc: 0.507812]  [A loss: 0.904003, acc: 0.105469]\n",
            "8857: [D loss: 0.706601, acc: 0.500000]  [A loss: 0.673682, acc: 0.562500]\n",
            "8858: [D loss: 0.730024, acc: 0.488281]  [A loss: 0.964387, acc: 0.046875]\n",
            "8859: [D loss: 0.702977, acc: 0.509766]  [A loss: 0.647419, acc: 0.683594]\n",
            "8860: [D loss: 0.714644, acc: 0.503906]  [A loss: 0.870943, acc: 0.175781]\n",
            "8861: [D loss: 0.699777, acc: 0.509766]  [A loss: 0.805825, acc: 0.253906]\n",
            "8862: [D loss: 0.708110, acc: 0.503906]  [A loss: 0.797781, acc: 0.332031]\n",
            "8863: [D loss: 0.699438, acc: 0.519531]  [A loss: 0.900712, acc: 0.101562]\n",
            "8864: [D loss: 0.714414, acc: 0.480469]  [A loss: 0.701148, acc: 0.511719]\n",
            "8865: [D loss: 0.717043, acc: 0.505859]  [A loss: 0.916986, acc: 0.078125]\n",
            "8866: [D loss: 0.696444, acc: 0.515625]  [A loss: 0.720165, acc: 0.449219]\n",
            "8867: [D loss: 0.707928, acc: 0.521484]  [A loss: 0.848952, acc: 0.195312]\n",
            "8868: [D loss: 0.690153, acc: 0.541016]  [A loss: 0.785945, acc: 0.281250]\n",
            "8869: [D loss: 0.708360, acc: 0.503906]  [A loss: 0.861382, acc: 0.160156]\n",
            "8870: [D loss: 0.695542, acc: 0.523438]  [A loss: 0.687254, acc: 0.554688]\n",
            "8871: [D loss: 0.711546, acc: 0.503906]  [A loss: 0.853949, acc: 0.144531]\n",
            "8872: [D loss: 0.704890, acc: 0.503906]  [A loss: 0.778059, acc: 0.339844]\n",
            "8873: [D loss: 0.709220, acc: 0.486328]  [A loss: 0.904113, acc: 0.105469]\n",
            "8874: [D loss: 0.708768, acc: 0.486328]  [A loss: 0.684931, acc: 0.511719]\n",
            "8875: [D loss: 0.706180, acc: 0.527344]  [A loss: 0.860823, acc: 0.167969]\n",
            "8876: [D loss: 0.702685, acc: 0.492188]  [A loss: 0.732061, acc: 0.421875]\n",
            "8877: [D loss: 0.716448, acc: 0.484375]  [A loss: 0.980217, acc: 0.093750]\n",
            "8878: [D loss: 0.698543, acc: 0.494141]  [A loss: 0.727841, acc: 0.402344]\n",
            "8879: [D loss: 0.706057, acc: 0.519531]  [A loss: 0.827118, acc: 0.179688]\n",
            "8880: [D loss: 0.708163, acc: 0.501953]  [A loss: 0.753363, acc: 0.343750]\n",
            "8881: [D loss: 0.694617, acc: 0.544922]  [A loss: 0.798295, acc: 0.253906]\n",
            "8882: [D loss: 0.694161, acc: 0.513672]  [A loss: 0.846595, acc: 0.164062]\n",
            "8883: [D loss: 0.698060, acc: 0.511719]  [A loss: 0.759271, acc: 0.343750]\n",
            "8884: [D loss: 0.700408, acc: 0.529297]  [A loss: 0.859551, acc: 0.171875]\n",
            "8885: [D loss: 0.693504, acc: 0.527344]  [A loss: 0.720426, acc: 0.488281]\n",
            "8886: [D loss: 0.702984, acc: 0.521484]  [A loss: 0.884844, acc: 0.132812]\n",
            "8887: [D loss: 0.691889, acc: 0.521484]  [A loss: 0.700953, acc: 0.511719]\n",
            "8888: [D loss: 0.715733, acc: 0.498047]  [A loss: 0.880558, acc: 0.179688]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8889: [D loss: 0.689997, acc: 0.542969]  [A loss: 0.737404, acc: 0.417969]\n",
            "8890: [D loss: 0.692326, acc: 0.541016]  [A loss: 0.903110, acc: 0.121094]\n",
            "8891: [D loss: 0.691776, acc: 0.535156]  [A loss: 0.746445, acc: 0.390625]\n",
            "8892: [D loss: 0.702989, acc: 0.501953]  [A loss: 0.843257, acc: 0.230469]\n",
            "8893: [D loss: 0.704567, acc: 0.501953]  [A loss: 0.774207, acc: 0.308594]\n",
            "8894: [D loss: 0.697223, acc: 0.533203]  [A loss: 0.808885, acc: 0.222656]\n",
            "8895: [D loss: 0.694905, acc: 0.490234]  [A loss: 0.811599, acc: 0.269531]\n",
            "8896: [D loss: 0.687107, acc: 0.533203]  [A loss: 0.778155, acc: 0.281250]\n",
            "8897: [D loss: 0.699772, acc: 0.517578]  [A loss: 0.824195, acc: 0.230469]\n",
            "8898: [D loss: 0.697080, acc: 0.521484]  [A loss: 0.750982, acc: 0.394531]\n",
            "8899: [D loss: 0.699820, acc: 0.533203]  [A loss: 0.817606, acc: 0.230469]\n",
            "8900: [D loss: 0.693496, acc: 0.519531]  [A loss: 0.811779, acc: 0.253906]\n",
            "8901: [D loss: 0.690458, acc: 0.523438]  [A loss: 0.792831, acc: 0.300781]\n",
            "8902: [D loss: 0.692137, acc: 0.509766]  [A loss: 0.830817, acc: 0.242188]\n",
            "8903: [D loss: 0.702418, acc: 0.500000]  [A loss: 0.794967, acc: 0.277344]\n",
            "8904: [D loss: 0.698863, acc: 0.519531]  [A loss: 0.915637, acc: 0.101562]\n",
            "8905: [D loss: 0.704441, acc: 0.500000]  [A loss: 0.650409, acc: 0.640625]\n",
            "8906: [D loss: 0.727638, acc: 0.513672]  [A loss: 1.059707, acc: 0.027344]\n",
            "8907: [D loss: 0.714364, acc: 0.492188]  [A loss: 0.675404, acc: 0.574219]\n",
            "8908: [D loss: 0.717117, acc: 0.501953]  [A loss: 0.933931, acc: 0.128906]\n",
            "8909: [D loss: 0.702235, acc: 0.503906]  [A loss: 0.711282, acc: 0.488281]\n",
            "8910: [D loss: 0.704654, acc: 0.529297]  [A loss: 0.828127, acc: 0.214844]\n",
            "8911: [D loss: 0.701992, acc: 0.529297]  [A loss: 0.768796, acc: 0.359375]\n",
            "8912: [D loss: 0.704846, acc: 0.488281]  [A loss: 0.782700, acc: 0.312500]\n",
            "8913: [D loss: 0.690892, acc: 0.521484]  [A loss: 0.784159, acc: 0.304688]\n",
            "8914: [D loss: 0.696633, acc: 0.507812]  [A loss: 0.804491, acc: 0.292969]\n",
            "8915: [D loss: 0.707703, acc: 0.511719]  [A loss: 0.784147, acc: 0.304688]\n",
            "8916: [D loss: 0.703241, acc: 0.511719]  [A loss: 0.847526, acc: 0.195312]\n",
            "8917: [D loss: 0.700716, acc: 0.509766]  [A loss: 0.801438, acc: 0.285156]\n",
            "8918: [D loss: 0.706463, acc: 0.507812]  [A loss: 0.800745, acc: 0.238281]\n",
            "8919: [D loss: 0.704154, acc: 0.494141]  [A loss: 0.802568, acc: 0.265625]\n",
            "8920: [D loss: 0.692023, acc: 0.525391]  [A loss: 0.814207, acc: 0.230469]\n",
            "8921: [D loss: 0.700991, acc: 0.541016]  [A loss: 0.783726, acc: 0.320312]\n",
            "8922: [D loss: 0.703882, acc: 0.492188]  [A loss: 0.838755, acc: 0.203125]\n",
            "8923: [D loss: 0.706982, acc: 0.490234]  [A loss: 0.782504, acc: 0.253906]\n",
            "8924: [D loss: 0.691755, acc: 0.542969]  [A loss: 0.858287, acc: 0.171875]\n",
            "8925: [D loss: 0.705472, acc: 0.496094]  [A loss: 0.748473, acc: 0.417969]\n",
            "8926: [D loss: 0.715293, acc: 0.482422]  [A loss: 0.911721, acc: 0.093750]\n",
            "8927: [D loss: 0.709440, acc: 0.501953]  [A loss: 0.744230, acc: 0.421875]\n",
            "8928: [D loss: 0.706856, acc: 0.505859]  [A loss: 0.820944, acc: 0.230469]\n",
            "8929: [D loss: 0.687141, acc: 0.537109]  [A loss: 0.711180, acc: 0.503906]\n",
            "8930: [D loss: 0.707855, acc: 0.507812]  [A loss: 0.920273, acc: 0.062500]\n",
            "8931: [D loss: 0.694228, acc: 0.546875]  [A loss: 0.708830, acc: 0.480469]\n",
            "8932: [D loss: 0.716215, acc: 0.519531]  [A loss: 0.856209, acc: 0.164062]\n",
            "8933: [D loss: 0.704340, acc: 0.517578]  [A loss: 0.684619, acc: 0.523438]\n",
            "8934: [D loss: 0.708566, acc: 0.519531]  [A loss: 0.852275, acc: 0.183594]\n",
            "8935: [D loss: 0.687364, acc: 0.550781]  [A loss: 0.722732, acc: 0.484375]\n",
            "8936: [D loss: 0.709652, acc: 0.507812]  [A loss: 0.803111, acc: 0.277344]\n",
            "8937: [D loss: 0.701131, acc: 0.529297]  [A loss: 0.769607, acc: 0.324219]\n",
            "8938: [D loss: 0.696439, acc: 0.523438]  [A loss: 0.809348, acc: 0.234375]\n",
            "8939: [D loss: 0.706705, acc: 0.525391]  [A loss: 0.830688, acc: 0.261719]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8940: [D loss: 0.700276, acc: 0.527344]  [A loss: 0.814499, acc: 0.230469]\n",
            "8941: [D loss: 0.701601, acc: 0.503906]  [A loss: 0.795211, acc: 0.265625]\n",
            "8942: [D loss: 0.713421, acc: 0.509766]  [A loss: 0.838495, acc: 0.191406]\n",
            "8943: [D loss: 0.692518, acc: 0.548828]  [A loss: 0.766948, acc: 0.324219]\n",
            "8944: [D loss: 0.701312, acc: 0.527344]  [A loss: 0.833054, acc: 0.250000]\n",
            "8945: [D loss: 0.712950, acc: 0.464844]  [A loss: 0.803673, acc: 0.257812]\n",
            "8946: [D loss: 0.692614, acc: 0.546875]  [A loss: 0.821231, acc: 0.238281]\n",
            "8947: [D loss: 0.695761, acc: 0.490234]  [A loss: 0.832299, acc: 0.218750]\n",
            "8948: [D loss: 0.697680, acc: 0.548828]  [A loss: 0.834165, acc: 0.210938]\n",
            "8949: [D loss: 0.689572, acc: 0.533203]  [A loss: 0.752929, acc: 0.398438]\n",
            "8950: [D loss: 0.691777, acc: 0.560547]  [A loss: 0.876059, acc: 0.156250]\n",
            "8951: [D loss: 0.694206, acc: 0.527344]  [A loss: 0.725706, acc: 0.429688]\n",
            "8952: [D loss: 0.701297, acc: 0.507812]  [A loss: 0.927355, acc: 0.097656]\n",
            "8953: [D loss: 0.699338, acc: 0.513672]  [A loss: 0.689420, acc: 0.542969]\n",
            "8954: [D loss: 0.715625, acc: 0.531250]  [A loss: 0.935233, acc: 0.082031]\n",
            "8955: [D loss: 0.706809, acc: 0.500000]  [A loss: 0.777312, acc: 0.351562]\n",
            "8956: [D loss: 0.706332, acc: 0.519531]  [A loss: 0.951297, acc: 0.113281]\n",
            "8957: [D loss: 0.710526, acc: 0.476562]  [A loss: 0.741002, acc: 0.390625]\n",
            "8958: [D loss: 0.709422, acc: 0.478516]  [A loss: 0.857445, acc: 0.128906]\n",
            "8959: [D loss: 0.691559, acc: 0.537109]  [A loss: 0.804576, acc: 0.250000]\n",
            "8960: [D loss: 0.691332, acc: 0.542969]  [A loss: 0.845122, acc: 0.191406]\n",
            "8961: [D loss: 0.693756, acc: 0.525391]  [A loss: 0.707707, acc: 0.484375]\n",
            "8962: [D loss: 0.718297, acc: 0.494141]  [A loss: 0.922976, acc: 0.085938]\n",
            "8963: [D loss: 0.687810, acc: 0.564453]  [A loss: 0.670911, acc: 0.574219]\n",
            "8964: [D loss: 0.709675, acc: 0.511719]  [A loss: 0.830957, acc: 0.207031]\n",
            "8965: [D loss: 0.710793, acc: 0.494141]  [A loss: 0.758470, acc: 0.328125]\n",
            "8966: [D loss: 0.709812, acc: 0.503906]  [A loss: 0.842029, acc: 0.210938]\n",
            "8967: [D loss: 0.698253, acc: 0.523438]  [A loss: 0.847054, acc: 0.304688]\n",
            "8968: [D loss: 0.694024, acc: 0.531250]  [A loss: 0.879355, acc: 0.167969]\n",
            "8969: [D loss: 0.693730, acc: 0.511719]  [A loss: 0.765979, acc: 0.304688]\n",
            "8970: [D loss: 0.697914, acc: 0.511719]  [A loss: 0.882405, acc: 0.128906]\n",
            "8971: [D loss: 0.715136, acc: 0.484375]  [A loss: 0.755983, acc: 0.351562]\n",
            "8972: [D loss: 0.694601, acc: 0.519531]  [A loss: 0.841403, acc: 0.160156]\n",
            "8973: [D loss: 0.699896, acc: 0.503906]  [A loss: 0.736778, acc: 0.398438]\n",
            "8974: [D loss: 0.699418, acc: 0.529297]  [A loss: 0.869408, acc: 0.144531]\n",
            "8975: [D loss: 0.696163, acc: 0.517578]  [A loss: 0.778921, acc: 0.328125]\n",
            "8976: [D loss: 0.705209, acc: 0.515625]  [A loss: 0.784385, acc: 0.250000]\n",
            "8977: [D loss: 0.705721, acc: 0.488281]  [A loss: 0.756902, acc: 0.382812]\n",
            "8978: [D loss: 0.703532, acc: 0.503906]  [A loss: 0.811396, acc: 0.226562]\n",
            "8979: [D loss: 0.689960, acc: 0.564453]  [A loss: 0.722377, acc: 0.449219]\n",
            "8980: [D loss: 0.702203, acc: 0.501953]  [A loss: 0.951969, acc: 0.097656]\n",
            "8981: [D loss: 0.700629, acc: 0.519531]  [A loss: 0.768241, acc: 0.359375]\n",
            "8982: [D loss: 0.698004, acc: 0.527344]  [A loss: 0.838820, acc: 0.148438]\n",
            "8983: [D loss: 0.699096, acc: 0.525391]  [A loss: 0.777743, acc: 0.371094]\n",
            "8984: [D loss: 0.713032, acc: 0.521484]  [A loss: 0.955965, acc: 0.078125]\n",
            "8985: [D loss: 0.702168, acc: 0.511719]  [A loss: 0.683426, acc: 0.539062]\n",
            "8986: [D loss: 0.704902, acc: 0.501953]  [A loss: 0.857163, acc: 0.167969]\n",
            "8987: [D loss: 0.699468, acc: 0.519531]  [A loss: 0.682838, acc: 0.527344]\n",
            "8988: [D loss: 0.714674, acc: 0.468750]  [A loss: 0.865442, acc: 0.121094]\n",
            "8989: [D loss: 0.701629, acc: 0.480469]  [A loss: 0.713921, acc: 0.472656]\n",
            "8990: [D loss: 0.707825, acc: 0.505859]  [A loss: 0.860681, acc: 0.136719]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8991: [D loss: 0.701561, acc: 0.515625]  [A loss: 0.767555, acc: 0.375000]\n",
            "8992: [D loss: 0.701990, acc: 0.531250]  [A loss: 0.812120, acc: 0.253906]\n",
            "8993: [D loss: 0.702589, acc: 0.480469]  [A loss: 0.766258, acc: 0.308594]\n",
            "8994: [D loss: 0.707256, acc: 0.511719]  [A loss: 0.944259, acc: 0.105469]\n",
            "8995: [D loss: 0.687092, acc: 0.550781]  [A loss: 0.743368, acc: 0.429688]\n",
            "8996: [D loss: 0.703764, acc: 0.494141]  [A loss: 0.772158, acc: 0.324219]\n",
            "8997: [D loss: 0.705725, acc: 0.527344]  [A loss: 0.771767, acc: 0.300781]\n",
            "8998: [D loss: 0.694166, acc: 0.515625]  [A loss: 0.815519, acc: 0.242188]\n",
            "8999: [D loss: 0.703558, acc: 0.535156]  [A loss: 0.789024, acc: 0.304688]\n",
            "9000: [D loss: 0.710890, acc: 0.503906]  [A loss: 0.841285, acc: 0.214844]\n",
            "9001: [D loss: 0.702141, acc: 0.505859]  [A loss: 0.744629, acc: 0.378906]\n",
            "9002: [D loss: 0.712339, acc: 0.498047]  [A loss: 0.868757, acc: 0.144531]\n",
            "9003: [D loss: 0.694572, acc: 0.542969]  [A loss: 0.737181, acc: 0.410156]\n",
            "9004: [D loss: 0.721381, acc: 0.466797]  [A loss: 0.866224, acc: 0.109375]\n",
            "9005: [D loss: 0.705568, acc: 0.503906]  [A loss: 0.729344, acc: 0.417969]\n",
            "9006: [D loss: 0.706918, acc: 0.511719]  [A loss: 0.836505, acc: 0.207031]\n",
            "9007: [D loss: 0.694547, acc: 0.521484]  [A loss: 0.805983, acc: 0.269531]\n",
            "9008: [D loss: 0.697172, acc: 0.517578]  [A loss: 0.819102, acc: 0.226562]\n",
            "9009: [D loss: 0.698303, acc: 0.529297]  [A loss: 0.799093, acc: 0.250000]\n",
            "9010: [D loss: 0.691969, acc: 0.535156]  [A loss: 0.746238, acc: 0.402344]\n",
            "9011: [D loss: 0.701282, acc: 0.507812]  [A loss: 0.815114, acc: 0.218750]\n",
            "9012: [D loss: 0.699536, acc: 0.505859]  [A loss: 0.770260, acc: 0.343750]\n",
            "9013: [D loss: 0.692213, acc: 0.537109]  [A loss: 0.823869, acc: 0.199219]\n",
            "9014: [D loss: 0.690125, acc: 0.533203]  [A loss: 0.721218, acc: 0.468750]\n",
            "9015: [D loss: 0.710344, acc: 0.501953]  [A loss: 0.867704, acc: 0.144531]\n",
            "9016: [D loss: 0.695288, acc: 0.515625]  [A loss: 0.756239, acc: 0.375000]\n",
            "9017: [D loss: 0.699031, acc: 0.529297]  [A loss: 0.851763, acc: 0.187500]\n",
            "9018: [D loss: 0.700450, acc: 0.533203]  [A loss: 0.774348, acc: 0.332031]\n",
            "9019: [D loss: 0.707477, acc: 0.521484]  [A loss: 0.847686, acc: 0.203125]\n",
            "9020: [D loss: 0.702035, acc: 0.513672]  [A loss: 0.736713, acc: 0.390625]\n",
            "9021: [D loss: 0.704895, acc: 0.523438]  [A loss: 0.803449, acc: 0.214844]\n",
            "9022: [D loss: 0.697574, acc: 0.548828]  [A loss: 0.735426, acc: 0.347656]\n",
            "9023: [D loss: 0.712226, acc: 0.513672]  [A loss: 0.877085, acc: 0.121094]\n",
            "9024: [D loss: 0.703715, acc: 0.494141]  [A loss: 0.754856, acc: 0.332031]\n",
            "9025: [D loss: 0.711166, acc: 0.505859]  [A loss: 0.862208, acc: 0.117188]\n",
            "9026: [D loss: 0.701820, acc: 0.517578]  [A loss: 0.708428, acc: 0.464844]\n",
            "9027: [D loss: 0.710908, acc: 0.509766]  [A loss: 0.935301, acc: 0.089844]\n",
            "9028: [D loss: 0.695748, acc: 0.525391]  [A loss: 0.721308, acc: 0.445312]\n",
            "9029: [D loss: 0.705589, acc: 0.541016]  [A loss: 0.912098, acc: 0.074219]\n",
            "9030: [D loss: 0.694176, acc: 0.517578]  [A loss: 0.733058, acc: 0.453125]\n",
            "9031: [D loss: 0.702577, acc: 0.542969]  [A loss: 0.858809, acc: 0.144531]\n",
            "9032: [D loss: 0.693411, acc: 0.537109]  [A loss: 0.757367, acc: 0.343750]\n",
            "9033: [D loss: 0.712835, acc: 0.505859]  [A loss: 0.851415, acc: 0.152344]\n",
            "9034: [D loss: 0.697701, acc: 0.519531]  [A loss: 0.756738, acc: 0.363281]\n",
            "9035: [D loss: 0.699384, acc: 0.519531]  [A loss: 0.856606, acc: 0.148438]\n",
            "9036: [D loss: 0.713353, acc: 0.441406]  [A loss: 0.735534, acc: 0.398438]\n",
            "9037: [D loss: 0.714663, acc: 0.484375]  [A loss: 0.835504, acc: 0.171875]\n",
            "9038: [D loss: 0.685350, acc: 0.558594]  [A loss: 0.817539, acc: 0.273438]\n",
            "9039: [D loss: 0.706271, acc: 0.505859]  [A loss: 0.835660, acc: 0.191406]\n",
            "9040: [D loss: 0.697000, acc: 0.531250]  [A loss: 0.742916, acc: 0.406250]\n",
            "9041: [D loss: 0.706300, acc: 0.521484]  [A loss: 0.842759, acc: 0.175781]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9042: [D loss: 0.701284, acc: 0.525391]  [A loss: 0.732511, acc: 0.406250]\n",
            "9043: [D loss: 0.700688, acc: 0.521484]  [A loss: 0.856245, acc: 0.148438]\n",
            "9044: [D loss: 0.694741, acc: 0.492188]  [A loss: 0.749957, acc: 0.347656]\n",
            "9045: [D loss: 0.698640, acc: 0.517578]  [A loss: 0.850510, acc: 0.171875]\n",
            "9046: [D loss: 0.693058, acc: 0.523438]  [A loss: 0.703138, acc: 0.539062]\n",
            "9047: [D loss: 0.700351, acc: 0.501953]  [A loss: 0.908265, acc: 0.074219]\n",
            "9048: [D loss: 0.708634, acc: 0.484375]  [A loss: 0.697470, acc: 0.507812]\n",
            "9049: [D loss: 0.716352, acc: 0.492188]  [A loss: 0.873399, acc: 0.105469]\n",
            "9050: [D loss: 0.690370, acc: 0.531250]  [A loss: 0.733243, acc: 0.414062]\n",
            "9051: [D loss: 0.706056, acc: 0.513672]  [A loss: 0.835825, acc: 0.175781]\n",
            "9052: [D loss: 0.695617, acc: 0.546875]  [A loss: 0.824870, acc: 0.187500]\n",
            "9053: [D loss: 0.682197, acc: 0.574219]  [A loss: 0.836539, acc: 0.175781]\n",
            "9054: [D loss: 0.689869, acc: 0.562500]  [A loss: 0.753886, acc: 0.390625]\n",
            "9055: [D loss: 0.700392, acc: 0.511719]  [A loss: 0.871170, acc: 0.167969]\n",
            "9056: [D loss: 0.686818, acc: 0.541016]  [A loss: 0.740523, acc: 0.367188]\n",
            "9057: [D loss: 0.699079, acc: 0.521484]  [A loss: 0.857909, acc: 0.183594]\n",
            "9058: [D loss: 0.712061, acc: 0.480469]  [A loss: 0.724013, acc: 0.449219]\n",
            "9059: [D loss: 0.697293, acc: 0.546875]  [A loss: 0.858438, acc: 0.160156]\n",
            "9060: [D loss: 0.695769, acc: 0.513672]  [A loss: 0.752998, acc: 0.335938]\n",
            "9061: [D loss: 0.693571, acc: 0.562500]  [A loss: 0.840745, acc: 0.191406]\n",
            "9062: [D loss: 0.702432, acc: 0.515625]  [A loss: 0.763655, acc: 0.359375]\n",
            "9063: [D loss: 0.711520, acc: 0.519531]  [A loss: 0.869717, acc: 0.109375]\n",
            "9064: [D loss: 0.688564, acc: 0.509766]  [A loss: 0.708432, acc: 0.460938]\n",
            "9065: [D loss: 0.691499, acc: 0.521484]  [A loss: 0.814624, acc: 0.210938]\n",
            "9066: [D loss: 0.698796, acc: 0.529297]  [A loss: 0.828077, acc: 0.230469]\n",
            "9067: [D loss: 0.693134, acc: 0.539062]  [A loss: 0.777184, acc: 0.308594]\n",
            "9068: [D loss: 0.689829, acc: 0.527344]  [A loss: 0.702174, acc: 0.476562]\n",
            "9069: [D loss: 0.706778, acc: 0.513672]  [A loss: 0.855254, acc: 0.171875]\n",
            "9070: [D loss: 0.708060, acc: 0.470703]  [A loss: 0.695101, acc: 0.519531]\n",
            "9071: [D loss: 0.706846, acc: 0.511719]  [A loss: 0.813182, acc: 0.242188]\n",
            "9072: [D loss: 0.691717, acc: 0.558594]  [A loss: 0.738271, acc: 0.375000]\n",
            "9073: [D loss: 0.697604, acc: 0.517578]  [A loss: 0.870952, acc: 0.128906]\n",
            "9074: [D loss: 0.698223, acc: 0.517578]  [A loss: 0.717550, acc: 0.425781]\n",
            "9075: [D loss: 0.712478, acc: 0.494141]  [A loss: 0.851452, acc: 0.144531]\n",
            "9076: [D loss: 0.699372, acc: 0.515625]  [A loss: 0.735705, acc: 0.394531]\n",
            "9077: [D loss: 0.690870, acc: 0.523438]  [A loss: 0.830800, acc: 0.203125]\n",
            "9078: [D loss: 0.697300, acc: 0.498047]  [A loss: 0.705102, acc: 0.460938]\n",
            "9079: [D loss: 0.707301, acc: 0.507812]  [A loss: 0.950240, acc: 0.062500]\n",
            "9080: [D loss: 0.693634, acc: 0.539062]  [A loss: 0.682571, acc: 0.570312]\n",
            "9081: [D loss: 0.716798, acc: 0.509766]  [A loss: 0.871823, acc: 0.144531]\n",
            "9082: [D loss: 0.700248, acc: 0.515625]  [A loss: 0.710713, acc: 0.425781]\n",
            "9083: [D loss: 0.703578, acc: 0.513672]  [A loss: 0.909088, acc: 0.125000]\n",
            "9084: [D loss: 0.696358, acc: 0.515625]  [A loss: 0.744860, acc: 0.363281]\n",
            "9085: [D loss: 0.704658, acc: 0.494141]  [A loss: 0.807713, acc: 0.214844]\n",
            "9086: [D loss: 0.687507, acc: 0.560547]  [A loss: 0.778952, acc: 0.328125]\n",
            "9087: [D loss: 0.707988, acc: 0.496094]  [A loss: 0.952155, acc: 0.066406]\n",
            "9088: [D loss: 0.690767, acc: 0.537109]  [A loss: 0.768371, acc: 0.304688]\n",
            "9089: [D loss: 0.706056, acc: 0.501953]  [A loss: 0.836859, acc: 0.156250]\n",
            "9090: [D loss: 0.692372, acc: 0.531250]  [A loss: 0.732265, acc: 0.375000]\n",
            "9091: [D loss: 0.696324, acc: 0.527344]  [A loss: 0.856937, acc: 0.164062]\n",
            "9092: [D loss: 0.702987, acc: 0.486328]  [A loss: 0.714686, acc: 0.480469]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9093: [D loss: 0.708572, acc: 0.511719]  [A loss: 0.877474, acc: 0.136719]\n",
            "9094: [D loss: 0.695566, acc: 0.517578]  [A loss: 0.703782, acc: 0.503906]\n",
            "9095: [D loss: 0.712680, acc: 0.529297]  [A loss: 0.877733, acc: 0.125000]\n",
            "9096: [D loss: 0.690880, acc: 0.527344]  [A loss: 0.709163, acc: 0.460938]\n",
            "9097: [D loss: 0.719976, acc: 0.480469]  [A loss: 0.921415, acc: 0.117188]\n",
            "9098: [D loss: 0.701276, acc: 0.519531]  [A loss: 0.701029, acc: 0.472656]\n",
            "9099: [D loss: 0.701968, acc: 0.525391]  [A loss: 0.851798, acc: 0.167969]\n",
            "9100: [D loss: 0.687018, acc: 0.531250]  [A loss: 0.751764, acc: 0.363281]\n",
            "9101: [D loss: 0.720114, acc: 0.468750]  [A loss: 0.828542, acc: 0.171875]\n",
            "9102: [D loss: 0.687449, acc: 0.537109]  [A loss: 0.764550, acc: 0.363281]\n",
            "9103: [D loss: 0.703172, acc: 0.492188]  [A loss: 0.806477, acc: 0.234375]\n",
            "9104: [D loss: 0.685480, acc: 0.533203]  [A loss: 0.767116, acc: 0.316406]\n",
            "9105: [D loss: 0.695495, acc: 0.527344]  [A loss: 0.796286, acc: 0.242188]\n",
            "9106: [D loss: 0.688590, acc: 0.541016]  [A loss: 0.747290, acc: 0.375000]\n",
            "9107: [D loss: 0.703120, acc: 0.488281]  [A loss: 0.799223, acc: 0.265625]\n",
            "9108: [D loss: 0.708782, acc: 0.492188]  [A loss: 0.741699, acc: 0.421875]\n",
            "9109: [D loss: 0.711051, acc: 0.488281]  [A loss: 0.838843, acc: 0.203125]\n",
            "9110: [D loss: 0.700814, acc: 0.507812]  [A loss: 0.697598, acc: 0.511719]\n",
            "9111: [D loss: 0.708343, acc: 0.515625]  [A loss: 0.849931, acc: 0.175781]\n",
            "9112: [D loss: 0.688880, acc: 0.509766]  [A loss: 0.725071, acc: 0.441406]\n",
            "9113: [D loss: 0.713595, acc: 0.507812]  [A loss: 0.916136, acc: 0.113281]\n",
            "9114: [D loss: 0.703060, acc: 0.507812]  [A loss: 0.709338, acc: 0.472656]\n",
            "9115: [D loss: 0.708957, acc: 0.515625]  [A loss: 0.866499, acc: 0.167969]\n",
            "9116: [D loss: 0.693069, acc: 0.533203]  [A loss: 0.784710, acc: 0.304688]\n",
            "9117: [D loss: 0.702369, acc: 0.505859]  [A loss: 0.838448, acc: 0.207031]\n",
            "9118: [D loss: 0.690057, acc: 0.523438]  [A loss: 0.760359, acc: 0.347656]\n",
            "9119: [D loss: 0.693137, acc: 0.548828]  [A loss: 0.806168, acc: 0.250000]\n",
            "9120: [D loss: 0.699862, acc: 0.486328]  [A loss: 0.726639, acc: 0.437500]\n",
            "9121: [D loss: 0.699240, acc: 0.529297]  [A loss: 0.903582, acc: 0.148438]\n",
            "9122: [D loss: 0.703265, acc: 0.507812]  [A loss: 0.831632, acc: 0.199219]\n",
            "9123: [D loss: 0.702166, acc: 0.509766]  [A loss: 0.826906, acc: 0.226562]\n",
            "9124: [D loss: 0.699319, acc: 0.525391]  [A loss: 0.750502, acc: 0.355469]\n",
            "9125: [D loss: 0.697203, acc: 0.500000]  [A loss: 0.854440, acc: 0.152344]\n",
            "9126: [D loss: 0.696568, acc: 0.490234]  [A loss: 0.686308, acc: 0.519531]\n",
            "9127: [D loss: 0.698606, acc: 0.511719]  [A loss: 0.844719, acc: 0.199219]\n",
            "9128: [D loss: 0.706140, acc: 0.513672]  [A loss: 0.839371, acc: 0.214844]\n",
            "9129: [D loss: 0.685629, acc: 0.556641]  [A loss: 0.799890, acc: 0.242188]\n",
            "9130: [D loss: 0.709454, acc: 0.476562]  [A loss: 0.816624, acc: 0.273438]\n",
            "9131: [D loss: 0.702510, acc: 0.513672]  [A loss: 0.869494, acc: 0.175781]\n",
            "9132: [D loss: 0.689119, acc: 0.527344]  [A loss: 0.713215, acc: 0.468750]\n",
            "9133: [D loss: 0.700716, acc: 0.527344]  [A loss: 0.927495, acc: 0.089844]\n",
            "9134: [D loss: 0.693953, acc: 0.531250]  [A loss: 0.766760, acc: 0.355469]\n",
            "9135: [D loss: 0.704044, acc: 0.515625]  [A loss: 0.897620, acc: 0.089844]\n",
            "9136: [D loss: 0.700369, acc: 0.501953]  [A loss: 0.753784, acc: 0.390625]\n",
            "9137: [D loss: 0.717349, acc: 0.527344]  [A loss: 0.932393, acc: 0.058594]\n",
            "9138: [D loss: 0.700217, acc: 0.482422]  [A loss: 0.667540, acc: 0.562500]\n",
            "9139: [D loss: 0.705542, acc: 0.517578]  [A loss: 0.848062, acc: 0.175781]\n",
            "9140: [D loss: 0.695987, acc: 0.517578]  [A loss: 0.718334, acc: 0.464844]\n",
            "9141: [D loss: 0.705094, acc: 0.521484]  [A loss: 0.862381, acc: 0.156250]\n",
            "9142: [D loss: 0.698361, acc: 0.505859]  [A loss: 0.732300, acc: 0.398438]\n",
            "9143: [D loss: 0.707964, acc: 0.513672]  [A loss: 0.841569, acc: 0.195312]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9144: [D loss: 0.692864, acc: 0.539062]  [A loss: 0.774523, acc: 0.363281]\n",
            "9145: [D loss: 0.687848, acc: 0.546875]  [A loss: 0.790758, acc: 0.265625]\n",
            "9146: [D loss: 0.707087, acc: 0.498047]  [A loss: 0.769743, acc: 0.277344]\n",
            "9147: [D loss: 0.697387, acc: 0.537109]  [A loss: 0.840359, acc: 0.187500]\n",
            "9148: [D loss: 0.697404, acc: 0.529297]  [A loss: 0.714147, acc: 0.449219]\n",
            "9149: [D loss: 0.700390, acc: 0.531250]  [A loss: 0.825769, acc: 0.195312]\n",
            "9150: [D loss: 0.705846, acc: 0.494141]  [A loss: 0.733498, acc: 0.445312]\n",
            "9151: [D loss: 0.708707, acc: 0.498047]  [A loss: 0.848936, acc: 0.164062]\n",
            "9152: [D loss: 0.684031, acc: 0.556641]  [A loss: 0.737883, acc: 0.410156]\n",
            "9153: [D loss: 0.697160, acc: 0.525391]  [A loss: 0.800668, acc: 0.226562]\n",
            "9154: [D loss: 0.689649, acc: 0.556641]  [A loss: 0.759769, acc: 0.343750]\n",
            "9155: [D loss: 0.700511, acc: 0.505859]  [A loss: 0.841963, acc: 0.148438]\n",
            "9156: [D loss: 0.703776, acc: 0.498047]  [A loss: 0.735764, acc: 0.386719]\n",
            "9157: [D loss: 0.702700, acc: 0.533203]  [A loss: 0.820872, acc: 0.187500]\n",
            "9158: [D loss: 0.699094, acc: 0.478516]  [A loss: 0.759012, acc: 0.304688]\n",
            "9159: [D loss: 0.703061, acc: 0.505859]  [A loss: 0.840157, acc: 0.191406]\n",
            "9160: [D loss: 0.701960, acc: 0.501953]  [A loss: 0.777527, acc: 0.285156]\n",
            "9161: [D loss: 0.702342, acc: 0.517578]  [A loss: 0.877747, acc: 0.140625]\n",
            "9162: [D loss: 0.694181, acc: 0.533203]  [A loss: 0.726086, acc: 0.429688]\n",
            "9163: [D loss: 0.700691, acc: 0.519531]  [A loss: 0.863728, acc: 0.132812]\n",
            "9164: [D loss: 0.701323, acc: 0.527344]  [A loss: 0.694684, acc: 0.511719]\n",
            "9165: [D loss: 0.711660, acc: 0.511719]  [A loss: 0.906277, acc: 0.078125]\n",
            "9166: [D loss: 0.696830, acc: 0.505859]  [A loss: 0.722114, acc: 0.437500]\n",
            "9167: [D loss: 0.717179, acc: 0.507812]  [A loss: 0.882164, acc: 0.121094]\n",
            "9168: [D loss: 0.696337, acc: 0.521484]  [A loss: 0.720661, acc: 0.433594]\n",
            "9169: [D loss: 0.712672, acc: 0.509766]  [A loss: 0.909876, acc: 0.105469]\n",
            "9170: [D loss: 0.694789, acc: 0.501953]  [A loss: 0.728778, acc: 0.417969]\n",
            "9171: [D loss: 0.700830, acc: 0.544922]  [A loss: 0.858353, acc: 0.167969]\n",
            "9172: [D loss: 0.691340, acc: 0.546875]  [A loss: 0.741359, acc: 0.410156]\n",
            "9173: [D loss: 0.705866, acc: 0.527344]  [A loss: 1.031665, acc: 0.074219]\n",
            "9174: [D loss: 0.690101, acc: 0.537109]  [A loss: 0.696130, acc: 0.531250]\n",
            "9175: [D loss: 0.692663, acc: 0.554688]  [A loss: 0.812638, acc: 0.250000]\n",
            "9176: [D loss: 0.704291, acc: 0.519531]  [A loss: 0.723360, acc: 0.441406]\n",
            "9177: [D loss: 0.702326, acc: 0.500000]  [A loss: 0.854466, acc: 0.175781]\n",
            "9178: [D loss: 0.695807, acc: 0.527344]  [A loss: 0.735183, acc: 0.421875]\n",
            "9179: [D loss: 0.705419, acc: 0.533203]  [A loss: 0.801002, acc: 0.242188]\n",
            "9180: [D loss: 0.701678, acc: 0.511719]  [A loss: 0.743332, acc: 0.378906]\n",
            "9181: [D loss: 0.703215, acc: 0.496094]  [A loss: 0.824944, acc: 0.191406]\n",
            "9182: [D loss: 0.679994, acc: 0.585938]  [A loss: 0.734383, acc: 0.417969]\n",
            "9183: [D loss: 0.707700, acc: 0.511719]  [A loss: 0.954541, acc: 0.070312]\n",
            "9184: [D loss: 0.690794, acc: 0.535156]  [A loss: 0.721463, acc: 0.441406]\n",
            "9185: [D loss: 0.714270, acc: 0.484375]  [A loss: 0.876624, acc: 0.125000]\n",
            "9186: [D loss: 0.705061, acc: 0.496094]  [A loss: 0.695674, acc: 0.488281]\n",
            "9187: [D loss: 0.705579, acc: 0.519531]  [A loss: 0.832936, acc: 0.160156]\n",
            "9188: [D loss: 0.697110, acc: 0.527344]  [A loss: 0.739153, acc: 0.398438]\n",
            "9189: [D loss: 0.701186, acc: 0.523438]  [A loss: 0.805030, acc: 0.207031]\n",
            "9190: [D loss: 0.704347, acc: 0.490234]  [A loss: 0.759315, acc: 0.324219]\n",
            "9191: [D loss: 0.698956, acc: 0.523438]  [A loss: 0.755247, acc: 0.351562]\n",
            "9192: [D loss: 0.697266, acc: 0.513672]  [A loss: 0.801984, acc: 0.218750]\n",
            "9193: [D loss: 0.695549, acc: 0.539062]  [A loss: 0.815440, acc: 0.207031]\n",
            "9194: [D loss: 0.708637, acc: 0.486328]  [A loss: 0.775911, acc: 0.300781]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9195: [D loss: 0.706299, acc: 0.498047]  [A loss: 0.810888, acc: 0.226562]\n",
            "9196: [D loss: 0.695305, acc: 0.515625]  [A loss: 0.754633, acc: 0.371094]\n",
            "9197: [D loss: 0.693285, acc: 0.525391]  [A loss: 0.770772, acc: 0.320312]\n",
            "9198: [D loss: 0.714313, acc: 0.492188]  [A loss: 0.817194, acc: 0.203125]\n",
            "9199: [D loss: 0.705950, acc: 0.464844]  [A loss: 0.741237, acc: 0.375000]\n",
            "9200: [D loss: 0.702705, acc: 0.501953]  [A loss: 0.797050, acc: 0.261719]\n",
            "9201: [D loss: 0.697087, acc: 0.527344]  [A loss: 0.742932, acc: 0.421875]\n",
            "9202: [D loss: 0.717660, acc: 0.472656]  [A loss: 0.906778, acc: 0.074219]\n",
            "9203: [D loss: 0.694368, acc: 0.544922]  [A loss: 0.725261, acc: 0.433594]\n",
            "9204: [D loss: 0.693347, acc: 0.533203]  [A loss: 0.828311, acc: 0.148438]\n",
            "9205: [D loss: 0.703305, acc: 0.498047]  [A loss: 0.725730, acc: 0.453125]\n",
            "9206: [D loss: 0.703837, acc: 0.519531]  [A loss: 0.934106, acc: 0.089844]\n",
            "9207: [D loss: 0.692743, acc: 0.519531]  [A loss: 0.714888, acc: 0.472656]\n",
            "9208: [D loss: 0.715253, acc: 0.480469]  [A loss: 0.905030, acc: 0.093750]\n",
            "9209: [D loss: 0.698038, acc: 0.505859]  [A loss: 0.687076, acc: 0.570312]\n",
            "9210: [D loss: 0.713879, acc: 0.511719]  [A loss: 0.909303, acc: 0.089844]\n",
            "9211: [D loss: 0.698113, acc: 0.519531]  [A loss: 0.725200, acc: 0.437500]\n",
            "9212: [D loss: 0.700808, acc: 0.515625]  [A loss: 0.787740, acc: 0.273438]\n",
            "9213: [D loss: 0.696291, acc: 0.548828]  [A loss: 0.816973, acc: 0.273438]\n",
            "9214: [D loss: 0.700922, acc: 0.503906]  [A loss: 0.811172, acc: 0.238281]\n",
            "9215: [D loss: 0.704163, acc: 0.500000]  [A loss: 0.823012, acc: 0.207031]\n",
            "9216: [D loss: 0.696196, acc: 0.494141]  [A loss: 0.779630, acc: 0.281250]\n",
            "9217: [D loss: 0.699302, acc: 0.531250]  [A loss: 0.807248, acc: 0.273438]\n",
            "9218: [D loss: 0.700994, acc: 0.486328]  [A loss: 0.779611, acc: 0.308594]\n",
            "9219: [D loss: 0.694909, acc: 0.525391]  [A loss: 0.787265, acc: 0.242188]\n",
            "9220: [D loss: 0.703240, acc: 0.533203]  [A loss: 0.823612, acc: 0.238281]\n",
            "9221: [D loss: 0.691501, acc: 0.521484]  [A loss: 0.758017, acc: 0.363281]\n",
            "9222: [D loss: 0.705123, acc: 0.498047]  [A loss: 0.905611, acc: 0.109375]\n",
            "9223: [D loss: 0.694892, acc: 0.513672]  [A loss: 0.678813, acc: 0.554688]\n",
            "9224: [D loss: 0.713384, acc: 0.498047]  [A loss: 0.934369, acc: 0.105469]\n",
            "9225: [D loss: 0.703459, acc: 0.519531]  [A loss: 0.669424, acc: 0.593750]\n",
            "9226: [D loss: 0.716979, acc: 0.501953]  [A loss: 0.825736, acc: 0.222656]\n",
            "9227: [D loss: 0.689563, acc: 0.550781]  [A loss: 0.682730, acc: 0.550781]\n",
            "9228: [D loss: 0.700213, acc: 0.535156]  [A loss: 0.814821, acc: 0.226562]\n",
            "9229: [D loss: 0.689091, acc: 0.548828]  [A loss: 0.743391, acc: 0.417969]\n",
            "9230: [D loss: 0.711942, acc: 0.472656]  [A loss: 0.813207, acc: 0.242188]\n",
            "9231: [D loss: 0.705427, acc: 0.496094]  [A loss: 0.796145, acc: 0.296875]\n",
            "9232: [D loss: 0.698287, acc: 0.521484]  [A loss: 0.761584, acc: 0.343750]\n",
            "9233: [D loss: 0.705971, acc: 0.490234]  [A loss: 0.791043, acc: 0.273438]\n",
            "9234: [D loss: 0.694604, acc: 0.519531]  [A loss: 0.839343, acc: 0.222656]\n",
            "9235: [D loss: 0.691705, acc: 0.539062]  [A loss: 0.836459, acc: 0.226562]\n",
            "9236: [D loss: 0.706102, acc: 0.501953]  [A loss: 0.834070, acc: 0.210938]\n",
            "9237: [D loss: 0.714124, acc: 0.492188]  [A loss: 0.773855, acc: 0.324219]\n",
            "9238: [D loss: 0.700548, acc: 0.531250]  [A loss: 0.775768, acc: 0.308594]\n",
            "9239: [D loss: 0.693588, acc: 0.544922]  [A loss: 0.783151, acc: 0.269531]\n",
            "9240: [D loss: 0.705654, acc: 0.513672]  [A loss: 0.885461, acc: 0.148438]\n",
            "9241: [D loss: 0.705834, acc: 0.517578]  [A loss: 0.831302, acc: 0.203125]\n",
            "9242: [D loss: 0.697188, acc: 0.525391]  [A loss: 0.735751, acc: 0.429688]\n",
            "9243: [D loss: 0.714277, acc: 0.509766]  [A loss: 0.878055, acc: 0.125000]\n",
            "9244: [D loss: 0.699231, acc: 0.542969]  [A loss: 0.702803, acc: 0.496094]\n",
            "9245: [D loss: 0.709451, acc: 0.505859]  [A loss: 0.818064, acc: 0.226562]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9246: [D loss: 0.686702, acc: 0.546875]  [A loss: 0.716159, acc: 0.464844]\n",
            "9247: [D loss: 0.713467, acc: 0.505859]  [A loss: 0.960386, acc: 0.074219]\n",
            "9248: [D loss: 0.690077, acc: 0.556641]  [A loss: 0.706794, acc: 0.468750]\n",
            "9249: [D loss: 0.710411, acc: 0.517578]  [A loss: 0.831568, acc: 0.222656]\n",
            "9250: [D loss: 0.700701, acc: 0.535156]  [A loss: 0.753199, acc: 0.343750]\n",
            "9251: [D loss: 0.705654, acc: 0.519531]  [A loss: 0.835391, acc: 0.167969]\n",
            "9252: [D loss: 0.700066, acc: 0.511719]  [A loss: 0.779511, acc: 0.320312]\n",
            "9253: [D loss: 0.698554, acc: 0.525391]  [A loss: 0.848725, acc: 0.156250]\n",
            "9254: [D loss: 0.689780, acc: 0.533203]  [A loss: 0.794904, acc: 0.222656]\n",
            "9255: [D loss: 0.689031, acc: 0.554688]  [A loss: 0.849712, acc: 0.148438]\n",
            "9256: [D loss: 0.699614, acc: 0.515625]  [A loss: 0.745950, acc: 0.386719]\n",
            "9257: [D loss: 0.696285, acc: 0.541016]  [A loss: 0.802172, acc: 0.226562]\n",
            "9258: [D loss: 0.702786, acc: 0.498047]  [A loss: 0.796652, acc: 0.281250]\n",
            "9259: [D loss: 0.702935, acc: 0.507812]  [A loss: 0.758219, acc: 0.386719]\n",
            "9260: [D loss: 0.699345, acc: 0.529297]  [A loss: 0.847108, acc: 0.167969]\n",
            "9261: [D loss: 0.709409, acc: 0.486328]  [A loss: 0.811516, acc: 0.210938]\n",
            "9262: [D loss: 0.699998, acc: 0.517578]  [A loss: 0.779037, acc: 0.296875]\n",
            "9263: [D loss: 0.698877, acc: 0.523438]  [A loss: 0.857364, acc: 0.160156]\n",
            "9264: [D loss: 0.699119, acc: 0.501953]  [A loss: 0.722864, acc: 0.449219]\n",
            "9265: [D loss: 0.701757, acc: 0.521484]  [A loss: 0.912017, acc: 0.101562]\n",
            "9266: [D loss: 0.691036, acc: 0.521484]  [A loss: 0.706984, acc: 0.484375]\n",
            "9267: [D loss: 0.698010, acc: 0.527344]  [A loss: 0.874362, acc: 0.121094]\n",
            "9268: [D loss: 0.699207, acc: 0.505859]  [A loss: 0.661698, acc: 0.605469]\n",
            "9269: [D loss: 0.696443, acc: 0.535156]  [A loss: 0.850625, acc: 0.183594]\n",
            "9270: [D loss: 0.694789, acc: 0.519531]  [A loss: 0.687344, acc: 0.531250]\n",
            "9271: [D loss: 0.699368, acc: 0.519531]  [A loss: 0.853192, acc: 0.191406]\n",
            "9272: [D loss: 0.690289, acc: 0.544922]  [A loss: 0.752923, acc: 0.367188]\n",
            "9273: [D loss: 0.709240, acc: 0.525391]  [A loss: 0.818476, acc: 0.210938]\n",
            "9274: [D loss: 0.703528, acc: 0.480469]  [A loss: 0.813052, acc: 0.253906]\n",
            "9275: [D loss: 0.704382, acc: 0.507812]  [A loss: 0.794342, acc: 0.265625]\n",
            "9276: [D loss: 0.703114, acc: 0.505859]  [A loss: 0.855422, acc: 0.171875]\n",
            "9277: [D loss: 0.692173, acc: 0.552734]  [A loss: 0.772993, acc: 0.292969]\n",
            "9278: [D loss: 0.706071, acc: 0.496094]  [A loss: 0.810449, acc: 0.199219]\n",
            "9279: [D loss: 0.701056, acc: 0.498047]  [A loss: 0.805257, acc: 0.210938]\n",
            "9280: [D loss: 0.694593, acc: 0.523438]  [A loss: 0.780176, acc: 0.328125]\n",
            "9281: [D loss: 0.699635, acc: 0.515625]  [A loss: 0.865204, acc: 0.125000]\n",
            "9282: [D loss: 0.703818, acc: 0.496094]  [A loss: 0.688102, acc: 0.503906]\n",
            "9283: [D loss: 0.711467, acc: 0.503906]  [A loss: 0.911276, acc: 0.062500]\n",
            "9284: [D loss: 0.712239, acc: 0.451172]  [A loss: 0.720760, acc: 0.464844]\n",
            "9285: [D loss: 0.704786, acc: 0.523438]  [A loss: 0.864243, acc: 0.128906]\n",
            "9286: [D loss: 0.703976, acc: 0.503906]  [A loss: 0.678577, acc: 0.578125]\n",
            "9287: [D loss: 0.703948, acc: 0.525391]  [A loss: 0.858795, acc: 0.136719]\n",
            "9288: [D loss: 0.701324, acc: 0.498047]  [A loss: 0.717151, acc: 0.437500]\n",
            "9289: [D loss: 0.720897, acc: 0.496094]  [A loss: 0.888461, acc: 0.066406]\n",
            "9290: [D loss: 0.701514, acc: 0.492188]  [A loss: 0.709084, acc: 0.398438]\n",
            "9291: [D loss: 0.701301, acc: 0.529297]  [A loss: 0.862754, acc: 0.125000]\n",
            "9292: [D loss: 0.696858, acc: 0.527344]  [A loss: 0.791102, acc: 0.273438]\n",
            "9293: [D loss: 0.693814, acc: 0.519531]  [A loss: 0.753476, acc: 0.351562]\n",
            "9294: [D loss: 0.710660, acc: 0.466797]  [A loss: 0.801909, acc: 0.277344]\n",
            "9295: [D loss: 0.706349, acc: 0.501953]  [A loss: 0.796768, acc: 0.261719]\n",
            "9296: [D loss: 0.708763, acc: 0.470703]  [A loss: 0.791122, acc: 0.253906]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9297: [D loss: 0.688748, acc: 0.535156]  [A loss: 0.774175, acc: 0.324219]\n",
            "9298: [D loss: 0.707316, acc: 0.498047]  [A loss: 0.793944, acc: 0.246094]\n",
            "9299: [D loss: 0.701320, acc: 0.486328]  [A loss: 0.788058, acc: 0.273438]\n",
            "9300: [D loss: 0.705120, acc: 0.486328]  [A loss: 0.821208, acc: 0.214844]\n",
            "9301: [D loss: 0.695457, acc: 0.529297]  [A loss: 0.756206, acc: 0.339844]\n",
            "9302: [D loss: 0.703412, acc: 0.511719]  [A loss: 0.883180, acc: 0.128906]\n",
            "9303: [D loss: 0.694777, acc: 0.541016]  [A loss: 0.667100, acc: 0.585938]\n",
            "9304: [D loss: 0.715424, acc: 0.505859]  [A loss: 0.839983, acc: 0.179688]\n",
            "9305: [D loss: 0.685015, acc: 0.521484]  [A loss: 0.728071, acc: 0.402344]\n",
            "9306: [D loss: 0.704701, acc: 0.527344]  [A loss: 0.821279, acc: 0.222656]\n",
            "9307: [D loss: 0.699986, acc: 0.509766]  [A loss: 0.751279, acc: 0.332031]\n",
            "9308: [D loss: 0.703625, acc: 0.488281]  [A loss: 0.849716, acc: 0.148438]\n",
            "9309: [D loss: 0.698192, acc: 0.527344]  [A loss: 0.750095, acc: 0.355469]\n",
            "9310: [D loss: 0.702677, acc: 0.505859]  [A loss: 0.886897, acc: 0.109375]\n",
            "9311: [D loss: 0.709557, acc: 0.462891]  [A loss: 0.691925, acc: 0.562500]\n",
            "9312: [D loss: 0.713990, acc: 0.494141]  [A loss: 0.851178, acc: 0.121094]\n",
            "9313: [D loss: 0.693580, acc: 0.511719]  [A loss: 0.699074, acc: 0.550781]\n",
            "9314: [D loss: 0.725385, acc: 0.468750]  [A loss: 0.862465, acc: 0.156250]\n",
            "9315: [D loss: 0.683542, acc: 0.539062]  [A loss: 0.764157, acc: 0.332031]\n",
            "9316: [D loss: 0.700344, acc: 0.511719]  [A loss: 0.783081, acc: 0.277344]\n",
            "9317: [D loss: 0.698027, acc: 0.537109]  [A loss: 0.798027, acc: 0.238281]\n",
            "9318: [D loss: 0.701535, acc: 0.503906]  [A loss: 0.751654, acc: 0.375000]\n",
            "9319: [D loss: 0.705831, acc: 0.503906]  [A loss: 0.742182, acc: 0.367188]\n",
            "9320: [D loss: 0.691864, acc: 0.552734]  [A loss: 0.823145, acc: 0.199219]\n",
            "9321: [D loss: 0.706082, acc: 0.505859]  [A loss: 0.770569, acc: 0.332031]\n",
            "9322: [D loss: 0.697013, acc: 0.513672]  [A loss: 0.847784, acc: 0.207031]\n",
            "9323: [D loss: 0.701403, acc: 0.511719]  [A loss: 0.761457, acc: 0.320312]\n",
            "9324: [D loss: 0.698642, acc: 0.517578]  [A loss: 0.837038, acc: 0.183594]\n",
            "9325: [D loss: 0.688061, acc: 0.552734]  [A loss: 0.704145, acc: 0.503906]\n",
            "9326: [D loss: 0.713284, acc: 0.503906]  [A loss: 0.899736, acc: 0.117188]\n",
            "9327: [D loss: 0.689119, acc: 0.521484]  [A loss: 0.709140, acc: 0.492188]\n",
            "9328: [D loss: 0.699279, acc: 0.515625]  [A loss: 0.854473, acc: 0.175781]\n",
            "9329: [D loss: 0.708698, acc: 0.482422]  [A loss: 0.758408, acc: 0.335938]\n",
            "9330: [D loss: 0.705504, acc: 0.505859]  [A loss: 0.887423, acc: 0.156250]\n",
            "9331: [D loss: 0.697121, acc: 0.525391]  [A loss: 0.710647, acc: 0.445312]\n",
            "9332: [D loss: 0.706670, acc: 0.519531]  [A loss: 0.911701, acc: 0.078125]\n",
            "9333: [D loss: 0.708304, acc: 0.484375]  [A loss: 0.684159, acc: 0.527344]\n",
            "9334: [D loss: 0.710069, acc: 0.511719]  [A loss: 0.850129, acc: 0.160156]\n",
            "9335: [D loss: 0.687043, acc: 0.521484]  [A loss: 0.727361, acc: 0.414062]\n",
            "9336: [D loss: 0.705664, acc: 0.527344]  [A loss: 0.796433, acc: 0.246094]\n",
            "9337: [D loss: 0.697200, acc: 0.531250]  [A loss: 0.769183, acc: 0.328125]\n",
            "9338: [D loss: 0.701402, acc: 0.519531]  [A loss: 0.764535, acc: 0.378906]\n",
            "9339: [D loss: 0.699699, acc: 0.552734]  [A loss: 0.833053, acc: 0.171875]\n",
            "9340: [D loss: 0.708939, acc: 0.472656]  [A loss: 0.742602, acc: 0.371094]\n",
            "9341: [D loss: 0.717662, acc: 0.470703]  [A loss: 0.891353, acc: 0.132812]\n",
            "9342: [D loss: 0.704375, acc: 0.484375]  [A loss: 0.754757, acc: 0.363281]\n",
            "9343: [D loss: 0.702846, acc: 0.501953]  [A loss: 0.810594, acc: 0.203125]\n",
            "9344: [D loss: 0.711561, acc: 0.486328]  [A loss: 0.777441, acc: 0.281250]\n",
            "9345: [D loss: 0.699172, acc: 0.507812]  [A loss: 0.771204, acc: 0.312500]\n",
            "9346: [D loss: 0.694120, acc: 0.527344]  [A loss: 0.816766, acc: 0.222656]\n",
            "9347: [D loss: 0.696632, acc: 0.505859]  [A loss: 0.768157, acc: 0.324219]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9348: [D loss: 0.700551, acc: 0.494141]  [A loss: 0.831562, acc: 0.187500]\n",
            "9349: [D loss: 0.700933, acc: 0.513672]  [A loss: 0.800503, acc: 0.250000]\n",
            "9350: [D loss: 0.707224, acc: 0.478516]  [A loss: 0.824569, acc: 0.167969]\n",
            "9351: [D loss: 0.704166, acc: 0.482422]  [A loss: 0.769181, acc: 0.253906]\n",
            "9352: [D loss: 0.702655, acc: 0.490234]  [A loss: 0.863202, acc: 0.156250]\n",
            "9353: [D loss: 0.706651, acc: 0.507812]  [A loss: 0.777692, acc: 0.347656]\n",
            "9354: [D loss: 0.696688, acc: 0.517578]  [A loss: 0.806619, acc: 0.230469]\n",
            "9355: [D loss: 0.699119, acc: 0.539062]  [A loss: 0.779641, acc: 0.292969]\n",
            "9356: [D loss: 0.708729, acc: 0.478516]  [A loss: 0.820733, acc: 0.222656]\n",
            "9357: [D loss: 0.703256, acc: 0.507812]  [A loss: 0.805971, acc: 0.226562]\n",
            "9358: [D loss: 0.698997, acc: 0.496094]  [A loss: 0.831919, acc: 0.160156]\n",
            "9359: [D loss: 0.703901, acc: 0.505859]  [A loss: 0.761404, acc: 0.324219]\n",
            "9360: [D loss: 0.698038, acc: 0.507812]  [A loss: 0.882774, acc: 0.085938]\n",
            "9361: [D loss: 0.694837, acc: 0.523438]  [A loss: 0.694332, acc: 0.539062]\n",
            "9362: [D loss: 0.712180, acc: 0.501953]  [A loss: 1.000588, acc: 0.074219]\n",
            "9363: [D loss: 0.706041, acc: 0.492188]  [A loss: 0.763283, acc: 0.351562]\n",
            "9364: [D loss: 0.700176, acc: 0.535156]  [A loss: 0.972509, acc: 0.042969]\n",
            "9365: [D loss: 0.699187, acc: 0.505859]  [A loss: 0.678866, acc: 0.558594]\n",
            "9366: [D loss: 0.710052, acc: 0.521484]  [A loss: 0.871699, acc: 0.121094]\n",
            "9367: [D loss: 0.696651, acc: 0.488281]  [A loss: 0.713883, acc: 0.480469]\n",
            "9368: [D loss: 0.710523, acc: 0.486328]  [A loss: 0.823529, acc: 0.164062]\n",
            "9369: [D loss: 0.716091, acc: 0.494141]  [A loss: 0.795069, acc: 0.238281]\n",
            "9370: [D loss: 0.689819, acc: 0.537109]  [A loss: 0.788659, acc: 0.242188]\n",
            "9371: [D loss: 0.705952, acc: 0.509766]  [A loss: 0.765767, acc: 0.292969]\n",
            "9372: [D loss: 0.702202, acc: 0.488281]  [A loss: 0.795784, acc: 0.246094]\n",
            "9373: [D loss: 0.706963, acc: 0.486328]  [A loss: 0.781471, acc: 0.308594]\n",
            "9374: [D loss: 0.699174, acc: 0.509766]  [A loss: 0.777714, acc: 0.265625]\n",
            "9375: [D loss: 0.698738, acc: 0.505859]  [A loss: 0.759953, acc: 0.312500]\n",
            "9376: [D loss: 0.696588, acc: 0.525391]  [A loss: 0.881417, acc: 0.144531]\n",
            "9377: [D loss: 0.701973, acc: 0.505859]  [A loss: 0.666986, acc: 0.625000]\n",
            "9378: [D loss: 0.707702, acc: 0.519531]  [A loss: 0.902250, acc: 0.078125]\n",
            "9379: [D loss: 0.704176, acc: 0.500000]  [A loss: 0.708329, acc: 0.492188]\n",
            "9380: [D loss: 0.709803, acc: 0.521484]  [A loss: 0.863073, acc: 0.109375]\n",
            "9381: [D loss: 0.705269, acc: 0.492188]  [A loss: 0.686927, acc: 0.554688]\n",
            "9382: [D loss: 0.708108, acc: 0.488281]  [A loss: 0.842827, acc: 0.156250]\n",
            "9383: [D loss: 0.695912, acc: 0.513672]  [A loss: 0.727811, acc: 0.394531]\n",
            "9384: [D loss: 0.702465, acc: 0.505859]  [A loss: 0.796994, acc: 0.238281]\n",
            "9385: [D loss: 0.707438, acc: 0.509766]  [A loss: 0.823045, acc: 0.195312]\n",
            "9386: [D loss: 0.712563, acc: 0.498047]  [A loss: 0.805764, acc: 0.203125]\n",
            "9387: [D loss: 0.698302, acc: 0.505859]  [A loss: 0.761542, acc: 0.312500]\n",
            "9388: [D loss: 0.702290, acc: 0.500000]  [A loss: 0.856522, acc: 0.117188]\n",
            "9389: [D loss: 0.702186, acc: 0.498047]  [A loss: 0.664356, acc: 0.566406]\n",
            "9390: [D loss: 0.714540, acc: 0.533203]  [A loss: 0.913162, acc: 0.054688]\n",
            "9391: [D loss: 0.691197, acc: 0.535156]  [A loss: 0.689308, acc: 0.535156]\n",
            "9392: [D loss: 0.713106, acc: 0.511719]  [A loss: 0.909914, acc: 0.078125]\n",
            "9393: [D loss: 0.694542, acc: 0.529297]  [A loss: 0.693596, acc: 0.550781]\n",
            "9394: [D loss: 0.708675, acc: 0.503906]  [A loss: 0.824967, acc: 0.183594]\n",
            "9395: [D loss: 0.699476, acc: 0.500000]  [A loss: 0.706929, acc: 0.441406]\n",
            "9396: [D loss: 0.702884, acc: 0.523438]  [A loss: 0.781820, acc: 0.296875]\n",
            "9397: [D loss: 0.703802, acc: 0.513672]  [A loss: 0.738218, acc: 0.363281]\n",
            "9398: [D loss: 0.715581, acc: 0.501953]  [A loss: 0.799372, acc: 0.250000]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9399: [D loss: 0.693013, acc: 0.507812]  [A loss: 0.718827, acc: 0.406250]\n",
            "9400: [D loss: 0.712808, acc: 0.501953]  [A loss: 0.844176, acc: 0.156250]\n",
            "9401: [D loss: 0.699395, acc: 0.505859]  [A loss: 0.746778, acc: 0.320312]\n",
            "9402: [D loss: 0.698919, acc: 0.525391]  [A loss: 0.871435, acc: 0.105469]\n",
            "9403: [D loss: 0.699208, acc: 0.527344]  [A loss: 0.733443, acc: 0.402344]\n",
            "9404: [D loss: 0.705852, acc: 0.486328]  [A loss: 0.811596, acc: 0.203125]\n",
            "9405: [D loss: 0.696139, acc: 0.521484]  [A loss: 0.737133, acc: 0.410156]\n",
            "9406: [D loss: 0.708976, acc: 0.488281]  [A loss: 0.850338, acc: 0.148438]\n",
            "9407: [D loss: 0.701365, acc: 0.519531]  [A loss: 0.737822, acc: 0.421875]\n",
            "9408: [D loss: 0.711279, acc: 0.501953]  [A loss: 0.909898, acc: 0.070312]\n",
            "9409: [D loss: 0.697263, acc: 0.505859]  [A loss: 0.685708, acc: 0.535156]\n",
            "9410: [D loss: 0.708782, acc: 0.511719]  [A loss: 0.846096, acc: 0.160156]\n",
            "9411: [D loss: 0.697805, acc: 0.529297]  [A loss: 0.718550, acc: 0.437500]\n",
            "9412: [D loss: 0.698351, acc: 0.523438]  [A loss: 0.835015, acc: 0.156250]\n",
            "9413: [D loss: 0.701002, acc: 0.480469]  [A loss: 0.759106, acc: 0.324219]\n",
            "9414: [D loss: 0.692077, acc: 0.544922]  [A loss: 0.791745, acc: 0.222656]\n",
            "9415: [D loss: 0.693601, acc: 0.527344]  [A loss: 0.770059, acc: 0.347656]\n",
            "9416: [D loss: 0.697799, acc: 0.533203]  [A loss: 0.890477, acc: 0.105469]\n",
            "9417: [D loss: 0.686630, acc: 0.541016]  [A loss: 0.760438, acc: 0.343750]\n",
            "9418: [D loss: 0.700615, acc: 0.527344]  [A loss: 0.827195, acc: 0.207031]\n",
            "9419: [D loss: 0.695936, acc: 0.513672]  [A loss: 0.738042, acc: 0.398438]\n",
            "9420: [D loss: 0.708293, acc: 0.515625]  [A loss: 0.862702, acc: 0.101562]\n",
            "9421: [D loss: 0.705661, acc: 0.488281]  [A loss: 0.729819, acc: 0.394531]\n",
            "9422: [D loss: 0.706602, acc: 0.511719]  [A loss: 0.824191, acc: 0.222656]\n",
            "9423: [D loss: 0.691313, acc: 0.539062]  [A loss: 0.746893, acc: 0.347656]\n",
            "9424: [D loss: 0.705687, acc: 0.494141]  [A loss: 0.894706, acc: 0.070312]\n",
            "9425: [D loss: 0.699338, acc: 0.513672]  [A loss: 0.742069, acc: 0.375000]\n",
            "9426: [D loss: 0.707230, acc: 0.513672]  [A loss: 0.862150, acc: 0.101562]\n",
            "9427: [D loss: 0.700433, acc: 0.509766]  [A loss: 0.735400, acc: 0.417969]\n",
            "9428: [D loss: 0.695676, acc: 0.521484]  [A loss: 0.827338, acc: 0.207031]\n",
            "9429: [D loss: 0.701166, acc: 0.494141]  [A loss: 0.770788, acc: 0.328125]\n",
            "9430: [D loss: 0.702221, acc: 0.501953]  [A loss: 0.774559, acc: 0.285156]\n",
            "9431: [D loss: 0.702347, acc: 0.494141]  [A loss: 0.790266, acc: 0.257812]\n",
            "9432: [D loss: 0.698282, acc: 0.513672]  [A loss: 0.818249, acc: 0.164062]\n",
            "9433: [D loss: 0.691060, acc: 0.500000]  [A loss: 0.725298, acc: 0.410156]\n",
            "9434: [D loss: 0.702646, acc: 0.492188]  [A loss: 0.817912, acc: 0.191406]\n",
            "9435: [D loss: 0.691105, acc: 0.539062]  [A loss: 0.724190, acc: 0.417969]\n",
            "9436: [D loss: 0.706789, acc: 0.498047]  [A loss: 0.815492, acc: 0.226562]\n",
            "9437: [D loss: 0.693720, acc: 0.525391]  [A loss: 0.699358, acc: 0.484375]\n",
            "9438: [D loss: 0.704159, acc: 0.521484]  [A loss: 0.801723, acc: 0.238281]\n",
            "9439: [D loss: 0.702834, acc: 0.505859]  [A loss: 0.729764, acc: 0.433594]\n",
            "9440: [D loss: 0.707524, acc: 0.490234]  [A loss: 0.849902, acc: 0.179688]\n",
            "9441: [D loss: 0.686809, acc: 0.552734]  [A loss: 0.747444, acc: 0.378906]\n",
            "9442: [D loss: 0.697001, acc: 0.533203]  [A loss: 0.847775, acc: 0.164062]\n",
            "9443: [D loss: 0.695871, acc: 0.525391]  [A loss: 0.720522, acc: 0.437500]\n",
            "9444: [D loss: 0.715177, acc: 0.513672]  [A loss: 0.864557, acc: 0.156250]\n",
            "9445: [D loss: 0.715085, acc: 0.468750]  [A loss: 0.715340, acc: 0.437500]\n",
            "9446: [D loss: 0.702363, acc: 0.511719]  [A loss: 0.837414, acc: 0.175781]\n",
            "9447: [D loss: 0.700428, acc: 0.527344]  [A loss: 0.745732, acc: 0.371094]\n",
            "9448: [D loss: 0.707677, acc: 0.521484]  [A loss: 0.846060, acc: 0.175781]\n",
            "9449: [D loss: 0.693859, acc: 0.529297]  [A loss: 0.692308, acc: 0.535156]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9450: [D loss: 0.707792, acc: 0.498047]  [A loss: 0.946865, acc: 0.074219]\n",
            "9451: [D loss: 0.697336, acc: 0.525391]  [A loss: 0.660044, acc: 0.605469]\n",
            "9452: [D loss: 0.708593, acc: 0.486328]  [A loss: 0.837125, acc: 0.160156]\n",
            "9453: [D loss: 0.689905, acc: 0.552734]  [A loss: 0.758434, acc: 0.335938]\n",
            "9454: [D loss: 0.705934, acc: 0.507812]  [A loss: 0.791897, acc: 0.257812]\n",
            "9455: [D loss: 0.699782, acc: 0.498047]  [A loss: 0.760769, acc: 0.285156]\n",
            "9456: [D loss: 0.712193, acc: 0.490234]  [A loss: 0.867228, acc: 0.128906]\n",
            "9457: [D loss: 0.688428, acc: 0.535156]  [A loss: 0.698561, acc: 0.480469]\n",
            "9458: [D loss: 0.701052, acc: 0.531250]  [A loss: 0.891996, acc: 0.117188]\n",
            "9459: [D loss: 0.686292, acc: 0.535156]  [A loss: 0.713762, acc: 0.472656]\n",
            "9460: [D loss: 0.711712, acc: 0.494141]  [A loss: 0.905116, acc: 0.113281]\n",
            "9461: [D loss: 0.694671, acc: 0.519531]  [A loss: 0.713426, acc: 0.476562]\n",
            "9462: [D loss: 0.715530, acc: 0.511719]  [A loss: 0.850665, acc: 0.164062]\n",
            "9463: [D loss: 0.693764, acc: 0.541016]  [A loss: 0.710247, acc: 0.476562]\n",
            "9464: [D loss: 0.717242, acc: 0.480469]  [A loss: 0.833446, acc: 0.148438]\n",
            "9465: [D loss: 0.708011, acc: 0.488281]  [A loss: 0.712438, acc: 0.453125]\n",
            "9466: [D loss: 0.705347, acc: 0.501953]  [A loss: 0.796636, acc: 0.250000]\n",
            "9467: [D loss: 0.701828, acc: 0.503906]  [A loss: 0.747740, acc: 0.320312]\n",
            "9468: [D loss: 0.695170, acc: 0.531250]  [A loss: 0.822534, acc: 0.199219]\n",
            "9469: [D loss: 0.699881, acc: 0.501953]  [A loss: 0.801076, acc: 0.265625]\n",
            "9470: [D loss: 0.697009, acc: 0.535156]  [A loss: 0.757824, acc: 0.351562]\n",
            "9471: [D loss: 0.711764, acc: 0.472656]  [A loss: 0.826022, acc: 0.179688]\n",
            "9472: [D loss: 0.687501, acc: 0.529297]  [A loss: 0.768892, acc: 0.308594]\n",
            "9473: [D loss: 0.692062, acc: 0.541016]  [A loss: 0.810017, acc: 0.207031]\n",
            "9474: [D loss: 0.696870, acc: 0.521484]  [A loss: 0.767397, acc: 0.312500]\n",
            "9475: [D loss: 0.705340, acc: 0.511719]  [A loss: 0.890234, acc: 0.105469]\n",
            "9476: [D loss: 0.706221, acc: 0.488281]  [A loss: 0.727240, acc: 0.445312]\n",
            "9477: [D loss: 0.701154, acc: 0.531250]  [A loss: 0.926489, acc: 0.058594]\n",
            "9478: [D loss: 0.709477, acc: 0.496094]  [A loss: 0.678665, acc: 0.589844]\n",
            "9479: [D loss: 0.706861, acc: 0.521484]  [A loss: 0.931170, acc: 0.058594]\n",
            "9480: [D loss: 0.702064, acc: 0.517578]  [A loss: 0.718462, acc: 0.449219]\n",
            "9481: [D loss: 0.704382, acc: 0.490234]  [A loss: 0.791967, acc: 0.234375]\n",
            "9482: [D loss: 0.700440, acc: 0.509766]  [A loss: 0.742957, acc: 0.382812]\n",
            "9483: [D loss: 0.704758, acc: 0.500000]  [A loss: 0.782481, acc: 0.261719]\n",
            "9484: [D loss: 0.688037, acc: 0.533203]  [A loss: 0.772598, acc: 0.347656]\n",
            "9485: [D loss: 0.696425, acc: 0.515625]  [A loss: 0.822176, acc: 0.210938]\n",
            "9486: [D loss: 0.704717, acc: 0.501953]  [A loss: 0.782306, acc: 0.304688]\n",
            "9487: [D loss: 0.708064, acc: 0.515625]  [A loss: 0.814003, acc: 0.199219]\n",
            "9488: [D loss: 0.700656, acc: 0.501953]  [A loss: 0.773724, acc: 0.285156]\n",
            "9489: [D loss: 0.694947, acc: 0.554688]  [A loss: 0.746794, acc: 0.363281]\n",
            "9490: [D loss: 0.697291, acc: 0.515625]  [A loss: 0.853982, acc: 0.093750]\n",
            "9491: [D loss: 0.701018, acc: 0.517578]  [A loss: 0.783684, acc: 0.277344]\n",
            "9492: [D loss: 0.710355, acc: 0.498047]  [A loss: 0.854297, acc: 0.121094]\n",
            "9493: [D loss: 0.702951, acc: 0.470703]  [A loss: 0.716450, acc: 0.406250]\n",
            "9494: [D loss: 0.712366, acc: 0.494141]  [A loss: 0.875874, acc: 0.109375]\n",
            "9495: [D loss: 0.701543, acc: 0.503906]  [A loss: 0.723233, acc: 0.445312]\n",
            "9496: [D loss: 0.712172, acc: 0.478516]  [A loss: 0.853849, acc: 0.132812]\n",
            "9497: [D loss: 0.699488, acc: 0.503906]  [A loss: 0.715281, acc: 0.464844]\n",
            "9498: [D loss: 0.703367, acc: 0.521484]  [A loss: 0.828441, acc: 0.171875]\n",
            "9499: [D loss: 0.701326, acc: 0.472656]  [A loss: 0.768702, acc: 0.316406]\n",
            "9500: [D loss: 0.711380, acc: 0.492188]  [A loss: 0.840298, acc: 0.203125]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9501: [D loss: 0.691013, acc: 0.533203]  [A loss: 0.703176, acc: 0.500000]\n",
            "9502: [D loss: 0.699934, acc: 0.511719]  [A loss: 0.899630, acc: 0.128906]\n",
            "9503: [D loss: 0.709878, acc: 0.484375]  [A loss: 0.714119, acc: 0.457031]\n",
            "9504: [D loss: 0.712459, acc: 0.505859]  [A loss: 0.838480, acc: 0.144531]\n",
            "9505: [D loss: 0.693574, acc: 0.511719]  [A loss: 0.779106, acc: 0.289062]\n",
            "9506: [D loss: 0.697307, acc: 0.505859]  [A loss: 0.781832, acc: 0.261719]\n",
            "9507: [D loss: 0.697006, acc: 0.500000]  [A loss: 0.781830, acc: 0.253906]\n",
            "9508: [D loss: 0.694119, acc: 0.519531]  [A loss: 0.783101, acc: 0.300781]\n",
            "9509: [D loss: 0.698928, acc: 0.531250]  [A loss: 0.803733, acc: 0.187500]\n",
            "9510: [D loss: 0.699023, acc: 0.533203]  [A loss: 0.891026, acc: 0.082031]\n",
            "9511: [D loss: 0.699037, acc: 0.500000]  [A loss: 0.715874, acc: 0.464844]\n",
            "9512: [D loss: 0.706622, acc: 0.517578]  [A loss: 0.939838, acc: 0.058594]\n",
            "9513: [D loss: 0.696947, acc: 0.496094]  [A loss: 0.709229, acc: 0.445312]\n",
            "9514: [D loss: 0.702297, acc: 0.501953]  [A loss: 0.805759, acc: 0.226562]\n",
            "9515: [D loss: 0.702357, acc: 0.488281]  [A loss: 0.768164, acc: 0.308594]\n",
            "9516: [D loss: 0.712120, acc: 0.494141]  [A loss: 0.858253, acc: 0.171875]\n",
            "9517: [D loss: 0.700800, acc: 0.492188]  [A loss: 0.712447, acc: 0.484375]\n",
            "9518: [D loss: 0.706424, acc: 0.509766]  [A loss: 0.860502, acc: 0.152344]\n",
            "9519: [D loss: 0.704642, acc: 0.488281]  [A loss: 0.719521, acc: 0.460938]\n",
            "9520: [D loss: 0.706137, acc: 0.509766]  [A loss: 0.815726, acc: 0.199219]\n",
            "9521: [D loss: 0.694871, acc: 0.513672]  [A loss: 0.729058, acc: 0.406250]\n",
            "9522: [D loss: 0.694948, acc: 0.541016]  [A loss: 0.830056, acc: 0.175781]\n",
            "9523: [D loss: 0.689721, acc: 0.535156]  [A loss: 0.702686, acc: 0.519531]\n",
            "9524: [D loss: 0.723190, acc: 0.494141]  [A loss: 0.890633, acc: 0.109375]\n",
            "9525: [D loss: 0.698300, acc: 0.505859]  [A loss: 0.694119, acc: 0.511719]\n",
            "9526: [D loss: 0.710273, acc: 0.501953]  [A loss: 0.828920, acc: 0.160156]\n",
            "9527: [D loss: 0.691548, acc: 0.517578]  [A loss: 0.796074, acc: 0.246094]\n",
            "9528: [D loss: 0.702425, acc: 0.500000]  [A loss: 0.774211, acc: 0.292969]\n",
            "9529: [D loss: 0.700543, acc: 0.501953]  [A loss: 0.845828, acc: 0.132812]\n",
            "9530: [D loss: 0.702368, acc: 0.500000]  [A loss: 0.763005, acc: 0.332031]\n",
            "9531: [D loss: 0.702207, acc: 0.515625]  [A loss: 0.858788, acc: 0.160156]\n",
            "9532: [D loss: 0.700598, acc: 0.503906]  [A loss: 0.732788, acc: 0.410156]\n",
            "9533: [D loss: 0.701329, acc: 0.513672]  [A loss: 0.859619, acc: 0.207031]\n",
            "9534: [D loss: 0.698421, acc: 0.511719]  [A loss: 0.792870, acc: 0.273438]\n",
            "9535: [D loss: 0.703293, acc: 0.500000]  [A loss: 0.810605, acc: 0.218750]\n",
            "9536: [D loss: 0.705508, acc: 0.507812]  [A loss: 0.798056, acc: 0.222656]\n",
            "9537: [D loss: 0.700984, acc: 0.511719]  [A loss: 0.795888, acc: 0.257812]\n",
            "9538: [D loss: 0.709804, acc: 0.505859]  [A loss: 0.802382, acc: 0.250000]\n",
            "9539: [D loss: 0.700759, acc: 0.511719]  [A loss: 0.828226, acc: 0.191406]\n",
            "9540: [D loss: 0.698089, acc: 0.519531]  [A loss: 0.819599, acc: 0.199219]\n",
            "9541: [D loss: 0.694476, acc: 0.542969]  [A loss: 0.832141, acc: 0.167969]\n",
            "9542: [D loss: 0.699981, acc: 0.527344]  [A loss: 0.809822, acc: 0.207031]\n",
            "9543: [D loss: 0.692437, acc: 0.531250]  [A loss: 0.846085, acc: 0.128906]\n",
            "9544: [D loss: 0.694045, acc: 0.533203]  [A loss: 0.780215, acc: 0.308594]\n",
            "9545: [D loss: 0.697727, acc: 0.539062]  [A loss: 0.838580, acc: 0.203125]\n",
            "9546: [D loss: 0.695607, acc: 0.535156]  [A loss: 0.799128, acc: 0.324219]\n",
            "9547: [D loss: 0.693940, acc: 0.525391]  [A loss: 0.874799, acc: 0.113281]\n",
            "9548: [D loss: 0.699934, acc: 0.521484]  [A loss: 0.761689, acc: 0.332031]\n",
            "9549: [D loss: 0.706801, acc: 0.501953]  [A loss: 0.788202, acc: 0.277344]\n",
            "9550: [D loss: 0.703073, acc: 0.507812]  [A loss: 0.844600, acc: 0.152344]\n",
            "9551: [D loss: 0.694156, acc: 0.519531]  [A loss: 0.692510, acc: 0.539062]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9552: [D loss: 0.692802, acc: 0.550781]  [A loss: 0.941932, acc: 0.066406]\n",
            "9553: [D loss: 0.699164, acc: 0.513672]  [A loss: 0.674238, acc: 0.597656]\n",
            "9554: [D loss: 0.725035, acc: 0.486328]  [A loss: 0.967745, acc: 0.050781]\n",
            "9555: [D loss: 0.710003, acc: 0.478516]  [A loss: 0.669858, acc: 0.582031]\n",
            "9556: [D loss: 0.709413, acc: 0.503906]  [A loss: 0.833228, acc: 0.144531]\n",
            "9557: [D loss: 0.699555, acc: 0.527344]  [A loss: 0.733705, acc: 0.382812]\n",
            "9558: [D loss: 0.708591, acc: 0.523438]  [A loss: 0.798340, acc: 0.210938]\n",
            "9559: [D loss: 0.691293, acc: 0.533203]  [A loss: 0.820695, acc: 0.250000]\n",
            "9560: [D loss: 0.709083, acc: 0.482422]  [A loss: 0.708088, acc: 0.472656]\n",
            "9561: [D loss: 0.704413, acc: 0.531250]  [A loss: 0.822915, acc: 0.171875]\n",
            "9562: [D loss: 0.700525, acc: 0.509766]  [A loss: 0.726276, acc: 0.386719]\n",
            "9563: [D loss: 0.697042, acc: 0.533203]  [A loss: 0.816894, acc: 0.187500]\n",
            "9564: [D loss: 0.699054, acc: 0.486328]  [A loss: 0.721760, acc: 0.449219]\n",
            "9565: [D loss: 0.707911, acc: 0.509766]  [A loss: 0.851553, acc: 0.171875]\n",
            "9566: [D loss: 0.682775, acc: 0.568359]  [A loss: 0.777790, acc: 0.300781]\n",
            "9567: [D loss: 0.709725, acc: 0.496094]  [A loss: 0.808871, acc: 0.230469]\n",
            "9568: [D loss: 0.704298, acc: 0.505859]  [A loss: 0.790141, acc: 0.238281]\n",
            "9569: [D loss: 0.707503, acc: 0.478516]  [A loss: 0.837229, acc: 0.164062]\n",
            "9570: [D loss: 0.693803, acc: 0.533203]  [A loss: 0.781640, acc: 0.257812]\n",
            "9571: [D loss: 0.694042, acc: 0.527344]  [A loss: 0.836236, acc: 0.199219]\n",
            "9572: [D loss: 0.696517, acc: 0.503906]  [A loss: 0.750040, acc: 0.375000]\n",
            "9573: [D loss: 0.707514, acc: 0.513672]  [A loss: 0.780550, acc: 0.273438]\n",
            "9574: [D loss: 0.688930, acc: 0.544922]  [A loss: 0.787285, acc: 0.316406]\n",
            "9575: [D loss: 0.703987, acc: 0.513672]  [A loss: 0.805544, acc: 0.250000]\n",
            "9576: [D loss: 0.700999, acc: 0.494141]  [A loss: 0.768273, acc: 0.269531]\n",
            "9577: [D loss: 0.689412, acc: 0.546875]  [A loss: 0.761319, acc: 0.324219]\n",
            "9578: [D loss: 0.687595, acc: 0.541016]  [A loss: 0.835344, acc: 0.171875]\n",
            "9579: [D loss: 0.694521, acc: 0.515625]  [A loss: 0.763247, acc: 0.289062]\n",
            "9580: [D loss: 0.705400, acc: 0.515625]  [A loss: 0.836983, acc: 0.191406]\n",
            "9581: [D loss: 0.688522, acc: 0.564453]  [A loss: 0.775384, acc: 0.296875]\n",
            "9582: [D loss: 0.697733, acc: 0.523438]  [A loss: 0.931093, acc: 0.097656]\n",
            "9583: [D loss: 0.692859, acc: 0.539062]  [A loss: 0.730909, acc: 0.433594]\n",
            "9584: [D loss: 0.707653, acc: 0.517578]  [A loss: 0.902525, acc: 0.097656]\n",
            "9585: [D loss: 0.695562, acc: 0.529297]  [A loss: 0.686026, acc: 0.515625]\n",
            "9586: [D loss: 0.713823, acc: 0.507812]  [A loss: 0.840180, acc: 0.167969]\n",
            "9587: [D loss: 0.696118, acc: 0.517578]  [A loss: 0.691395, acc: 0.519531]\n",
            "9588: [D loss: 0.713297, acc: 0.500000]  [A loss: 0.906507, acc: 0.074219]\n",
            "9589: [D loss: 0.706242, acc: 0.490234]  [A loss: 0.695573, acc: 0.515625]\n",
            "9590: [D loss: 0.703566, acc: 0.529297]  [A loss: 0.842045, acc: 0.148438]\n",
            "9591: [D loss: 0.705058, acc: 0.505859]  [A loss: 0.738571, acc: 0.351562]\n",
            "9592: [D loss: 0.724466, acc: 0.460938]  [A loss: 0.878366, acc: 0.074219]\n",
            "9593: [D loss: 0.706407, acc: 0.490234]  [A loss: 0.739718, acc: 0.398438]\n",
            "9594: [D loss: 0.712895, acc: 0.501953]  [A loss: 0.861118, acc: 0.132812]\n",
            "9595: [D loss: 0.688507, acc: 0.525391]  [A loss: 0.798435, acc: 0.343750]\n",
            "9596: [D loss: 0.702180, acc: 0.511719]  [A loss: 0.926726, acc: 0.093750]\n",
            "9597: [D loss: 0.701043, acc: 0.501953]  [A loss: 0.690038, acc: 0.523438]\n",
            "9598: [D loss: 0.712336, acc: 0.527344]  [A loss: 0.936242, acc: 0.074219]\n",
            "9599: [D loss: 0.696197, acc: 0.513672]  [A loss: 0.700827, acc: 0.539062]\n",
            "9600: [D loss: 0.714908, acc: 0.509766]  [A loss: 0.962021, acc: 0.058594]\n",
            "9601: [D loss: 0.699071, acc: 0.531250]  [A loss: 0.675039, acc: 0.589844]\n",
            "9602: [D loss: 0.707884, acc: 0.519531]  [A loss: 0.852578, acc: 0.132812]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9603: [D loss: 0.688796, acc: 0.550781]  [A loss: 0.751907, acc: 0.324219]\n",
            "9604: [D loss: 0.696918, acc: 0.527344]  [A loss: 0.786611, acc: 0.269531]\n",
            "9605: [D loss: 0.697878, acc: 0.542969]  [A loss: 0.769635, acc: 0.281250]\n",
            "9606: [D loss: 0.705336, acc: 0.505859]  [A loss: 0.772863, acc: 0.281250]\n",
            "9607: [D loss: 0.698926, acc: 0.529297]  [A loss: 0.796153, acc: 0.250000]\n",
            "9608: [D loss: 0.700968, acc: 0.515625]  [A loss: 0.814296, acc: 0.203125]\n",
            "9609: [D loss: 0.696140, acc: 0.498047]  [A loss: 0.767572, acc: 0.328125]\n",
            "9610: [D loss: 0.698718, acc: 0.531250]  [A loss: 0.806369, acc: 0.199219]\n",
            "9611: [D loss: 0.698150, acc: 0.515625]  [A loss: 0.809467, acc: 0.195312]\n",
            "9612: [D loss: 0.693146, acc: 0.507812]  [A loss: 0.775653, acc: 0.285156]\n",
            "9613: [D loss: 0.697674, acc: 0.511719]  [A loss: 0.826290, acc: 0.175781]\n",
            "9614: [D loss: 0.693266, acc: 0.537109]  [A loss: 0.737303, acc: 0.386719]\n",
            "9615: [D loss: 0.706274, acc: 0.500000]  [A loss: 0.806549, acc: 0.214844]\n",
            "9616: [D loss: 0.702876, acc: 0.490234]  [A loss: 0.819325, acc: 0.218750]\n",
            "9617: [D loss: 0.710710, acc: 0.484375]  [A loss: 0.765052, acc: 0.273438]\n",
            "9618: [D loss: 0.703040, acc: 0.500000]  [A loss: 0.808661, acc: 0.257812]\n",
            "9619: [D loss: 0.699312, acc: 0.490234]  [A loss: 0.759278, acc: 0.359375]\n",
            "9620: [D loss: 0.699809, acc: 0.533203]  [A loss: 0.870728, acc: 0.117188]\n",
            "9621: [D loss: 0.696372, acc: 0.513672]  [A loss: 0.709085, acc: 0.492188]\n",
            "9622: [D loss: 0.707609, acc: 0.498047]  [A loss: 0.823516, acc: 0.203125]\n",
            "9623: [D loss: 0.692347, acc: 0.519531]  [A loss: 0.743659, acc: 0.355469]\n",
            "9624: [D loss: 0.699475, acc: 0.535156]  [A loss: 0.815050, acc: 0.191406]\n",
            "9625: [D loss: 0.697509, acc: 0.537109]  [A loss: 0.729712, acc: 0.433594]\n",
            "9626: [D loss: 0.715672, acc: 0.474609]  [A loss: 0.839434, acc: 0.191406]\n",
            "9627: [D loss: 0.693932, acc: 0.554688]  [A loss: 0.720937, acc: 0.441406]\n",
            "9628: [D loss: 0.703081, acc: 0.513672]  [A loss: 0.830599, acc: 0.183594]\n",
            "9629: [D loss: 0.697779, acc: 0.525391]  [A loss: 0.734300, acc: 0.449219]\n",
            "9630: [D loss: 0.710544, acc: 0.531250]  [A loss: 0.872646, acc: 0.105469]\n",
            "9631: [D loss: 0.702817, acc: 0.482422]  [A loss: 0.739548, acc: 0.382812]\n",
            "9632: [D loss: 0.708958, acc: 0.494141]  [A loss: 0.850642, acc: 0.171875]\n",
            "9633: [D loss: 0.692359, acc: 0.529297]  [A loss: 0.725079, acc: 0.417969]\n",
            "9634: [D loss: 0.702942, acc: 0.501953]  [A loss: 0.823725, acc: 0.175781]\n",
            "9635: [D loss: 0.693965, acc: 0.511719]  [A loss: 0.803573, acc: 0.207031]\n",
            "9636: [D loss: 0.700429, acc: 0.503906]  [A loss: 0.808574, acc: 0.285156]\n",
            "9637: [D loss: 0.696188, acc: 0.515625]  [A loss: 0.743901, acc: 0.417969]\n",
            "9638: [D loss: 0.704667, acc: 0.515625]  [A loss: 0.865059, acc: 0.175781]\n",
            "9639: [D loss: 0.706577, acc: 0.476562]  [A loss: 0.703243, acc: 0.496094]\n",
            "9640: [D loss: 0.711695, acc: 0.492188]  [A loss: 0.835883, acc: 0.175781]\n",
            "9641: [D loss: 0.700781, acc: 0.476562]  [A loss: 0.761847, acc: 0.320312]\n",
            "9642: [D loss: 0.691875, acc: 0.517578]  [A loss: 0.788032, acc: 0.261719]\n",
            "9643: [D loss: 0.704902, acc: 0.498047]  [A loss: 0.809180, acc: 0.210938]\n",
            "9644: [D loss: 0.697889, acc: 0.511719]  [A loss: 0.861300, acc: 0.152344]\n",
            "9645: [D loss: 0.690965, acc: 0.552734]  [A loss: 0.788019, acc: 0.250000]\n",
            "9646: [D loss: 0.708687, acc: 0.507812]  [A loss: 0.843502, acc: 0.160156]\n",
            "9647: [D loss: 0.706282, acc: 0.498047]  [A loss: 0.763929, acc: 0.335938]\n",
            "9648: [D loss: 0.701022, acc: 0.531250]  [A loss: 0.816080, acc: 0.222656]\n",
            "9649: [D loss: 0.697367, acc: 0.513672]  [A loss: 0.769016, acc: 0.292969]\n",
            "9650: [D loss: 0.692391, acc: 0.537109]  [A loss: 0.821912, acc: 0.207031]\n",
            "9651: [D loss: 0.686454, acc: 0.574219]  [A loss: 0.723958, acc: 0.425781]\n",
            "9652: [D loss: 0.701539, acc: 0.492188]  [A loss: 0.841781, acc: 0.187500]\n",
            "9653: [D loss: 0.697568, acc: 0.539062]  [A loss: 0.671741, acc: 0.550781]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9654: [D loss: 0.723448, acc: 0.476562]  [A loss: 0.911169, acc: 0.074219]\n",
            "9655: [D loss: 0.694347, acc: 0.501953]  [A loss: 0.697741, acc: 0.519531]\n",
            "9656: [D loss: 0.706512, acc: 0.486328]  [A loss: 0.845629, acc: 0.140625]\n",
            "9657: [D loss: 0.696635, acc: 0.539062]  [A loss: 0.734805, acc: 0.425781]\n",
            "9658: [D loss: 0.719588, acc: 0.484375]  [A loss: 0.816801, acc: 0.195312]\n",
            "9659: [D loss: 0.695055, acc: 0.529297]  [A loss: 0.725361, acc: 0.406250]\n",
            "9660: [D loss: 0.704929, acc: 0.517578]  [A loss: 0.856459, acc: 0.140625]\n",
            "9661: [D loss: 0.698507, acc: 0.492188]  [A loss: 0.727711, acc: 0.406250]\n",
            "9662: [D loss: 0.706314, acc: 0.507812]  [A loss: 0.789875, acc: 0.242188]\n",
            "9663: [D loss: 0.698197, acc: 0.503906]  [A loss: 0.740129, acc: 0.414062]\n",
            "9664: [D loss: 0.698652, acc: 0.511719]  [A loss: 0.928757, acc: 0.089844]\n",
            "9665: [D loss: 0.695934, acc: 0.523438]  [A loss: 0.730431, acc: 0.406250]\n",
            "9666: [D loss: 0.707522, acc: 0.505859]  [A loss: 0.888591, acc: 0.085938]\n",
            "9667: [D loss: 0.694032, acc: 0.523438]  [A loss: 0.692220, acc: 0.535156]\n",
            "9668: [D loss: 0.694781, acc: 0.527344]  [A loss: 0.838643, acc: 0.156250]\n",
            "9669: [D loss: 0.697507, acc: 0.511719]  [A loss: 0.728954, acc: 0.433594]\n",
            "9670: [D loss: 0.712522, acc: 0.490234]  [A loss: 0.820379, acc: 0.234375]\n",
            "9671: [D loss: 0.709427, acc: 0.486328]  [A loss: 0.753551, acc: 0.355469]\n",
            "9672: [D loss: 0.695593, acc: 0.511719]  [A loss: 0.793830, acc: 0.230469]\n",
            "9673: [D loss: 0.704739, acc: 0.501953]  [A loss: 0.811406, acc: 0.218750]\n",
            "9674: [D loss: 0.701099, acc: 0.501953]  [A loss: 0.805334, acc: 0.246094]\n",
            "9675: [D loss: 0.706427, acc: 0.505859]  [A loss: 0.787775, acc: 0.277344]\n",
            "9676: [D loss: 0.702428, acc: 0.500000]  [A loss: 0.782972, acc: 0.281250]\n",
            "9677: [D loss: 0.702626, acc: 0.492188]  [A loss: 0.781890, acc: 0.296875]\n",
            "9678: [D loss: 0.699388, acc: 0.515625]  [A loss: 0.805134, acc: 0.253906]\n",
            "9679: [D loss: 0.692130, acc: 0.535156]  [A loss: 0.813203, acc: 0.242188]\n",
            "9680: [D loss: 0.691568, acc: 0.505859]  [A loss: 0.753537, acc: 0.382812]\n",
            "9681: [D loss: 0.716027, acc: 0.480469]  [A loss: 0.836854, acc: 0.218750]\n",
            "9682: [D loss: 0.701182, acc: 0.494141]  [A loss: 0.833242, acc: 0.187500]\n",
            "9683: [D loss: 0.682489, acc: 0.560547]  [A loss: 0.718949, acc: 0.429688]\n",
            "9684: [D loss: 0.706439, acc: 0.515625]  [A loss: 0.849305, acc: 0.140625]\n",
            "9685: [D loss: 0.699523, acc: 0.507812]  [A loss: 0.696554, acc: 0.527344]\n",
            "9686: [D loss: 0.706912, acc: 0.513672]  [A loss: 0.866804, acc: 0.128906]\n",
            "9687: [D loss: 0.699580, acc: 0.496094]  [A loss: 0.697386, acc: 0.496094]\n",
            "9688: [D loss: 0.701160, acc: 0.515625]  [A loss: 0.880446, acc: 0.113281]\n",
            "9689: [D loss: 0.694656, acc: 0.515625]  [A loss: 0.689272, acc: 0.550781]\n",
            "9690: [D loss: 0.714321, acc: 0.478516]  [A loss: 0.831481, acc: 0.160156]\n",
            "9691: [D loss: 0.699649, acc: 0.507812]  [A loss: 0.744134, acc: 0.375000]\n",
            "9692: [D loss: 0.696400, acc: 0.539062]  [A loss: 0.836291, acc: 0.148438]\n",
            "9693: [D loss: 0.689501, acc: 0.556641]  [A loss: 0.773129, acc: 0.339844]\n",
            "9694: [D loss: 0.711870, acc: 0.464844]  [A loss: 0.820645, acc: 0.207031]\n",
            "9695: [D loss: 0.699330, acc: 0.503906]  [A loss: 0.739162, acc: 0.378906]\n",
            "9696: [D loss: 0.692368, acc: 0.537109]  [A loss: 0.844153, acc: 0.164062]\n",
            "9697: [D loss: 0.683635, acc: 0.566406]  [A loss: 0.718472, acc: 0.414062]\n",
            "9698: [D loss: 0.697195, acc: 0.523438]  [A loss: 0.813507, acc: 0.199219]\n",
            "9699: [D loss: 0.689587, acc: 0.562500]  [A loss: 0.739141, acc: 0.363281]\n",
            "9700: [D loss: 0.704450, acc: 0.509766]  [A loss: 0.888507, acc: 0.109375]\n",
            "9701: [D loss: 0.702043, acc: 0.476562]  [A loss: 0.762142, acc: 0.347656]\n",
            "9702: [D loss: 0.708355, acc: 0.517578]  [A loss: 0.869602, acc: 0.128906]\n",
            "9703: [D loss: 0.698950, acc: 0.525391]  [A loss: 0.740404, acc: 0.386719]\n",
            "9704: [D loss: 0.698852, acc: 0.529297]  [A loss: 0.880367, acc: 0.121094]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9705: [D loss: 0.695868, acc: 0.513672]  [A loss: 0.742805, acc: 0.375000]\n",
            "9706: [D loss: 0.701722, acc: 0.521484]  [A loss: 0.836566, acc: 0.207031]\n",
            "9707: [D loss: 0.704078, acc: 0.527344]  [A loss: 0.793344, acc: 0.242188]\n",
            "9708: [D loss: 0.701147, acc: 0.519531]  [A loss: 0.798768, acc: 0.253906]\n",
            "9709: [D loss: 0.700729, acc: 0.533203]  [A loss: 0.765385, acc: 0.292969]\n",
            "9710: [D loss: 0.702329, acc: 0.500000]  [A loss: 0.768945, acc: 0.335938]\n",
            "9711: [D loss: 0.706420, acc: 0.500000]  [A loss: 0.853031, acc: 0.105469]\n",
            "9712: [D loss: 0.701604, acc: 0.500000]  [A loss: 0.747856, acc: 0.371094]\n",
            "9713: [D loss: 0.712453, acc: 0.480469]  [A loss: 0.878345, acc: 0.117188]\n",
            "9714: [D loss: 0.696565, acc: 0.525391]  [A loss: 0.759950, acc: 0.363281]\n",
            "9715: [D loss: 0.707173, acc: 0.490234]  [A loss: 0.803945, acc: 0.222656]\n",
            "9716: [D loss: 0.690940, acc: 0.535156]  [A loss: 0.753954, acc: 0.351562]\n",
            "9717: [D loss: 0.699688, acc: 0.533203]  [A loss: 0.850606, acc: 0.152344]\n",
            "9718: [D loss: 0.691226, acc: 0.554688]  [A loss: 0.707075, acc: 0.519531]\n",
            "9719: [D loss: 0.711976, acc: 0.509766]  [A loss: 0.863696, acc: 0.167969]\n",
            "9720: [D loss: 0.694080, acc: 0.535156]  [A loss: 0.729680, acc: 0.394531]\n",
            "9721: [D loss: 0.704169, acc: 0.519531]  [A loss: 0.866477, acc: 0.128906]\n",
            "9722: [D loss: 0.697140, acc: 0.527344]  [A loss: 0.720662, acc: 0.410156]\n",
            "9723: [D loss: 0.711843, acc: 0.523438]  [A loss: 0.858280, acc: 0.183594]\n",
            "9724: [D loss: 0.692201, acc: 0.507812]  [A loss: 0.712698, acc: 0.460938]\n",
            "9725: [D loss: 0.697765, acc: 0.511719]  [A loss: 0.798861, acc: 0.222656]\n",
            "9726: [D loss: 0.702520, acc: 0.507812]  [A loss: 0.831140, acc: 0.187500]\n",
            "9727: [D loss: 0.698360, acc: 0.500000]  [A loss: 0.756011, acc: 0.316406]\n",
            "9728: [D loss: 0.699213, acc: 0.517578]  [A loss: 0.781210, acc: 0.253906]\n",
            "9729: [D loss: 0.695103, acc: 0.521484]  [A loss: 0.761044, acc: 0.316406]\n",
            "9730: [D loss: 0.685933, acc: 0.580078]  [A loss: 0.759452, acc: 0.332031]\n",
            "9731: [D loss: 0.706159, acc: 0.511719]  [A loss: 0.829421, acc: 0.164062]\n",
            "9732: [D loss: 0.696037, acc: 0.531250]  [A loss: 0.746449, acc: 0.359375]\n",
            "9733: [D loss: 0.702981, acc: 0.517578]  [A loss: 0.847190, acc: 0.148438]\n",
            "9734: [D loss: 0.685126, acc: 0.544922]  [A loss: 0.742709, acc: 0.359375]\n",
            "9735: [D loss: 0.713168, acc: 0.503906]  [A loss: 0.869280, acc: 0.140625]\n",
            "9736: [D loss: 0.681159, acc: 0.560547]  [A loss: 0.722353, acc: 0.406250]\n",
            "9737: [D loss: 0.708866, acc: 0.494141]  [A loss: 0.873455, acc: 0.140625]\n",
            "9738: [D loss: 0.697650, acc: 0.503906]  [A loss: 0.745734, acc: 0.394531]\n",
            "9739: [D loss: 0.708928, acc: 0.496094]  [A loss: 0.789578, acc: 0.261719]\n",
            "9740: [D loss: 0.698491, acc: 0.501953]  [A loss: 0.757023, acc: 0.347656]\n",
            "9741: [D loss: 0.715391, acc: 0.519531]  [A loss: 0.880480, acc: 0.156250]\n",
            "9742: [D loss: 0.698396, acc: 0.501953]  [A loss: 0.725170, acc: 0.453125]\n",
            "9743: [D loss: 0.702546, acc: 0.519531]  [A loss: 0.830624, acc: 0.187500]\n",
            "9744: [D loss: 0.694502, acc: 0.527344]  [A loss: 0.734203, acc: 0.402344]\n",
            "9745: [D loss: 0.706730, acc: 0.501953]  [A loss: 0.842317, acc: 0.140625]\n",
            "9746: [D loss: 0.695934, acc: 0.527344]  [A loss: 0.703220, acc: 0.492188]\n",
            "9747: [D loss: 0.714024, acc: 0.501953]  [A loss: 0.922497, acc: 0.058594]\n",
            "9748: [D loss: 0.696379, acc: 0.529297]  [A loss: 0.708532, acc: 0.476562]\n",
            "9749: [D loss: 0.707347, acc: 0.494141]  [A loss: 0.873612, acc: 0.179688]\n",
            "9750: [D loss: 0.699070, acc: 0.525391]  [A loss: 0.781628, acc: 0.253906]\n",
            "9751: [D loss: 0.687509, acc: 0.539062]  [A loss: 0.814569, acc: 0.218750]\n",
            "9752: [D loss: 0.688360, acc: 0.544922]  [A loss: 0.766481, acc: 0.308594]\n",
            "9753: [D loss: 0.702960, acc: 0.492188]  [A loss: 0.793272, acc: 0.304688]\n",
            "9754: [D loss: 0.706944, acc: 0.490234]  [A loss: 0.831329, acc: 0.167969]\n",
            "9755: [D loss: 0.689825, acc: 0.527344]  [A loss: 0.780939, acc: 0.285156]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9756: [D loss: 0.706481, acc: 0.507812]  [A loss: 0.854364, acc: 0.125000]\n",
            "9757: [D loss: 0.701748, acc: 0.498047]  [A loss: 0.765091, acc: 0.351562]\n",
            "9758: [D loss: 0.701044, acc: 0.515625]  [A loss: 0.808006, acc: 0.222656]\n",
            "9759: [D loss: 0.693956, acc: 0.527344]  [A loss: 0.780437, acc: 0.281250]\n",
            "9760: [D loss: 0.694334, acc: 0.544922]  [A loss: 0.759156, acc: 0.316406]\n",
            "9761: [D loss: 0.688397, acc: 0.535156]  [A loss: 0.836838, acc: 0.164062]\n",
            "9762: [D loss: 0.692128, acc: 0.515625]  [A loss: 0.720890, acc: 0.421875]\n",
            "9763: [D loss: 0.694541, acc: 0.531250]  [A loss: 0.816033, acc: 0.214844]\n",
            "9764: [D loss: 0.689637, acc: 0.529297]  [A loss: 0.790959, acc: 0.234375]\n",
            "9765: [D loss: 0.703741, acc: 0.507812]  [A loss: 0.774312, acc: 0.308594]\n",
            "9766: [D loss: 0.712240, acc: 0.492188]  [A loss: 0.850155, acc: 0.148438]\n",
            "9767: [D loss: 0.709823, acc: 0.472656]  [A loss: 0.828113, acc: 0.183594]\n",
            "9768: [D loss: 0.705296, acc: 0.480469]  [A loss: 0.749447, acc: 0.351562]\n",
            "9769: [D loss: 0.714817, acc: 0.476562]  [A loss: 0.922533, acc: 0.082031]\n",
            "9770: [D loss: 0.700937, acc: 0.523438]  [A loss: 0.657598, acc: 0.613281]\n",
            "9771: [D loss: 0.732421, acc: 0.486328]  [A loss: 0.892412, acc: 0.097656]\n",
            "9772: [D loss: 0.704311, acc: 0.505859]  [A loss: 0.677946, acc: 0.593750]\n",
            "9773: [D loss: 0.712358, acc: 0.494141]  [A loss: 0.839986, acc: 0.167969]\n",
            "9774: [D loss: 0.709975, acc: 0.480469]  [A loss: 0.739838, acc: 0.398438]\n",
            "9775: [D loss: 0.701045, acc: 0.511719]  [A loss: 0.785602, acc: 0.234375]\n",
            "9776: [D loss: 0.698059, acc: 0.523438]  [A loss: 0.741700, acc: 0.355469]\n",
            "9777: [D loss: 0.697759, acc: 0.552734]  [A loss: 0.794994, acc: 0.242188]\n",
            "9778: [D loss: 0.707364, acc: 0.486328]  [A loss: 0.757858, acc: 0.359375]\n",
            "9779: [D loss: 0.705228, acc: 0.505859]  [A loss: 0.845843, acc: 0.214844]\n",
            "9780: [D loss: 0.700878, acc: 0.507812]  [A loss: 0.762139, acc: 0.324219]\n",
            "9781: [D loss: 0.701019, acc: 0.539062]  [A loss: 0.921775, acc: 0.078125]\n",
            "9782: [D loss: 0.688072, acc: 0.541016]  [A loss: 0.698564, acc: 0.492188]\n",
            "9783: [D loss: 0.714000, acc: 0.523438]  [A loss: 0.883548, acc: 0.125000]\n",
            "9784: [D loss: 0.697617, acc: 0.509766]  [A loss: 0.700786, acc: 0.515625]\n",
            "9785: [D loss: 0.705090, acc: 0.517578]  [A loss: 0.858055, acc: 0.140625]\n",
            "9786: [D loss: 0.697473, acc: 0.539062]  [A loss: 0.685911, acc: 0.519531]\n",
            "9787: [D loss: 0.726266, acc: 0.500000]  [A loss: 0.905713, acc: 0.093750]\n",
            "9788: [D loss: 0.702231, acc: 0.503906]  [A loss: 0.723528, acc: 0.500000]\n",
            "9789: [D loss: 0.707791, acc: 0.511719]  [A loss: 0.787050, acc: 0.273438]\n",
            "9790: [D loss: 0.696151, acc: 0.501953]  [A loss: 0.733318, acc: 0.402344]\n",
            "9791: [D loss: 0.713510, acc: 0.484375]  [A loss: 0.775339, acc: 0.269531]\n",
            "9792: [D loss: 0.696002, acc: 0.544922]  [A loss: 0.831657, acc: 0.164062]\n",
            "9793: [D loss: 0.697962, acc: 0.500000]  [A loss: 0.734784, acc: 0.414062]\n",
            "9794: [D loss: 0.709919, acc: 0.482422]  [A loss: 0.787684, acc: 0.265625]\n",
            "9795: [D loss: 0.692076, acc: 0.544922]  [A loss: 0.716472, acc: 0.429688]\n",
            "9796: [D loss: 0.699572, acc: 0.513672]  [A loss: 0.800137, acc: 0.242188]\n",
            "9797: [D loss: 0.700652, acc: 0.494141]  [A loss: 0.810720, acc: 0.210938]\n",
            "9798: [D loss: 0.698117, acc: 0.519531]  [A loss: 0.797514, acc: 0.250000]\n",
            "9799: [D loss: 0.690250, acc: 0.529297]  [A loss: 0.772723, acc: 0.300781]\n",
            "9800: [D loss: 0.705754, acc: 0.505859]  [A loss: 0.795892, acc: 0.292969]\n",
            "9801: [D loss: 0.697266, acc: 0.498047]  [A loss: 0.824613, acc: 0.179688]\n",
            "9802: [D loss: 0.693755, acc: 0.539062]  [A loss: 0.730365, acc: 0.410156]\n",
            "9803: [D loss: 0.706166, acc: 0.503906]  [A loss: 0.868938, acc: 0.160156]\n",
            "9804: [D loss: 0.703608, acc: 0.509766]  [A loss: 0.739481, acc: 0.363281]\n",
            "9805: [D loss: 0.710042, acc: 0.507812]  [A loss: 0.808116, acc: 0.230469]\n",
            "9806: [D loss: 0.690975, acc: 0.546875]  [A loss: 0.753101, acc: 0.347656]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9807: [D loss: 0.708740, acc: 0.490234]  [A loss: 0.807207, acc: 0.214844]\n",
            "9808: [D loss: 0.694003, acc: 0.525391]  [A loss: 0.733067, acc: 0.390625]\n",
            "9809: [D loss: 0.702590, acc: 0.513672]  [A loss: 0.815308, acc: 0.218750]\n",
            "9810: [D loss: 0.704323, acc: 0.488281]  [A loss: 0.719453, acc: 0.433594]\n",
            "9811: [D loss: 0.700013, acc: 0.527344]  [A loss: 0.810889, acc: 0.203125]\n",
            "9812: [D loss: 0.700764, acc: 0.498047]  [A loss: 0.737265, acc: 0.402344]\n",
            "9813: [D loss: 0.703874, acc: 0.492188]  [A loss: 0.856596, acc: 0.125000]\n",
            "9814: [D loss: 0.695760, acc: 0.519531]  [A loss: 0.719553, acc: 0.445312]\n",
            "9815: [D loss: 0.710020, acc: 0.507812]  [A loss: 0.889048, acc: 0.085938]\n",
            "9816: [D loss: 0.701714, acc: 0.498047]  [A loss: 0.679813, acc: 0.523438]\n",
            "9817: [D loss: 0.711585, acc: 0.523438]  [A loss: 0.903646, acc: 0.097656]\n",
            "9818: [D loss: 0.701680, acc: 0.496094]  [A loss: 0.737972, acc: 0.386719]\n",
            "9819: [D loss: 0.717893, acc: 0.494141]  [A loss: 0.827538, acc: 0.214844]\n",
            "9820: [D loss: 0.695384, acc: 0.533203]  [A loss: 0.777341, acc: 0.386719]\n",
            "9821: [D loss: 0.695850, acc: 0.521484]  [A loss: 0.916524, acc: 0.070312]\n",
            "9822: [D loss: 0.694378, acc: 0.521484]  [A loss: 0.730349, acc: 0.390625]\n",
            "9823: [D loss: 0.713105, acc: 0.505859]  [A loss: 0.832115, acc: 0.183594]\n",
            "9824: [D loss: 0.692759, acc: 0.535156]  [A loss: 0.736343, acc: 0.390625]\n",
            "9825: [D loss: 0.694041, acc: 0.542969]  [A loss: 0.821730, acc: 0.175781]\n",
            "9826: [D loss: 0.701909, acc: 0.507812]  [A loss: 0.777487, acc: 0.308594]\n",
            "9827: [D loss: 0.707540, acc: 0.492188]  [A loss: 0.752405, acc: 0.347656]\n",
            "9828: [D loss: 0.689579, acc: 0.544922]  [A loss: 0.790622, acc: 0.265625]\n",
            "9829: [D loss: 0.699911, acc: 0.521484]  [A loss: 0.760838, acc: 0.308594]\n",
            "9830: [D loss: 0.690691, acc: 0.558594]  [A loss: 0.776867, acc: 0.289062]\n",
            "9831: [D loss: 0.701138, acc: 0.513672]  [A loss: 0.778165, acc: 0.312500]\n",
            "9832: [D loss: 0.704371, acc: 0.496094]  [A loss: 0.766462, acc: 0.324219]\n",
            "9833: [D loss: 0.703299, acc: 0.519531]  [A loss: 0.840148, acc: 0.179688]\n",
            "9834: [D loss: 0.693379, acc: 0.542969]  [A loss: 0.786698, acc: 0.273438]\n",
            "9835: [D loss: 0.704211, acc: 0.501953]  [A loss: 0.829935, acc: 0.203125]\n",
            "9836: [D loss: 0.698925, acc: 0.527344]  [A loss: 0.786242, acc: 0.246094]\n",
            "9837: [D loss: 0.693286, acc: 0.542969]  [A loss: 0.828586, acc: 0.187500]\n",
            "9838: [D loss: 0.697589, acc: 0.503906]  [A loss: 0.770025, acc: 0.277344]\n",
            "9839: [D loss: 0.705937, acc: 0.486328]  [A loss: 0.796289, acc: 0.261719]\n",
            "9840: [D loss: 0.705542, acc: 0.484375]  [A loss: 0.744557, acc: 0.378906]\n",
            "9841: [D loss: 0.709954, acc: 0.511719]  [A loss: 0.884377, acc: 0.121094]\n",
            "9842: [D loss: 0.693091, acc: 0.523438]  [A loss: 0.739395, acc: 0.425781]\n",
            "9843: [D loss: 0.701009, acc: 0.521484]  [A loss: 0.909160, acc: 0.101562]\n",
            "9844: [D loss: 0.707810, acc: 0.472656]  [A loss: 0.758370, acc: 0.359375]\n",
            "9845: [D loss: 0.705904, acc: 0.527344]  [A loss: 0.892155, acc: 0.074219]\n",
            "9846: [D loss: 0.700139, acc: 0.515625]  [A loss: 0.721941, acc: 0.433594]\n",
            "9847: [D loss: 0.699779, acc: 0.529297]  [A loss: 0.878302, acc: 0.148438]\n",
            "9848: [D loss: 0.696898, acc: 0.521484]  [A loss: 0.732443, acc: 0.433594]\n",
            "9849: [D loss: 0.711157, acc: 0.496094]  [A loss: 0.866344, acc: 0.148438]\n",
            "9850: [D loss: 0.693521, acc: 0.531250]  [A loss: 0.692163, acc: 0.531250]\n",
            "9851: [D loss: 0.703201, acc: 0.529297]  [A loss: 0.879399, acc: 0.121094]\n",
            "9852: [D loss: 0.709465, acc: 0.507812]  [A loss: 0.737902, acc: 0.382812]\n",
            "9853: [D loss: 0.697398, acc: 0.523438]  [A loss: 0.777449, acc: 0.257812]\n",
            "9854: [D loss: 0.701238, acc: 0.517578]  [A loss: 0.777148, acc: 0.339844]\n",
            "9855: [D loss: 0.688559, acc: 0.550781]  [A loss: 0.754452, acc: 0.328125]\n",
            "9856: [D loss: 0.708545, acc: 0.488281]  [A loss: 0.859931, acc: 0.140625]\n",
            "9857: [D loss: 0.693227, acc: 0.527344]  [A loss: 0.746789, acc: 0.367188]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9858: [D loss: 0.696713, acc: 0.513672]  [A loss: 0.806897, acc: 0.261719]\n",
            "9859: [D loss: 0.695208, acc: 0.513672]  [A loss: 0.786985, acc: 0.277344]\n",
            "9860: [D loss: 0.694117, acc: 0.507812]  [A loss: 0.742563, acc: 0.351562]\n",
            "9861: [D loss: 0.713113, acc: 0.478516]  [A loss: 0.827864, acc: 0.183594]\n",
            "9862: [D loss: 0.696503, acc: 0.500000]  [A loss: 0.706215, acc: 0.507812]\n",
            "9863: [D loss: 0.720194, acc: 0.501953]  [A loss: 0.894537, acc: 0.113281]\n",
            "9864: [D loss: 0.697049, acc: 0.533203]  [A loss: 0.694472, acc: 0.496094]\n",
            "9865: [D loss: 0.705898, acc: 0.492188]  [A loss: 0.803794, acc: 0.207031]\n",
            "9866: [D loss: 0.693937, acc: 0.523438]  [A loss: 0.739368, acc: 0.406250]\n",
            "9867: [D loss: 0.702806, acc: 0.517578]  [A loss: 0.819929, acc: 0.207031]\n",
            "9868: [D loss: 0.710670, acc: 0.505859]  [A loss: 0.786440, acc: 0.304688]\n",
            "9869: [D loss: 0.697572, acc: 0.533203]  [A loss: 0.770588, acc: 0.277344]\n",
            "9870: [D loss: 0.696883, acc: 0.525391]  [A loss: 0.756892, acc: 0.351562]\n",
            "9871: [D loss: 0.704173, acc: 0.501953]  [A loss: 0.800307, acc: 0.242188]\n",
            "9872: [D loss: 0.696268, acc: 0.523438]  [A loss: 0.769110, acc: 0.312500]\n",
            "9873: [D loss: 0.696400, acc: 0.531250]  [A loss: 0.777217, acc: 0.285156]\n",
            "9874: [D loss: 0.702760, acc: 0.488281]  [A loss: 0.767064, acc: 0.343750]\n",
            "9875: [D loss: 0.704899, acc: 0.519531]  [A loss: 0.795240, acc: 0.289062]\n",
            "9876: [D loss: 0.697268, acc: 0.519531]  [A loss: 0.801738, acc: 0.242188]\n",
            "9877: [D loss: 0.705889, acc: 0.513672]  [A loss: 0.781689, acc: 0.300781]\n",
            "9878: [D loss: 0.694633, acc: 0.523438]  [A loss: 0.780378, acc: 0.292969]\n",
            "9879: [D loss: 0.695943, acc: 0.521484]  [A loss: 0.798823, acc: 0.277344]\n",
            "9880: [D loss: 0.696546, acc: 0.527344]  [A loss: 0.807616, acc: 0.261719]\n",
            "9881: [D loss: 0.696240, acc: 0.511719]  [A loss: 0.761322, acc: 0.335938]\n",
            "9882: [D loss: 0.702200, acc: 0.529297]  [A loss: 0.856821, acc: 0.128906]\n",
            "9883: [D loss: 0.691006, acc: 0.537109]  [A loss: 0.732142, acc: 0.398438]\n",
            "9884: [D loss: 0.705076, acc: 0.507812]  [A loss: 0.825176, acc: 0.195312]\n",
            "9885: [D loss: 0.703805, acc: 0.496094]  [A loss: 0.781749, acc: 0.320312]\n",
            "9886: [D loss: 0.701278, acc: 0.498047]  [A loss: 0.827479, acc: 0.160156]\n",
            "9887: [D loss: 0.706973, acc: 0.488281]  [A loss: 0.806547, acc: 0.265625]\n",
            "9888: [D loss: 0.695548, acc: 0.521484]  [A loss: 0.790697, acc: 0.296875]\n",
            "9889: [D loss: 0.686440, acc: 0.562500]  [A loss: 0.746414, acc: 0.371094]\n",
            "9890: [D loss: 0.706858, acc: 0.503906]  [A loss: 0.968015, acc: 0.058594]\n",
            "9891: [D loss: 0.705023, acc: 0.501953]  [A loss: 0.701722, acc: 0.500000]\n",
            "9892: [D loss: 0.717795, acc: 0.490234]  [A loss: 0.875480, acc: 0.109375]\n",
            "9893: [D loss: 0.701474, acc: 0.494141]  [A loss: 0.825238, acc: 0.160156]\n",
            "9894: [D loss: 0.696399, acc: 0.535156]  [A loss: 0.818461, acc: 0.195312]\n",
            "9895: [D loss: 0.705072, acc: 0.462891]  [A loss: 0.818081, acc: 0.234375]\n",
            "9896: [D loss: 0.695602, acc: 0.490234]  [A loss: 0.769142, acc: 0.285156]\n",
            "9897: [D loss: 0.697045, acc: 0.527344]  [A loss: 0.861549, acc: 0.148438]\n",
            "9898: [D loss: 0.699413, acc: 0.507812]  [A loss: 0.705055, acc: 0.511719]\n",
            "9899: [D loss: 0.712127, acc: 0.494141]  [A loss: 0.904347, acc: 0.101562]\n",
            "9900: [D loss: 0.692951, acc: 0.525391]  [A loss: 0.700108, acc: 0.523438]\n",
            "9901: [D loss: 0.722924, acc: 0.482422]  [A loss: 0.939636, acc: 0.062500]\n",
            "9902: [D loss: 0.699052, acc: 0.523438]  [A loss: 0.707255, acc: 0.492188]\n",
            "9903: [D loss: 0.708510, acc: 0.503906]  [A loss: 0.828219, acc: 0.187500]\n",
            "9904: [D loss: 0.703879, acc: 0.486328]  [A loss: 0.736432, acc: 0.363281]\n",
            "9905: [D loss: 0.701326, acc: 0.505859]  [A loss: 0.784087, acc: 0.292969]\n",
            "9906: [D loss: 0.703521, acc: 0.501953]  [A loss: 0.784901, acc: 0.285156]\n",
            "9907: [D loss: 0.709921, acc: 0.507812]  [A loss: 0.763790, acc: 0.320312]\n",
            "9908: [D loss: 0.708571, acc: 0.458984]  [A loss: 0.808051, acc: 0.246094]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9909: [D loss: 0.700087, acc: 0.523438]  [A loss: 0.783294, acc: 0.296875]\n",
            "9910: [D loss: 0.708348, acc: 0.482422]  [A loss: 0.747680, acc: 0.394531]\n",
            "9911: [D loss: 0.688032, acc: 0.556641]  [A loss: 0.791053, acc: 0.289062]\n",
            "9912: [D loss: 0.706446, acc: 0.507812]  [A loss: 0.797934, acc: 0.265625]\n",
            "9913: [D loss: 0.698526, acc: 0.500000]  [A loss: 0.739611, acc: 0.386719]\n",
            "9914: [D loss: 0.715325, acc: 0.494141]  [A loss: 0.889208, acc: 0.109375]\n",
            "9915: [D loss: 0.695981, acc: 0.539062]  [A loss: 0.719783, acc: 0.429688]\n",
            "9916: [D loss: 0.703640, acc: 0.513672]  [A loss: 0.868421, acc: 0.136719]\n",
            "9917: [D loss: 0.705067, acc: 0.505859]  [A loss: 0.725966, acc: 0.449219]\n",
            "9918: [D loss: 0.704536, acc: 0.507812]  [A loss: 0.831588, acc: 0.167969]\n",
            "9919: [D loss: 0.693707, acc: 0.521484]  [A loss: 0.715610, acc: 0.460938]\n",
            "9920: [D loss: 0.696744, acc: 0.525391]  [A loss: 0.805871, acc: 0.242188]\n",
            "9921: [D loss: 0.697904, acc: 0.521484]  [A loss: 0.726808, acc: 0.445312]\n",
            "9922: [D loss: 0.718906, acc: 0.474609]  [A loss: 0.845946, acc: 0.171875]\n",
            "9923: [D loss: 0.698023, acc: 0.515625]  [A loss: 0.729107, acc: 0.414062]\n",
            "9924: [D loss: 0.701814, acc: 0.546875]  [A loss: 0.848172, acc: 0.156250]\n",
            "9925: [D loss: 0.695243, acc: 0.521484]  [A loss: 0.682397, acc: 0.574219]\n",
            "9926: [D loss: 0.727176, acc: 0.507812]  [A loss: 0.919477, acc: 0.070312]\n",
            "9927: [D loss: 0.706183, acc: 0.490234]  [A loss: 0.702373, acc: 0.496094]\n",
            "9928: [D loss: 0.709549, acc: 0.523438]  [A loss: 0.802543, acc: 0.226562]\n",
            "9929: [D loss: 0.691162, acc: 0.521484]  [A loss: 0.743910, acc: 0.367188]\n",
            "9930: [D loss: 0.714806, acc: 0.486328]  [A loss: 0.803068, acc: 0.261719]\n",
            "9931: [D loss: 0.701364, acc: 0.482422]  [A loss: 0.796381, acc: 0.253906]\n",
            "9932: [D loss: 0.690242, acc: 0.535156]  [A loss: 0.809782, acc: 0.238281]\n",
            "9933: [D loss: 0.696641, acc: 0.519531]  [A loss: 0.757940, acc: 0.378906]\n",
            "9934: [D loss: 0.702561, acc: 0.515625]  [A loss: 0.925102, acc: 0.078125]\n",
            "9935: [D loss: 0.694790, acc: 0.523438]  [A loss: 0.671851, acc: 0.562500]\n",
            "9936: [D loss: 0.703184, acc: 0.521484]  [A loss: 0.823949, acc: 0.191406]\n",
            "9937: [D loss: 0.695657, acc: 0.525391]  [A loss: 0.729498, acc: 0.441406]\n",
            "9938: [D loss: 0.703849, acc: 0.531250]  [A loss: 0.792051, acc: 0.269531]\n",
            "9939: [D loss: 0.700407, acc: 0.535156]  [A loss: 0.765610, acc: 0.320312]\n",
            "9940: [D loss: 0.693770, acc: 0.556641]  [A loss: 0.848071, acc: 0.179688]\n",
            "9941: [D loss: 0.696696, acc: 0.529297]  [A loss: 0.768320, acc: 0.312500]\n",
            "9942: [D loss: 0.718129, acc: 0.480469]  [A loss: 0.879774, acc: 0.132812]\n",
            "9943: [D loss: 0.692026, acc: 0.523438]  [A loss: 0.709759, acc: 0.445312]\n",
            "9944: [D loss: 0.699530, acc: 0.515625]  [A loss: 0.824817, acc: 0.199219]\n",
            "9945: [D loss: 0.692290, acc: 0.507812]  [A loss: 0.721911, acc: 0.410156]\n",
            "9946: [D loss: 0.707589, acc: 0.501953]  [A loss: 0.891798, acc: 0.113281]\n",
            "9947: [D loss: 0.701699, acc: 0.523438]  [A loss: 0.670140, acc: 0.558594]\n",
            "9948: [D loss: 0.705426, acc: 0.521484]  [A loss: 0.861690, acc: 0.128906]\n",
            "9949: [D loss: 0.703528, acc: 0.474609]  [A loss: 0.703814, acc: 0.503906]\n",
            "9950: [D loss: 0.707067, acc: 0.529297]  [A loss: 0.843527, acc: 0.183594]\n",
            "9951: [D loss: 0.704092, acc: 0.482422]  [A loss: 0.715813, acc: 0.468750]\n",
            "9952: [D loss: 0.701771, acc: 0.511719]  [A loss: 0.874840, acc: 0.132812]\n",
            "9953: [D loss: 0.697594, acc: 0.529297]  [A loss: 0.721296, acc: 0.417969]\n",
            "9954: [D loss: 0.695597, acc: 0.523438]  [A loss: 0.845775, acc: 0.156250]\n",
            "9955: [D loss: 0.700364, acc: 0.541016]  [A loss: 0.750477, acc: 0.324219]\n",
            "9956: [D loss: 0.694676, acc: 0.501953]  [A loss: 0.791328, acc: 0.226562]\n",
            "9957: [D loss: 0.687725, acc: 0.535156]  [A loss: 0.798653, acc: 0.250000]\n",
            "9958: [D loss: 0.699924, acc: 0.517578]  [A loss: 0.830358, acc: 0.195312]\n",
            "9959: [D loss: 0.703285, acc: 0.496094]  [A loss: 0.739468, acc: 0.457031]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9960: [D loss: 0.710596, acc: 0.496094]  [A loss: 0.818573, acc: 0.214844]\n",
            "9961: [D loss: 0.689844, acc: 0.558594]  [A loss: 0.735124, acc: 0.382812]\n",
            "9962: [D loss: 0.698465, acc: 0.537109]  [A loss: 0.801343, acc: 0.242188]\n",
            "9963: [D loss: 0.698175, acc: 0.527344]  [A loss: 0.762920, acc: 0.355469]\n",
            "9964: [D loss: 0.711572, acc: 0.480469]  [A loss: 0.774184, acc: 0.328125]\n",
            "9965: [D loss: 0.705690, acc: 0.509766]  [A loss: 0.822562, acc: 0.144531]\n",
            "9966: [D loss: 0.697852, acc: 0.498047]  [A loss: 0.771473, acc: 0.335938]\n",
            "9967: [D loss: 0.696499, acc: 0.537109]  [A loss: 0.807584, acc: 0.207031]\n",
            "9968: [D loss: 0.694130, acc: 0.523438]  [A loss: 0.755382, acc: 0.320312]\n",
            "9969: [D loss: 0.709859, acc: 0.500000]  [A loss: 0.867538, acc: 0.140625]\n",
            "9970: [D loss: 0.694523, acc: 0.554688]  [A loss: 0.740314, acc: 0.398438]\n",
            "9971: [D loss: 0.716128, acc: 0.490234]  [A loss: 0.903026, acc: 0.105469]\n",
            "9972: [D loss: 0.697815, acc: 0.523438]  [A loss: 0.663660, acc: 0.601562]\n",
            "9973: [D loss: 0.727536, acc: 0.484375]  [A loss: 0.938250, acc: 0.050781]\n",
            "9974: [D loss: 0.703230, acc: 0.501953]  [A loss: 0.691938, acc: 0.500000]\n",
            "9975: [D loss: 0.720219, acc: 0.500000]  [A loss: 0.874734, acc: 0.117188]\n",
            "9976: [D loss: 0.701509, acc: 0.496094]  [A loss: 0.745678, acc: 0.363281]\n",
            "9977: [D loss: 0.705052, acc: 0.515625]  [A loss: 0.852844, acc: 0.167969]\n",
            "9978: [D loss: 0.697076, acc: 0.503906]  [A loss: 0.721709, acc: 0.425781]\n",
            "9979: [D loss: 0.712779, acc: 0.476562]  [A loss: 0.804883, acc: 0.222656]\n",
            "9980: [D loss: 0.697280, acc: 0.519531]  [A loss: 0.755780, acc: 0.359375]\n",
            "9981: [D loss: 0.709272, acc: 0.480469]  [A loss: 0.860065, acc: 0.152344]\n",
            "9982: [D loss: 0.700856, acc: 0.509766]  [A loss: 0.758729, acc: 0.378906]\n",
            "9983: [D loss: 0.710923, acc: 0.507812]  [A loss: 0.821893, acc: 0.175781]\n",
            "9984: [D loss: 0.705563, acc: 0.517578]  [A loss: 0.793008, acc: 0.273438]\n",
            "9985: [D loss: 0.690797, acc: 0.527344]  [A loss: 0.773055, acc: 0.257812]\n",
            "9986: [D loss: 0.702765, acc: 0.500000]  [A loss: 0.800938, acc: 0.277344]\n",
            "9987: [D loss: 0.694622, acc: 0.517578]  [A loss: 0.770541, acc: 0.312500]\n",
            "9988: [D loss: 0.704402, acc: 0.531250]  [A loss: 0.797669, acc: 0.214844]\n",
            "9989: [D loss: 0.711634, acc: 0.490234]  [A loss: 0.827587, acc: 0.203125]\n",
            "9990: [D loss: 0.689130, acc: 0.533203]  [A loss: 0.753121, acc: 0.359375]\n",
            "9991: [D loss: 0.713686, acc: 0.468750]  [A loss: 0.835948, acc: 0.179688]\n",
            "9992: [D loss: 0.693337, acc: 0.539062]  [A loss: 0.750388, acc: 0.339844]\n",
            "9993: [D loss: 0.710013, acc: 0.494141]  [A loss: 0.792174, acc: 0.269531]\n",
            "9994: [D loss: 0.695300, acc: 0.513672]  [A loss: 0.832699, acc: 0.156250]\n",
            "9995: [D loss: 0.693976, acc: 0.517578]  [A loss: 0.725027, acc: 0.406250]\n",
            "9996: [D loss: 0.712741, acc: 0.470703]  [A loss: 0.864747, acc: 0.136719]\n",
            "9997: [D loss: 0.702209, acc: 0.492188]  [A loss: 0.732005, acc: 0.375000]\n",
            "9998: [D loss: 0.708509, acc: 0.500000]  [A loss: 0.821805, acc: 0.195312]\n",
            "9999: [D loss: 0.689077, acc: 0.527344]  [A loss: 0.706511, acc: 0.417969]\n",
            "Elapsed: 1.725600201818678 hr \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAALECAYAAAACS1bEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBkVRuw+FMJsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe85c8aaeb8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}